images are considered to be the gold standard in the diagnosis of many diseases _cite_ . In many situations, the cellular components are an important determinant. For example, in the biopsy sections of bone marrow, the abnormal cellular constitution indicates the presence of blood disease _cite_ . Bone marrow is the key component of both the hematopoietic system and the lymphatic system by producing large amounts of blood cells. The cell lines undergoing maturation in the marrow mostly include myeloid cells (granulocytes, monocytes, megakaryocytes, and their precursors), erythroid cells (normoblasts), and lymphoid cells (lymphocytes and their precursors) . Figure~ _ref_ are examples of five main cellular components in bone marrow. These components are significant to both the systemic circulation and the immune system. Several kinds of cancer are characterized by the cellular constitution in bone marrow _cite_ . For instance, too many granulocytes precursors such as myeloblasts indicate the presence of chronic myeloid leukemia. Having large, abnormal lymphocytes heralds the presence of lymphoma. Figure~ _ref_ shows the difference between normal and abnormal bone marrow histopathology images from the perspective of cells. As described above, cell-level information is irreplaceable for histopathology image analysis. Cell-level visual attributes such as the morphological features of nuclei and the openness of chromatin are helpful for various tasks such as cell-level classification and nuclei segmentation. We define cell-level images as the output from nuclei segmentation. Each cell-level image contains only one cell. We opt to perform representation learning on these cell-level images, in which the visual attributes such as the nuclei morphology and chromatin openness are distinguished. The learned features are further utilized to assist tasks such as cell counting to highlight the quantification of certain types of cells. To achieve this, the main obstacle is the labeling of cells. There are massive amounts of cells in each histopathology image, which makes manual labeling ambiguous and laborious. Therefore, an unsupervised cell-level visual representation learning method based on unlabeled data is believed to be more reasonable than fully supervised methods. Unsupervised cell-level visual representation learning is known to be difficult. First, geometrical and morphological appearances of cells from the same category can have a distinct diversity due to factors such as cell cycles. Furthermore, the staining conditions of histopathology images can be pretty diverse, resulting in inconsistent color characteristics of nuclei and cytoplasm. Recently, deep learning has been proven to be powerful in histopathology image analysis such as classification _cite_, segmentation _cite_, and detection _cite_ . Generative Adversarial Networks (GANs) _cite_ are a class of generative models that use unlabeled data to perform representation learning. GAN is capable of transforming noise variables into visually appealing image samples by learning a model distribution that imitates the real data distribution. Several GAN architectures such as Deep Convolutional Generative Adversarial Nets (DCGAN) _cite_ have proven their advantages in various natural images datasets. Recently, Wasserstein-GAN (WGAN) _cite_ and WGAN with gradient penalty (WGAN-GP) _cite_ have greatly improved the stability of training GAN. More complex network structures such as residual networks _cite_ can now be fused into GAN models. Meanwhile, Information Maximizing Generative Adversarial Networks (InfoGAN) _cite_ makes a modification that encourages GAN to learn interpretable and meaningful representations. InfoGAN maximizes the mutual information between the chosen random variables and the observations to make variables represent interpretable semantic features. The problem is that InfoGAN utilizes a DCGAN architecture, which requires meticulous attention towards hyperparameters. For our problem, it suffers a severe convergence problem. Inspired by WGAN-GP and InfoGAN, we present an unsupervised representation learning method for cell-level images using a unified GAN architecture with a new formulation of loss, which inherits the superiority from both WGAN-GP and InfoGAN. We observe great improvements followed by the setting of WGAN-GP. Introducing mutual information into our formulation, we are capable of learning interpretable and disentangled cell-level visual representations, as well as allocate cells into different categories according to their most significant semantic features. Our method achieves promising results in the unsupervised classification of bone marrow cellular components. Based on the cell-level visual representations, the quantification of each cellular component can be obtained by the trained model. Followed by this, cell proportions for each histopathology image can then be calculated to assist image-level classification. We further develop a pipeline combining cell-level unsupervised classification and nuclei segmentation to conduct image-level classification of histopathology images, which shows its advantages via experimentations on bone marrow datasets. The contributions of this work include the following: (N) We present an unsupervised framework to perform cell-level visual representation learning using generative adversarial networks. (N) A unified GAN architecture with a new formulation of loss is proposed to generate representations that are both high-quality and interpretable, which also endows our model the capability of cell-level unsupervised classification. (N) A pipeline is developed that exploits the varieties of cell-level elements to perform image-level classification of histopathology images.