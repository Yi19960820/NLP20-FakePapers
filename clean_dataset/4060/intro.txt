deep convolutional neural networks (DCNN) have been extensively used for a wide range of visual perception tasks, such as object detection/classification, action/activity recognition, etc. Behind the remarkable success of DCNN on image/video anlaytics are its unique capabilities of extracting underlying nonlinear structures of image data as well as discerning the categories of semantic data contents by jointly optimizing parameters of multiple layers together. Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image (HSI) classification~ _cite_ . However, in reality, large scale HSI datasets are not currently commonly available, which leads to sub-optimal learning of DCNN with large numbers of parameters due to the lack of enough training samples. The limited access to large scale hyperspectral data has been preventing existing CNN-based approaches for HSI classification~ _cite_ from leveraging {\it deeper} and {\it wider} networks that can potentially better exploit very rich spectral and spatial information contained in hypersepctral images. Therefore, current state-of-the-art CNN-based approaches mostly focus on using small-scale networks with relatively fewer numbers of layers and nodes in each layer at the expense of a decrease in performance. Deeper and wider mean using relatively larger numbers of layers (depth) and nodes in each layer (width), respectively. Accordingly, the reduction of the spectral dimension of the hyperspectral images is in general initially performed to fit the input data into the small-scale networks by using techniques, such as principal component analysis (PCA) ~ _cite_, balanced local discriminant embedding (BLDE) ~ _cite_, pairwise constraint discriminant analysis and nonnegative sparse divergence (PCDA-NSD) ~ _cite_, etc. However, leveraging large-scale networks is still desirable to jointly exploit underlying nonlinear spectral and spatial structures of hyperspectral data residing in a high dimensional feature space. In the proposed work, we aim to build a deeper and wider network given limited amounts of hypersectral data that can jointly exploit spectral and spatial information together. To tackle issues associated with training a large scale network on limited amounts of data, we leverage a recently introduced concept of ``residual learning'', which has demonstrated the ability to significantly enhance the train efficiency of large scale networks. The residual learning~ _cite_ basically reformulates the learning of subgroups of layers called modules in such a way that each module is optimized by the residual signal, which is the difference between the desired output and the module input, as shown in Figure~ _ref_ . It is shown that the residual structure of the networks allows for considerable increase in depth and width of the network leading to enhanced learning and eventually improved generation performance. Therefore, the proposed network does not require pre-processing of dimensionality reduction of the input data as opposed to the current state-of-the art techiniques. To achieve the state-of-the art performance for HSI classification, it is essential that spectral and spatial features are jointly exploited. As can be seen in _cite_, the current state-of-the-art approaches for deep learning based HSI classification fall short of fully exploiting spectral and spatial information together. The two different types of information, spectral and spatial, are more or less acquired separately from pre-processing and then processed together for feature extraction and classification in~ _cite_ . Hu et al.~ _cite_ also failed to jointly process the spectral and spatial information by only using individual spectral pixel vectors as input to the CNN. In this paper, inspired by~ _cite_, we propose a novel deep learning based approach that uses fully convolutional layers (FCN) ~ _cite_ to better exploit spectral and spatial information from hyperspectral data. At the initial stage of the proposed deep CNN, a multi-scale convolutional filter bank conceptually similar to the ``inception module'' in~ _cite_ is simultaneously scanned through local regions of hyperspectral images generating initial spatial and spectral feature maps. The multi-scale filter bank is basically used to exploit various local spatial structures as well as local spectral correlations. The initial spatial and spectral feature maps generated by applying the filter bank are then combined together to form a joint spatio-spectral feature map, which contains rich spatio-spectral characteristics of hyperspectral pixel vectors. The joint feature map is in turn used as input to subsequent layers that finally predict the labels of the corresponding hyperspectral pixel vectors. The proposed network is an end-to-end network, which is optimized and tested all together without additional pre-and post-processing. The proposed network is a fully convolutional network (FCN) ~ _cite_ (Figure~ _ref_) to take input hyperspectral images of arbitrary size and does not use any subsampling (pooling) layers that would otherwise result in the output with different size than the input; this means that the network can process hyperspectral images with arbitrary sizes. In this work, we evaluate the proposed network on three benchmark datasets with different sizes (N _inline_eq_ N pixels for the Indian Pines dataset, N _inline_eq_ N pixels for the University of Pavia dataset, and N _inline_eq_ N for the Salinas dataset) . The proposed network is composed of three key components; a novel fully convolutional network, a multi-scale filter bank, and residual learning as illustrated in Figure~ _ref_ . Performance comparison shows enhanced classification performance of the proposed network over the current state-of-the-art on the three datasets. The main contributions of this paper are as follows: The remainder of this paper is organized as follows. In Section~ _ref_, related works are described. Details of the proposed network are explained in Section~ _ref_ . Performance comparisons among the proposed network and current sate-of-the-art approaches are described in Section~ _ref_ . The paper is concluded in Section~ _ref_ .