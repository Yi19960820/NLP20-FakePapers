Most remote sensing applications require images at the highest resolution both in spatial and spectral domains which is very hard to achieve by a single sensor. To alleviate this problem, many optical Earth observation satellites, such as QuickBird, GeoEye and IKONOS, carry two kinds of optical sensors, acquiring multi-modal data with different but complementary characteristics, in which the panchromatic sensor acquires high spatial resolution images with only a single band, while the multi-spectral sensor acquires low spatial resolution images with multiple bands. These modalities are known as panchromatic (PAN) image and multi-spectral (MS) image, respectively. The technique of PAN and MS image fusion (also known as pan-sharpening) is to fuse information from PAN and MS modalities to generate images with spatial resolution of PAN images and spectral resolution of the corresponding MS images, simultaneously. Pan-sharpening can be helpful for many practical applications, such as change detection, land cover classification, so it has been raising much attention within remote sensing community. Many research efforts have been devoted to developing pan-sharpening algorithms during the last decades~ _cite_ . Most of these methods can be classified into three categories: N) component substitution (CS) methods; N) am _inline_eq_ lioration de la r _inline_eq_ solution spatiale par injection de structures (ARSIS) concept methods (which means enhancement of the spatial resolution by structure injections) ; and N) model-based methods. The CS methods assume that the geometric detail information of a MS image lies in its structural component which can be obtained by transforming it into a new space. Then the structural component is substituted or partially substituted by the PAN to inject the spatial information. Pan-sharpening is achieved after an inverse transformation. The PCA based~ _cite_, the IHS based~ _cite_ and the Gram-Schmidt (GS) transform~ _cite_ based methods are those of the most widely known CS methods. The fundamental assumption of the ARSIS concept methods is that the missing spatial information in MS can be inferred from the high frequencies of the corresponding PAN images~ _cite_ . To pan-sharpen a MS image, ARSIS methods apply multi-resolution algorithms, such as discrete wavelet transform (DWT) ~ _cite_, “ _inline_eq_ trous” wavelet transform~ _cite_ or curvelet transform~ _cite_ on a PAN image to extract high-frequency information and then inject it into a MS image. The model based methods construct degradation models of how PAN and MS images are degraded from the desired high resolution MS image and restore it from the degradation models~ _cite_ . Methods beyond this scope are also developed to address the pan-sharpening problem. For instance, Li~ _cite_ and Zhu~ _cite_ modeled pan-sharpening from compressed sensing theory. He et al.~ _cite_ introduced a variational model based on spatial and spectral sparsity priors for pan-sharpening. Liu et al.~ _cite_ addressed pan-sharpening from a manifold learning framework. Recently, deep learning techniques, especially convolutional neural networks (CNNs), have been applied to various research fields and achieved astonishing performance~ _cite_, motivating researchers in remote sensing community to apply CNNs on pan-sharpening problems. Inspired by SRCNN ~ _cite_, Masi et al.~ _cite_ proposed a pan-sharpening method based on convolutional neural networks (CNNs) . They utilized a three-layered CNN architecture, which was originally designed for image super-resolution~ _cite_, to achieve pan-sharpening. Zhong et al.~ _cite_ presented a CNN based hybrid pan-sharpening method, in which CNN was employed to enhance the spatial resolution of the MS image, then the GS transform was utilized to fuse the enhanced MS and PAN image to obtain the pan-sharpened images. The network used to enhance the spatial resolution of MS image is also a three-layered CNN similar to SRCNN~ _cite_ . Motivated by the great successes achieved by CNNs both in pan-sharpening and other research fields, and the fact that CNN is a powerful tool to extract hierarchical features of an image, we propose to perform pan-sharpening task in feature level instead of pixel level that the previous CNN based methods belong to. To achieve this end, we design an encoder-decoder like two-stream fusion network that encodes (fuses) features of PAN and MS, and then decodes the fused features to recover the pan-sharpened image. The code of our method is available at . To summarize, the main contributions of this paper are in three-fold: This is an extension of our work~ _cite_ . Compare with it, this paper provides a more comprehensive and systematic report of our work. Furthermore, backgrounds of CNN and related work are added in this paper. And we provide motivations for designing the proposed network and two improvements of it to further boost the performance. Last but not least, more extensive experiments are presented to valid our methods. The rest of this paper is organized as follows. In, we introduce background of CNNs and give a brief review on CNN based pan-sharpening methods.~ explains the motivation of our two-stream pan-sharpening network and elaborate the detail architecture. ~ gives experiments and comparisons with other methods. Finally, this paper is concluded in .