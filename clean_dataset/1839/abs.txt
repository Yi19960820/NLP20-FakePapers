The goal of this work is to demonstrate the use of the {\em ballistocardiogram (BCG)} signal, derived using head-mounted wearable devices, as a viable biometric for authentication. The BCG signal is the measure of an person's body acceleration as a result of the heart's ejection of blood. It is a characterization of the cardiac cycle and can be derived non-invasively from the measurement of subtle movements of a person's extremities. In this paper, we use several versions of the BCG signal, derived from accelerometer and gyroscope sensors on a Smart Eyewear (SEW) device, for authentication. The derived BCG signals are used to train a convolutional neural network (CNN) as an authentication model, which is personalized for each subject. We evaluate our authentication models using data from N subjects and show that our approach has an equal error rate (EER) of N \% immediately after training and N \% after about N months, in the worst case. We also explore the use of our authentication approach for people with motor disabilities. Our analysis using a separate dataset of N subjects with non-spastic cerebral palsy shows an EER of N \% immediately after training and N \% after about N months, in the worst-case.