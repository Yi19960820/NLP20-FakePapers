Convolutional Neural Networks (CNNs) have a dominant performance in a collection of domains, of which computer vision has been perhaps the most successful application _cite_ . However, recently people have shown that CNN models are susceptible to small adversarial perturbations that have come to be termed _cite_ . As significantly, many studies have demonstrated the extensive portability, or of AEs across deep learning models _cite_ . More precisely, an AE generated against one model has been shown to commonly fool another deep learning model with similar architecture and trained independently either on a similar dataset, or using queries from the original model. The phenomenon of transferability has been critical to the successful design of black-box attacks on deep learning, where the attacker need not have any knowledge of the model they are attacking to succeed _cite_ . In our paper, we provide an in-depth study on how the hyperparameters of CNN models influenced the transferability of AEs generated from them. More importantly, we studied how transferability of AEs is influenced by the characteristic of target models and test models we chose. We summarize our primary contributions as the following: In the next section, we give a brief overview of related work to our discussion on transferability. We then discuss the methodology we used during our experiments. After that, we discussed the experiment setting and results. Finally, we provide our conclusion on transferability. We also provide all terminologies we used throughout the paper in Table~ _ref_ .