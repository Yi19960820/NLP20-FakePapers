Touch-screen devices, such as smartphone and iPad, enable users to draw free-hand sketches conveniently. These sketches are highly iconic, succinct, and abstract representations, and usually convey richer and more accurate information than texts in some scenarios. Consequently, they spawned many novel applications. One of the most representative examples is the Sketch-Based Image Retrieval (SBIR), which has attracted significant attention from the computer vision community during the past decades _cite_ . For the SBIR task, learning good representations for both sketches and photos is of vital importance and is considered as a challenging problem _cite_ . We give an illustrative example of the SBIR task in Figure _ref_ . Given a query sketch, the objective is to find all of its relevant photos that are semantically related, e.g, they come from the same category. This task appears to be easy for us humans but is very difficult for a machine. The main challenge comes from the fact that there is a significant gap between the data representation in the two domains: the sketches are represented by highly iconic, abstract and sparse lines, whilst the photos are composed of dense color pixels with rich texture information. Recently, many works have been proposed to address this problem. A popular approach is constructing a good intermediate representation, i.e., converting photos to edge maps _cite_ or translating sketches into the photo domain using generative models _cite_ . Another widely adopted approach is learning a semi-heterogeneous network in an end-to-end manner _cite_ . These approaches have one thing in common--they all aim to find a feature space in which the gap between sketches and photos is minimized. Therefore, a loss function, e.g., semantic factorization loss _cite_ and semantic loss _cite_, that aims to minimize the domain discrepancy and intra-class distance is usually constructed. In this work, we argue that only minimizing the domain discrepancy and intra-class distance is not sufficient for achieving accurate SBIR. Even the distance (in a certain feature space) between samples from the same class is small, it is still possible that there exist irrelevant samples near the query sample, leading to poor retrieval results. Motivated by this intuition, we propose a novel loss function, named Euclidean Margin Softmax (EMS), that minimizes the intra-class distance and maximizes the inter-class distance simultaneously. We show that the EMS loss is able to yield highly accurate retrieval results, which surpass all existing algorithms by a large margin. Further, to accompany the proposed loss function, we introduce a conditional neural network architecture, that could incorporate our prior knowledge about which domain the sample comes from. Specifically, our base network is the ResNeXt model _cite_ with Squeeze and Excitation (SE) module _cite_, since it not only has high representation power but also enables us to encode the conditional information conveniently. In each SE module, the convolutional features are firstly squeezed into a low dimensional embedding by an encoder network, then they are decoded to generate a channel-wise attention vector, which is applied to the original feature maps. Based on the SE module, we can simply append one binary code, which indicates which domain the sample comes from, to the low dimensional embedding. Through extensive experiments, we show that this change is simple yet highly effective. \noindent Contributions . We highlight the main contributions of this work. (N) A novel loss function that simultaneously minimizes intra-class distance and maximizes inter-class distances is proposed. (N) We propose a novel conditional network architecture that could incorporate the additional information about the domain attribution, which helps to boost the retrieval performance. (N) New state-of-the-art results have been obtained on several competitive SBIR tasks. In addition, we show our model can be directly extended to address the challenging zero-shot SBIR task.