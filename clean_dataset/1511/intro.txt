In this paper, we investigate an important and nontrivial problem in computer vision, namely object skeleton extraction from natural images (Fig.~ _ref_) . Here, the concept of ``object'' means a standalone entity with a well-defined boundary and center~ _cite_, such as an animal, a human, and a plane, as opposed to amorphous background stuff, such as sky, grass, and mountain. The skeleton, also called the, is a useful structure-based object descriptor. Extracting object skeletons directly from natural images can deliver important information about the presence and size of objects. Therefore, it is useful for many real applications including object recognition/detection~ _cite_, text recognition~ _cite_, road detection and blood vessel detection~ _cite_ . Skeleton extraction from pre-segmented images~ _cite_ has been well studied and successfully applied to shape-based object matching and recognition~ _cite_ . However, such methods have severe limitations when applied to natural images, because segmentation from natural images is still an unsolved problem. Skeleton extraction from natural images is a very challenging problem, which requires addressing two tasks. One is skeleton localization to classify whether a pixel is a skeleton pixel or not (the top row in Fig.~ _ref_) and the other is skeleton scale prediction to estimate the scale of each skeleton pixel (the bottom row in Fig.~ _ref_) . The latter task has not been studied explicitly in the past, although it is very important, because using the predicted scales, we can obtain object segmentation from a skeleton directly. In this paper, we address skeleton localization and scale prediction in a unified framework which performs them simultaneously. The main difficulties for skeleton extraction stem from four issues: (N) The complexity of natural scenes: Natural scenes are typically very cluttered. Amorphous background elements, such as fences, bricks and even the shadows of objects, exhibit some self-symmetry, and thus can cause distractions. (N) The diversity of object appearance: Objects in natural images exhibit very different colors, textures, shapes and sizes. (N) The variability of skeletons: local skeleton segments have a variety of patterns, such as straight lines, T-junctions and Y-junctions. (N) The: A local skeleton segment is naturally associated with an unknown scale, determined by the thickness of its corresponding object part. We term this last problem the unknown-scale problem for skeleton extraction. A number of methods have been proposed to perform skeleton extraction or skeleton localization in the past decade. Broadly speaking, they can be categorized into two groups: (N) Traditional image processing methods~ _cite_, which compute skeletons from a gradient intensity map according to some geometric constraints between edges and skeletons. Due to the lack of supervised learning, these methods have difficulty in handling images with complex scenes; (N) Recent learning based methods~ _cite_, which learn a per-pixel classification or segment-linking model based on hand-designed features for skeleton extraction computed at multi-scales. But the limitations of hand-designed features cause these methods to fail to extract the skeletons of objects with complex structures and cluttered interior textures. In addition, such per-pixel/segment models are usually time consuming. More importantly, most current methods only focus on skeleton localization, but are unable to predict skeleton scales, or are only able to provide a coarse prediction for skeleton scales. This big shortcoming limits the application of the extracted skeletons to object detection. Consequently, there remain big gaps between these skeleton extraction methods and human perception, in both performance and speed. Skeleton extraction has the unique aspect of requiring both local and non-local image context, which requires new techniques for both multi-scale feature learning and classifier learning. This is challenging, since visual complexity increases exponentially with the size of the context field. To tackle the obstacles mentioned above, we develop a holistically-nested network with multiple scale-associated side outputs for skeleton extraction. The holistically-nested network (HED) ~ _cite_ is a deep fully convolutional network (FCN) ~ _cite_, which enables holistic image training and prediction for per-pixel tasks. A side output is the output of a hidden layer of a deep network. The side outputs of the hidden layers, from shallow to deep, give multi-scale responses, and can be guided by supervision to improve the directness and transparency of the hidden layer learning process~ _cite_ . Here we connect two sibling scale-associated side outputs to each convolutional layer in the holistically-nested network to address the unknown-scale problem in skeleton extraction. Referring to Fig.~ _ref_, imagine that we are using multiple filters with different sizes (such as the convolutional kernels in convolutional networks) to detect a skeleton pixel at a specific scale; then only the filters with sizes larger than the scale will have responses, and others will not. Note that the sequential convolutional layers in a hierarchical network can be consider as filters with increasing sizes (the receptive field sizes of the original image of each convolutional layer are increasing from shallow to deep) . So each convolutional layer is only able to capture the features of the skeleton pixels with scales less than its receptive field size. This sequence of increasing receptive field sizes provide a principle to quantize the skeleton scale space. With these observations, we propose to impose supervision at each side output (SO), optimizing them towards a scale-associated groundtruth skeleton map. More specifically, only skeleton pixels whose scales are smaller than the receptive field size of the SO are labeled by quantized scale values. The two sibling SOs at each stage are trained with multi-task loss for both skeleton localization and skeleton scale prediction. Thus the SOs at each stage are associated with specific scales and give a number of scale-specific skeleton score maps (the score map for one specified quantized scale value) as well as a skeleton scale map. Since the SOs in our network are scale-associated, we call them scale-associated side outputs (SSOs) and we refer to the SSOs for skeleton localization and skeleton scale prediction as Loc-SSO and ScalePred-SSO respectively. The final predicted skeleton map is obtained by fusing Loc-SSOs. A straightforward fusion method is to average them. However, a skeleton pixel with large scale typically has a stronger response at the deeper SOs, and a weaker response at the shallower SOs; By contrast, a skeleton pixel with small scale may have strong responses at both of the two SOs. This motivates us to use a scale-specific weight layer to fuse the corresponding scale-specific skeleton score maps provided by each Loc-SSO. In summary, the core contribution of this paper is the scale-associated side output layers, which enable both multi-task learning and fusion in a scale-depended way, to deal with the unknown scale problem. Therefore our network is able to detect skeleton pixels at multiple scales and estimate the scales. To evaluate the performances of skeleton extraction methods, datasets with groundtruth skeleton maps as well as groudtruth scale maps are required. We constructed such a dataset in our previous work~ _cite_, which we called SKN . There are N natural images in this dataset, which were selected from the recent published MS COCO dataset~ _cite_ . A skeletonization method~ _cite_ was applied to the human-annotated foreground segmentation maps of the selected images to generate the groundtruth skeleton maps and the groundtruth scale maps. But the size of this dataset was small. Therefore, in this paper, we construct a larger dataset, containing _inline_eq_ natural images, annotated in the same way. We rename the SKN dataset SK-SMALL and call the newly constructed one SK-LARGE. For consistency, SK-SMALL is a subset of SK-LARGE. This paper extends our preliminary work~ _cite_ by the following contributions: (N) Training the side outputs of each stage with a multi-task loss by introducing a new scale regression term. (N) Constructing a larger dataset for skeleton extraction. (N) More experimental results and discussions about the usefulness of the extracted skeletons in object detection applications.