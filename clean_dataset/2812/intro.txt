Autonomous driving is a large system that consists of various sensors and control modules. The first key step for robust autonomous driving is to recognize and understand the environment around a subject. However, simple recognition of obstacles and understanding of geometry around a vehicle is insufficient. There are traffic regulations dictated by traffic symbols such as lane and road markings that should be complied with. Moreover, for an algorithm to be applicable to autonomous driving, it should be robust under diverse environments and perform in real-time. However, research on lane and road marking detection thus far has been limited to fine weather conditions. Hand-crafted feature based methods exploit edge, color or texture information for detection, which results in a performance drop when the algorithm is tested under challenging weather and illumination conditions. Likewise, methods based on a combination of a Convolutional Neural Network (CNN) and hand-crafted features face the same challenge. Recently, a few CNN based approaches have been developed to tackle the problem in an end-to-end fashion including learning-based algorithms. They demonstrate good performance on benchmarks and in real road scenes, but are still limited to fine weather and simple road conditions. The lack of public lane and road marking datasets is another challenge for the advancement of autonomous driving. Available datasets are often limited and insufficient for deep learning methods. For example, Caltech Lanes Dataset~ _cite_ contains N, N images taken from four different places. Further, Road Marking Dataset~ _cite_ contains N, N images manually labeled into N classes of road markings. Existing datasets are all taken under sunny days with a clear scene and adverse weather scenarios are not considered. With recent advances in deep learning, the key to robust recognition in challenging scenes is a large dataset that incorporates data captured under various circumstances. Since no proper datasets available for lane and road marking recognition, we have collected and annotated lanes and road markings of challenging scenes captured in urban areas. Additionally, a higher network capability with a proper training scheme is required to generate a fine representation to cope with varied data. We propose to train a network that recognizes a global context in a manner similar to humans. Interestingly, humans can drive along a lane even when it is hard to spot. Research works _cite_ have empirically shown that the driverâ€™s gaze direction is highly correlated with the road direction. This implies that a geometric context plays a significant role in the lane localization. Inspired by this, we aim to utilize a vanishing point prediction task to embed a geometric context recognition capability to the proposed network. Further, we hope to advance autonomous driving research with the following contributions: This paper is organized as follows. Section~ _ref_ covers recent algorithms developed for lane and road marking detection. A description of the benchmark is given in Section~ _ref_ . Section~ _ref_ explains our network architecture and training scheme. Experimental results are reported in Section~ _ref_ . Finally, Section~ _ref_ concludes our work.