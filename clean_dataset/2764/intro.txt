Recognizing human activities in sequences, known as human activity recognition (HAR), is a key research topic in human-computer interaction and human behaviour analysis in ubiquitous computing~ _cite_ . Among diverse human activities, some are more frequent or are of different durations than others. For example, an older person may spend prolonged periods in bed or sitting as opposed to ambulating. Consequently, class imbalance is an inherent nature of HAR problems. Time series signals in real applications are often collected from multiple sensors with very different characteristics. Thus it is very challenging to design good features and classifiers to recognize these activities both rapidly and accurately. A typical workflow of HAR methods for sequential data collected from wearable sensors contains the following steps: preprocessing, segmentation, feature extraction, and classification. Many works focus on handcrafting effective features such as signal-based feature~ _cite_, transform-based feature~ _cite_, and multilevel features~ _cite_ . Another research avenue focus on using powerful learning algorithms to train classifiers (using existing features) such as Support Vector Machines (SVMs) ~ _cite_, boosting~ _cite_, and temporal probabilistic graphical models such as Hidden Markov Model (HMM) ~ _cite_, conditional random field (CRF) ~ _cite_, and semi-Markov models~ _cite_ . Due to the success of deep learning~ _cite_, researchers have recently started to learn HAR features in an end-to-end fashion instead of handcrafting them. _cite_ learned the layers of the autoencoder network with restricted Boltzmann machine for HAR. _cite_ proposed convolutional neural networks (CNNs) based approaches to automatically extract discriminative features for HAR. _cite_ utilized CNNs to model audio data for ubiquitous computing (ubicomp) applications. _cite_ investigated different types of deep neural networks for HAR with wearable sensors data. _cite_ explored temporal deep neural networks for active biometric authentication. These deep learning based methods outperform other methods due to their ability of learning better features (than handcrafted ones) . However, regardless of using hand-crafted features or learned features, the input sensor data are always segmented into sections, typically using a sliding-window. It is hoped that each segment only contains a single activity. Given a sliding-window, one label is generated for all samples within the window. While widely used, this has several of issues. First, the sliding-window procedure creates the difficulty of defining the best window length, sampling stride and window labeling strategy; Second, the samples in one window may not always share the same ground truth label. People resort to intuitions and heuristics such as majority voting to force all samples to take one label. This inevitably loses original information, and causes label inconsistency---true labels or ground truth of some samples are not the label of the window and this can misguide the classifier; Third, for current sliding window based CNN methods, the window size for testing data must be the same as the window size used during the training. The imposes two issues. If users believe a different window size is better for the new testing data, they either have to stick to the old window size during the training (which they believe will be worse), or re-train the model from scratch. There are cumbersome ways to introduce some flexibility to the window size, but at the cost of speed and efficiency. Then the need to accumulate data over a fixed window can lead to intolerable prediction delays in real-time applications. To manage these issues, we propose a method that can efficiently predict labels for each individual sample (which we call dense labeling) without any window based labeling procedure. Our contributions are three folds: i) We are the first to do dense labeling for HAR and avoid the label inconsistency problem caused by all sliding window approaches; ii) Our algorithm based on a fully convolutional network is much more efficient than CNN counter-parts, and can handle sequences of arbitrary length without window size restrictions; and iii) We release a new daily activity dataset collected from hospitalised older people which we believe will be beneficial to the community.