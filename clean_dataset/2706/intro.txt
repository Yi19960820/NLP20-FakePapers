The problem of face aging targets on the capabilities to aesthetically synthesize the faces of a subject at older ages, i.e. age progression, or younger ages, i.e. age regression or deaging . This problem is applicable in various real-world applications from age invariant face verification, finding missing children to cosmetic studies. Indeed, face aging has raised considerable attentions in computer vision and machine learning communities recently. Several breakthroughs with numerous face aging approaches, varying from anthropology theories to deep learning structures have been presented in literature. However, the synthesized results in these previous approaches are still far from perfect due to various challenging factors, such as heredity, living styles, etc. In addition, face aging databases used in most methods to learn the aging processes are usually limited in both number of images per subject and the covered age ranges of each subject. Both conventional and deep learning methods usually include two directions, i.e. direct and step-by-step aging synthesis, in exploring the temporal face aging features from training databases. In the former direction, these methods directly synthesize a face to the target age using the relationships between training images and their corresponding age labels. For example, the prototyping approaches use age labels to organize images into age groups and compute average faces for their prototypes. Then, the difference between source-age and target-age prototypes is applied directly to the input image to obtain the age progressed face at the target age. Similarly, the Generative Adversarial Networks (GAN) approach models the relationship between high-level representation of input faces and age labels by constructing a deep neural network generator. This generator is then incorporated with the target age labels to synthesize the outputs. Although these kinds of models are easy to train, they are limited in capabilities to synthesize faces much older than the input faces of the same subject, e.g. directly from ten to N years old. Indeed, the progression of a face at ten years old to the one at N years old in these methods usually ends up with a synthesized face using N-year-old features plus wrinkles. Meanwhile, the latter approaches decompose the long-term aging process into short-term developments and focus on the aging transform embedding between faces of two consecutive development stages. Using learned transformation, these methods step-by-step generate progressed faces from one age group to the next until reaching the target. These modeling structures can efficiently learn the temporal information and provide more age variation even when a target age is very far from the input age of a subject. However, the main limitation of these methods is the lack of longitudinal face aging databases. The longest training sequence usually contains only three or four images per subject. In either directions, i.e. direct or step-by-step aging synthesis, the aging approach falls in, these previous approaches still suffer from many challenging factors and remain with lots of limitations. Table _ref_ compares the properties of different aging approaches. The paper presents a novel Subject-dependent Deep Aging Path (SDAP) model to face age progression, which is an extension of our previous work . In that work, TNVP structure is proposed to embed the pairwise transformations between two consecutive age groups. In this work, the SDAP structure is introduced to further enhance the capability to discover the optimal aging development path for each individual. This goal can be done by embedding the transformation over the whole aging sequence of a subject under an IRL framework. Our contributions can be summarized as follows. We believe that this is the first work that designs an IRL framework to model the longitudinal face aging.