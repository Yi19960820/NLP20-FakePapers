Edge detection is a long-standing task in computer vision _cite_ . In early years, the objective is defined as to find sudden changes of discontinuities in intensity images _cite_ . Nowadays, it is expected to localize semantically meaningful objectsâ€™ boundaries, which play a fundamental and significant role in many computer vision tasks such as image segmentation _cite_ and optical flow _cite_ . In the past few years, deep convolutional neural networks (CNNs) have dominated the research on edge detection. CNN based methods, such as DeepEdge _cite_, DeepContour _cite_, HED _cite_ and RCF _cite_, take advantage of its remarkable ability of hierarchical feature learning and have demonstrated state-of-the-art F-score performance on the benchmarks such as BSDSN _cite_ and NYUDvN _cite_ . Although CNN-based methods are good at producing semantically meaningful contours, we observe a common behavior that their prediction is much thicker than the result of classic methods. For example, in Figure _ref_ we show two prediction examples from the Sobel detector _cite_ and the HED detector, respectively. The edge of the polar bear that we highlight in the dotted rectangle on the HED result is roughly N pixels wide, which is two times wider than the Sobel result (roughly N pixels) . Note that, the behavior of thick prediction is not only on the result of HED but also can be found in many recent representative works such as RCF, Casenet _cite_ and CEDN _cite_ . Existing works in the literature seldom discuss this issue of predicted boundaries being overly thick. One possible reason is that edge detection methods typically apply edge thinning post-processing to obtain one-pixel wide results after generating an initial prediction. Therefore it seems no difference that how wide the initial prediction is. However, this behavior attracts our attention and we believe it is worth finding out the reason behind it which in turn improves the quality of prediction. The work in _cite_ addressed this problem by proposing a refinement architecture (encoder-decoder) for achieving crips edges. As we show in our experiments, it only slightly improves the result of HED. Instead of modifying the convolutional network for boundary detection, we address this problem by investigating the loss function. In this work, we explore and solve the thickness issue of CNN-based boundary predictions. We present an end-to-end fully convolutional network which is accurate, fast and convenient to perform image-to-boundary prediction. Our method consists of two key components, which are a fully convolutional neural network of the bottom-up/top-town architecture and a simple yet effective loss function. The method can automatically learn rich hierarchical features, resolve ambiguity in prediction and predict crisp results without postprocessing. Figure~ _ref_ gives an example of the improvement of edge quality between our method and the HED detector. More examples can be found in Section~ _ref_ . We demonstrate that tackling the issue of thickness is critical for CNNs performing crisp edge detection, which improves the visual result as well as promotes the performance in terms of boundary detection evaluation metrics. We achieve the state-of-the-art performance on the BSDSN dataset with the ODS F-score of N and the fast version of our method achieves ODS F-score of N at the speed of N FPS.