Among the several human-centered research activities (e.g. human detection, tracking, pose estimation and motion recognition) in computer vision, human motion recognition is particularly important due to its potential application in video surveillance, human computer interfaces, ambient assisted living, human-robot interaction, intelligent driving, etc. A human motion recognition task can be summarised as the automatic identification of human behaviours from images or video sequences. The complexity and duration of the motion involved can be used as basis for broad categorization into four kinds namely gesture, action, interaction and group activity. A gesture can be defined as the basic movement or positioning of the hand, arm, body, or head that communicates an idea, emotion, etc. ``Hand waving" and ``nodding" are some typical examples of gestures. Usually, a gesture has relatively short duration. An action is considered as a type of motion performed by a single person during short time period and involves multiple body parts, in contrast with the few body parts that involved in gesture. An activity is composed by a sequence of actions. An interaction is a type of motion performed by two actors; one actor is human while the other may be human or an object. This implies that the interaction category will include human-human or human-object interaction. ``Hugging each other" and ``playing guitar" are examples of these two kinds of interaction, respectively. Group activity is the most complex type of activity, and it may be a combination of gestures, actions and interactions. Necessarily, it involves more than two humans and from zero to multiple objects. Examples of group activities would include ``two teams playing basketball" and ``group meeting". Early research on human motion recognition was dominated by the analysis of still images or videos~ . Most of these efforts used color and texture cues in ND images for recognition. However, the task remains challenging due to problems posed by background clutter, partial occlusion, view-point, lighting changes, execution rate and biometric variation. This challenge remains even with current deep learning approaches~ . With the recent development of cost-effective RGB-D sensors, such as Microsoft Kinect~ \texttrademark and Asus Xtion~ \texttrademark, RGB-D-based motion recognition has attracted much attention. This is largely because the extra dimension (depth) is insensitive to illumination changes and includes rich ND structural information of the scene. Additionally, ND positions of body joints can be estimated from depth maps~ . As a consequence, several methods based on RGB-D data have been proposed and the approach has proven to be a promising direction for human motion analysis. Several survey papers have summarized the research on human motion recognition using RGB-D data~ . Specifically, Chen et al.~ focused on depth sensors, pre-processing of depth data, depth-based action recognition methods and datasets. In their work, Ye et al.~ presented an overview of approaches using depth and skeleton modalities for tasks including activity recognition, head/hand pose estimation, facial feature detection and gesture recognition. The survey presented by Aggarwal and Xia~ summarized five categories of representations based on ND silhouettes, skeletal joints/body part location, local spatial-temporal features, scene flow features and local occupancy features. The work of Cheng et al.~ focused on RGB-D-based hand gesture recognition datasets and summarized corresponding methods from three perspectives: static hand gesture recognition, hand trajectory gesture recognition and continuous hand gesture recognition. In another effort Escalera et al.~ reviewed the challenges and methods for gesture recognition using multimodal data. Some of the surveys have focused on available datasets for RGB-D research. For example, the work of Zhang et al.~ described available benchmark RGB-D datasets for action/activity recognition and included N single-view datasets, N multi-view datasets and N multi-person datasets. Other works as Presti and La Cascia~ and Han et al.~ mainly reviewed skeleton-based representation and approaches for action recognition. A short survey on RGB-D action recognition using deep learning was recently presented in~, analysing RGB and depth cues in terms of NDCNN, NDCNN, and Deep temporal approaches All above surveys mainly focused on the analysis of handcrafted features. Here, we provide a comprehensive review of RGB-D-based human motion recognition using deep learning approaches. Even while focusing on deep learning approaches, the nature of the input data is still important. RGB-D data for human motion analysis comprises three modalities: RGB, depth and skeleton. The main characteristic of RGB data is its shape, color and texture which brings the benefits of extracting interesting points and optical flow. Compared to RGB videos, the depth modality is insensitive to illumination variations, invariant to color and texture changes, reliable for estimating body silhouette and skeleton, and provides rich ND structural information of the scene. Differently from RGB and depth, skeleton data containing the positions of human joints, is a relatively high-level feature for motion recognition. The different properties of the three modalities have inspired the various methods found in the literature. For example, optical flow-based methods with Convolutional Neural Networks (CNN) is very effective for RGB channel~ ; depth rank pooling based-method with CNN is a good choice for depth modality~ ; sequence based method with Recurrent Neural Networks (RNN) ~ and image-based method with CNN~ are effective for skeleton; and scene flow-based method using CNN are promising for RGB + D channels~ . These methods are very effective for specific modalities, but not always the case for all the modalities. Given these observations, this survey identified four broad categories of methods based on the modality adopted for human motion recognition. The categories include RGB-based, depth-based, skeleton-based and RGB + D-based. In each category, two sub-divisions are further identified, namely segmented human motion recognition and continuous/online motion recognition. For segmented motion recognition, the scenario of the problem can be simply described as classifying a well delineated sequence of video frames as one of a set of motion types. This is in contrast to continuous/online human motion recognition where there are no a priori given boundaries of motion execution. The online situation is compounded by the fact that the video sequence is not recorded and the algorithm must deal with frames as they are being captured, save for possibly a small data cache. During the performance of a specified motion spatial information which refers to the spatial configuration of human body at an instant of time (e.g. relative positions of the human body parts) can be identified. Similarly, there is the temporal information which characterizes the spatial configuration of the body over time (i.e. the dynamics of the body) . Lastly, the structural information encodes the coordination and synchronization of body parts over the period in which the action is being performed. It describes the relationship of the spatial configurations of human body across different time slots. In reviewing the various methods, consideration has been given to the manner in which the spatial, temporal and structural information have been exploited. Hence, the survey discusses the advantages and limitations of the reviewed methods from the spatial-temporal-structural encoding viewpoint, and suggests potential directions for future research. A key novelty of this survey is the focus on three architectures of neural networks used in the various deep learning methods reviewed namely CNN-based, RNN-based and other structured networks. Fig.~ _ref_ illustrates the taxonomy underpinning this survey. This is one of the first surveys dedicated to RGB-D-based human motion recognition using deep learning. Apart from this claim, this survey distinguishes itself from other surveys through the following contributions: Additionally, several recently released or commonly used RGB-D-based benchmark datasets associated with deep learning are surveyed. The main application domain of interest in this survey paper is human motion recognition based on RGB-D data, including gesture recognition, action/activity recognition and interaction recognition. The lack of datasets focused on RGB-D-based group activity recognition has led to paucity of research on this topic and thus this survey does not cover this topic. Other RGB-D-based human-centered applications, such as human detection, tracking and pose estimation, are also not the focus of this paper. For surveys on RGB-D data acquisition readers are referred to~ . Subsequent sections of the this survey are organized as follows. Commonly used RGB-D-based benchmark datasets are described in Section~ _ref_ . Sections~ _ref_ to~ _ref_ discuss methods of RGB-D-based motion recognition using deep learning from four perspectives: RGB-based motion recognition, depth-based motion recognition, skeleton-based motion recognition and RGB + D-based motion recognition. Challenges of RGB-D-based motion recognition and pointers to future directions are presented in Section~ _ref_ . The survey provides concluding remarks in Section~ _ref_ .