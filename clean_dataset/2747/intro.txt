Modern structure from motion (SfM) and multiview stereo approaches _cite_ are widely used to recover viewpoint and shape information of objects and scenes in realistic settings, but require multiple images with overlapping fields of view. If only a single image of the target object is available, or if multiple ones are available but from viewpoints far apart, these methods are, respectively, inapplicable or prone to fail. Here we aim to extend SfM-style techniques to these cases by incorporating recognition. Once an object is recognized into some potentially broad class such as "cars" or "aeroplanes", one can leverage a reusable collection of images of similar objects to aid reconstruction. This is in the spirit of recent papers on face reconstruction using automatically learned morphable models _cite_ but we target generic categories and use SfM techniques. Our main insight is the following: SfM algorithms inhabit a rudimentary visual world made of ND points in correspondence and these are all they ``see''. In this visual world, novel views can be faked much more easily than in ours, where light complicates matters. Our idea, illustrated in fig. _ref_ is to synthesize virtual (SfM) views of the target object by aligning it with images of different instances from the same class then employing robust rigid SfM techniques to reconstruct its visible surfaces. This idea is compatible with findings that human perception of structure from motion is robust to small shape deformations of the object _cite_ and prefers to interpret them as manifestations of a rigid object with slightly altered shape instead of a non-rigid object _cite_ . The main technical challenge we face is the need to align the target object with every different object in a collection, which may be pictured with arbitrary viewpoint displacements, all the way up to N degrees from the viewpoint of the target object. There is no dense ND alignment technique that we know of that is prepared for such large viewpoint variation, so we propose a new one: instead of attempting to match the target object with each object in the collection individually, we predict the pose of the target object and identify a subset of objects from the collection with similar poses--the intuition is that these will be easier to align with. Afterwards we propagate the correspondences to all other collection objects along geodesics on our new virtual view networks . An additional difficulty for structure from such virtual motions is that the tight rigidity assumptions made by epipolar geometry and fundamental matrix estimation in standard RANSAC-based SfM approaches are unlikely to hold in our setting because the objects do not have exactly the same shape. Non-rigid structure from motion _cite_ approaches, developed for reconstruction from video, have not yet been demonstrated on deformations arising from intra-class variation for generic classes. We pursue instead scaled-orthographic factorization techniques _cite_ that are more regularized, because they have fewer parameters to optimize, and we introduce methodology for a) increasing robustness to the multitude of noise sources we have by extrapolating synthetic inliers using domain knowledge and b) increasing the specificity of the resulting reconstructions, by emphasizing information in images that we are more confident about being related to the target object. We will review related work in the next section, before explaining in sec. _ref_ how we build and use virtual view networks to synthesize large sets of new views from one or more images of a target object to feed to SfM. Sec. _ref_ introduces novel techniques to robustly perform SfM from noisy virtual views and sec. _ref_ has results on alignment and reconstruction before the paper concludes in sec. _ref_ . Source code to reproduce all results will be made available online .