Neural networks, especially convolutional neural network (CNN) _cite_, have been successfully applied in many computer vision tasks such as object recognition _cite_ . A key to this success is that the neural networks allow appearance representation which is invariant of several image transformations such as small translation. Another important class of tasks in computer vision is the inference of relations between two images. Two images can be related by object motion, camera motion or environmental factors such as lighting change. For these problems, instead of aiming for invariance of appearance changes, we want to detect and estimate appearance changes. For example, given two consecutive video frames, we want to infer the movement of each pixel from one image to the other (optical flow) . For another example, given two images taken by a camera on a moving robot, we want to infer the ego-motion of the robot (visual odometry) . The traditional approach to perform the relation inference tasks is knowledge-based. By acquiring knowledge of a task and making reasonable assumptions for simplification, one designs an algorithm to perform the inference. A classic example is the Horn-Schunck algorithm for computing optical flow _cite_ . However, in situations where we lack sufficient knowledge or the assumptions fail, the knowledge-based approach may not perform well. For example, the Horn-Schunck algorithms assumes brightness constancy of the moving pixels. This assumption can be violated by many factors such as occlusion, shading and noise. An alternative approach to solve the relation inference problem is learning-based _cite_ . From a collection of training data, we aim to learn a function such that given two images _inline_eq_ and _inline_eq_ as inputs, the function will output their relation variables _inline_eq_ . The relation variables can be rotation angle, motion field, affine transformation parameters, etc. Compared to the knowledge-based approach, the learning-based approach does not require sufficient knowledge or assumptions but a large amount of training images with ground-truth relation variables. When it is difficult to obtain the ground-truth for real world images, one can often resort to synthetic images rendered by graphics engines. An example is the Sintel dataset for learning optical flow _cite_ . Recently, the learning-based approach has been adopted to compute optical flow _cite_, stereo disparity _cite_, camera motion _cite_ and visual odometry _cite_ . Some of the results are competitive to the knowledge-based methods. Note that relation learning can also serve as supervision for learning appearance representation, as demonstrated in learning ego-motion _cite_ and robot actions _cite_ . Additionally, there are methods combining knowledge-based and learning-based approaches _cite_ . In these methods, a neural network is trained to match two image patches and a knowledge-based post-processing is applied on the matching results to output the relation variables. In this paper, we focus on the pure learning-based approach, that is, neural networks are trained in an end-to-end manner, given raw images as inputs and ground-truth relation variables as targets. Although a relation learning model can also be trained unsupervisedly _cite_, we restrict our discussion mainly to supervised learning. While both object recognition and relation inference can be treated as supervised learning tasks, the two tasks have much difference in nature. Object recognition aims for invariance of several image transformations (e.g. translation, rotation and scaling) but relation inference aims for equivariance of these transformations. For example, the conventional CNN with a pooling operation is known to be invariant of small translation. This property is suitable for object recognition but not for motion detection, whose goal is to estimate the translation. This difference should be kept in mind when designing a relation learning model. In this paper, we propose a new relation unit, contrast association unit (CAU) . We show that CAUs are suitable for relation learning tasks with analysis and experiments. We adopt a multiplicative update algorithm for learning the non-negative weights in CAUs. The multiplicative update algorithm is compatible with gradient descent algorithms for unconstrained weights. The whole neural network can be trained in an end-to-end manner. Next, in Section _ref_, we outline the general neural network architecture for relation learning. In Section _ref_, we introduce our proposed relation unit CAU. In Section _ref_, we present the multiplicative update algorithm for learning the non-negative weights in CAUs. In Section _ref_, we discuss models related to CAU. In Section _ref_, we present the experiments on the five relation learning tasks.