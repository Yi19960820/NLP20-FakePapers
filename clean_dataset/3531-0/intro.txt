In this paper we report the results of an experiment _cite_ that combines a high-resolution NK node software retina _cite_ with a custom designed DL architecture (based on DeepFix _cite_) coupled to an image stream collected by Tobii Pro N eye-tracking glasses _cite_ (Figure _ref_) worn by a human observer. Our objective is to allow a human operator to collect appropriate training data for a software retina-based egocentric perception _cite_ system simply by looking at objects. These objects may then be recognised in images collected by a human observer using eye tracking glasses, or a machine observer equipped with a saliency model to direct visual gaze. The space-variant sampling within the retina, as illustrated in Figure _ref_, affords almost two orders of magnitude data reduction to the brain. Furthermore, the pathway from the retina to area N in the visual cortex (VN) computes a form of complex-log conformal mapping that affords a degree of scale and rotation invariance to the appearance of fixated objects _cite_ . We previously reported that this mapping can reduce the input visual data rate by a factor of _inline_eq_ _inline_eq_ N for a NK node retina and _inline_eq_ _inline_eq_ N for a NK node retina. A corresponding network size reduction of _inline_eq_ N \% and _inline_eq_ N \% is obtained respectively, however, at the expense of an FN classification score reduction of N \% to N \% as reported at _cite_ . In this paper our objective is to demonstrate that we can achieve state-of-the-art recognition performance using our high-resolution retina implementation while also achieving efficiency gains. In addition, we wanted to investigate the potential to adopt a human observer for directing our software retina's gaze to thereby construct a truly egocentric perception system suitable for both humans and robots.