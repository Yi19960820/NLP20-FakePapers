Generic image retrieval is widely employed in practical Structure-from-Motion (SfM) ~ _cite_ and visual simultaneous localization and mapping (SLAM) ~ _cite_ systems to accelerate the image matching process or identify possible closed loops. Until recently, the preferred image retrieval techniques used in SfM are largely variants of the Bag-of-Words (BoW) models~ _cite_, despite the fact that CNN-based approaches~ _cite_ have shown superior efficiency and scalability for particular object retrieval. This discrepancy can be explained by the difference between and . For SfM tasks, geometric overlaps among images (geometric similarity), rather than information about object categories (semantic similarity), are required for later reliable image matching. We refer to this specific type of image retrieval task as, the goal of which is to find images with large overlaps. Two images are overlapped if they include the same area of the viewed objects or scenes. In this scenario, BoW models based on local descriptors are more robust since they serve as predictors~ _cite_ for how well the local descriptors can be matched. However, neither BoW models nor CNN-based methods perfectly solve the matchable image retrieval problem. On the one hand, BoW models generally have limited scalability as the efficiency and accuracy drop quickly with the increase of data. CNN-based methods, on the other hand, offer efficient and scalable solutions by compact global image representations distilled from intermediate feature maps, yet they lack the ability to identify regional discriminations and local information. This problem has long been overlooked because nearly all of these CNN-based methods are evaluated on object retrieval datasets such as OxfordNk~ _cite_ and ParisNk~ _cite_, in which images are organized by semantic similarity rather than geometric overlaps. However, in a typical SfM scene (Fig.~ _ref_) consisting of overlapping images with weak semantics, current CNN-based methods are worse than BoW models because they fail to render a fine-grained ranking with respect to scene overlaps. That is probably the reason why stable SfM~ _cite_ and SLAM~ _cite_ solutions still adopt BoW models for matchable image retrieval. CNN-based methods should be employed because of its superior efficiency and scalability, and its previous success in object retrieval tasks. However, several problems should be addressed to get rid of the above flaws. First, we are in need of a large-scale SfM database to avoid the data bias in previous evaluations. Second, information about geometric relationships between images should be further exploited to better encode local information. Several methods such as~ _cite_ have attempted to do so but stayed in the SfM level instead of using dense correspondences. Third, the training process should be made more efficient to cope with big data. In this paper, we present an efficient CNN-based method for matchable image retrieval that utilizes rich geometric context mined from densely reconstructed structures, namely mesh re-projection and overlap masks. Moreover, local information is taken good care of with a post-processing step that exploits regional matching. In summary, our contributions are threefold: \smallskip