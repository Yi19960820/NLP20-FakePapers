This paper introduces the system we developed for the Youtube-NM Video Understanding Challenge, in which a large-scale benchmark dataset _cite_ was used for multi-label video classification. The proposed framework contains hierarchical deep architecture, including the frame-level sequence modeling part and the video-level classification part. In the frame-level sequence modelling part, we explore a set of methods including Pooling-LSTM (PLSTM), Hierarchical-LSTM (HLSTM), Random-LSTM (RLSTM) in order to address the problem of large amount of frames in a video. We also introduce two attention pooling methods, single attention pooling (ATT) and multiply attention pooling (Multi-ATT) so that we can pay more attention to the informative frames in a video and ignore the useless frames. In the video-level classification part, two methods are proposed to increase the classification performance, i.e. Hierarchical-Mixture-of-Experts (HMoE) and Classifier Chains (CC) . Our final submission is an ensemble consisting of N sub-models. In terms of the official evaluation metric Global Average Precision (GAP) at N, our best submission achieves N on the public N \% of test dataset and N on the private N \% of test data.