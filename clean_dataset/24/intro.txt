Automated assessment or rating of pictorial aesthetics has many applications, such as in an image retrieval system or a picture editing software _cite_ . Compared to many typical machine vision problems, the aesthetics assessment is even more challenging, due to the highly subjective nature of aesthetics, and the seemingly inherent semantic gap between low-level computable features and high-level human-oriented semantics. Though aesthetics influences many human judgments, our understanding of what makes an image aesthetically pleasing is still limited. Contrary to semantics, an aesthetics response is usually very subjective and difficult to gauge even among human beings. Existing research has predominantly focused on constructing hand-crafted features that are empirically related to aesthetics. Those features are designed under the guidance of photography and psychological rules, such as rule-of-thirds composition, depth of field (DOF), and colorfulness _cite_, _cite_ . With the images being represented by these hand-crafted features, aesthetic classification or regression models can be trained on datasets consisting of images associated with human aesthetic ratings. However, the effectiveness of hand-crafted features is only empirical, due to the vagueness of certain photographic or psychologic rules. Recently, Lu et.al. _cite_ proposed the Rating Pictorial Aesthetics using Deep Learning (RAPID) model, with impressive accuracies on the Aesthetic Visual Analysis (AVA) dataset _cite_ . However, they have not yet studied more precise predictions, such as finer-grain ratings or rating distributions _cite_ . Furthermore, the study of the cognitive and neural underpinnings of aesthetic appreciation by means of neuroimaging techniques yields some promise for understanding human aesthetics _cite_ . Although the results of these studies have been somewhat divergent, a hierarchical set of core mechanisms involved in aesthetic preference have been identified _cite_ . Whereas deep learning is well known to be analogous to brain mechanisms _cite_, there is hardly any work providing the synergy between the neuroaesthetics and the advances of learning-based aesthetics assessment models. In this work, we develop a novel deep-learning based image aesthetics assessment model, called Brain-Inspired Deep Networks (BDN) . BDN clearly distinguishes itself from prior models, for its unique architecture inspired the Chatterjee's visual neuroscience model _cite_ . We introduce the specific architecture of parallel supervised pathways, to learn multiple attributes on a variety of selected feature dimensions. Those attributes are then associated and transformed into the overall aesthetic rating, by a high-level synthesis network . We extend BDN to predicting the distribution of human ratings, since aesthetics ratings often vary somewhat from observer to observer. Our technical contribution also includes the study of label-preserving transformations in the context of aesthetics assessment, which facilitates data augmentation. We examine the BDN model on the large-scale AVA dataset _cite_, for both binary rating and rating distribution prediction tasks, and confirms its superiority over a few competitive methods with the same or larger amounts of parameters. While the neuroscience principles were also considered for traditional aesthetics assessment tasks, BDN makes innovative and meaningful progresses to develop a much more sophisticated and brain-type model, in two ways. First, a deep model by itself, BDN processes the input information in a multiphase hierarchy, which emulates the underlying complex neural mechanisms of human perception. It is more effective and ``biologically plausible'', compared to most standard aesthetics models with hand-crafted features and linear classifiers. Second, among a few existing deep aesthetics assessment models (e.g, RAPID), BDN is the first to introduce the design of independent feature dimensions as parallel pathways, followed by fusing the prediction score. In sum, BDN exploits the neuroaesthetic wisdom (parallel feature extraction, multi-stage prediction, etc.), a part of which were previously utilized only in an oversimplified way, and further integrates such prior wisdom with the power of deep models. Datta et.al. _cite_ first casted the image aesthetics assessment problem as a classification or regression problem. A given image is mapped to an aesthetic rating, which is usually collected from multiple subject raters. The rating is normally quantized with discrete values. The earliest work _cite_, _cite_ extracted various handcrafted features, including low-level image statistics such as distributions of edges and color histograms, and high-level photographic rules such as the rule of thirds. A part of subsequent efforts, such as _cite_, _cite_, _cite_, focus on improving the quality of those features. Generic image features _cite_, such as SIFT and Fisher Vector _cite_, have also been applied to predict aesthetics. However, empirical features cannot accurately and exhaustively represent the aesthetic properties. The human brain transforms and synthesizes a torrent of complex and ambiguous sensory information into coherent thought and decisions. Most aesthetic assessment methods adopt simple linear classifiers to categorize the input features, which is obviously oversimplified. Deep networks _cite_ attempt to emulate the underlying complex neural mechanisms of human perception, and display the ability to describe image content from the primitive level (low-level features) to the abstract level (high-level features) . They are composed of multiple non-linear transformations to yield more abstract and descriptive embedding representations. The RAPID model _cite_ is among the first to apply deep convolutional neural networks (CNN) _cite_ to the aesthetics rating prediction, where the features are automatically learned. They further improved the model by exploring style annotations _cite_ associated with images. In fact, even the hidden activations from a generic CNN proved to work reasonably well for aesthetics features _cite_ . Most current work treat aesthetics assessment as a conventional classification problem: the user ratings of each photo are transformed into a ordinal scalar rating (by averaging, etc.), which is taken as the label of the photo. For example, RAPID _cite_ simply divided all samples as aesthetic or unaesthetic, and trained a binary classification model. However, it is common for different users to rate visual subjects inconsistently or even oppositely due to the subjective problem nature _cite_ . Since human aesthetic assessment depends on multiple dimensions such as composition, colorfulness, or even emotion _cite_, it is difficult for individuals to reliably convert their experiences to a single rating, resulting in noisy estimates of real aesthetic responses. In _cite_, Wu et.al. first proposed to represent each photo's rating as a distribution vector over basic ratings, constituting a structural regression problem. Gao et.al. _cite_ formulated the aesthetic assessment as a multi-label task, where multiple aesthetic attributes were predicted jointly via bayesian networks. Large and reliable datasets, consisting of images and corresponding human ratings, are the essential foundation for the development of machine assessment models. Several Web photo resources have taken advantage of crowdsourcing contributions, such as Flickr and DPChallenge.com _cite_ . The AVA dataset is a large-scale collection of images and meta-data derived from DPChallenge.com. It contains over N, N images with aesthetic ratings from N to N, and a N, N subset with binary style labels (e.g., rule of thirds, motion blur, and complementary colors), making automatic feature learning using deep learning approaches possible. In this paper, we focus on AVA as our research subject.