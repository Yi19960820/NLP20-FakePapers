Deep neural networks are good candidates to enable the next generation of pervasive devices. Internet-of-Things (IoT) devices are commonplace in our everyday lives, yet are still limited in their functionality. Combining the intelligence of deep neural networks with vast amounts of rich sensor data available in an IoT ecosystem could allow for a truly Internet-of-Smart-Things. \newline Deep neural networks require large amounts of resources, both to train and to evaluate. Training is usually less of a problem since this can be done offline on large GPU clusters in the cloud. Inference on the other hand is more of a challenge. The typical IoT devices are limited in the resources available, they usually contain a low-power single-core CPU, limited memory and are often battery powered. Evaluating the current state-of-the-art deep neural networks on these devices is often simply not possible. \newline Current state-of-the-art architectures are usually deep and wide. Impressive results have been obtained by converting these large trained networks into smaller, computationally less expensive versions. _cite_ . \newpage It is well known that N bit floating point numbers are not needed, N bit _cite_, N bit _cite_, N bit _cite_ and even binary _cite_ and fixed point precision _cite_ weights and activations are sufficient for training and evaluating a neural network. \newline Another approach is presented in _cite_ where the authors use a hash function to group connection weights into hash buckets. All connections with the same hash value share the same parameter value thereby reducing the number of parameters to store. Other techniques to exploit the redundancy among weights include low-rank decompositions of the weight matrices _cite_ and sparsity inducing regularisation techniques _cite_ . \newline Other approaches optimize the structure of the neural network itself. A three step method is presented in _cite_ where first the network is trained to discover which connections are important, then, the redundant connections are pruned and finally the network is retrained to fine-tune the weights of the remaining connections. This procedure is able to reduce the number of parameters up to N times without any loss of accuracy. \newline In this paper we present a lazy evaluation approach which allows reducing the required runtime of a deep neural network by selectively evaluating the convolutional filters. Our approach is most similar to the perforatedCNNs technique _cite_ which avoids evaluating convolutional filters for some of the spatial positions. The filters are only evaluated for a subset of the spatial positions, an interpolated value is used for the other positions. Our approach on the other hand evaluates the filters at every spatial position but reduces the number of filters that need to be evaluated. A combination of both techniques could allow for an even larger reduction in computational cost since both techniques exploit orthogonal properties of the network. \newline The remainder of this paper is organised as follows: In Section _ref_ we introduce the concept of Lazy evaluation of convolutional filters. In Section _ref_ we present the experimental results. We conclude in Section _ref_ with the future work.