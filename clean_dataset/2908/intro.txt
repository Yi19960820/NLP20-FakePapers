overall urban growth in the past two decades has led to a considerable development of transportation networks. Such constantly evolving infrastructure necessitates frequent updates of existing road maps. A wide range of applications are depending on this information, such as city development monitoring, automated data update for geolocalization systems or support to disaster relief missions. A satellite equipped with a Synthetic Aperture Radar (SAR) can get information on an area's topography. The resulting information is more robust to changes in illumination conditions and color fluctuation with respect to optical imagery. Moreover, SAR sensors can operate independently from weather conditions, and are therefore the sensor of choice to survey regions affected by weather-related disasters. The extraction of roads in SAR satellite images has been researched for several decades _cite_ and is generally addressed in the following manner: road candidates are extracted from SAR images using a feature detector. This initial segmentation is then transformed into a topological graph, where each segment represents a road section. The graph is finally optimized to form a coherent road network, often by applying a Markov Random Field (MRF) _cite_ using contextual information from the SAR image to reconnect loose segments and correct the overall network structure. Recently, Xu et al. _cite_ proposed a Conditional Random Field (CRF) model capable of jointly extracting road candidates and applying topological constraints. This end-to-end scheme reduced the inevitable performance loss occurring when separately extracting road priors and constructing a road network graph. These methods all rely on an efficient road candidate extraction algorithm and most of them entrust this task to traditional computer vision algorithms. To date, few works study the potential of the recent advances in deep learning in the context of road segmentation. Deep Convolutional Neural Networks (DCNNs) first demonstrated unmatched effectiveness in N on the ImageNet classification challenge and their performance has been improving at a fast pace ever since, receiving a lot of attention from the computer vision community. However, unlike the medium-sized images used in classification competitions, the aerial images used in remote sensing often cover hundreds of square kilometers. Today, Fully-Convolutional Neural Networks (FCNNs) are the most successful method to perform pixel-wise segmentation on large-scale images. Given an input image, they produce an identically-sized prediction map. Introduced in N with FCNNs _cite_, FCNNs allowed the establishment of new states-of-the-art in semantic segmentation of aerial optical images _cite_ and were successfully applied to satellite SAR images _cite_ . In _cite_, Yao et al. use off-the-shelf pre-trained FCNNs on SAR images to classify buildings, landuse, bodies of water and other natural areas. They report good segmentation results for the landuse and natural classes but unsatisfactory results for buildings, showing a striking performance contrast between larger and smaller objects. As roads are thin objects by nature, it becomes evident that FCNNs models must be specifically adjusted for our task. Starting from another perspective, Geng et al. successively proposed two methods for land cover classification, including roads. In _cite_, they emphasize low-level features in SAR images using traditional computer vision techniques on top of which they train a stack of auto-encoders. In _cite_, they further improve their results by using Long-Short-Term Memory units (LSTM) to transform the N-D information contained in the image into N-D information fed to auto-encoders. They report around N \% overall accuracy across several areas totaling N km, however the road class accuracy remains invariably behind the accuracy of all other classes by N \% to N \%. Roads are difficult to identify even in high resolution SAR images. They can often be confused with other targets such as railway tracks, rivers or even tree hedges, as illustrated in Fig. _ref_ . Identifying roads often involves the opinion of an expert, but deep learning proved it could deal with such delicate study cases, motivating the thorough assessment of the potential of some powerful FCNNs on the task at hand. The success of this initial experiment would open new prospects in the future, like semi-automated annotation of SAR images, which could prove much faster and more reliable than fully-manual annotation. Time-critical missions such as disaster relief would particularly benefit from a steep increase in the speed of satellite data analysis. This letter presents the evaluation of three FCNNs for road segmentation in high resolution SAR satellite images: FCN-Ns _cite_, Deep Residual U-Net _cite_ and DeepLabvN + _cite_ . Crucial adjustments are made in the training procedure to improve the base performance of the FCNNs, with a class-weighted Mean Squared Error (MSE) loss and a control parameter over the spatial tolerance of the models. The evaluation is performed on several custom datasets, whose design is critical to the success of the method and is therefore detailed. Unlike Yao et al. in _cite_, we set aside the OpenStreetMap (OSM) data due to the lower geo-localization accuracy compared to SAR data. Unlike previous works, we manually label every single road from the most visible highways to the less distinguishable dirt paths. We obtain good qualitative results and satisfying quantitative results, thus demonstrating the effectiveness of well-fitted FCNNs as road candidate extractors in SAR images.