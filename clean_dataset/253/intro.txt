Many document types have a distinct visual style. For example, ``letter'' documents are typically written in a standard format, which is recognizable even at scales where the text is unreadable. Motivated by this observation, this paper addresses the problem of document classification and retrieval, based on the visual structure and layout of document images. Content-based analysis of document images has a number of applications. In digital libraries, documents are often stored as images before they are processed by an optical character recognition (OCR) system, which means basic image analysis is the only available tool for initial indexing and classification _cite_ . As a pre-processing stage, document image analysis can facilitate and improve OCR by providing information about each document's visual layout _cite_ . Furthermore, document information that is lost in OCR, such as typeface, graphics, and layout, can only be stored and indexed using images or image descriptors. Therefore, image analysis is complementary to OCR at several stages of document analysis. The challenge of document image analysis arises from the fact that within each document type, there exists a wide range of visual variability. For example, of the correspondence documents shown in Figure~ _ref_, no two documents share the exact same spatial arrangement of header, date, address, body, and signature; some of the documents even omit these components entirely. This level of intra-class variability renders spatial layout analysis difficult, and rigid template matching impossible _cite_ . Another issue is that documents of different categories often have substantial visual similarities. For instance, there exist advertisements that look like news articles, and questionnaires that look like forms, and so on. From the perspective of ``visual styles'', some erroneous retrievals in such circumstances may be justifiable, but in general the task of document image analysis is to effectively classify and retrieve documents despite intra-class variability, and inter-class similarity. Similar challenges appear in other fields, such as object recognition and scene classification. In those domains the current state-of-the-art approach involves training a deep convolutional neural network (CNN) to learn features for the task _cite_ . Inspired by the success of CNNs in other domains, this paper presents an extensive evaluation of CNNs for document classification and retrieval. In the end, it is determined that features extracted from deep CNNs exceed the performance of all popular alternative features on both classification and retrieval, by a large margin. Experiments are also presented on transfer learning, which demonstrate that CNNs trained on object recognition learn features that are surprisingly effective at describing documents. Furthermore, it is found that the deep net strategy is not significantly improved by additional guidance toward region-focused features, suggesting that a CNN trained on whole images may already be capable of learning some amount of the information that region-based analysis would add. In the past twenty years of document image analysis, research has oscillated from region-based analysis to whole image analysis, and simultaneously, from handcrafted features to machine-learned ones. The power of region-based analysis of document images has been clearly demonstrated in the domain of rigidly structured documents, such as forms and business letters _cite_ . In general, this approach assumes that many document types have a distinct and consistent configuration of visually-identifiable components. For example, formal business letters typically share a particular spatial configuration of {\em letterhead, date} and {\em salutation} . To some extent, the classification of perfectly rigid documents (\eg, forms) can be reduced to the problem of template matching _cite_, and less-rigid document types (\eg, letters) can similarly be classified by fitting the geometric configuration of the document's components to one of several template configurations, via geometric transformations _cite_ . The drawback of this approach is that it requires the manual definition of a template for each document type to be categorized. Furthermore, the approach is limited to documents for which a template definition is possible. For documents with more flexible structures, as considered herein, template-based approaches are inapplicable. An alternative strategy is to treat document images holistically, or at least in very large regions, and search for discriminative ``landmark'' features that may appear anywhere in the document _cite_ . This strategy is sometimes called a ``bag of visual words'' approach, since it describes images with a histogram over an orderless vocabulary of features _cite_ . For example, a landmark feature discriminating letters from most other document classes is the salutation: finding a salutation in a document (potentially through OCR) is a good cue that the document is a letter, regardless of that feature's exact spatial position _cite_ . The advantage of holistic analysis is that the resulting representation of documents is invariant to the geometric configuration of the features. This approach has therefore been successful in retrieving and classifying a broader range of documents than the template-based approaches, although the approach is less discriminating in the domain of rigid-template documents. Recently, there have been attempts to bridge the gap between region-based and holistic analyses. By concatenating image features pooled at several stages, beginning with a whole-image pool and proceeding into smaller and smaller regions, it is possible to build a descriptor that contains both global and local layout characteristics _cite_ . This technique, known as spatial pyramid matching, was initially developed for categorizing scenes, but it has been shown to apply well to documents also, especially if the pooling regions are designed with document categorization in mind _cite_ . For document retrieval, this type of representation represents the current state-of-the-art. At the same time, many researchers have replaced handcrafted features and representations with machine-learned variants _cite_ . A popular area of research in this domain concerns the task of learning document structure. This typically involves training a decision tree to navigate the various possible geometric configurations of fixed features (i.e. ``landmarks'') within each document type, toward the goal of structure-based classification _cite_ . Most recently, it was shown that the entire pipeline of supervised document image classification, from feature-building to decision making, can be learned by a convolutional neural network (CNN) _cite_ . In that work, the authors reported a remarkable N \% increase in classification accuracy compared to the previous best reported on the same dataset, which had used spatial pyramid matching. However, the CNN approach has not yet been applied to document retrieval. A shift toward machine-learned features has been taking place in other areas of computer vision as well. In the object recognition literature, CNNs currently exceed the performance of every other approach by a very large margin _cite_ . The CNN approach has even been shown to apply well to domains for which it was traditionally believed ill-suited, such as attribute detection, and fine-grained object recognition _cite_ . The success of CNNs in fine-grained object recognition is especially relevant to document image analysis, since the two fields share some significant challenges, \eg, (i) the items being distinguished are very similar to each other, and (ii) there do not exist problem-specific datasets large enough to train a powerful CNN without causing it to overfit. It makes sense, therefore, to draw inspiration from fine-grained object recognition research on how to overcome these challenges. Two major points on the training and usage of CNNs can be gleaned from fine-grained classification research. First, before training the CNN on the data of interest, it is recommended to pre-train the network on a much larger related problem, such as the ILSVRC N challenge _cite_ . This regularization technique addresses the issue of overfitting, and allows large CNNs to be effectively applied to small problems. Second, in problems where spatial information is important, it is potentially better to encode this information in multiple networks trained on specific regions of interest than in a single network trained on the entire image _cite_ . More generally, this second point suggests that it is unnecessary to rely entirely on machine learning, especially when human knowledge can be easily implemented in the system. This paper seeks to investigate whether these insights are relevant to document image analysis. Finally, CNNs in other domains have recently been extended to the task of image retrieval. After a CNN is trained on classification, the layers of the network can be interpreted as forming a hierarchical chain of abstraction, where the lowest layers contain simple features, and the highest layers contain concise and descriptive representations _cite_ . Therefore, output extracted near the top of a CNN can serve as a feature vector which can be used for any task, including retrieval _cite_ . The present work is the first to apply this idea toward document retrieval. In the light of previous work, this paper makes the following contributions. First, the paper thoroughly evaluates the power of deep CNN features for representing document images. Toward this end, the paper presents experiments in CNN design, training, feature processing, and compression. Results show that features extracted from CNNs are superior to all handcrafted competitors, and furthermore can be compressed to very short codes with negligible loss in performance. Second, this work demonstrates that CNNs trained on non-document images transfer well to document-related tasks. Third, this paper explores a strategy of embedding human knowledge of document structure into CNN architectures, by guiding an ensemble of CNNs toward learning region-specific features. Interestingly, results show little to no improvement in classification and retrieval after this augmentation, suggesting that a basic holistic CNN may be learning region-specific features (or perhaps better features) automatically. Finally, this work makes available a new labelled subset of the IIT-CDIP collection of tobacco litigation documents _cite_, containing N, N document images across N categories.