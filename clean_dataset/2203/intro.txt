Image sharing in social networks has increased exponentially in the past years. For example, according to official Instagram stats, there are N million Instagrammers uploading around N million photos and videos per day. Although the analysis of trends, topics and brands in social networks is mostly based solely on texts, the analysis of such a vast amount of images is starting to play an important role for understanding and predicting human decision making, while becoming essential for digital marketing, and customer understanding, among others. Previous works have proven the relation between text and the personality of the authors _cite_, and recent studies have also shown that some image features can be related to the personality of users in social networks _cite_ . The main hypothesis of this work is that the relation between text and personality observed by researchers like Yarkoni _cite_ translates well into a relation between images and personality when we consider the images conditioned on specific word use. In his work, Yarkoni proved that there exist words that correlate with different personality traits with statistical evidence, see Table _ref_ . For example, a neurotic personality trait correlates positively with negative emotion words such as 'awful' or 'terrible', whereas an extroverted person correlates positively with words reflecting social settings or experiences like 'bar', 'drinking' and 'crowd'. Considering this proven relation between text and personality, and the fact that posted images have a relation with their accompanying texts, we propose a methodology which, taking advantage of such existing text-personality correlation, exploits the relation between texts and images in social networks to determine those images most correlated with personality traits. The final aim is to use this set of images to train a personality model with similar performances than previous work based on texts or images alone. In the computer vision community, the relationship between language and images has been exploited to automatically generate textual descriptions from pictures _cite_ . Indeed automatic captioning can be understood as a sampling process of words from a text distribution _inline_eq_ given an image _inline_eq_, or _inline_eq_ . In this paper we aim at the opposite: we want to determine _inline_eq_, that means, those images mostly related with a specific word that is strongly associated to a particular personality trait. Once the set of images is defined, the potential relation between personality and images will be modeled using a state-of-the-art deep neural network. Classification results will suggest whether there is psychological content in certain images, like it has been previously observed for certain texts and image features. In our work, the human personality characterization called the model of personality is considered _cite_ . The Big Five model is a well-researched personality description, which has been proven to be consistent across age, gender, language and culture _cite_ . In essence, this model distinguishes five main different human personality dimensions: Openness to experience (O), Conscientiousness (C), Extraversion (E), Agreeableness (A) and Neuroticism (N), hence it is often referred as OCEAN . Personality traits are characterized in the OCEAN model by the following features: The five personality traits have already been related to text _cite_ and images _cite_ uploaded by users. Therefore, personality might be an important factor in the underlying distribution of the user's public posts in social media, and thus, it is possible to infer some degree of personality knowledge from such data. In this work we go a step beyond the works in _cite_, and _cite_, showing that personality remains invariant to changes from the text domain to the image domain. Concretely, our contributions are: