Deep learning methods have gained interest from the machine learning and computer vision research community over the last years because these methods provide exceptional performance in classification tasks. Especially Convolutional Neural Networks (CNNs)---first introduced in N by LeCun et el.~ _cite_---have become popular for object classification. CNNs were more widely used after the deep CNN from Krizhevsky et al.~ _cite_ outperformed the state of the art methods in ILSVRCN~ _cite_ by a wide margin in N. Convolutional neural networks consist of multiple layers of nodes, also called neurons. One important layer type is the convolutional layer from which the networks obtain their name. In a convolutional layer the responses of the nodes depend on the convolution of a region of the input image with a kernel. Additional layers introduce non-linearities, rectification, pooling, etc. The goal of training a CNN lies in optimizing the network weights using image-label pairs to best reconstruct the correct label given an image. During testing the network is confronted with novel images and expected to generate the correct label. The network is trained by gradient descent. The gradient is calculated by backpropagation of labeling errors. The general idea of CNNs is to automatically learn the features needed to distinguish classes and generate increasingly abstract features as the information moves up the layers. Since CNNs are very popular at the moment and perceived---in parts of the computer vision community---as obtaining human like performance we wanted to test their applicability on visual tasks slightly outside the mainstream which are still trivially solvable by humans. We chose to learn simple abstract classes using a standard CNN not because we assume that they will perform better on the tasks than other, possibly much simpler methods, but because we want to gain insights into CNNs and how they perform on tasks which can be solved trivially by humans. We will mainly try to give insight into the amount of training images needed and how well the classifier generalizes to previously unseen shapes representing the same abstract concepts. Until now, most of the classes used for training and testing convolutional neural networks were concrete (e.g. \detecting classes of objects, animal species in an image, \dots) . One notable exception is the work by G {\"u} l {} ehre et al. _cite_ who trained a CNN to recognize whether multiple presented shapes are the same. This is in essence a training on two abstract classes. The problems presented by Bongard~ _cite_ inspired us to do the research presented in this paper. Foundalis~ _cite_ gives a good introduction to these problems and presents a system intended to solve them computationally. He used other methods than deep learning though. Previously, Fleuret et al. _cite_ compared human performance to classical machine learning methods (Adaboost on decision stumps and Support Vector Machines) on classification tasks. The classes used were similar in spirit to Bongard problems (e.g. \object similarity, relative position,) . Problems of similar nature are also often given at aptitude and intelligence tests to measure the ability for abstract, non-verbal reasoning. We decided to use the two classes horizontal and vertical for our classification experiments since they are abstract, visually unambiguous, easy to differentiate by humans, and easily transfer to very different shapes. The goal is to learn a classifier that can distinguish between horizontally and vertically oriented structures and can transfer this knowledge to previously unseen objects and shapes. These are the first experiments exploring the representational capabilities of current deep learning systems regarding abstract classes.