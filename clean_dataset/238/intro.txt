Recognizing objects and estimating their poses in ND has a wide range of applications in robotic tasks. For instance, recognizing the ND location and orientation of objects is important for robot manipulation. It is also useful in human-robot interaction tasks such as learning from demonstration. However, the problem is challenging due to the variety of objects in the real world. They have different ND shapes, and their appearances on images are affected by lighting conditions, clutter in the scene and occlusions between objects. Traditionally, the problem of ND object pose estimation is tackled by matching feature points between ND models and images _cite_ . However, these methods require that there are rich textures on the objects in order to detect feature points for matching. As a result, they are unable to handle texture-less objects. With the emergence of depth cameras, several methods have been proposed for recognizing texture-less objects using RGB-D data _cite_ . For template-based methods _cite_, occlusions significantly reduce the recognition performance. Alternatively, methods that perform learning to regress image pixels to ND object coordinates in order to establish the ND-ND correspondences for ND pose estimation _cite_ cannot handle symmetric objects. In this work, we propose a generic framework for ND object pose estimation where we attempt to overcome the limitations of existing methods. We introduce a novel Convolutional Neural Network (CNN) for end-to-end ND pose estimation named PoseCNN. A key idea behind PoseCNN is to decouple the pose estimation task into different components, which enables the network to explicitly model the dependencies and independencies between them. Specifically, PoseCNN performs three related tasks as illustrated in Fig.~ _ref_ . First, it predicts an object label for each pixel in the input image. Second, it estimates the ND pixel coordinates of the object center by predicting a unit vector from each pixel towards the center. Using the semantic labels, image pixels associated with an object vote on the object center location in the image. In addition, the network also estimates the distance of the object center. Assuming known camera intrinsics, estimation of the ND object center and its distance enables us to recover its ND translation _inline_eq_ . Finally, the ND Rotation _inline_eq_ is estimated by regressing convolutional features extracted inside the bounding box of the object to a quaternion representation of _inline_eq_ . As we will show, the ND center voting followed by rotation regression to estimate _inline_eq_ and _inline_eq_ can be applied to textured/texture-less objects and is robust to occlusions since the network is trained to vote on object centers even when they are occluded. Handling symmetric objects is another challenge for pose estimation, since different object orientations may generate identical observations. For instance, it is not possible to uniquely estimate the orientation of the red bowl or the wood block shown in Fig.~ _ref_ . While pose benchmark datasets such as the OccludedLINEMOD dataset _cite_ consider a special symmetric evaluation for such objects, symmetries are typically ignored during network training. However, this can result in bad training performance since a network receives inconsistent loss signals, such as a high loss on an object orientation even though the estimation from the network is correct with respect to the symmetry of the object. Inspired by this observation, we introduce ShapeMatch-Loss, a new loss function that focuses on matching the ND shape of an object. We will show that this loss function produces superior estimation for objects with shape symmetries. We evaluate our method on the OccludedLINEMOD dataset~ _cite_, a benchmark dataset for ND pose estimation. On this challenging dataset, PoseCNN achieves state-of-the-art results for both color only and RGB-D pose estimation (we use depth images in the Iterative Closest Point (ICP) algorithm for pose refinement) . To thoroughly evaluate our method, we additionally collected a large scale RGB-D video dataset named YCB-Video, which contains ND poses of N objects from the YCB object set~ _cite_ in N videos with a total of N, N frames. Objects in the dataset exhibit different symmetries and are arranged in various poses and spatial configurations, generating severe occlusions between them. In summary, our work has the following key contributions: \noindent This paper is organized as follows. After discussing related work, we introduce PoseCNN for ND object pose estimation, followed by experimental results and a conclusion.