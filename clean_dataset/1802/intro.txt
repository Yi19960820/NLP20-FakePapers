Image-based localization, or camera relocalization refers to the problem of estimating camera pose (orientation and position) from visual data. It plays a key role in many computer vision applications, such as simultaneous localization and mapping (SLAM), structure from motion (SfM), autonomous robot navigation, and augmented and mixed reality. Currently, there are plenty of relocalization methods proposed in the literature. However, many of these approaches are based on finding matches between local features extracted from an input image (by usually applying local image descriptor methods such as SIFT, ORB, or SURF~ _cite_) and features corresponding to ND points in a model of the scene. In spite of their popularity, feature-based methods are not able to find matching points accurately in all scenarios. In particular, extremely large viewpoint changes, occlusions, repetitive structures and textureless scenes often produce simply too many outliers in the matching process. In order to cope with many outliers, the typical first aid is to apply RANSAC which unfortunately increases time and computational costs. The increased computational power of graphic processing units (GPUs) and the availability of large-scale training datasets have made Convolutional Neural Networks (CNNs) the dominant paradigm in various computer vision problems, such as image retrieval~ _cite_, object recognition, semantic segmentation, and image classification~ _cite_ . For image-based localization, CNNs were considered for the first time by Kendall \etal~ _cite_ . Their method, named PoseNet, casts camera relocalization as a regression problem, where N-DoF camera pose is directly predicted from a monocular image by leveraging transfer learning from a large scale classification data. Although PoseNet overcomes many limitations of the feature-based approaches, its localization performance still lacks behind traditional approaches in typical cases where local features perform well. Looking for possible ways to further improve the accuracy of image-based localization using CNN-based architectures, we adopt some recent advances discovered in efforts solving the problems of image restoration~ _cite_, semantic segmentation~ _cite_ and human pose estimation~ _cite_ . Inspired by these ideas, we propose to add more context to the regression process to better collect the overall information, from coarse structures to fine-grained object details, available in the input image. We argue that this kind of a mechanism is suitable for getting an accurate camera pose estimate using CNNs. In detail, we propose a network architecture which consists of a bottom part (the encoder) that is used to encode the overall context and a latter part (the decoder) that recovers the fine-grained visual information by up-convolving the output feature map of the encoder by gradually increasing its size towards the original resolution of the input image. Such a symmetric "encoder-decoder" network structure is also known as an hourglass architecture~ _cite_ . The contributions of this paper can be summarized as follows: The remainder of this paper is organized as follows. Section~ _ref_ discusses related work. In Section~ _ref_ we provide the details of the proposed CNN architecture. Section~ _ref_ presents the experimental methodology and results on a standard evaluation dataset. We conclude with a summary and ideas for future work. The source code and trained models will be publicly available upon publication.