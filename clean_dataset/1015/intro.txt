Person Re-identification (Re-ID) is the problem of identifying the re-appearing person in a non-overlapping multi-camera surveillance system. Two primary tasks in person Re-ID are learning the subjects' features and developing new similarity measurements, which should be invariant to the viewpoint, pose, illumination and occlusion. Due to its potential applications in security and surveillance, person Re-ID has received substantial attention from both academia and industry. As a result, the person Re-ID performance on existing datasets has been significantly improved in the recent years. For example, the Rank-N accuracy of a single query search on the MarketN dataset _cite_ has been pushed from N \% _cite_ to N \% _cite_ . The Rank-N accuracy of the DukeMTMC-reID dataset _cite_ released in N has been quickly improved from N \% _cite_ to N \% _cite_ . However, most of these approaches follow supervised learning frameworks which required a large number of manually labelled images . In real-world person Re-ID deployment, typical video surveillance systems usually consist of over one hundred cameras. Manual labelling all those cameras is a prohibitively expensive job. The limited scalability severely hinders the applicability of existing supervised Re-ID approaches in the real-world scenarios. One solution to make a person Re-ID model scalable is designing an unsupervised algorithm for the unlabelled data. In recent years, some unsupervised methods have been proposed to extract view-invariant features and measure the similarity of images without label information _cite_ . These approaches only analyse the unlabelled datasets and generally yield poor person Re-ID performance due to the lack of strong supervised tuning and optimisation. Another approach to solve the scalability issue of Re-ID is unsupervised transfer learning via domain adaptation strategy. The unsupervised domain adaptation methods leverage labelled data in one or more related source datasets (also known as source domains) to learn models for unlabelled data in a target domain. However, most domain adaptation frameworks _cite_ assume that the source domain and target domain contain the same set of class labels. Such assumption does not hold for person Re-ID because different Re-ID datasets usually contain completely different sets of persons (classes) . Therefore, most unsupervised cross-dataset Re-ID methods proposed in recent years _cite_ did not use conventional domain adaptation mechanisms. For example, _cite_ uses image-to-image translation to transfer the style of images in the target domain to the source domain images for generating a new training dataset. These newly generated samples which inherit the identity labels from the source domain and the image style of the target domain can be used for supervised person Re-ID learning. _cite_ trains two individual models: identity classification and attribute recognition and performs the domain adaptation between two models. In our work, we rethink the assumption made for the unsupervised cross-dataset Re-ID. Although the identity labels of the source and target datasets are non-overlapping, many of the mid-level semantic features of different people such as genders, age-groups or colour/texture of the outfits are commonly shared between different people across different datasets. Hence, these mid-level visual attributes of the people can be considered as the common labels between different datasets. If we assume these mid-level semantic features are shared between the different domains, we can then treat the unsupervised cross-dataset person Re-ID as a domain adaptation transfer learning based on the mid-level semantic features from the source domain to the target domain. Therefore, we propose a M ulti-task M id-level F eature A lignment network (MMFA) which can simultaneously learn the feature representation from the source dataset and perform domain adaptation to the target dataset via aligning the distributions of the mid-level features. The contributions of our MMFA model are summarized below: