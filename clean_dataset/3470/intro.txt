Image classification is a fundamental problem in computer vision. With the availability of large-scale image datasets~ _cite_ and powerful computational resources such as modern GPUs, it is possible to train a convolutional neural network (CNN) ~ _cite_ which significantly outperforms the conventional models like the Bag-of-Visual-Words~ _cite_ . Most CNN architectures contain convolutional (or fully-connected) layers with a large number of filters, which are designed to capture the increasing number of mid-level or high-level visual concepts. These layers contribute significantly to model complexity. As an example, the first fully-connected layer of {\bf AlexNet} ~ _cite_ contains _inline_eq_ filters, requiring _inline_eq_ parameters (more than _inline_eq_ of the parameters used in the entire network) . We formulate the function of a convolutional layer as learning a large visual vocabulary, in which each filter is used to detect a specific visual concept via template matching. Note that some previous work trains a large visual vocabulary~ _cite_ using the composition of several small ones. This idea is successfully applied to approximate nearest neighbor search~ _cite_ _cite_, image classification~ _cite_ and retrieval~ _cite_ . We borrow this idea to reduce the computational complexity of the convolutional layers. Our algorithm is named {\bf Deep Collaborative Learning} (DCL) . It is a generalized module which applies to a wide range of network structures. The idea is very simple: a large convolutional layer can be simulated with the combination of several small convolutional layers. As illustrated in Figure~ _ref_, DCL is a two-stage module to replace a convolutional layer. At the first stage, we individually construct several convolutional layers with the same spatial resolution. These {\em branches} are fused at the second stage, which involves linear weighting followed by element-wise operation at each spatial position. In mathematics, DCL can be explained as an efficient way of constructing a compositional visual vocabulary, in which we spend linear complexity to increase the vocabulary size exponentially. We evaluate DCL on a wide range of visual recognition tasks. First, we generate a series of multi-digit number classification datasets by pasting random {\bf MNIST} digits into a fixed spatial layout (see Section~ _ref_ for details) . We keep the number of training images unchanged, although the number of categories grows exponentially. DCL works better than conventional models because of two factors. First, DCL enjoys a lower risk of over-fitting, especially in the scenario that the amount of training data is limited. Second, as shown in visualization, DCL uses different branches to learn complementary visual concepts, so that they can be combined to represent the large but decomposable set of visual categories. We also apply DCL to some state-of-the-art network structures, and achieve high accuracy on some generic recognition tasks, including {\bf SVHN}, {\bf CIFAR} and {\bf ILSVRCN} . The remainder of this paper is organized as follows. Section~ _ref_ briefly reviews related work. The Deep Collaborative Learning (DCL) module is presented in Section~ _ref_ . In Section~ _ref_, we evaluate DCL on a wide range of visual recognition tasks. Conclusions are drawn in Section~ _ref_ .