Object detection is one of the most fundamental problems in computer vision. It has various real-world applications, ranging from robotics, autonomous car, to video surveillance and image retrieval. Object detection is very challenging since it suffers from scale variation, viewpoint change, intra-class variation, shape variation, and occlusion of object, as well as background clutters. Deep ConvNets are excellent at learning representation, thus, to some extent, deep ConvNets based object detectors are more robust to the challenges mentioned above. However, explicit modeling is still beneficial to solving the object detection problem. Different from the previous deep ConvNets based detectors which focus on learning better features for this task, in this paper, we propose to study better object model to achieve better object detector in the framework of deep ConvNets. After the deep ConvNets had obtained great successes on image classification~ _cite_, utilizing deep ConvNets for object detection is becoming a new challenge. The developments of object detection using deep learning can be summarized into two stages. In the first stage, the object detectors based on deep ConvNets follows the ``sliding window" strategy. They learn classifiers to check candidate windows one by one and obtain the top scoring candidate windows after non-maximum suppression as the detection results, such as OverFeat _cite_, R-CNN _cite_, Fast-R-CNN _cite_ . These kinds of methods have some limitations: N) The detector only sees local information when making a decision and is hard to reason about global context. N) Even most of the deep CNN features of candidate windows are shareable, learning additional features for individual windows and classifying them are still computationally expensive. Thus, these methods are relatively slow. In the second stage, deep detectors can directly predict/regress object bounding boxes using a single ConvNet, such as Deep MultiBox~ _cite_, YOLO~ _cite_, Faster-R-CNN~ _cite_, and~SSD _cite_ . A common strategy is to map a labeled bounding-box to a grid in the convolutional feature map and then each cell responses to predicting the coordinates and class label (\eg, _inline_eq_) of the mapped bounding box. When predicting the coordinates, usually a cell has multiple anchors for different default aspect ratios of bounding box. The crux of these methods is representing a various number of bounding boxes using a fixed length vector (the grids with no matched bounding box will be ignored during training) . Deep ConvNets are excellent at learning a mapping between the input image and a fixed length vector contains its semantic information and there is no extra computation for a large number of candidate windows. Thus YOLO, Faster-R-CNN, SSD \etc have obtained very impressive object detection accuracy and speed. However, current bounding box regression methods still suffer from the large variation of the aspect ratios of bounding boxes, scale variation, and occlusion. To address these problems, we propose a new solution for object detection based deep networks. We cast the object detection problem into two sub-problems: a point detection problem and a point linking problem. As shown in Fig.~ _ref_, there are two kinds of points in our system, the center point of an object bounding box which is denoted as _inline_eq_ and a corner point of an object bounding box, \eg _inline_eq_ . There are four corner points in Fig.~ _ref_ which are the top-left corner, the top-right corner, the bottom-left corner and the bottom-right corner. It is clear that any pair of center point and corner point can determine a bounding box. In order to detect the point pair, there are two tasks, the first task is to localize the two points that is termed as point detection, and the second task is to associate the two points, say the points belonging to the same object, which termed as point linking. This is the general object detection idea in this paper, which is point-based object detection framework. Compared to the previous bounding box regression methods, this new framework has three advantages: N) It is very flexible to represent bounding box in any scale and any aspect ratio. N) For each bounding box, there are at least four pairs of points, object detection performance can be boosted via voting. N) It is naturally robust to occlusion, since it can infer object location using local cues. We implement this point-based object detection framework using a single deep network, termed as Point Linking Network (PLN) . In PLN, both point detection and point linking are implemented in a joint loss function. As shown in Fig.~ _ref_, each grid cell represents a grid cell the convolutional feature map of the input image. A grid cell is responsible for predicting the center point inside includes its confidence, x-offset, y-offset and link, as well as the corner point inside also includes its confidence, x-offset, y-offset and link. The details will be introduced in Section~ _ref_ . We have tested it on the standard object detection benchmarks, PASCAL VOC N \& N, and COCO. The results show PLN is superior to the widely used Faster-RNN, YOLO and SSD in the same data augmentation setting.