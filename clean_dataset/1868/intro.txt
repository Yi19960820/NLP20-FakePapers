object tracking aims to locate a target object in a video sequence given its location in the first frame. It is a very challenging problem because target appearance may vary dramatically due to illumination change, partial occlusion, object deformation, etc. To solve these issues, some trackers _cite_ employ local patch based appearance models to achieve very promising performance. Feature representation is very important to object tracking. Recently, deep learning based trackers _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ have achieved very promising performance by using learned hierarchical features rather than raw pixel values or hand-crafted features. Deep neural networks usually require a lot of training data to learn a large number of parameters. However, training data is not sufficient for visual object tracking as annotations of a target object are only available in the first frame of a test sequence. To overcome this problem, existing feature learning based trackers pre-train their neural networks by using auxiliary data and then fine-tune network parameters according to specific target objects. Different from these methods, we propose to learn hierarchical features for visual object tracking by using tree structure based Recursive Neural Networks (RNN), which have fewer parameters than other deep neural networks, \eg Convolutional Neural Networks (CNN) . As a result, our feature learning method does not require any network pre-training on auxiliary data and will not suffer from fine-tuning network parameters. First, we learn RNN parameters to discriminate between target object and background in the first frame of a test sequence. Tree structure over local patches of an exemplar region is randomly generated by using a bottom-up greedy search strategy. Given the learned RNN parameters, we create two dictionaries regarding target regions and corresponding local patches based on the learned hierarchical features from both top and leaf nodes of multiple random trees. In each of the subsequent frames, we conduct sparse dictionary coding on all candidates to select the best candidate as the new target location. In addition, we online update two dictionaries to handle appearance changes of target objects. The main contribution is that hierarchical features are learned to discriminate between target and background by using RNN which can successfully encode spatial information among local patches of a target object based on multiple random trees. RNN features learned at top nodes of random trees are able to capture structural information of target objects, which are robust to holistic appearance changes caused by illumination change or object deformation. Moreover, RNN features learned at leaf nodes represent local patches and capture local appearance changes due to partial occlusion. Therefore, our hierarchical features learned from both top and leaf nodes are beneficial for visual object tracking. Experimental results demonstrate that using our feature learning method can significantly improve tracking performance on the benchmark dataset _cite_ .