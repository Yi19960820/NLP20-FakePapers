Deep Convolutional Networks (ConvNets) _cite_ are the architecture of choice for many practical problems such as large-scale image recognition _cite_ . Typically, these networks have millions of free parameters that are learned from large datasets. The great success of ConvNets and an abundance of hardware and software frameworks _cite_ has led to the availability of a set of pre-trained models for specified tasks. Retraining these pre-trained models to a new task allows to successfully use ConvNets also in small sample settings _cite_ . This procedure is an instance of the transfer learning paradigm _cite_ . In a nutshell, a model is trained on a domain related to the problem at hand, then adapted to the target domain with only few data points. In this contribution a pre-trained deep neural network trained for gender and age classification _cite_ is used and subsequently retrained to predict psychological attributes such as attractiveness, happiness, confidence and intelligence from face photographs. Since most labelled attribute datasets are rather small, we use a pre-trained model and thus harvest from the rich representation that the neural network has learned on a related problem. If the tasks are sufficiently similar, we can transfer the knowledge acquired by the pre-trained model from one domain, e.g., age or gender, to another, e.g., happiness or attractiveness. Our study is based on the Nk US faces dataset _cite_ . Note that only a subset of N images in that dataset are labelled with the needed attributes. Therefore we retrain the neural network _cite_ to reproduce the human assessment labels from the Bainbridge dataset. However, our focus is not primarily the excellent prediction of these attributes as such, but the explanation thereof. So, we focus on the question of {\it what} makes the neural network assign certain attractiveness, happiness scores etc. \to a novel test image and whether this assignment corresponds to what we as humans expect. For this we apply a recently proposed explanation method termed Layer-wise Relevance Propagation (LRP) _cite_ that allows a better understanding of what a neural network is using as decisive features on a single sample basis. We visualize the rationale of the trained predictors using this method, study its robustness and relate the results to human expectations.