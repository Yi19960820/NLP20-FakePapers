Image segmentation is a fundamental task in biomedical image analysis. Recent advances in deep learning _cite_ have achieved promising results on many biomedical image segmentation benchmarks _cite_ . Due to its accuracy and generality, deep learning has become a main choice for image segmentation. But, despite its huge success in biomedical applications, deep learning based segmentation still faces a critical obstacle: the difficulty in acquiring sufficient training data due to high annotation efforts and costs. Comparing to applications in natural scene images, it is much harder to acquire training data in biomedical applications for two main reasons. (N) Only trained biomedical experts can annotate data, which makes crowd leveraging quite difficult. (N) Biomedical images often contain much more object instances than natural scene images, which can incur extensive manual efforts of annotation. For example, public datasets in biomedical areas have significantly fewer spatial annotated images (N for MICCAI Gland Challenge _cite_ ; N for ISBI EM Challenge _cite_) . To alleviate the common burden of manual annotation, an array of weakly supervised segmentation algorithms _cite_ has been proposed. However, they did not address well the question that which data samples should be selected for annotation for high quality performance. Active learning _cite_, which allows the learning model to choose training data, provided a way to answer this need. As shown in _cite_, using active learning, state-of-the-art level performance can be achieved using significantly less training data in natural scene image segmentation. But, this method is based on the pre-trained region proposal model and pre-trained image descriptor network, which cannot be easily acquired in biomedical image settings due to large variations in biomedical applications. In this paper, we present a new framework that combines fully convolutional network (FCN) _cite_ and active learning _cite_ to reduce annotation effort by making judicious suggestions on the most effective annotation areas. To address the issues in _cite_, we exploit FCN to obtain domain specific image descriptor and directly generate segmentation without using region proposals. Fig.~ _ref_ outlines the main ideas and steps of our deep active learning framework. Starting with very little training data, we iteratively train a set of FCNs. At the end of each stage, we extract useful information (such as uncertainty estimation and similarity estimation) from these FCNs to decide what will be the next batch of images to annotate. After acquiring the new annotation data, the next stage is started using all available annotated images. Although the above process seems straightforward, we need to overcome several challenges in order to integrate FCNs into this deep active learning framework, as discussed below. Challenges from the perspective of FCNs. (N) The FCNs need to be fast to train, so that the time interval between two annotation stages is acceptable. (N) They need to be of good generality, in order to produce reasonable results when little training data is available. To make the model fast to train, we utilize the ideas of batch normalization _cite_ and residual networks _cite_ . Then, we use bottleneck design _cite_ to significantly reduce the number of parameters (for better generality) while maintaining a similar number of feature channels as in _cite_ . Challenges from the perspective of active learning. It needs to exploit well the information provided by the FCNs when determining the next batch of training data. For this, we first demonstrate how to estimate uncertainty of the FCNs based on the idea of bootstrapping and how to estimate similarity between images by using the final layer of the encoding part of the FCNs. Based on such information, we formulate a generalized version of the maximum set cover problem _cite_ for suggesting the next batch of training data. Experiments using the N MICCAI Gland Challenge dataset _cite_ and a lymph node ultrasound image segmentation dataset _cite_ show that (N) annotation suggestions by our framework are more effective than common methods such as random query and uncertainty query, and (N) our framework can achieve state-of-the-art segmentation performance by using only N \% of training data.