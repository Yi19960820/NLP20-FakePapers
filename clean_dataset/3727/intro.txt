smart city aims to improve quality and performance of urban services by using digital technologies or information and communication technologies. Data analytics plays an important role in smart cities. Many sensors are installed in a smart city to capture a huge volume of data such as surveillance videos, environment and transportation data. To capture useful information from such big data, machine learning algorithms are often used and have achieved very promising results in a wide range of applications, \eg video analytics. Therefore, leveraging on machine learning can facilitate smart city development. Machine learning aims to develop the computer algorithms which can learn experience from example inputs and make data-driven predictions on unknown test data. Such algorithms can be divided into two categories: supervised learning (\eg _cite_ _cite_) and unsupervised learning (\eg _cite_ _cite_) . Given labeled input and output pairs, supervised learning aims to find a mapping rule for predicting outputs of unknown inputs. In contrast, unsupervised learning focuses on exploring intrinsic characteristics of inputs. Supervised learning and unsupervised learning are complementary to each other. Since supervised learning leverages labels of inputs which are meaningful to human, it is easy to apply this kind of learning algorithms to pattern classification and data regression problems. However, supervised learning relies on labeled data which could cost a lot of manual works. Moreover, there are uncertainties and ambiguities in labels. In other words, the label for an object is not unique. To mitigate these problems, unsupervised learning can be used to handle intra-class variation as it does not require labels of data. In the past decades, machine learning methods have been applied to a wide range of applications such as bioinformatics, computer vision, medical diagnosis, natural language processing, robotics, sentiment analysis, speech recognition and stock market analysis, etc. In this paper, we focus on reviewing the recent achievements of deep learning which is a subfield of machine learning. In contrast with shallow learning algorithms, deep learning aims to extract hierarchical representations from large-scale data (\eg images and videos) by using deep architecture models with multiple layers of non-linear transformations. With such learned feature representations, it becomes easier to achieve better performance than using raw pixel values or hand-crafted features. The principle behind this success is that deep learning is able to disentangle different levels of abstractions embedded in observed data by elaborately designing the layer depth and width, and properly selecting features that are beneficial for learning tasks. In fact, the history of deep learning starts at least from N, when Neocognitron _cite_ is proposed by Fukushima. In N, LeCun \etal _cite_ propose to apply backpropagation onto a deep neural network for handwritten ZIP code recognition. However, the training time on the network was too long for practical use. Also, deep neural networks have been studied in speech recognition for many years, but can hardly surpass the shallow generative models. It is due to the fact that deep learning architectures require large training data which was scarce in those early days. Hinton \etal _cite_ review these difficulties and claim their confidence of solving these issues for applying deep learning to speech recognition, since Hinton _cite_ has achieved breakthroughs on training multi-layer neural networks by pre-training one layer at a time as an unsupervised restricted Boltzmann machine and then using supervised backpropagation for fine-tuning. Since the breakthrough of deep learning, it has been applied to many other research areas besides speech recognition. Deep learning architectures have different variants such as Deep Belief Networks (DBN) _cite_, Convolutional Neural Networks (CNN) _cite_, Deep Boltzmann Machines (DBM) _cite_ and Stacked Denoising Auto-Encoders (SDAE) _cite_, etc. The most attractive model is Convolutional Neural Networks which have achieved very promising results in both computer vision and speech recognition. An illustration of the CNN proposed by LeCun \etal _cite_ for digits recognition is presented in Figure~ _ref_ . As shown in the figure, a CNN usually consists of convolutional layers, pooling layers and fully connected layers. With loss layers on the top of the CNN, the whole network can be trained end-to-end by using the backpropagation algorithm. Compared to other deep feed-forward neural networks, a CNN is easier to train as it has fewer parameters to estimate. As a result, CNN has a wide range of applications such as image classification _cite_, face recognition _cite_, object tracking _cite_, pedestrian detection _cite_, attribute prediction _cite_, scene labeling _cite_, person re-identification _cite_, RGB-D object recognition _cite_, image labeling _cite_, scene image classification _cite_, speech recognition _cite_ and natural language processing _cite_, etc. Deep learning has received much attention from not only academic but also industry. For example, Geoff Hinton and Li Deng started their collaborations from N in the focus of applying deep learning to large-scale speech recognition, in which the performance is significantly improved against the traditional generative models by using big training data and the correspondingly designed deep neural networks. Another exciting example is that Andrew Ng and Jeff Dean from the Google Brain team successfully extract object-level semantics (\eg cats) from unlabeled YouTube videos by using a neural network with the self-taught capacity. In future, deep learning will have more and more real applications in industry. Besides methodology breakthroughs and available big training data, the recent success for deep learning is also due to advances in hardware. Specifically, an electronic circuit called Graphics Processor Unit (GPU) is designed for accelerating the algorithms that need to process a large number of blocks of data, and is characteristic of its highly parallel structure. For example, Nvidia's latest GPU, the GTX _inline_eq_, is based on their _inline_eq_ th generation GPU architecture, called Maxwell, which delivers double the performance per watt compared to the previous generation. The GM _inline_eq_ chip is composed of an array of _inline_eq_ Graphics Processing Clusters (GPCs), _inline_eq_ Streaming Multiprocessors (SMs), and _inline_eq_ memory controllers. The GeForce GTX _inline_eq_ uses the full complement of these architectural components. Its parallel structure is illustrated in Figure~ _ref_ . It is necessary to mention that the Nvidia company has made a lot of contributions for popularizing GPUs, \eg Nvidia marketed the GeForce N as the world's first GPU. Recently, GPUs are very popular in machine learning. For a general instance, Raina \etal _cite_ propose to accelerate the sparse coding algorithm _cite_ by using GPUs and finally speed up the previous method using a dual-core CPU up to _inline_eq_ times. In particular, Raina \etal _cite_ also report that the GPU speedup on learning Deep Belief Networks (DBNs) achieves up to _inline_eq_ times against a dual-core CPU implementation. For learning a four-layer DBN with _inline_eq_ million parameters, using GPU rather than CPU is able to reduce the required time from several weeks to around a single day. Smart city is so-called ``smart" as it has the capability of computing and analyzing urban data collected from \eg monitoring systems, government agencies, commercial companies and social networking websites. Since deep learning is suitable for handling large-scale data, it can be used to process and analyze millions of video data captured from the distributed sensors in a smart city. Regarding such data, there are many active research topics such as object detection, object tracking, face recognition, image classification and scene labeling. In the following sections, we review the state-of-the-art deep learning algorithms in these application areas.