Accurate multi-label image segmentation is one of the top challenges in both computer vision and medical image analysis. Specifically, in computer-aided healthcare applications, medical image segmentation constitutes a critical step for tracking the evolution of anatomical structures and lesions in the brain using neuroimaging, as well as quantitatively measuring group structural difference between image populations _cite_ . Multi-label image segmentation is widely addressed as a classification problem. Previous works _cite_ used individual classifiers such as support vector machine (SVM) to segment each label class independently, then fuse the different label maps into a multi-label map. However, prior to the fusion step, the produced label maps may largely overlap one another, which might yield to biased fused label map. Alternatively, the integration of multiple classifiers within the same segmentation framework would help reduce this bias and improve the overall multi-label classification performance since M heads are better than one as reported in _cite_ . Broadly, one can categorize the segmentation methods that combine multiple classifiers into two groups: (N) cascaded classifiers, and (N) ensemble classifiers. In the first group, classifiers are chained such that the output of each classifier is fed into the next classifier in the cascade to generate the final segmentation result at the end of the cascade. Such architecture can be adopted for two different goals. First, cascaded classifiers take into account contextual information, encoded in the segmentation map outputted from the previous classifier, thereby enforcing spatial consistency between neighboring image elements (e.g., patches, superpixels) in the spirit of an auto-context model _cite_ . Second, this allows to combine classifiers hierarchically, where each classifier in the cascade is assigned to a more specific segmentation task (or a sub-task), as it further sub-labels the output label map of its antecedent classifier _cite_ . Although these methods produced promising results, and clearly outperformed the use of single (non-cascaded) classifiers in different image segmentation applications, cascading classifiers only allows a unidirectional learning transfer, where the learned mapping from the previous classifier is somehow ‘communicated' to the next classifier in the chain for instance through the output segmentation map. The second group represents ensemble classifiers based methods, which train individual classifiers, then aggregate their segmentation results _cite_ . Specifically, such frameworks combine a set of independently trained classifiers on the same labeling problem and generates the final segmentation result by fusing the individual segmentation results using a fusion method, which is typically weighted or unweighted voting _cite_ . Hence, it constructs a strong classifier that outperforms each individual `weak' classifier (or base classifier) _cite_ . For instance, Random Forest (RF) classification algorithm, independently trains weak decision trees using bootstrap samples generated from the training data to learn a mapping between the feature and the label sets _cite_ . The segmentation map of a new input image is the aggregation of the trees' decisions by major voting. RF demonstrated its efficiency in solving different image classification problems _cite_, which reflects the power of the ensemble classifiers technique. In addition to significantly improving the segmentation results when compared with single classifiers, ensemble classifiers based methods are powerful in addressing several known classification problems such as imbalanced correlation and over-fitting _cite_ . However, such combination technique is not enough to fully exploit the training of classifiers and leverage their strengths. Indeed, the base classifiers perform segmentation independently without any cooperation to solve the target classification problem. Moreover, the learning of each classifier in the ensemble is performed in one-step, as opposed to multi-step classifier training, where the learning of each classifier gradually improves from one step to the next one. We note that this differs from cascaded classifiers, where each classifier is ‘visited' or trained once through combining the contextual segmentation map of the previous classifier along with the original input image. To address the aforementioned limitations of both categories, we propose a Dynamic Multi-scale Tree (DMT) architecture for multi-label image segmentation. DMT is a binary tree, where each node nests a classifier, and each traversed path from the root node to a leaf node encodes a cascade of classifiers (i.e., nodes on the path) . Our proposed DMT architecture allows a bidirectional information flow between two successive nodes in the tree (from parent node to child node and from child node back to parent node) . Thus, DMT is based on ascending and descending feedbacks between each parent node and its children nodes. This allows to gradually refine the learning of each node classifier, while benefitting from the learning of its immediate neighboring nodes. To generate the final segmentation results, we combine the elementary segmentation results produced at the leaf nodes using majority voting strategy. The proposed architecture integrates different possible combinations of different classifiers, while taking advantage of their strengths and overcoming their limitations through the bidirectional learning transfer between them, which defines the dynamic aspect of the proposed architecture. Furthermore, the DMT inherently integrates contextual information in the classification task, since each classifier inputs the segmentation result of its parent node or children nodes classifiers. Additionally, to capture a coarse-to-fine image details for accurate segmentation, the DMT is designed to consider different scale at each level in the tree in a way that the adopted scale decreases as we go deeper along the tree edges nearing its leaf nodes. In this work, we define our DMT classification model using two strong classifiers: Structured Random Forest (SRF) and Bayesian Network (BN) . SRF is an improved version of Random Forest _cite_ . In addition of being fast, resistant to over-fitting and having a good performance in classifying high-dimensional data, SRF handles structural informationand integrates spatial information. It has shown good performance in several classification tasks especially muli-label image segmentation _cite_ . On the other hand, BN is a learning graphical model that statistically represents the dependencies between the image elements and their features. It is suitable for multi-label segmentation for its effectiveness in fusing complex relationships between image features of different natures and handling noisy as well as missing signals in images _cite_ . Embedding SRF and BN within our DMT leverages their strengths and helps overcome their limitations (i.e. not accurately classifying transitions between label classes for SRF and the problem of parameters learning such as prior probabilities for BN) . Moreover, the SRF-BN bidirectional cooperation during learning and testing stages enables the integration of multi-level image knowledge through the combination of regular and irregular image elements (i.e. patch-level classification produced by SRF and superpixel-level classification produced by BN) . To sum up, our SRF-BN DMT has promise for multi-label image segmentation as it: