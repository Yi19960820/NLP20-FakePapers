and noisy images are always annoying for a variety of practical applications such as image and video display, surveillance, to name a few. In order to enlarge image's resolution and enhance the quality of super-resolution image, a tremendous amount of works have been developed in the field of color super-resolution (SR) for several decades _cite_ . Recently several convolutional neural network (CNN) based methods such as _cite_ have reported better super-resolution results than previous methods, whose complexity could be an order of magnitude lower. One of the earliest CNN-based super-resolution works is three SRCNN in _cite_ . Latter, the deconvolution operation is used in _cite_ to directly learn the projection from low resolution (LR) image to high-resolution (HR) image. In _cite_, an efficient sub-pixel convolution layer is introduced to learn a series of filters to project the final LR feature maps into HR image. Different from the shallow neural network in _cite_, a very deep convolutional network is presented in _cite_ to learn image's residuals with extremely high learning rates. However, these methods' objective functions are always the mean squared SR errors, so their SR output images usually fail to have high-frequency details when the up-sampling factor is large. In _cite_, a generative adversarial network is proposed to infer photo-realistic images in terms of the perceptual loss. In addition to the single image SR, image SR with its neighboring viewpoint's high/low resolution image has also been explored. For instance, in _cite_ high-frequency information from the neighboring full-resolution views and corresponding depth image are used to enhance the low-resolution view images. In _cite_, except mixed resolutions, the multiple LR stereo observations are leveraged to increase image's resolution. Due to depth information's facilities to many real-world applications, depth SR problems have been widely explored in recent years. When only LR depth image is given, this SR problem is called single depth super-resolution. But, if the LR depth image is available accompanied with HR color image, researchers often name this kind problem of SR after joint depth SR/color image-guided SR. In _cite_, by searching a list of HR candidate patches from the database to match with the LR patches, the problem of depth SR is transformed into Markov random field (MRF) labeling problem to reconstruct the full HR image. After that, single depth SR is decomposed as two-step procedures: first the HR edge map is synthesized with HR patches according to the MRF optimization problem; and then a modified joint bilateral filtering is employed to achieve image up-sampling with this HR edge map _cite_ . Since the HR color image can be easily got by the consumer camera sensors in most cases, so the available color image can be used as an available prior information to upscaling the LR depth image, under the assumption of structural similarity between color image and depth image. Here, we just classify joint depth SR approaches into three classes: filtering-based methods, optimization methods and CNN-based SR methods. For example, bilateral filtering and guided image filtering are often used to get the interpolation weights to resolve the problem of depth SR _cite_ . The joint bilateral filtering in _cite_ use color image as a prior to guide the up-sampling from LR to HR. Meanwhile, bilateral filtering is iteratively used to refine the input low-resolution depth image in _cite_ to improve the spatial resolution and depth precision. Later, to prevent texture-copy artifacts from color image and against the inherent noisy nature of real-time depth data, an adaptive multi-lateral up-sampling filter in _cite_ is described to up-sample depth information. In _cite_, a more advanced filtering is called guided filtering, whose ambition is to transfer the structures from a guidance image into a target image. The second class of joint depth super-resolution methods often build their model by converting SR problems into the convex and non-convex optimization with different prior knowledge to regularize the objective function. For example, a MRF-based model _cite_, which consists of data term and smoothness prior term, is built up to align the discontinuities of depth image with color image's boundaries. However, this model always suffers from the texture-copy artifacts and depth bleeding artifacts, when color image could not provide enough information for depth image reconstruction. Thus, to sharpen depth boundaries and to prevent depth bleeding, a nonlocal means term is incorporated into the MRF model to help local structure to be preserved _cite_ . To suppress texture-copy artifacts and reduce computational cost, variable bandwidth weighting scheme _cite_ is used into the MRF model to adjust the guidance weights based on depth local smoothness. These methods of _cite_ implicitly put the inconsistency between the depth image and the color image into the smoothness term of MRF model. Later, a unified framework proposes to cast guided interpolation into a global weighted least squares optimization framework _cite_ . In _cite_, the higher order regularization is used to formulate depth image up-sampling as a convex optimization problem. In _cite_, a static and dynamic filter (SDF) is designed to address the problem of guided image filtering by jointly using structural information from the guidance image and input image. Although these recent advanced techniques achieve some appealing performances, they are built on the complex optimization algorithms using hand-designed objective functions, which always have high complexity of computation and limit their widely practical applications. Recently, deep joint image filtering framework based on convolutional neural network is proposed in _cite_ to adaptively transfer co-occurrence information from the guidance image to the target images. Meanwhile, in order to adaptively up-sample depth image's small-scale and large-scale structures, a multi-scale guided convolutional network is trained in high-frequency domain for up-sampling depth map _cite_ . Some of literatures always claim that LR depth image can be available and accompanied with HR color image in the dynamic scene, so the majority of these works put their emphasis on HR color image aided depth super-resolution. But they often lose sight of the significance of simultaneously depth image and color image SR with deep learning. As a matter of fact, this task is very important for several ND video application fields. For example, the ND-HEVC _cite_ has leveraged the full-resolution color video and depth video with multi-view video plus depth (MVD) format to compress ND video. If the techniques of simultaneous depth and color SR can be put into the ND-HEVC framework, apparently their coding efficiency can be greatly improved. From our investigation, we find some works such as _cite_ have embedded the CNN-based SR into HEVC coder to achieve significant bits saving, so the research of simultaneously depth and color image SR is a meaningful topic for both industry and academia. Recently, generative adversarial networks _cite_ is used to generate high-quality image to achieve the tasks of super-resolution and image style transfer, and image-to-image transfer _cite_ . In _cite_, perceptual loss function is applied on the tasks of image transformation such as image style transfer by training feed-forward networks. In _cite_, a general solution to the problem of image-to-image translation is proposed to finish a lot of tasks, such as synthesizing a new image from the label map, reconstructing a scene image from an edge map. Following the works of _cite_, we propose to use color-depth conditional generative adversarial network (CDcGAN) to deal with both challenging tasks of color SR and depth SR at the same time. Our generative network consists of five components: color feature extraction subnetwork, depth feature extraction subnetwork, color-depth feature merge subnetwork, color image reconstruction subnetwork and depth image reconstruction subnetwork. First, we respectively extract color feature and depth feature in the first two subnetworks and then these features are merged by color-depth feature merge subnetwork, which is inspired by the literature _cite_ . After that, color feature and/or depth feature feed into the last two subnetwork in addition to the merged depth-color features in order to produce HR color-depth images at the same time. Secondly, one discriminator is used to distinguish real color image from the generated color image. The reasons of why depth image SR without discriminator comes from a fact that depth image is not used to directly displayed on the screen, but it is always used as scene's geometry information to direct the rendering of virtual images with each pixel of depth image representing the distance between camera and object. Thus, only three auxiliary losses are taken to regularize depth image SR. Thirdly, in our generative network, three additional loss: data loss, Total Variation (TV) loss, and N-connected gradient difference loss are also used for color image, so as to ensure that image pairs produced by the generator are similar to the true image pairs. The rest of paper is organized as follows. First, our approach is presented in Section N. After experimental results are evaluated in Section N, we draw a conclusion in Section N.