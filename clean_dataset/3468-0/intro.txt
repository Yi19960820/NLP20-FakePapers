The image segmentation problem is a core vision problem with a longstanding history of research. Historically, this problem has been studied in the unsupervised setting as a clustering problem: given an image, produce a pixelwise prediction that segments the image into coherent clusters corresponding to objects in the image. In classical computer vision, there are a number of well-known techniques for this problem, including normalized cuts ~ _cite_, Markov random field-based methods~ _cite_, mean shift ~ _cite_, hierarchical methods ~ _cite_, and many others. Given the recent success of deep learning within the computer vision field, there has been a resurgence in interest in the image segmentation problem. The vast majority of recent work in this area has been focused on the problem of semantic segmentation ~ _cite_, a supervised variant of the image segmentation problem. Typically, these methods are trained using models such as fully convolutional networks to produce a pixelwise prediction, and supervised training methods can then be employed to learn filters to produce segments on novel images. One such popular recent approach is the U-Net architecture~ _cite_, a fully convolutional network that has been used to achieve impressive results in the biomedical image domain. Unfortunately, existing semantic segmentation methods require a significant amount of pixelwise labeled training data, which can be difficult to collect on novel domains. Given the importance of the segmentation problem in many domains, and due to the lack of supervised data for many problems, we revisit the problem of unsupervised image segmentation, utilizing recent ideas from semantic segmentation. In particular, we design a new architecture which we call W-Net, and which ties two fully convolutional network (FCN) architectures (each similar to the U-Net architecture) together into a single autoencoder. The first FCN encodes an input image, using fully convolutional layers, into a k-way soft segmentation. The second FCN reverses this process, going from the segmentation layer back to a reconstructed image. We jointly minimize both the reconstruction error of the autoencoder as well as a ``soft’’ normalized cut loss function on the encoding layer. In order to achieve state-of-the-art results, we further appropriately postprocess this initial segmentation in two steps: we first apply a fully conneceted conditional random field (CRF) ~ _cite_ smoothing on the outputted segments, and we second apply the hierarchical merging method of~ _cite_ to obtain a final segmentation, showed as Figure _ref_ . We test our method on the Berkeley Segmentation Data set benchmark. We follow standard benchmarking practices and compute the segmentation covering (SC), probabilistic Rand index (PRI), and variation of information (VI) metrics of our segmentations as well as segmentation of several existing algorithms. We compare favorably with a number of classical and recent segmentation approaches, and even approach human-level performance in some cases---for example, our algorithm achieves N PRI versus N by humans, in the optimal image scale setting. We further show several examples of segments produced by our algorithm as well as some competing methods. The rest of this paper is organized as follows. We first review related works in Section N. The architecture of our network is described in Section N. Section N presents the detailed procedure of the post-processing method, and experimental results are demonstrated in Section N. Section N discusses the conclusions that have been drawn.