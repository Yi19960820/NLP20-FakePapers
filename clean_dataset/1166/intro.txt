The problem of unsupervised learning is one of the most difficult and intriguing in computer vision and machine learning today. In a very general sense, many researchers believe that unsupervised learning from video could help decode many hard questions regarding the nature of intelligence and learning. Since unlabeled videos are easy to collect at a very low cost, solving this task would bring a great practical value in many vision and robotics applications. There are several papers addressing this difficult task, but the current methods are still far from fully solving the challenge. Many recent unsupervised methods in vision follow two main directions: one is to learn powerful features in a completely unsupervised manner and then use them in a classic supervised learning scheme in combination with different classifiers, such as SVMs or CNNs~ _cite_ . The second, more classical line of research, is to discover common patterns in unlabeled data, at test time, using different clustering, feature matching or other data mining approaches~ _cite_ . In the first case the unsupervised learning task is limited to the intermediate level of feature learning, while in the second, its performance depends on the specific structure of the image collection given at test time. The task of object discovery and unsupervised learning in video is related to co-segmentation~ _cite_ and weakly supervised localization~ _cite_ . Earlier methods are based on local feature matching and detection of their co-occurrences patterns~ _cite_, while recent approaches~ _cite_ discover object tubes by linking candidate detections between frames with or without refining their location. Traditionally, the task of unsupervised learning from image sequences, formulated as an optimization problem for either feature matching, conditional random fields or data clustering is inherently expensive due to the combinatorial nature of the problem. That is why our approach, in which we learn to detect in a fast, feed-forward manner from an unsupervised object discoverer in video (while having virtually unlimited training data), has certain advantages that might open new possibilities in the quest for solving the unsupervised learning problem in the real world. Our system is presented in Figure _ref_ . We have an unsupervised training stage, in which a student deep neural network (Figure _ref_) learns frame by frame from an unsupervised teacher, which performs object segmentation discovery in videos, to produce similar object masks in single images. The teacher method takes advantage of the consistency in appearance, shape and motion manifested by objects in video. In this way, it discovers objects in the video and produces a foreground segmentation for each individual frame. Then, the student network tries to imitate for each frame the output of the teacher, while having as input only a single image-the current frame. The teacher pathway is much simpler in structure, but it has access to information over time. In contrast, the student is much deeper in structure, but has access only to one image. Thus, the information discovered by the teacher in time is captured by the student in depth, over neural layers of abstraction. In experiments, we show a very encouraging fact: the student easily learns to outperform its teacher and discovers by itself general knowledge about the shape and appearance properties of objects, well beyond the abilities of the teacher. Thus, the student produces significantly better object masks, which generally have a good form, do not have holes and display smooth contours, while having an appearance that is often in contrast to the background scene. Since there are available methods for video discovery with good performance, the training task becomes immediately feasible. In this work we chose the VideoPCA algorithm introduced as part of the system in~ _cite_ because it is very fast (N-N fps), uses very simple features (pixel colors) and it is completely unsupervised-with no usage of supervised pre-trained features. That method exploits the stability in appearance and location of objects, which is common in video shots. While the object masks discovered are far from being perfect and are often noisy, the student deep network manages to generalize and overcome some of these limitations. We propose a ten layer deep neural network for the student pathway (Figure _ref_) . It takes as input the original RGB, HSV and image spatial derivatives channels. It outputs a low resolution soft segmentation mask of the main objects present in a given image. Our main contributions are: N) Our approach, to our best knowledge, is the first one that learns to detect and segment foreground objects in images in a completely unsupervised fashion, with no pre-trained features needed or manual labeling, while requiring only a single image at test time. N) We propose a novel architecture for unsupervised learning in video, consisting of two processing pathways, with complementary functions and properties. The first pathway discovers foreground objects in videos in an unsupervised manner and has access to all the video frames. It acts as a teacher. The second "student" pathway, which is a deep convolutional net, learns to predict the teacher's output for each frame while having access only to a single input image. An important fact, shown in our experiments, is that the student learns to outperform its teacher, despite being limited to a single image input. Once trained using our dual-pathway system, the student achieves state of the art results on two important datasets.