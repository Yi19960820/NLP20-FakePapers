Compressed sensing or compressive sampling (CS) is a theory _cite_ that merges compression and acquisition, exploiting sparsity to recover signals that have been sampled at a drastically lower rate than what the Shannon/Nyquist theorem imposes. The results of CS have an important impact on numerous signal processing applications including the efficient processing and analysis of high-dimensional data such as audio _cite_, image _cite_ and video _cite_ . Assume a finite-length, real-valued signal _inline_eq_, CS yields a compressed representation of the treated signal using a sensing mechanism that is realized by a or . The linear measurement process is described by where _inline_eq_, _inline_eq_, is the projection matrix and _inline_eq_ is the vector containing the obtained measurements. In CS, we assume that either _inline_eq_ is a sparse signal or that _inline_eq_ has a sparse representation with respect to a suitable basis _inline_eq_, that is, _inline_eq_, _inline_eq_, _inline_eq_, where _inline_eq_ is the _inline_eq_ quasi-norm counting the non-vanishing coefficients of the treated signal. Therefore, we obtain the underdetermined linear system A sparse vector satisfying can be obtained as the solution of the _inline_eq_-minimization problem employing well-known algorithms like Basis Pursuit _cite_ . Conventional CS theory is based on random Gaussian or random Bernoulli matrices, which can be used to recover a _inline_eq_-dimensional _inline_eq_-sparse signal, provided that the number of measurements _inline_eq_ is _inline_eq_ _cite_ . An important issue when considering random matrices is that such matrices are typically difficult to build in hardware. The difficulty in storing these matrices and certain physical constraints on the measurement process makes it challenging to realize CS in practice. Moreover, when multiplying arbitrary matrices with signal vectors of high dimension, the lack of any fast matrix multiplication algorithm results in high computational cost. Deep learning is an emerging field that learns multiple levels of representation of data and has been used successfully in image processing tasks. Existing work has been presented for image super-resolution _cite_, image denoising _cite_ and compressed sensing _cite_ . Deep learning has also been applied in distributed CS _cite_, quantized CS _cite_ and video CS _cite_ . In this paper, we adopt a deep learning approach to learn an optimized projection matrix and a non-linear reconstruction mapping from measurements to the original signal. In order to design projections suitable for hardware implementation, we focus on sparse matrices composed of _inline_eq_, imposing sparsity and binary constraints on the proposed network architecture. The network is trained on image patches and the learned projection matrix is used to acquire images in a block-based manner. Our experimental results show that high quality reconstruction can be achieved with projections containing only _inline_eq_ \% nonzero _inline_eq_ entries. The rest of the paper is organized as follows. In Section _ref_ we review related work in CS and deep learning. Section _ref_ includes the proposed approach and Section _ref_ our experimental results. Conclusions are drawn in Section _ref_ .