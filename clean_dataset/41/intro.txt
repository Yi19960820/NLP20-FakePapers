Recent great progress on object detection is stimulated by the deep learning pipelines that learn deep representations from the region of interest (RoI) and perform classification based on the learned representations, such as Fast R-CNN~ _cite_ and Faster R-CNN~ _cite_ . Those pipelines indeed work well on large objects with high resolution, clear appearance and structure from which the discriminative features can be learned. But they usually fail to detect objects, as rich representations are difficult to learn from their poor-quality appearance and structure, as shown in Figure~ _ref_ . However, small objects are very common in many real world applications such as traffic sign detection, pedestrian detection for advanced autonomous driving. Small object detection is much more challenging than normal object detection and good solutions are still rare so far. Some efforts~ _cite_ have been devoted to addressing small object detection problems. One common practice~ _cite_ is to increase the scale of input images to enhance the resolution of small objects and produce high-resolution feature maps. Some others~ _cite_ focus on developing network variants to generate multi-scale representation which enhances high-level small-scale features with multiple lower-level features layers. However, all of those approaches try to enhance the performance of small object detection by data augmentation or naively increasing the feature dimension. Simply increasing the scale of input images often results in heavy time consumption for training and testing. Besides, the multi-scale representation constructed by the low-level features just works like a black-box and cannot guarantee the constructed features are interpretable and discriminative enough for object detection. In this work, we argue that a preferable way to effectively represent the small objects is to discover the intrinsic structural correlations between small-scale and large-scale objects for each category and then use the transformed representations to improve the network capability in a more intelligent way. Therefore, we propose a novel Perceptual Generative Adversarial Network (Perceptual GAN) to generate super-resolved representations for small objects for better detection. The Perceptual GAN aims to enhance the representations of small objects to be similar to those of large object, through fully exploiting the structural correlations between objects of different scales during the network learning. It consists of two subnetworks, i.e., a generator network and a perceptual discriminator network. Specifically, the generator is a deep residual based feature generative model which transforms the original poor features of small objects to highly discriminative ones by introducing fine-grained details from lower-level layers, achieving ``super-resolution" on the intermediate representations. The discriminator network serves as a supervisor and provides guidance on the quality and advantages of the generated fine-grained details. Different from the vanilla GAN, where the discriminator is only trained to differentiate fake and real representations, our proposed Perceptual GAN includes a new perceptual loss tailored for the detection purpose. Namely, the discriminator network is trained not only to differentiate between the generated super-resolved representations for small objects and the original ones from real large objects with an adversarial loss, but also to justify the detection accuracy benefiting from the generated super-resolved features with a perceptual loss. We optimize the parameters of the generator and the discriminator network in an alternative manner to solve the min-max problem. In particular, the generator network is trained with the goal of fooling the discriminator by generating the most large-object like representations from small objects as well as benefiting the detection accuracy. On the other hand, the discriminator is trained to improve its discriminative capability to correctly distinguish the generated super-resolved representations from those from real large objects, and also provides feedback about the localization precision to the generator. Through competition between these two networks, generator is effectively trained to enhance the representations for small objects to super-resolved ones capable of providing high detection accuracy. We evaluate our Perceptual GAN method on the challenging Tsinghua-Tencent NK~ _cite_ and the Caltech benchmark~ _cite_ for traffic sign and pedestrian detection respectively. Small instances are common on these two datasets, thus they provide suitable testbed for evaluating methods on detecting small objects. Our proposed method shows large improvement over state-of-the-art methods and demonstrates its superiority on detecting small objects. To sum up, this work makes the following contributions. (N) We are the first to successfully apply GAN-alike models to solve the challenging small-scale object detection problems. (N) We introduce a new conditional generator model that learns the additive residual representation between large and small objects, instead of generating the complete representations as before. (N) We introduce a new perceptual discriminator that provides more comprehensive supervision beneficial for detections, instead of barely differentiating fake and real. (N) Successful applications on traffic sign detection and pedestrian detection have been achieved with the state-of-the-art performance.