As data-hungry methods such as deep neural networks become predominant in most areas of computer vision, the community faces the challenge of obtaining sufficiently large quantities of supervised data to train models. One increasingly popular and effective approach is to use synthetic data~ _cite_ . While this data can be created ad-hoc, research in reinforcement learning has recently built on the idea of using video games as off-the-shelf virtual environments suitable to learn agents~ _cite_ . This approach is rather powerful as, while video games may not be entirely realistic, they capture many of the fundamental nuances and challenges of real-life perception. This is especially true for modern ND games. We believe that these ideas can be applied well beyond reinforcement learning, and that video games can be used to train and evaluate in a direct manner a wide variety of computer vision algorithms. In order to explore this idea, in this paper we propose to extract richly-annotated data from Doom, one of the early examples of ND games. In order to do so, we introduce a modification of the open-source Doom engine. This variant, which we call (), is able to extract a wealth of geometric and semantic metadata during gaming sessions. Second, in order to lower as much as possible the barrier of entry for other computer vision researchers, we also provide pre-computed Doom data with full annotations, as well as a subset of the annotations using the Microsoft Coco format~ _cite_, including well defined training, validation, and test split to simplify comparing results. We call this dataset () . We open source both ResearchDoom and CocoDoom and make them available at _url_ for other researchers to use. As noted above, several researchers have been proposing to use computer graphics and simulated data for learning in computer vision and reinforcement learning. The work that is probably most related to ours is, a modified version of the Doom engine that allows interfacing the game to machine learning algorithms for the purpose of reinforcement learning. ResearchDoom, which was developed partially concurrently to VizDoom, rather than providing an interface to control the game as needed in reinforcement learning, it focuses on extracting abundant metadata from recorded gaming sessions, including extracting depth information, object instance and class segmentations, as well as other data such as egomotion. The idea is that such annotated data can be used in a large number of computer vision tasks even without reinforcement learning. Example problems that can be targeted by using this data include object recognition, detection, and tracking, instance and semantic segmentation, monocular depth estimation, and ego-motion estimation. While ResearchDoom was developed independently of VizDoom, in the future we hope to be able to port ResearchDoom functionalities to VizDoom. Another recent effort similar to ResearchDoom is Unreal CV~ _cite_ . This engine can also extract metadata similar to ResearchDoom and, by building on the Unreal engine, can potentially be applicable to a huge variety of modern video games. ResearchDoom is much simpler than Unreal CV as it applies to a single and relatively old game. While Doom incorporates several limitations, such as the fact that the camera can only rotate around the vertical axis, the data is nevertheless fairly complex. Furthermore, Doom provides a relatively restricted and consistent world form which data can be extracted for experiments. We leverage the latter fact to define and provide abundant pre-computed data with detailed metadata as well as with annotations using the Microsoft Coco format. Another related project is the OpenAI Gym~ _cite_, a collection of simulations and virtual environments, including video games such as Doom, for research in reinforcement learning by OpenAI.