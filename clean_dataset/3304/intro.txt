The advance of low-power mobile sensors leads to new applications for real-time environmental monitoring, which include acoustic event detection (AED) systems using wireless sensor networks, e.g. for vehicle classification (_cite_) . Acoustic events can be effectively classified by convolutional neural networks (CNN) as shown by _cite_, if a large labeled training dataset is available (_cite_) . However, for some application scenarios, e.g. in micro-seismic acoustic emission monitoring (_cite_), the advantages of mentioned CNNs are diminished due to the lack of ground truth. In this scenario distinguishing between relevant events in an audio stream and non-relevant events is non-trivial, since the domain-specific categories of these acoustic events are not known a priori. Unsupervised feature learning provides a mean to gather useful information from such unexplored datasets, which has been shown for video (_cite_) and audio (_cite_) analysis. Recently, convolutional long short-term memory (ConvLSTM) layers have proven to be effective as feature extractors for time series data (_cite_) and for unsupervised video analysis (_cite_) . Except for speech recognition (_cite_), ConvLSTM layers have not been used for audio analysis, despite their advantages for time series data. As a consequence, in this paper a novel audio frame predictor (AFP) using ConvLSTM layers is presented, which is used to learn representative features of acoustic events. Second a novel approach to train the AFP in regard to generating and extracting distinct features is presented which diversifies the features based on inter-sample similarities.