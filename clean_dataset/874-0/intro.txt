In the vision community, boundary detection has always been considered a low-level problem. However, psychological studies suggest that when a human observer perceives boundaries, object level reasoning is used~ _cite_ . Despite these findings, most of the boundary detection methods rely exclusively on low-level color and gradient features. In this work, we present a method that uses object-level features to detect boundaries. We argue that using object-level information to predict boundaries is more similar to how humans reason. Our boundary detection scheme can be viewed as a High-for-Low approach where we use high-level object features as cues for a low-level boundary detection process. Throughout the rest of the paper, we refer to our proposed boundaries as High-for-Low boundaries (\HfL) . We present an efficient deep network that uses object-level information to predict the boundaries. Our proposed architecture reuses features from the sixteen convolutional layers of the network of Simonyan et al.~ _cite_, which we refer to as VGG net. The VGG net has been trained for object classification, and therefore, reusing its features allows our method to utilize high-level object information to predict \HfL boundaries. In the experimental section, we demonstrate that using object-level features produces semantically meaningful boundaries and also achieves above state-of-the-art boundary detection accuracy. Additionally, we demonstrate that we can successfully apply our \HfL boundaries to a number of high-level vision tasks. We show that by using \HfL boundaries we improve the results of three existing state-of-the-art methods on the tasks of semantic boundary labeling, semantic segmentation and object proposal generation. Therefore, using \HfL boundaries to boost the results in high level vision tasks can be viewed as a Low-for-High scheme, where boundaries serve as low-level cues to aid high-level vision tasks. We present the summarized results for the boundary detection and the three mentioned high-level vision tasks in Table~ _ref_ . Specifically, we compare our proposed method and an appropriate state-of-the-art method for that task. As the results indicate, we achieve better results in each of the tasks for each presented evaluation metric. We present more detailed results for each of these tasks in the later sections. In summary, our contributions are as follows. First, we show that using object-level features for boundary detection produces perceptually informative boundaries that outperform prior state-of-the-art boundary detection methods. Second, we demonstrate that we can use \HfL boundaries to enhance the performance on the high-level vision tasks of semantic boundary labeling, semantic segmentation and object proposal. Finally, our method can detect boundaries in near-real time. Thus, we present a boundary detection system that is accurate, efficient, and is also applicable to high level vision tasks.