Within a decade, performances on classical vision problems such as image classification _cite_, object detection _cite_, and segmentation _cite_ have been largely improved by the use of deep learning frameworks. Based on the great successes of deep learning for such low-level vision problems, a next step could be deriving semantics from images such as relations between objects. For example, to understand a given soccer scene more deeply, it would be very important not only to detect the objects in the image, such as players and a ball but also to figure out the relationships between the objects. In this work, among various vision problems, we aim to understand diagram images, which have played a major role in classical knowledge representation and education. Previously, most machine learning algorithms have focused on extracting knowledge from the information described by natural languages or structured databases (e.g. Freebase _cite_, Wordnet _cite_) . In contrast to language-based knowledge, a diagram contains rich illustrations including text, visual information and their relationships, which can depict human's perception of objects more succinctly. As shown in Figure _ref_, some complicated concepts such as ``food web in a jungle" and ``life cycle of a moth" can be easily described as a diagram. On the other hand, a single natural image or a single sentence may not be sufficient to deliver the same amount of information to the readers. Whereas the diagram has good characteristics of knowledge abstraction, it requires composite solutions to properly analyze and extract the contained knowledge. Since diagrams in a science textbook employ a wide variety of methods for explaining concepts in their layout and composition, understanding a diagram can be a challenging problem of inferring human's general perception of structured knowledge. Unlike conventional vision problems, this task must involve inference models for vision, language and particularly relations among objects which can be a novel point. Despite the noted arbitrariness, we believe that a simple method generally exists to analyze and interpret the knowledge conveyed in a diagram. There have not been many studies on diagram analysis yet, but Kembhavi~ \etal~ _cite_ recently proposed a pioneering work analyzing the diagram's structure. The main flow of the algorithm is twofold: N) Object detection: Objects in the diagram are detected and segmented individually by conventional methods such as those in _cite_ . N) Relation inference: The relations among detected objects are inferred by a recurrent neural network (RNN) to transmit contexts sequentially. However, this approach has several limitations. First, concatenating separated methods results in a long pipeline from input to output, which can cause accumulated errors and lose contexts on a diagram. Second, and more importantly, the vanilla RNN is not fully capable of dealing with the information formed as a graph structure. In this paper, we propose a novel method to solve the aforementioned issues. Our contributions are twofold. First, using a robust object detection model and a novel graph-based method, a unified diagram parsing network (UDPnet) is proposed to understand a diagram by jointly solving the two tasks of object detection and relation matching, which tackles the first limitation of the existing work. Second, we propose a RNN-based dynamic graph generation network (DGGN) to fully exploit the diagram information by describing with a graph structure. To solve the problem, we propose a dynamic adjacency tensor memory (DATM) for the DGGN to store information about the relationships among the elements in a diagram. The DATM has features of both an adjacency matrix in graph theory and a dynamic memory in recent deep learning. With this new type of memory, the DGGN suggests a novel way to propagate information through the structure of a graph. In order to demonstrate the effectiveness of the proposed DGGN, we evaluated our model on a couple of diagram datasets. We also analyzed the inside of GRU _cite_ cells to observe the dynamics of information in the DGGN.