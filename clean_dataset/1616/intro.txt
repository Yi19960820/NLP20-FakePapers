Motion estimation in videos, has been an active area of research in computer vision during the last few decades, due to its potential applications in robot navigation, healthcare, surveillance, elderly and child monitoring, human-robot interaction, structure from motion, three-dimensional reconstruction and autonomous driving and many more, by understanding the appearance of objects in motion _cite_ . The first step in motion estimation is to compute displacement vectors between different points. Scene flow is a three dimensional displacement vector of scene points moving between different time steps. Scene flow can be considered as the three dimensional form of optical flow. Scene flow provides the motion vectors of the scene points in three dimensional space: along x, y and z axes. This can be used to obtain full information and geometry of the scene objects. A sufficient knowledge of scene flow is important for scene understanding during motion in RGB-D videos. For a complete definition of scene flow, stereo image pairs at different time steps are required. It can also computed using RGB-D image pairs where the depth data is directly available. The scene flow can be constructed using optical flow and disparity obtained from stereo pairs. Figure _ref_ shows stereo image pairs with its ground truth disparities, optical flow and scene flow along the three orthogonal directions. Hence, the accuracy of computed scene flow depends on accurate estimation of optical flow and disparity. A small error in sub-components optical flow and disparity will produce very large error in corresponding scene flow. Given the camera parameters and consecutive pairs of stereo images, problem of scene flow estimation is to compute three dimensional motion field of all the scene points along the three orthogonal directions. There are various challenges involved in scene flow estimation process. In case of occlusion, the obstruction can lead to inaccurate information of the scene points. If there are large displacements between the two consecutive frames then accuracy of estimation is less. Scene flow estimation also becomes difficult in outdoor scenes where variations in illumination are present. Insufficient texture also poses challenge to the estimation process, as it becomes difficult to calculate the motion when pixels look alike. Several classical or non-learning based techniques are developed specifically to tackle some of these challenges. Most of these state-of-the-art methods can be considered as an extension of the optical flow estimation process to ND. The classical methods of scene flow estimation often take time ranging from several seconds to minutes. Thus, they are not suitable for real-time applications. With the recent advancements of sophisticated techniques to handle large amount of data, a deep learning based technique is necessary to estimate scene flow. Unfortunately, a very few efforts have been found in the literature to estimate scene flow by deep learning technique _cite_ . We propose a deep learning approach for end-to-end learning of scene flow. The proposed technique take the advantage of availability of a large dataset of stereo images with corresponding ground truth optical flow and disparity. Though the training time for deep learning methods on large dataset is much higher, unlike classical techniques it is faster during runtime. Since the network is trained over large dataset, it learns the cases where assumptions such as brightness constancy and insufficient texture are violated. There are some works reported in estimation of optical flow and disparity using neural networks. However, reconstructing scene flow from these two components will be inaccurate depending upon the lack of accuracy of the optical flow and disparity estimation. Unlike classification, scene flow estimation through neural network is structured prediction problem where labels are provided for every pixel. As encoder decoder architectures have shown significant success in many reconstruction problems (such as ND reconstruction _cite_), this paper presents a fully convolutional encoder decoder architecture to estimate dense scene flow. The contributions of this paper can be considered as two folds. First, we introduce an encoder decoder architecture for direct scene flow estimation (without going for estimation of optical flow and disparity) from a huge dataset. Second, we have annotated the FlyingThingsND dataset _cite_ by providing the ground truth scene flow along the x, y and z directions for each video, for training a deep learning architecture.