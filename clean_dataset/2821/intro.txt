The appearance of visual objects is significantly affected by multiple factors of variability such as, for example, pose, illumination, identity, and expression in case of faces. Each factor accounts for a source of variability in the data, while their complex interactions give rise to the observed entangled variability. Discovering the modes of variation, or in other words disentangling the latent factors of variations in visual data, is a very important problem in the intersection of statistics, machine learning, and computer vision. Factor analysis~ _cite_ and the closely related Principal Component Analysis (PCA) ~ _cite_ are probably the most popular statistical methods that find a single mode of variation explaining the data. Nevertheless, visual appearance (e.g., facial appearance) is affected by several modes of variations. Hence, methods such as PCA are not able to identify such multiple factors of variation. For example, when PCA is applied to facial images, the first principal component captures both pose and expressions variations. An early approach for learning different modes of variation in the data is TensorFaces _cite_ . In particular, TensorFaces is a strictly supervised method as it not only requires the facial data to be labelled (e.g., in terms of expression, identity, illumination etc.) but the data tensor must also contain all samples in all different variations. This is the primary reason that the use of such tensor decompositions is still limited to databases that have been captured in a strictly controlled environment, such as the Weizmann face database _cite_ . Recent unsupervised tensor decompositions methods _cite_ automatically discover the modes of variation in unlabelled data. In particular, the most recent one _cite_ assumes that the original visual data have been produced by a hidden multilinear structure and the aim of the unsupervised tensor decomposition is to discover both the underlying multilinear structure, as well as the corresponding weights (coefficients) that best explain the data. Special instances of the unsupervised tensor decomposition are the Shape-from-Shading (SfS) decompositions in _cite_ and the multilinear decompositions for ND face description in _cite_ . In _cite_, it is shown that the method indeed can be used to learn representations where many modes of variation have been disentangled (e.g., identity, expression and illumination etc.) . Nevertheless, the method in _cite_ is not able to find pose variations and bypasses this problem by applying it to faces which have been frontalised by applying a warping function (e.g., piece-wise affine warping _cite_) . Another promising line of research for discovering latent representations is unsupervised Deep Neural Networks (DNNs) . Unsupervised DNNs architectures include the Auto-Encoders (AE) _cite_, as well as the Generative Adversarial Networks (GANs) _cite_ or adversarial versions of AE, e.g., the Adversarial Auto-Encoders (AAE) _cite_ . Even though GANs, as well as AAEs, provide very elegant frameworks for discovering powerful low-dimensional embeddings without having to align the faces, due to the complexity of the networks, unavoidably all modes of variation are multiplexed in the latent-representation. Only with the use of labels it is possible to model/learn the manifold over the latent representation, usually as a post-processing step _cite_ . In this paper, we show that it is possible to learn a disentangled representation of the human face captured in arbitrary recording conditions in an unsupervised manner by imposing a multilinear structure on the latent representation of an AAE _cite_ . To the best of our knowledge, this is the first time that unsupervised tensor decompositions have been combined with DNNs for learning disentangled representations. We demonstrate the power of the proposed approach by showing expression/pose transfer using only the latent variable that is related to expression/pose. We also demonstrate that the disentangled low-dimensional embeddings are useful for many other applications, such as facial expression, pose, and identity recognition and clustering. An example of the proposed approach is given in Fig.~ _ref_ . In particular, the left pair of images have been decomposed, using the encoder of the proposed neural network _inline_eq_, into many different latent representations including latent representations for pose, illumination, identity and expression. Since our framework has learned a disentangled representation we can easily transfer the expression by only changing the latent variable related to expression and passing the latent vector into the decoder of our neural network _inline_eq_ . Similarly, we can transfer the pose merely by changing the latent variable related to pose.