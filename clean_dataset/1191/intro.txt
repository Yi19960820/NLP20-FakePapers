Providing efficient solutions to image classification has always been a major focus in computer vision. Recent years have witnessed considerable progress in image classification. However, most popular systems heavily rely on manually labeled training data, which is expensive and sometimes impractical to acquire. Despite substantial efforts towards efficient annotation by developing online games or appealing software tools, collecting training data for classification is still very time-consuming and tedious. The scarcity of annotations, combined with the explosion of image data, starts shifting focus towards learning with less supervision. As a result, numerous techniques have been developed to learn classification models with cheaper annotations. The most notable ones include unsupervised feature learning~, semi-supervised learning, active learning, transfer learning, weakly-supervised learning, self-taught learning, and image clustering . In this paper, we are interested in the problem of image classification with limited or no annotation. Instead of regularizing the classifiers like most of the previous methods, we learn a new feature representation using the all available data (labeled + unlabeled) . Specifically, we aim to learn a new feature representation by exploiting the distribution patterns of the data to be handled. The setting assumes the availability of unlabeled data in the same or a similar distribution as the test data. This form of weak supervision is naturally available in applications such as semi-supervised image classification and image clustering, where data in the same or a similar distribution as the test data is available. The learned feature is specifically tuned for the data distribution of interest and performs better for the data than the standard features the method started with. The features to start with for our method can be hand-crafted features~, learned features in a supervised manner~ _cite_ or learned features in an unsupervised way~ _cite_ . Learning with unlabeled data has been quite successful in many fields, for instance in semi-supervised learning (SSL) ~, in image clustering~ _cite_, and in unsupervised feature representation learning~ _cite_ . Typically these methods build upon the assumption that data samples with high similarity should share the same label. This is also called, and it is often used to regularize the training process for the classifiers or feature representations. In this paper, we propose another way to exploit the assumption to learn a new feature representation. The new feature representation is learned in a discriminative way to capture not only the information of individual images, but also the relationships among images. The learning is conceptually straightforward and computationally simple. The learned features can be fed into any classifiers for the final classification of the unlabeled samples. Thus, the method is agnostic to the classifier choice. This facilitates the deployment of SSL methods, as users often have their favorite classifiers and are reluctant to drop them. For image clustering, we apply the same feature learning methods to all provided images, and then feed the learned features to standard clustering methods such as _inline_eq_-means and Spectral Clustering. Below, we present our motivations and outline the method. People learn and abstract the concepts of object classes well from their intrinsic characteristics, such as colors, textures, and shapes. For instance, is blue, and a is spherical. We also do so by comparing new object classes to those classes that have already been learned. For example, a is similar in appearance to a, but is smaller. This paradigm of learning-by-comparison or characterization-by-comparison is part of Eleanor Rosch's prototype theory, that states that an object's class is determined by its to prototypes which represent object classes. The theory has been used successfully in transfer learning, when labeled data of different classes are available. An important question is whether the theory can also be used for feature representation learning when a large amount of unlabeled data is available. This paper investigates this problem. To use this paradigm, we first need to create the prototypes automatically from the available data. In keeping with Eleanor Rosch's prototype theory, ideal prototypes should have two properties: N) images in the same prototype are to be from the same class; and N) images of different prototypes are to be from different classes. They guarantee meaningful comparisons and reduce ambiguity. Without access to labels of data samples, the prototypes have to be created in an unsupervised way, based on some assumptions. In addition to the widely-used, we propose another one called, which states that samples that are far apart in the feature space are very likely to come from different classes. The assumptions have been verified experimentally, and will be presented in Section~ _ref_ . Based on these two assumptions, it stands to reason that samples along with their closest neighbors can be ``good'' prototypes, and such prototypes that are far apart can play the role of different classes. According to this observation, we design a method to sample the prototype set from all available images by encoding them on a graph with links reflecting their affinity. The sampled prototypes are taken as surrogate classes and discriminative learning is yields projection functions tuned to the classes. Images are then linked to the prototypes via their projection values (classification scores) by the functions. Since information carried by a single prototype set is limited and can be noisy, we borrow ideas from ensemble learning to create an ensemble of diverse prototype sets, which in turn leads to an ensemble of projection functions, to mitigate the influence of the deficiencies of each training set. The idea is that if the deficiency modes of the individual training sets are different or `orthogonal', ensemble learning is able to cancel out or at least mitigate their effect. This conjecture is verified with a simulated experiment in Section~ _ref_, and is also supported by the superior performance of our method in real applications. With the ensemble of classifiers, images are then represented by the concatenation of their classification scores--similarities to all the sampled image prototypes--for the final classification, which is in keeping with prototype theory . We call the method Ensemble Projection (EP) . Its schematic diagram is sketched in Figure _ref_ . EP was evaluated on eight image classification datasets, ranging from texture classification, over object classification and scene classification, to style classification. For SSL, EP is compared to three baselines and three other methods. For image clustering, EP is compared to the original features it started with. Two standard clustering methods are used: _inline_eq_-means and Spectral Clustering. The experiments show that: (N) EP improves over the original features by exploiting the data distribution of interest, and outperforms competing SSL methods; (N) EP produces promising results for self-taught image classification where the unlabeled data does not follow the same distribution as the labeled ones; (N) EP improves over the original features for image clustering. This paper is an extension of our conference papers~ . In addition to putting the two tasks, image clustering and semi-supervised image classification, into the same framework, this paper brings several new contributions. First, in the conference papers, EP was validated only with hand-crafted features, such as LBP, GIST, and PHOG . These features, however, are obsolete for image classification. Recently, features learned by CNN has resulted in state-of-the-art performance in various classification tasks . In this paper, we validate the efficacy of EP also with CNN features. Second, experiments are conducted on eight standard classification datasets instead of only four in . Third, more analyses and insights are given. Our feature learning method can be used for other tasks as well. For instance, extended the idea to generate hashing functions for efficient image retrieval. The rest of this paper is organized as follows. Section~ _ref_ reports on related work. Section~ _ref_ describes the observations that motivate the method. Section~ _ref_ is devoted to the approach, followed by experiments in Section~ _ref_ . Section~ _ref_ concludes the paper.