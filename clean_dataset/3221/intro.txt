Rain can severely impair the performance of many computer vision systems, such as road surveillance, autonomous driving and consumer camera. Effectively removing rain streaks from images is an important task in the computer vision community. To address the deraining problem, many algorithms have been designed to remove rain streaks from single rainy images. Unlike video based methods _cite_, which have useful temporal information, single image deraining is a significantly harder problem. Furthermore, success in single images can be directly extended to video, and so single image deraining has received much research attention. In general, single image deraining methods can be categorized into two classes: model-driven and data-driven. Model-driven methods are designed by using handcrafted image features to describe physical characteristics of rain streaks, or exploring prior knowledge to constrain the ill-posed problem. In _cite_, the derained image is obtained by filtering a rainy image with a nonlocal mean smoothing filter. Several model-driven methods adopt various priors to separate rain streaks and content form rainy images. For example, in _cite_ morphological component analysis based dictionary learning is used to remove rain streaks in high frequency regions. To recognize rain streaks, a self-learning based image decomposition method is introduced in _cite_ . In _cite_, based on image patches, a discriminative sparse coding is proposed to distinguish rain streaks from non-rain content. In _cite_, low-rank assumptions are used to model and separate rain streaks. In _cite_, the authors use a hierarchical scheme combined with dictionary learning to progressively remove rain and snow. In _cite_, the authors utilize convolutional analysis and synthesis sparse representation to extract rain streaks. In _cite_, three priors are explored and combined into a joint optimization process for rain removal. Recently, data-driven methods using deep learning have dominated high-level vision tasks _cite_ and low-level image processing _cite_ . The first deep learning method for rain streaks removal was introduced by _cite_, where the authors use domain knowledge and train the network on high-frequency parts to simplify the learning processing. This method was improved in _cite_ by combining ResNet _cite_ and a global skip connection. Other methods focus on designing advanced network structure to improve deraining performance. In _cite_, a recurrent dilated network with multi-task learning is proposed for joint rain streaks detection and removal. In _cite_, the recurrent neural network architecture is adopted and combined with squeeze-and-excitation (SE) blocks _cite_ for rain removal. In _cite_, a density aware multi-stream dense CNN, combined with generative adversarial network _cite_, is proposed to jointly estimate rain density and remove rain. Deep learning methods can focus on incorporating domain knowledge to simplify the learning process with generic networks _cite_ or on designing new network architectures for effective modeling representations _cite_ . These works do not model the structure of the features themselves for deraining. In this paper, we show that feature fusion can improve single image deraining and reduce the number of parameters, as shown in Figure _ref_ . In this paper, we propose a deep tree-structured hierarchical fusion model. The proposed tree-structured fusion operation is deployed within each dilated convolutional block and across all blocks, and can explore both spatial and content information. The proposed network is easy to implement by using standard CNN techniques and has far fewer parameters than typical networks for this problem.