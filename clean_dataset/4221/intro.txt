Saliency detection, which locates the regions most attracting human beings, is an important branch of image processing. The goal of saliency detection is to find the most distinctive regions in an given image. Saliency detection has attracted widespread attentions owing to its widely application and high research values. Therefore, many efficient and robust saliency detection methods are developed recently. Saliency detection methods can be used as image preprocessing, due to the valuable semantic information that are contained by salient regions. The performance of many fields in computer vision and image processing can be enhanced by employing saliency detection, such as content-aware image editing _cite_, image compression _cite_, visual tracking _cite_, person re-identification _cite_, image retrieval _cite_, and video summarization _cite_ . However, improving the accuracy of saliency detection, especially in a clutter, is still a huge challenge. The early saliency detection methods are generally inspired by the visual attention model proposed by Itti _cite_ . This kind of method usually extracts features manually, and calculates the visual contrast of each region via these handcrafted features. These methods follow a principle that the most salient regions have the highest visual contrast. Therefore global contrast and local contrast, which are two common measurements, are developed to simulate the visual contrast, and many saliency features are exploited based on the global and local contrasts in previous studies. However, the accuracy of methods based on handcrafted features is not satisfactory in a clutter background. To obtain reliable and robust results, machine learning algorithms are developed to enhance the performance of saliency detection methods~ _cite_ . In the beginning, machine learning algorithms are employed to detect salient objects based on different handcrafted features. However, the deficiencies of handcrafted features could not be eliminated by this way. With the purpose of overcoming the drawback of handcrafted features, more methods based on deep convolutional neural networks (CNNs) are emerging. Depending on the learning ability of CNNs, the accuracy of saliency detection has been improved significantly. And end-to-end convolutional neural network could directly generate the salient maps without any manual operations so that it can make up the deficiencies of handcrafted features. The end-to-end network is generally composed of convolution operations, pooling operations, etc. The saliency features are generated in the process of convolution operations. Due to different sizes of receptive fields, shallow layers often contain more local information, and deep layers contain more global information. Therefore, how to utilize the convolutional information of different layers is still a key problem. Shallow layers contain plentiful local saliency information, there are lack of effective methods to enhance and take advantage of the local information. Moreover, deep layers contain plentiful global saliency information, which is need to be enhanced to highlight salient regions and suppress interference of background. To overcome the aforementioned issues, we propose a novel end-to-end convolutional neural networks structure, which combined self-attention mechanism and recurrent convolutional layers (RCL) to enhance global and local saliency information. Deep network structure we proposed in this paper is composed of two subnetworks as shown in Figure~ _ref_ . One subnetwork is used to extract feature maps based on VGGN _cite_ . The other subnetwork, called attentional recurrent network (ARN), is used to fuse different feature maps generated by VGGN. In the ARN subnetwork, RCL is used to receive the feature maps from shallow layers, and enhance the local saliency information in these feature maps with a shared weight recurrent structures. Moreover, an attention mechanism called self-attention is used to handle the feature maps in deep layers. Self-attention mechanism is used to obtain attentional weights, which are assigned more to salient regions for improving global saliency perception ability of ARN. The network proposed in this paper can capture subtle visual contrast for saliency detection, and generate delicate saliency maps. Experimental results demonstrate that our method have a better performance than N exact algorithms on four open datasets. In summary, contributions of this paper are as followings: