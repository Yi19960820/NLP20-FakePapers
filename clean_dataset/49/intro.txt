Creating an accurate measure of cloud cover is a crucial step in the collection of satellite imagery. The presence of cloud and its coverage level in an image could affect the integrity and the value of that image in most remote sensing applications that rely on optical satellite imagery. Moreover, transmission and storage of images with high cloud coverage seem to be unnecessary and perhaps even wasteful. Therefore, accurate identification of cloud regions in satellite images is an active subject of research. Since clouds share similar reflection characteristics with some other ground objects/surfaces such as snow, ice, and white man-made objects, identification of the cloud and its separation from non-cloud regions is a challenging task. The existence of additional data such as multi-spectral bands could assist a more accurate cloud identification process by utilizing temperature and water content information that are provided through additional bands. The difficulty in automation of cloud segmentation becomes more significant when access to spectral bands is limited to Red, Green, Blue, and Near-infrared (Nir) only. Such limitation exists in the data of many satellites such as HJ-N and GF-N, as they do not provide more spectral band data. In recent years, many cloud detection algorithms have been developed. These methods can be divided into three main categories: threshold-based approaches _cite_, handcrafted approaches _cite_, and deep-learning based _cite_ . Function of Mask (FMask) _cite_ and Automated Cloud-Cover Assessment (ACCA) _cite_ algorithms are among the most known and reliable threshold-based algorithms for cloud identification. They use a decision tree to label each pixel as cloud or non-cloud. In each branch of the tree, the decision is made based on the result of a thresholding function that utilizes one or more spectral bands of data. Haze optimized Transformation (HOT) is among the group of handcrafted methods, which isolates haze and thick clouds from other pixels using the relationship between spectral responses of two visible bands. _cite_, as another handcrafted approach, incorporates an object-based Support Vector Machine (SVM) classifier to identify clouds from non-cloud regions using local cloud patterns. With the recent advances made in deep-learning algorithms for image segmentation, several methods have been developed for cloud detection using deep-learning approaches. Xie et al. _cite_ trained a convolutional Neural network (CNN) from multiple small patches. This network classified each image patch into three classes of thin cloud, thick cloud, and non-cloud and as the output it created a probability map for each class. A major problem in cloud detection based on deep-learning is the lack of accurately annotated ground truth. Most default ground truths, obtained through automatic/semi-automatic approaches are not accurate enough. For instance, they label icy or snowy areas as clouds. Such erroneous ground truth limits their use for training new systems based on deep-learning. Fig. _ref_ illustrates an example of these errors in a default ground truth. Although the above mentioned methods have shown limited good results for scenes including thick clouds, they cannot deliver robust and accurate results in scenes where snow is present alongside of the cloud. Here, we propose a new method based on both thresholding and deep-learning to identify the cloud regions and separate them from icy/snow ones in multi-spectral Landsat N images. Our threshold based method utilizes band N in Landsat N and image gradient to detect regions of snow. We augment the existing Landsat N ground truth images by first identifying the icy/snowy regions and second removing them from the ground truth data that is used for the training of our deep-learning system. Our proposed deep-learning system is a Fully Convolutional Neural Network (FCN) that is trained using cropped patches of the training set images. The weights of the trained network are used to detect cloud pixels in an end-to-end manner. Unlike FMask and ACCA, this approach is not blind to the existing global and local cloud contexts in the image. In addition, since only four spectral bands---Red, Green, Blue (band N), and Nir (RGBNir)---are required for the system training and prediction, this architecture can be simply utilized for detection of clouds in images obtained from many other satellites as well as air-born systems.