an indispensable step in many image processing applications, lossy image compression (LIC) is a classical yet still active topic. The goal of LIC is to reduce the image storage space without sacrificing much the image quality, and thus provide an economic solution to image storage and transmission systems. Recently, with the development of portable imaging devices and social media (\eg, Facebook, Instagram and Flickr), billions of images are transmitted and stored daily on social networks _cite_ . The explosive growth of the amount of shared images on Internet raises higher requirements on LIC for more effective visual communication systems. A typical LIC system contains mainly three modules: transformation (\eg, an encoder and a corresponding decoder), quantization (e.g., a quantizer), and encoding. To compress an image into bitstreams, conventional LIC methods firstly apply predefined transformations to transform an image into a sparse domain, then perform lossy quantization on the transformed coefficients, followed by entropy coding _cite_ . Notwithstanding their demonstrated success, conventional LIC methods suffer from three major drawbacks. First, they generally employ a series of cascaded modules to compress an image, which may introduce cumulative errors because there are few interactions between these modules. Second, the transformations employed in these LIC methods are generally designed in a hand-crafted manner (\eg, discrete cosine transform (DCT) for JPEG _cite_ and discrete wavelet transform (DWT) for JPEG N _cite_), which are limited to represent the various complex structures in natural images. Third, traditional LIC methods' performance is poor for compression with a low bits-per-pixel (bpp) rate, often generating severe visual artifacts (\eg, blocky artifacts, blurrings and ringings) . Deep convolutional neural networks (CNNs) have recently led to a series of breakthroughs in many vision problems _cite_ . The flexible non-linear modelling capability and powerful end-to-end training paradigm of CNN also make it a promising new approach to LIC. In the last several years, a flurry of CNN-based LIC methods have been proposed, including the study of network structures _cite_ as well as loss functions _cite_ . Firstly, the end-to-end training manner enables CNN-based LIC systems to adaptively learn an effective encoder-decoder pair from a large amount of image data and in a larger context to represent more complex image structures, reducing the artifacts in the decompressed image. Secondly, by adopting specific loss functions (\ie, perceptual metrics) in the training, the CNN compressors are able to strengthen certain desired aspects (\ie, perceptual quality) of the decomposed image. Despite the advantages of employing CNN for compression, there are still some challenges which limit the performance of CNN-based compressors. First, existing CNN-based LIC methods can only change the number of latent feature maps and/or quantized values to adjust the bpp rate. As a result, the network is trained dedicatedly for a specific bpp rate once at a time. Such a ``one network per bpp" problem limits the flexibility and applicability of CNNs to practical image compression systems. Second, because of the non-differentiable property of discrete operation, quantizer is hard to be updated during the end-to-end CNN network training. Therefore, the optimal decision boundaries of quantization levels are almost unreachable. Third, existing CNN based LIC methods usually adopt fixed quantization bins to discretize the latent image representation and treat each element of the latent image representation equally. Such a quantization scheme, however, ignores the prior knowledge that the local content is spatially variant in an image, and restricts the capability of CNNs in compressing complex image structures. To address the aforementioned issues, in this work, we propose a new paradigm for deep LIC. More specifically, we proposed a deep Tucker Decomposition Network (TDNet) which takes the sparsity/low-rankness of latent image representations into consideration. The key component of TDNet is a novel tucker decomposition layer (TDL), which decomposes the latent image representation into a set of projection matrices and a compact core tensor. By changing the rank of core tensor and its quantization levels, we can easily adjust the bpp rate of latent image representation, and thus a single CNN model can be trained to compress and reconstruct images under multiple bpp rates. Besides, we propose an iterative non-uniform quantization strategy to obtain the optimal quantization boundaries based on the distribution of encoding coefficients. A coarse-to-fine training strategy is introduced to train a stable TDNet and reconstruct the decompressed images. Extensive experiments demonstrate that, our proposed TDNet trained with the mean-squared error (MSE) loss or the multi-scale structural similarity index (MS-SSIM) _cite_ loss can yield competitive results with state-of-the-art CNN-based LIC schemes but it uses only a single network to achieve this goal. The contributions of this work are summarized as follows: The remainder of this paper is organized as follows. Section _ref_ provides a brief survey of related work. Section _ref_ introduces our proposed TDNet model. Section _ref_ presents in detail the tucker decomposition layer. Section _ref_ presents the all-in-one training strategy. In Section _ref_, extensive experiments are conducted to evaluate TDNet. Finally, several concluding remarks are given in Section _ref_ .