The problem of unsupervised image-to-image translation has made promising strides with the advent of Generative Adversarial Networks (GAN) _cite_ in recent years. Given an input from a particular domain, the goal of image-to-image translation is to transform the input onto a specified second domain. Recent works in image-to-image translation has successfully learned this transformation across various tasks including satellite images to map images, night images to day images, greyscale images to color images etc. _cite_, _cite_, _cite_ _cite_ . In this work, we propose an extension of the original problem from a single input image to multiple input images, called multi-image-to-image translation _inline_eq_ . Given semantically related multiple images across _inline_eq_ number of different domains, the goal of _inline_eq_ is to produce the corresponding image in a specified domain. For example, the traditional problem of translating a greyscale image onto the RGB domain can be extended into an _inline_eq_ problem by providing the near infrared (NIR) image of the same scene as an additional input. Now, the objective would be to use information present in greyscale and NIR domains to produce the corresponding output in the RGB domain as shown in Figure _ref_ . In this paper, we study the problem of _inline_eq_ in the more generic unsupervised setting and provide initial direction to solve the problem. Image-to-image translation is a challenging problem. For a given input, there exists multiple possible representations in the specified second domain. Having multiple inputs from different image modalities reduces this ambiguity due to the presence of complimentary information. Therefore, as we show later in experimental results section, leveraging multiple input images leads to an output of higher perceptual quality. Multiple input modalities can be incorporated naively by concatenating all available modalities as channels and feeding into an existing image-to-image translation algorithm. However, such an approach leads to unsatisfactory results (see supplementary material for experiments) . Therefore, we argue that unsupervised multi-image-to-image translation should be treated as a unique problem. In this work our main contributions are three-fold: \noindent N. We introduce the problem of unsupervised multi-image-to-image translation. We show that by leveraging multiple modalities one can produce a better output in the desired domain as compared to when only a single input modality is used. \noindent N. A GAN-based scheme is proposed to combine information of multiple modalities to produce the corresponding output from the desired domain. We introduce a new latent consistency loss term, into the objective function. \noindent N. We propose a generalization to the GAN generator network by introducing a multi-modal generator structure.