Deep learning has been applied with tremendous success on a variety of tasks in remote sensing image analysis. For instance, achievement of state-of-the-art performance in scene classification, pixel-wise labeling of both multispectral and hyperspectral datasets, object detection and image retrieval, highlights the recent success of deep learning models in remote sensing. But these phenomenal performances is highly dependant on the availability of large collection of datasets with accurate annotations (labels) . If either the size of the dataset or the accuracy of the labels is not sufficient (i.e, small scale datasets or inaccurate labels), the performance of the deep learning methods could suffer drastically. The former one can be addressed to some degree by data augmentation strategies, however solving the later case of inaccurate labeling is more difficult. To address the large scale data requirements of deep learning methods, new datasets have been proposed recently in the remote sensing community . This trend will grow continuously in the coming years, due for instance to the large constellation of the Earth observation satellites. One of the major challenge in collecting this new large scale data is accurate labeling of the samples. Manual expert labeling of such large collection of samples is often not feasible and not cost-effective. Thus, labeling is usually performed by non-experts through crowd sourcing, keyword query through search engine in the case of images, open street maps, and out-dated classification maps . These cheap surrogate procedures allows scaling the size of labeled datasets, but at the cost of introducing label noise (i.e. inaccurately labeled samples) . Even when manual experts are involved in labeling the data samples, they must be provided with sufficient information; otherwise inaccurate labeling may still occur (for instance, during the field survey) . Note that in the some applications, labeling is a subjective task that can again introduce label noise. Furthermore, the label noise could occur due to the misregistration of satellite images. Hence in general, large scale datasets might mostly contain inaccurately labeled samples or affected by label noise. In this case, when deep learning methods are employed with conventional loss functions (for instance, categorical cross entropy, mean square error), they will not be robust to label noise, and as a result the classification accuracy decreases significantly . This calls for robust approaches to mitigate the impact of label noise on the deep learning methods. Recently, it was shown that while training deeper neural networks, models tend to memorize the training data, and this phenomena is more severe when the dataset is affected by the label noise . The impact of the label noise in the deep learning models can be partly circumvented by regularization techniques such as drop out layers, and weight regularization. These standard procedures make neural networks robust to some extend, but they are still prone to memorize noisy labels for medium-to-large noise levels. The problem of learning with noisy labels has been long studied in machine learning, but still only few works have focused on neural networks. Recently, new approaches have been proposed in the computer vision and machine learning fields to tackle the label noise by cleaning the noisy labels or designing robust loss functions within the deep learning framework . To mitigate the impact of label noise, one category of method relies on estimating the noise transition probability that describes the probability of _inline_eq_ class label being mislabeled to the _inline_eq_ class label, and use it to be robust to label noise . Among those, some of them require a small set of clean labels to estimate the noise transition probability . The other category of methods proposes to use loss functions which are inherently tolerant to the label noise . Though these methods provided satisfactory results, none of them consider the implicit local geometric structure of the underlying data. The primary objective of this paper is to develop a robust approach to tackle the label noise for remote sensing image analysis. The sensitiveness of deep neural networks to label noise has not been well studied in remote sensing image analysis so far as per our knowledge. Hence the first contribution of this article lies in studying the robustness of deep neural networks to label noise, and also to analyse the efficiency of existing robust loss functions for remote sensing classification tasks. The second contribution of this paper is to propose a novel robust solution to tackle the label noise based on optimal transportation theory~ . Indeed we propose to learn a deep learning model which is robust to label noise by fitting the model to the label-features joint distribution of the dataset with respect to the entropy-regularized optimal transport distance. We coin this method as CLEOT for Classification Loss with Entropic Optimal Transport. One major advantage of our approach compared to existing methods is that our method inherently exploits the geometric structure of the underlying data. A stochastic approximation schemes is proposed to solve the learning problem, and allows the use of our approach within deep learning frameworks. Experiments are conducted on several remote sensing aerial and hyperspectral benchmark datasets, and the results demonstrate that our approach is more robust (tolerant) to high level label noise than current state-of-the-art methods. The remaining of the paper is organized as follows. Section _ref_ discusses related works, section _ref_ defines the label noise and describes the problem formulation, and section _ref_ introduces optimal transport. The proposed method is then presented in section _ref_ while experimental datasets and results are explained in section _ref_ . We finally draw some conclusions in section _ref_ .