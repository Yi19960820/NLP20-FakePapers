Up-to-date maps of buildings are crucial for navigation, urban planning, disaster management, population estimation, and many other geospatial related applications. As advances are made in remote sensing technologies, high resolution overhead imagery including spaceborne and airborne images is widely available and thus provides an ideal data source for creating such maps. However, manually delineating buildings on images is notoriously time and effort consuming. Due to the potential productivity gain, automatic building extraction has been extensively studied for decades. Much of the past work defines criteria of building appearance such as uniform colors, regular shapes, and nearby shadows, and designs a system that identifies objects satisfying the criteria _cite_ . Such approaches have limited generalization abilities because the criteria account for only certain types of buildings whether hand-coded or learned from samples, and results are sensitive to parameter choice. Therefore, despite promising performance on small images containing relative homogeneous buildings, at the time of writing there has not been any automatic system that works reliably on real-world datasets (e.g., images containing a large urban scene) . Some methods utilize LiDAR data that give detailed height information and are able to obtain more reliable results _cite_ . However, compared with imagery, LiDAR data are considerably more expensive to acquire and thus much less accessible. In this paper, we focus on image data. Recognizing the difficulty in developing automatic methods, crowdsourcing emerges as an alternative strategy. One of the most successful examples is OpenStreetMap, which has millions of contributors providing manual labeling. However, a major problem of crowdsourcing maps is inconsistent quality. Position accuracy and completeness vary greatly across different places due to participation inequality _cite_ . The issue is more severe for buildings than other objects like roads and water bodies, because buildings are smaller objects and require more effort to identify and delineate. We take a unique approach that utilizes the convolutional network (ConvNet) framework coupled with labeled data procured from GIS resources. Deep ConvNets trained with very large labeled data have shown to be very powerful to capture the hierarchical nature of features in images and generalize beyond training samples _cite_ . The capabilities lead to great success in many challenging pattern recognition tasks _cite_ . Meanwhile, there exist a massive amount of building footprints from various GIS databases, including crowdsourcing resources. Since both building footprints and images are georeferenced, they can easily be converted to training samples where individual buildings are labeled. Unlike many machine learning problems that requires tremendous effort to collect enough labeled data, abundant human-labeled data are readily available for building extraction. The remainder of the paper is organized as follows. In Section~ _ref_, we present a network architecture capable of learning pixel-wise classification. Section~ _ref_ introduces an output representation that is well suited for our task. In Section~ _ref_, we provide the details of data preparation and network training, as well as evaluation on large datasets. Finally, we conclude in Section~ _ref_ .