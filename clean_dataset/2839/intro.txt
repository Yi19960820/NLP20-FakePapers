Rapid improvements in ND capturing techniques increased the utilization of ND face recognition especially when the regular ND images fail due to lighting and appearance changes. The techniques used for ND based face recognition have been summarized in . Relevant studies are explained in the following text. The work in uses ND face recognition by segmenting a range image based on principal curvature and finding a plane of bilateral symmetry through the face. This plane is used for pose normalization. The authors consider methods of matching the profile from the plane of symmetry and of matching the face surface. A modified technique proposed in, where the authors use segment convex regions in the range image based on the sign of the mean and Gaussian curvatures, and create an Extended Gaussian Image (EGI) for each convex region. A match between a region in a probe image and in a gallery image is done by correlating EGIs. A graph matching algorithm incorporating relational constraints is used to establish an overall match of probe image to gallery image. Convex regions are believed to change shape less than other regions in response to changes in facial expression. This gives this approach some ability to cope with changes in facial expression. However, EGIs are not sensitive to change in object size, and hence two similarly shaped differently sized faces will not be distinguishable in this representation. In the author begins with a curvature-based segmentation of the face. Then a set of features are extracted that describe both curvature and metric size properties of the face. Thus each face becomes a point in feature space, and matching is done by a nearest-neighbor match in feature space. It is noted that the values of the features used are generally similar for different images of the same face, \textquotedblleft except for the cases with large feature detection error, or variation due to expression . Instead of working on all face points, in the authors used ND five feature points only, using these feature points to standardize face pose, and then matching various curves or profiles through the face data. Experiments are performed for sixteen subjects, with ten images per subject. The best recognition rates are found using vertical profile curves that pass through the central portion of the face. Computational requirements were apparently regarded as severe at the time this work was performed, as the authors note that \textquotedblleft using the whole facial data may not be feasible considering the large computation and hardware capacity needed . In they extend Eigenface and hidden Markov model approaches used for ND face recognition to work with range images. also perform curvature-based segmentation and represent the face using an Extended Gaussian Image (EGI) . Recognition is then performed using a spherical correlation of the EGIs. In the authors report on a method of ND face recognition that uses an extension of the Hausdorff distance matching. Again, work in explores principal component analysis (PCA) style approaches using different numbers of eigenvectors and image sizes. The image data set used has N different facial expressions for each of the N subjects. The performance figures reported resulting from using multiple images per subject in the gallery. This effectively gives the probe image more chances to make a correct match, and is known to raise the recognition rate relative to having a single sample per subject in the gallery . Registration and correspondence has been used in to perform ND face recognition using iterative closest point (ICP) matching of face surfaces. Even though most of the work covered here used ND shape acquired through a structured-light sensor, this work uses a stereo-based system. The Approach used in is ND face recognition by first performing a segmentation based on Gaussian curvature and then creating a feature vector based on the segmented regions. The authors report results on a dataset of N face meshes representing N different persons, with some sampling of different expressions and poses for each person. Another research is perform ND face recognition by locating the nose tip, and then forming a feature vector based on contours along the face at a sequence of depth values . An isometric transformation approach has been used in to analyze ND face in an attempt to better cope with variation due to facial expression. Rather than performing recognition on the all face as one module, the authors in have performed recognition using registration on separate face parts and uses fusion to come up with a final decision. Moreover, other research as in and use the high dimensional extracted features, viz. scale invariant feature transform (SIFT, mesh-SIFT) and histograms for both gradient and shapes, from the ND cloud, and perform the recognition process on them. The survey indicates that most if not all research work on extracting some features from given ND face point clouds and using these features in the recognition process. The extracted features heavily depend on the cloud space and can be easily affected by the structure and size of the given points cloud. These clouds can be modeled to save the storage size or to regenerate the depth information. Other research converts the given ND points cloud to N at standard _inline_eq_ and _inline_eq_ coordinates using orthographic projection and convert the problem to pixel image recognition as suggested by . Figure _ref_ shows a complete system that uses this technique. As previously mentioned, there is literature that focus on modeling the ND face clouds as in . Here, a neural model is designed as shown in Figure _ref_ . In this network, the input consists of second order values for all input points cloud and the output is N. Additional input values are added for extra generated surfaces inside and outside the point cloud surface. The output in this case should be proportional to the distance from the input point to the cloud surface as shown in Figure _ref_ . The model however, requires the generation of at least N times the number of the original points cloud. Furthermore, the output is not guaranteed to be on the original surface since the acceptance tolerance _inline_eq_ is defined for scaling purposes making this model computationally expensive if a higher accuracy required. Despite the fact that there is an increase in the literature that includes Deep-learning and Deep-neural systems in ND object recognition as in, none of these techniques have been applied to ND face recognition, or it can use the regular ND representation of the ND face as in . One reason for this lack of applicability is the high sensitivity and the closeness of features between the faces of different individuals, specifically if the ND data is used alone without any texture. Addressing these issues, the main contributions of the proposed ND neural recognition and verification system are listed as follows.