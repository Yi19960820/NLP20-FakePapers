{A} {n} old desirable objective of artificial intelligence (AI) has been the understanding of emotions by machines. Despite the exceptional recent advancements in computer science, emotion understanding still remains a challenging problem for machines. It is one of the key distinguishing factors between humans and AI. To reduce the gap between human and machine by incorporating emotions, the field of affective computing has been devoted to the emotion recognition and integration in human--computer interaction (HCI) scenarios. While the recognition of the emotional state of the users is an active area of research, the extent of emotion realization does not need to be limited to the user state. The recognition of the scene pleasantness independent of a user is an example of such a case. Affective computing utilizes the facial expression and/or the posture of user, physiological signals such as electroencephalography (EEG), magnetoencephalography (MEG), skin conductance response, and eye movement in order to decode the user's state of mind~ _cite_ . On the other hand, the perception of scene pleasantness goes beyond user monitoring and can incorporate machine vision techniques to recognize the scene content in order to judge its emotional message~ _cite_ . The first problem is well established and studied to provide user dependent emotion estimation, however, the second problem is viewer independent and is yet a challenge. The ability to recognize the emotional gist of a scene could facilitate more accurate emotional semantic image retrieval~ _cite_ . Further potential applications can include image/video content analysis and annotation, affective assessment and refinement of advertisements, multimedia affective rating, etc. Motivated enough by such applications, in this work, we focus on decoding the pleasantness of images. The image pleasantness or {\it valence} is the indicator of the amount of positive expression or the negative effect of an image. In order to estimate the pleasantness, we employ computer-vision-based techniques and user-in-the-loop methods as well as the combination of the two procedures. \subsection* {Contributions:} Our main contribution is the assessment of image pleasantness recognition in a realistic, less constrained human-computer interaction scenario, in which the most recent computer vision state-of-the-art and eye tracking based techniques are challenged. More precisely, our contribution includes: In the rest of this paper, we first overview the related work. Then we introduce a new dataset including stimuli, setup and procedure for recording eye movements, and analyze the statistics of the collected data. In Section~ _ref_, we elaborate the basis of a machine learning approach in which classifiers are trained with various visual and gaze-based features in order to decode the pleasantness category of an image. Section~ _ref_ contains several experiments to investigate the performance of features using the adopted machine learning approach. Afterwards, we discuss the results, followed by conclusions.