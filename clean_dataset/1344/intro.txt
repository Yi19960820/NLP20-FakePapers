There are growing demands for tumor identification in pathology for time consuming tasks such as measuring tumor burden, grading tissue samples, determining cell cellularity and many others. Recognizing tumor in histology images continues to be a challenging problem due to complex textural patterns and appearances in the tissue bed. With the addition of tumor, subtle changes which occur in the underlying morphology are difficult to distinguish from healthy structures and require expertise from a trained pathologist to interpret. An accurate automated solution for recognizing tumor in vastly heterogeneous pathology datasets would be of great benefit, enabling high-throughput experimentation, greater standardization and easing the burden of manual assessment of digital slides. Deep convolutional neural networks (CNNs) are now a widely adopted architecture in machine learning. Indeed, CNNs have been adopted for tumor classification in applications such as analysis of whole slide images (WSI) of breast tissue using AlexNet _cite_ and voxel-level analysis for segmenting tumor in CT scans _cite_ . Such applications of CNNs continue to grow and the traditional architecture of a CNN has also evolved since its origination in N _cite_ . A basic CNN architecture encompasses a combination of convolution and pooling operations. As we traverse deeper in the network, the network size decreases resulting in a series of outputs, whether that be classification scores or regression outcomes. In lower layers of a typical CNN, fully-connected (FC) layers are required to learn non-linear combinations of learned features. However the transition between a series of two-dimensional convolutional layers to a one-dimensional FC layer is abrupt, making the network susceptible to overfitting _cite_ . In this paper we propose a method for transitioning between convolutional layers and FC layers by introducing a framework which encourages generalization. Different from other regularizers _cite_, our method congregates high-dimensional data from features maps produced in convolutional layers in an efficient manner before flattening is performed. To ease the dimensionality reduction between convolutional and FC layers we propose a transition module, inspired by the inception module _cite_ . Our method encompasses convolution layers of varying filter sizes, capturing learned feature properties at multiple scales, before collapsing them to a series of average pooling layers. We show that this configuration gives considerable performance gains for CNNs in a tumor classification problem in scanned images of breast cancer tissue. We also evaluate the performance of the transition module compared to other commonly used regularizers (section _ref_) .