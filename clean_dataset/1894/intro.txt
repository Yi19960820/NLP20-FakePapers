Colorectal cancer is the third most commonly occurring cancer in men and the second most commonly occurring cancer in women, where approximately N \% of all colorectal cancers are adenocarcinomas~ . Colorectal adenocarcinoma develops in the lining of the colon or rectum, which makes up the large intestine and is characterised by glandular formation. Histological examination of the glands, most frequently with the Hematoxylin \& Eosin (H \&E) stain, is routine practice for assessing the differentiation of the cancer within colorectal adenocarcinoma. Pathologists use the degree of glandular formation as an important factor in deciding the grade or degree of differentiation of the tumour. Within well differentiated cases, above N \% of the tumour is gland forming~, whereas in poorly differentiated cases, typical glandular appearance is lost. Within the top row of Figure N, (a) shows a healthy case, (b) shows a moderately differentiated tumour and (c) shows a poorly differentiated tumour. We observe the loss of glandular formation as the grade of cancer increases. There is a growing trend towards a digitised pathology workflow, where digital images are acquired from glass histology slides using a scanning device. The advent of digital pathology has led to a rise in computational pathology, where algorithms are implemented to assist pathologists in diagnostic decision making. In routine pathological practice, accurate segmentation of structures such as glands and nuclei are of crucial importance because their morphological properties can assist a pathologist in assessing the degree of malignancy~ . With the advent of computational pathology, digitised histology slides are being leveraged such that pathological segmentation tasks can be completed in an objective manner. In particular, automated gland segmentation within H \&E images can enable pathologists to extract vital morphological features from large scale histopathology images, that would otherwise be impractical. Computerized techniques play a significant role in automated digitalized histology image analysis, with applications to various tasks including but limited to nuclei detection and segmentation~, mitosis detection~, tumor segmentation~, image retrieval~, cancer type classification~, etc. Most of the previous literature focused on the hand-crated features for histopathological image analysis~ . Recently, deep learning achieved great success on image recognition tasks with powerful feature representation~ . For example, U-Net achieved excellent performance on the gland segmentation task~ . To further improve the gland instance segmentation performance, Chen et al. presented a deep contour-aware network by formulating an explicit contour loss function in the training process and achieved the best performance during the N MICCAI Gland Segmentation (GlaS) on-site challenge~ . In addition, a framework was proposed in~ _cite_ by fusing complex multichannel regional and boundary patterns with side supervision for gland instance segmentation. This work was extended in~ _cite_ to incorporate additional bounding box information for an enhanced performance. A Multi-Input-Multi-Output network (MIMO-Net) was presented for gland segmentation in~ _cite_ and achieved the state-of-the-art performance. Furthermore, several methods have investigated the segmentation of glands from histology images using limited expert annotation effort. For example, a deep active learning framework was presented in~ _cite_ for gland segmentation using suggestive annotation. Unannotated images were utilized in~ _cite_ with the design of deep adversarial networks and consistently good segmentation performance was attained. However, automated gland segmentation remains a challenging task due to several important factors. First, a high resolution level is needed for precise delineation of glandular boundaries, that is important when extracting morphological measurements. Next, glands vary in their size and shape, especially as the grade of cancer increases. Furthermore, the output of solely the gland object gives limited information when making a diagnosis. Extra information, such as the uncertainty of a prediction and the simultaneous segmentation of additional histological components, may give additional diagnostic power. For example, the pathologist may choose to ignore areas with high uncertainty, such as areas with dense nuclei and areas containing artifacts. An additional histological component of particular interest is the lumen, which is ultimately the defining structure of a gland. This structure can help empower diagnostic decision making, because its presence and morphology can be indicative of the grade of cancer. In this paper we propose a minimal information loss dilated network that aims to solve the key challenges posed by automated gland segmentation. During feature extraction, we introduce minimal information loss (MIL) units, where we incorporate the original down-sampled image into the residual unit after max-pooling. This, alongside dilated convolution, helps retain maximal information that is essential for segmentation, particularly at the glandular boundaries. We use atrous spatial pyramid pooling for multi-level aggregation that is essential when segmenting glands of varying shapes and sizes. After feature extraction, our network up-samples the feature maps to localise the regions of interest. During uncertainty quantification, we apply random transformations to the input images as a method of generating the predictive distribution. This leads to a superior segmentation result and allows us to observe areas of uncertainty that may be clinically informative. Furthermore, we use this measure of uncertainty to rank images that should be prioritised for pathologist annotation. As an extension, we demonstrate how our method can be modified to simulatenously segment the gland lumen. The additional segmentation of the gland lumen can empower current automated methods to achieve a more accurate diagnosis. Our proposed framework can be trained end to end, with one minimal information loss dilated feature extraction network. Experimental results show that the proposed framework achieves state-of-the-art performance on the N MICCAI GlaS Challenge dataset and on a second independent colorectal adenocarcinoma dataset.