Single-image super-resolution (SR) algorithms aim to construct a high-quality high-resolution (HR) image from a single low-resolution (LR) input. Numerous single-image SR algorithms have been recently proposed for generic images that exploit priors based on edges~ _cite_, gradients~ _cite_, neighboring interpolation _cite_, regression~ _cite_, and patches _cite_ . Most SR methods focus on generating sharper edges with richer textures, and are usually evaluated by measuring the similarity between super-resolved HR and ground-truth images through full-reference metrics such as the mean squared error (MSE), peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) index~ _cite_ . In our recent SR benchmark study~ _cite_, we show that the information fidelity criterion (IFC) ~ _cite_ performs favorably among full-reference metrics for SR performance evaluation. However, full-reference metrics are originally designed to account for image signal and noise rather than human visual perception~ _cite_, even for several recently proposed methods . We present N example SR images generated from a same LR image in Figure~ _ref_ . Table _ref_ shows that those full-reference metrics fail to match visual perception of human subjects well for SR performance evaluation. In addition, full-reference metrics require ground-truth images for evaluation which are often unavailable in practice. The question how we can effectively evaluate the quality of SR images based on visual perception still remains open. In this work, we propose to learn a no-reference metric for evaluating the performance of single-image SR algorithms. It is because no-reference metrics are designed to mimic visual perception (i.e., learned from large-scale perceptual scores) without requiring ground-truth images as reference. With the increase of training data, no-reference metrics have greater potential to match visual perception for SR performance evaluation. We first conduct human subject studies using a large set of SR images to collect perceptual scores. With these scores for training, we propose a novel no-reference quality assessment algorithm that matches visual perception well. Our work, in essence, uses the same methodology as that of general image quality assessment (IQA) approaches. However, we evaluate the effectiveness of the signal reconstruction by SR algorithms rather than analyzing noise and distortions (e.g., compression and fading) as in existing IQA methods~ _cite_ . We quantify SR artifacts based on their statistical properties in both spatial and frequency domains, and regress them to collected perceptual scores. Experimental results demonstrate the effectiveness of the proposed no-reference metric in assessing the quality of SR images against existing IQA measures. The main contributions of this work are summarized as follows. First, we propose a novel no-reference IQA metric, which matches visual perception well, to evaluate the performance of SR algorithms. Second, we develop a large-scale dataset of SR images and conduct human subject studies on these images. We make the SR dataset with collected perceptual scores publicly available at _url_ .