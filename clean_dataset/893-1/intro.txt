Emotion is a psycho-physiological process that can be triggered by conscious and/or unconscious perception of objects and situations, associated with multitude of factors such as mood, temperament, personality, disposition, and motivation _cite_ . Emotions are very important in human decision handling, interaction and cognitive process _cite_ . With the advancement of technology and as our understanding of emotions is advancing, there is a growing need for automatic emotion recognition systems. Emotion recognition has been studied widely using speech _cite_ _cite_ _cite_, text _cite_, facial cues _cite_, and EEG based brain waves _cite_ individually. One of the biggest open-sourced multimodal resources available in emotion detection is IEMOCAP dataset _cite_ which consists of approximately N hours of audio-visual data, including facial recordings, speech and text transcriptions. In this paper we combine these modes to make a stronger and more robust detector for emotions. We explore various deep learning based architectures to first get the best individual detection accuracy from each of the different modes. We then combine them in an ensemble based architecture to allow for training across the different modalities using the variations of the better individual models. Our ensemble consists of Long Short Term Memory networks, Convolution Neural Networks, fully connected Multi-Layer Perceptrons and we complement them using techniques such as Dropout, adaptive optimizers such as Adam, pretrained word-embedding models and Attention based RNN decoders. This allows us to individually target each modality and only perform feature fusion at the final stage. The advantages of our study are two-fold. First, since we target each modality individually, lack of availability of any modality does not cripple our algorithm and would not require retraining of other modalities but only the prefinal layer. This also allows our approach to be modular. Second, we use Motion-capture data instead of Video recording, hence we do not use ND-Convolutions but ND-Convolutions which are faster have less memory requirements. We also use advanced hyperparameter optimization tools to achieve the best possible model configuration depending on our resource constraints. Our code is open sourced for other researchers to repeat and enhance our study.