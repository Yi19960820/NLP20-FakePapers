\noindent With the development of Internet, in recent years, large-scale image and multimedia video data have increased explosively, resulting in urgent demands for advanced intelligent image analysis technology, such as semantic image parsing. As a fundamental and long-standing problem in computer vision, semantic image parsing is performed at three levels, which will be discussed below. \romannumeralN. Category-level semantic segmentation . It attempts to assign a single category label to each pixel. Here, a category label corresponds to a specific object category or a local part of the object. Therefore, category-level semantic segmentation consists of basic semantic segmentation and semantic part segmentation (called object parsing in the literature), as illustrated in Fig. _ref_ . The former predicts the segmentation mask and its label for the entire object, as shown in the middle of Fig. _ref_, while the latter refers to segmenting an object into its constituent semantic parts and predicting the segmentation mask for each local part, as shown on the right side of Fig. _ref_ . According to the definition, part segmentation can be regarded as a special type of fine-grained category-level semantic segmentation task. Category-level semantic segmentation is actually a pixel-wise dense prediction problem, which is supported by two key technologies: N) classification: an object is assigned a specific semantic-concept label; and N) localization: the classification label for a pixel must match the appropriate coordinates in the output score map _cite_ . \romannumeralN. Instance-level semantic segmentation . In contrast to category-level segmentation, it requires precise segmentation of each object and correct detection of all the object instances in one image _cite_ . In the middle of Fig. _ref_, three boats are segmented by assigning the same category label (i.e., "boat") . Clearly, category-level segmentation cannot distinguish the object instances belonging to the same category. In the right column of Fig. _ref_, the three boats are segmented by assigning different IDs with the same category label (i.e., "boat one", "boat two", and "boat three") . Thus, the instance-level segmentation requires support from both classification and detection technologies. \romannumeralN. Beyond segmentation . In recent years, works extending beyond semantic segmentation have also received substantial attention. This task is inspired by previous work on image parsing _cite_, which refers to the process of decomposing an image into its constituent visual structured configuration _cite_ . Works beyond segmentation not only semantically segment images but also predict richer and finer results, such as the structures and relations of objects and the spatial layout. Specifically, images are decomposed into semantic regions and the structures and relationships among objects are constructed. For example, in Fig. _ref_, the image caption is "there is one person sitting on the chair nearby the table with one monitor". Following the work in _cite_, the beyond segmentation method first segments all the objects (i.e., "person", "chair", "table", and "bottle") in the image, predicts the relations among objects (i.e., "hold", "stand by", "support", and "sit on"), and finally estimates the hierarchical structures. Intuitively, works beyond segmentation produces detailed parsing results that are consistent with human perception. Similar to most vision problems, the discriminant features greatly affect the performance of semantic image parsing. Traditional semantic segmentation methods adopt hand-crafted features, such as SIFT _cite_, HOG _cite_, and LBP _cite_ . However, these hand-crafted features are not applicable to various tasks. Therefore, the automatic extraction of valuable information and effective representation of image/video data are critical. Representation learning, i.e., learning representations of data, makes it easier to extract useful information from raw data to build predictors. The representation algorithms for semantic image parsing have experienced three periods of progress in the continuous improvement of image parsing performance: N) traditional hand-crafted methods; N) deep learning, such as convolutional neural networks (CNNs), recurrent neural networks, and recursive neural networks (RNNs) ; and N) the integration of the two methods to complement each other. Extensive experiments _cite_ have demonstrated that the representation ability of traditional hand-crafted features is insufficient. Meanwhile, deep learning currently achieves the best representation ability and has had tremendous success in many applications, such as image classification _cite_, object detection, and natural language understanding _cite_ . Therefore, we list only the main differences among the three-level semantic segmentation tasks accomplished by deep representation models, as illustrated in Table _ref_ . \doublerulesep N Deep learning is defined as learning multiple levels of representations from the local and detailed levels in the shallow layers to the global and abstract levels in the deeper layers _cite_ . Specifically, deep neural networks consist of several simple but non-linear modules, each of which transforms the simple representation at the shallow layer (starting with the raw input) into slightly more abstract representation at the deep layer. Several well-known deep neural networks, such as the CNN, recurrent neural network, and RNN, have been reported in recent years. Moreover, abundant variants of these networks, which we discuss in the following sections, have emerged. Convolutional Neural Networks . The CNN _cite_ is designed for data with grid-like structures and consists of convolutional layers, pooling layers, and non-linear rectification layers. The units in the neural network are locally connected, which results in shared weights of the local parameters and features in the deeper abstract layers being invariant to local image transformation. Despite the numerous applications of CNNs, they were not well-known until their successful application to object recognition during the ImageNet challenge in N. Then, CNN was quickly applied to semantic segmentation _cite_ and achieved great successes. Recurrent Neural Networks . In contrast to CNNs, which are tailored for grid-structure data _cite_, recurrent neural networks are more appropriate for sequential data _cite_ . The principal characteristic of a recurrent neural network is that neurons (units) are connected by synaptic links to express temporal relations. To alleviate the explosion or vanishing of the backpropagated gradients in the shallow layers _cite_, long short-term memory (LSTM) networks _cite_ were proposed by introducing special hidden units to memorize the observed knowledge of the previous and current inputs. The success of LSTM has demonstrated that LSTM is more effective than conventional recurrent neural networks in image captioning _cite_ and machine translation _cite_ . Additionally, many works _cite_ utilize LSTM to improve the performance of semantic image parsing. Recursive Neural Networks . Unlike the aforementioned recurrent neural networks _cite_, which are designed for time sequential data, RNNs _cite_ are designed for hierarchical space structural data. Recurrent neural networks for chain structures by connecting hidden units, whereas RNNs recursively form a hierarchical structure because the structures of networks are similar at every level of the hierarchy. This characteristic is in line with the structures of natural language, which results in successful natural language parsing _cite_ . Some recent works _cite_ proposed RNNs for structural semantic parsing. With a unique perspective, this work comprehensively reviews deep representation learning-based semantic image parsing at three levels: category-level semantic segmentation, instance-level semantic segmentation, and beyond segmentation. Specifically, for each level of semantic segmentation, we elaborate the relative terminology and background knowledge. Furthermore, this paper reviews and compares existing models and relatively well-known datasets and evaluation metrics. To the best of our knowledge, there is no such overview of semantic image parsing in the literature. The rest of this article is organized as follows. In Section N, we review deep representations for semantic image parsing at three levels. Datasets and evaluation metrics are introduced in Section N. Finally, we present the conclusions and discuss promising future research directions in Section N.