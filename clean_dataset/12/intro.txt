The manual segmentation of cardiac images is tedious and time-consuming, which is even more critical given the new availability of huge databases (e.g. UK Biobank _cite_) . Magnetic resonance imaging (MRI) is widely used by cardiologists. Yet MRI is challenging to segment due to its anisotropic resolution with somewhat distant ND slices which might be misaligned. There is hence a great need for automated and accurate cardiac MRI segmentation methods. In recent years, many state-of-the-art cardiac segmentation methods are based on deep learning and substantially overcome the performance of previous methods. Currently, they dominate various cardiac segmentation challenges. For instance, in the Automatic Cardiac Diagnosis Challenge (ACDC) of MICCAI N, N out of the N cardiac segmentation methods were based on deep learning. In particular, the N best-ranked methods were all deep learning ones. Deep learning methods can be roughly divided into to N classes: ND methods, which segment each slice independently (i.e. _cite_, _cite_, _cite_), and ND methods, which segment multiple slices together as a volume (i.e. _cite_, _cite_) . ND methods are popular because they are lightweight and require less data for training. But as no ND context is taken into consideration, they might hardly maintain the ND-consistency between the segmentation of different slices, and even fail on ``difficult" slices. For example, the ND method used in _cite_ achieves state-of-the-art segmentation on several widely used datasets but makes the most prominent errors in apical slices and even fails to detect the presence of the heart. On the other hand, ND methods should theoretically be robust to these issues. But in _cite_, with experiments on the ACDC dataset, the authors found that all the ND approaches they proposed consistently outperformed the ND method being considered. In fact, ND methods have some significant shortcomings. First, using ND data drastically reduces the number of training images. Second, ND methods mostly rely on ND convolution. Yet border effects from ND convolution may compromise the information in intermediate representations of the neural networks. Third, ND methods require far more GPU memory. Therefore, substantial downsampling of data is often necessary for training and prediction, which causes loss of information. One possible way to combine the strengths of ND and ND methods is to use recurrent neural networks. In _cite_, the authors merge U-Net _cite_ and a recurrent unit into a neural network to process all slices in the same stack, arranging the slices from the base to the apex. Information from the slices already segmented in the stack is preserved in the recurrent unit and used as context while segmenting the current slice. Comparisons in _cite_ prove that this contextual information is helpful to achieve better segmentation. However, the approaches based on recurrent neural networks are still limited. On the one hand, as the slice thickness (usually N to Nmm) is often very large compared to the slice resolution (usually N to Nmm), the correlation between slices is low except for adjacent slices. Thus, considering all slices at once may not be optimal. On the other hand, the prediction on each slice made by a recurrent neural network does not depend on an existing prediction. With this setting, the automatic segmentation is remarkably different from the procedure of human experts. As presented in _cite_, human experts are very consistent in the sense that the intra-observer variability is low; yet the inter-observer variability is high, as segmentation bias varies remarkably between human experts. Hence in general, for given a slice, there is no a unique correct segmentation. But human operators still maintain consistency in their predictions respectively. Being inspired by these facts, we adopt a novel perspective: we train our networks to explicitly maintain the consistency between the current segmentation and the already predicted segmentation on an adjacent slice. We do not assume that there is a unique correct segmentation. Instead, the prediction for the current slice explicitly depends on another previously predicted segmentation. Another possible method to improve segmentation consistency is to incorporate anatomical prior knowledge into neural networks. In _cite_, the segmentation models are trained to follow the cardiac anatomical properties via a learned representation of the ND shape. While adopting novel training procedure, this method is based on ND convolution neural networks for segmentation. So the issues of ND methods discussed above still exist. In this paper, we propose a novel method based on deep learning to perform cardiac segmentation. Our main contribution is threefold: \textbullet \The spatial consistency in cardiac segmentation is barely addressed in general, while this is a remarkable aspect of human expertise. Our method explicitly provides spatially consistent results by propagating the segmentations across slices. This is a novel perspective, as we do not assume the existence of a unique correct segmentation, and the prediction of the current segmentation depends on the segmentation of the previous slice. \textbullet \After training our method with a large dataset, we demonstrate its robustness and generalization ability on a large number of unseen cases from the same cohort as well as from other reference databases. These aspects are crucial for the application of a segmentation model in general, yet have not yet been explored before. \textbullet \Most segmentation methods proceed in a ND manner to benefit from more training samples and higher training speed in comparison with ND methods. In contrast, we proposed an original approach that keeps the computational assets of ND methods but still addresses key ND issues. We hence believe in its potential impact on the community .