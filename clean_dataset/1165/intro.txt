Multimedia data has been ubiquitous in search engines and online communities, while its efficient retrieval is important to enhance user experience. The major challenges in multimedia retrieval reside in the large-scale and high-dimension of multimedia data. To enable accurate retrieval under efficient computation, approximate nearest neighbors (ANN) search has attracted increasing attention. Parallel to the traditional indexing methods _cite_ for candidates pruning, another advantageous solution is hashing methods _cite_ for data compression, which transform high-dimensional media data into compact binary codes while similar binary codes are generated for similar data items. In this paper, we focus on the learning to hash methods _cite_, which build data-dependent hash encoding schemes for efficient image retrieval. These methods can capture the underlying data distributions to achieve better performance than traditional data-independent hashing methods, e.g. Locality-Sensitive Hashing (LSH) _cite_ . A fruitful line of learning to hash methods have been designed to enable efficient ANN search, where the efficiency comes from the compact binary codes that are orders of magnitude smaller than the original high-dimensional feature descriptors. Ranking these binary codes in response to each query entails only a few computations of the Hamming distance between the query and each database item. Hash lookup further reduces the search to constant time by early pruning of irrelevant candidates falling out of a small Hamming ball. The literature can be divided into supervised and unsupervised paradigms _cite_ . Recently, deep learning to hash methods _cite_ have shown that deep neural networks can be used as nonlinear hash functions to enable end-to-end learning of deep representations and hash codes. These deep hashing methods have shown state-of-the-art results. In particular, it proves crucial to jointly learn similarity-preserving representations and control quantization error of converting continuous representations to binary codes _cite_ . Most of the existing methods are tailored to image retrieval scenarios with balanced or nearly balanced data. In other words, they weigh equally each data pair, no matter they are similar pairs or dissimilar pairs. Thus, they can maximize retrieval performance on average per-instance accuracy. However, due to the well-known long-tail law, multimedia data with skewed distribution are prevalent in many online image search systems. The data skewness may either stem from the imbalanced numbers of similar and dissimilar pairs associated with each query, or from the diversity of popular and rare classes, or even from the variations in easy and difficult pairs of images. Such data skewness will severely affect the retrieval performance, especially when one needs to trade off the precision (weigh dissimilar pairs more in order to discard irrelevant results) from recall (weigh similar pairs more in order to include potentially relevant results) . Therefore, how to address various data skewness problems simultaneously remains an open problem. This work presents Deep Priority Hashing (DPH), a novel deep hashing model that generates compact binary codes to enable effective and efficient image retrieval under data skewness problems. DPH is formalized as a Bayesian learning framework, providing two novel loss functions motivated by the success of the focal loss in object detection problem~ _cite_ . One is a cross-entropy loss for similarity-preserving learning, which prioritizes difficult image pairs over easy image pairs to learn prioritized deep representations. The other is a quantization loss, which prioritizes hard-to-quantize examples for generating nearly lossless hash codes. Both loss functions are well-specified to similarity retrieval of highly skew image data. The proposed DPH model is an end-to-end architecture that can be trained by standard back-propagation. Extensive experiments demonstrate that DPH can generate high-quality hash codes and yield state-of-the-art image retrieval performance on three benchmark datasets, ImageNet, NUS-WIDE, and MS-COCO.