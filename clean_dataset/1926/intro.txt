Automatic fingerprint recognition is one of the most widely studied topic in biometrics over the past _inline_eq_ years~ _cite_ . One of the main challenges in fingerprint recognition is to increase the recognition accuracy, especially for latent fingerprints. Fingerprint comparison is primarily based on minutiae set comparison~ _cite_ . A number of hand-crafted approaches~ _cite_ have been used to augment the minutiae with their attributes to improve the recognition accuracy. However, robust automatic fingerprint minutiae extraction, particularly for noisy fingerprint images, continues to be a bottleneck in fingerprint recognition systems. With rapid developments and success of deep learning techniques in a variety of applications in computer vision and pattern recognition~ _cite_, we are beginning to see network-based approaches being proposed for fingerprint recognition. Still, the prevailing methods of minutiae extraction primarily utilize fingerprint domain knowledge and handcrafted features. Typically, minutiae extraction and matching involves pre-processing stages such as ridge extraction and ridge thinning, followed by minutiae extraction~ _cite_ and finally heuristics to define minutiae attributes. While such an approach works well for good quality fingerprint images, it provides inaccurate minutiae location and orientation for poor quality rolled/plain prints and, particularly for latent fingerprints. To overcome the noise in fingerprint images, Yoon \etal _cite_ used Gabor filtering to calculate the reliability of extracted minutiae. Although this approach can work better than~ _cite_, it also resulted in poor results with highly noisy images. Because these prevailing approaches are based on handcrafted methods or heuristics, they are only able to extract basic (or low level) features of images. We believe learning based approaches using deep networks will have better ability to extract high level features from low quality fingerprint images. In this paper, we present a novel framework that exploits useful domain knowledge coded in the deep neural networks to overcome limitations of existing approaches to minutiae extraction. Figure _ref_ visualizes results of the proposed framework on two latent fingerprints from the NIST SDN dataset. Specifically, our proposed approach comprises of two networks, called CoarseNet and FineNet:-CoarseNet is a residual learning~ _cite_ based convolutional neural network that takes a fingerprint image as initial input, and the corresponding enhanced image, segmentation map, and orientation field (computed by the early stages of CoarseNet) as secondary input to generate the minutiae score map. The minutiae orientation is also estimated by comparing with the fingerprint orientation.-FineNet is a robust inception-resnet~ _cite_ based minutiae classifier. It processes each candidate patch, a square region whose center is the candidate minutiae point, to refine the minutiae score map and approximate minutiae orientation by regression. Final minutiae are the classification results. Deep learning approach has been used by other researchers for minutiae extraction (see Table _ref_) . But, our approach differs from published methods in the way we encode fingerprint domain knowledge in deep learning. Sankaran \etal~ _cite_ classified the minutiae and non-minutiae patches by using sparse autoencoders. Jiang \etal~ _cite_ introduced a combination of two networks: JudgeNet for classifying minutiae patches, and LocateNet for locating precise minutiae location. While Jiang \etal use neural networks, their approach is very time-consuming due to use of sliding window to extract minutiae candidates. Another limitation of this approach is that it does not provide minutiae orientation information. Tang \etal~ _cite_ utilized the idea of object detection to detect candidate minutiae patches, but it suffers from two major weaknesses: (i) hard threshold to delete the candidate patches, and (ii) the same network is used for both candidate generation and classification. By using sliding windows, Darlow \etal~ _cite_ fed each pixel of the input fingerprint to a convolutional neural network, called MENet, to classify whether it corresponds to a minutia or not. It also suffers from time-consuming sliding windows as in~ _cite_, and separate modules for minutiae location and orientation estimates. Tang \etal~ _cite_ proposed FingerNet that maps traditional minutiae extraction pipeline including orientation estimation, segmentation, enhancement, and extraction to a network with fixed weights. Although this approach is promising because it combines domain knowledge and deep network, it still uses plain network architecture and hard threshold in non-maximum suppression . Finally, the accuracy of FingerNet depends largely on the quality of the enhanced and segmentation stage while ignoring texture information in the ridge pattern. In summary, the published approaches suffer from using sliding windows to process each pixel in input images, setting hard threshold in post-processing step, and using plain convolutional neural network to classify candidate regions. Furthermore, the evaluation process in these studies is not consistent in terms of defining ``correct'' minutiae. The contributions of our approach are as follows: