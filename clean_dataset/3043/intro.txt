In recent years, convolutional neural networks _cite_ (CNNs) have achieved great success for pattern recognition and computer vision, leading to important progress in a variety of tasks, like image classification _cite_, object detection _cite_, instance segmentation _cite_ and so on. Despite the success of CNN, it still suffer from some serious problems. One example is the existence of adversarial samples _cite_, when we add small noises or make some small changes to the initial samples, CNN will give different predictions for these samples with high confidence, although visually we can hardly find any significant changes in the images. Another example is the rejection ability of CNN, when feed a sample from an unseen class to CNN, it will still allocate the sample to a known class with high confidence. These two phenomena indicate that CNN is not robust, though it can achieve human-level or even better accuracy on some specific datasets, its performance will degenerate obviously in the complex scenes of the reality. This greatly limits the application of CNN in real worlds. The main reasons for these problems include two aspects: First, CNN is a purely discriminative model, it essentially learns a partition of the ``whole" feature space, therefore, the samples from unseen classes are still predicted to some specific regions under the partition, and CNN still views these samples as some known classes with high confidence. This explains why the rejection ability of CNN is poor; Second, from the perspective of representation learning, the learned representation of CNN is linear separable, see Fig. _ref_ for an illustration, and under this kind of representation, the inter-class distance is sometimes even smaller than the intra-class distance, this significantly reduces the robustness of CNN in real and complicated environments. Several methods have been proposed to improve the robustness of CNN and most of them concentrate on designing better loss functions. _cite_ and _cite_ proposed the contrastive loss and triplet loss to learn a more robust feature representation, in which the input pairs and triplets need to be carefully selected from the training data to ensure the convergence and stability. _cite_ proposed the center loss to improve the performance of softmax-based CNN, however, the centers can not be learned jointly with the CNN and are only updated according to some pre-defined rules rather than learned directly from data. Our CPL is more general than the center loss, since we totally abandon softmax layer and all the prototypes are learned automatically from data. Moreover, previous work of _cite_ and _cite_ also made improvements and extensions for the softmax based loss but they still kept the softmax layer with the traditional framework of CNN for classification. In this paper, we propose a novel framework called convolutional prototype learning (CPL) for image classification. In the bottom of CPL, the convolutional layers are used to extract discriminative features just like traditional CNN, but in the top of CPL we assign multiple prototypes to represent different classes. The classification is simply implemented by finding the nearest prototype (using Euclidean distance) in the feature space. We design multiple loss functions for this framework, making the CNN feature extractor and the prototypes being learned jointly from the raw data. Therefore, the whole framework can be trained efficiently and effectively. Experiments on several datasets demonstrate that the CPL framework can achieve comparable or even better classification accuracies compared with traditional CNN models. Benefited from the prototype-based decision function, a natural prototype loss (PL) can be added to our CPL framework, to pull the feature vector closer to their corresponding prototypes (genuine class representation) . The PL is akin to the maximum likelihood (ML) regularization proposed in _cite_ . On one hand, it acts like a regularizer, which can prevents the model form over-fitting and improves the performance of CPL. On the other hand, it can also improves the intra-class compactness in feature representation. Therefore, the final learned representation is intra-class compact and inter-class separable, which makes the representation more discriminative and robust. From the perspective of probability, our CPL and PL framework essentially extract, transform, and model the data of each class as a Gaussian mixture distribution and the prototypes act as the means of Gaussian components for each class, this enables integrating probabilistic methods such as Bayesian models into our framework. Compared with the traditional CNN framework, we do not make partition for the ``whole'' feature space, but project the samples to some specific regions of the feature space (near the prototypes), thus our model is more robust to samples from unseen classes and more suitable for rejection. CPL can also be viewed as a hybrid discriminative and generative model (like the discriminative density model in _cite_) which will lead to better generalization performance.