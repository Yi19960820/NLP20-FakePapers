Semantic labeling in very high resolution (VHR) images is a long-standing research problem in remote sensing field. It plays a vital role in many important applications, such as infrastructure planning, territorial planning and urban change detection . The target of this problem is to assign each pixel to a given object category. Note that it is not just limited to building extraction, road extraction and vegetation extraction which only consider labeling one single category, semantic labeling usually considers several categories simultaneously . As a result, this task is very challenging, especially for the urban areas, which exhibit high diversity of manmade objects. Specifically, on one hand, many manmade objects (e.g., buildings) show various structures, and they are composed of a large number of different materials. Meanwhile, plenty of different manmade objects (e.g., buildings and roads) present much similar visual characteristics. These confusing manmade objects with high intra-class variance and low inter-class variance bring much difficulty for coherent labeling. On the other hand, fine-structured objects in cities (e.g., cars, trees and low vegetations) are quite small or threadlike, and they also interact with each other through occlusions and cast shadows. These factors always lead to inaccurate labeling results. Furthermore, it poses additional challenge to simultaneously label all these size-varied objects well. To accomplish such a challenging task, features at different levels are required. Specifically, abstract high-level features are more suitable for the recognition of confusing manmade objects, while labeling of fine-structured objects could benefit from detailed low-level features. Convolutional neural networks (CNNs) in field are well-known for feature learning . CNNs consist of multiple trainable layers which can extract expressive features of different levels . Moreover, recently, CNNs with have demonstrated remarkable learning ability in computer vision field, such as scene recognition and image segmentation . Meanwhile, the development of remote sensing has also been greatly promoted by numerous CNNs-based methods . For example, deconvolution networks are investigated by Lu et al. for remote sensing scene classification, and Chen et al. perform target classification using CNNs for SAR Images. Based on CNNs, many patch-classification methods are proposed to perform semantic labeling . These methods determine a pixel's label by using CNNs to classify a small patch around the target pixel. However, they are far from optimal, because they ignore the inherent relationship between patches and their time consumption is huge . Typically, fully convolutional networks (FCNs) have boosted the accuracy of semantic labeling a lot . FCNs perform pixel-level classification directly and now become the normal framework for semantic labeling. Nevertheless, due to multiple in FCNs, the final are much coarser than the input image, resulting in less accurate labeling results. Accordingly, a tough problem locates on how to perform accurate labeling with the coarse output of FCNs-based methods, especially for fine-structured objects in VHR images. To solve this problem, some researches try to reuse the low-level features learned by CNNs' shallow layers . The aim is to utilize the local details (e.g., corners and edges) captured by the in fine resolution. Technically, they perform operations of multi-level feature fusion, or with recorded indices . Most of these methods use the strategy of direct stack-fusion. However, this strategy ignores the inherent semantic gaps in features of different levels. An alternative way is to impose boundary detection . It usually requires extra boundary supervision and leads to extra model complexity despite boosting the accuracy of object localization. Another tricky problem is the labeling incoherence of confusing objects, especially of the various manmade objects in VHR images. To tackle this problem, some researches concentrate on leveraging the multi-context to improve the recognition ability of those objects. They use multi-scale images or multi-region images as input to CNNs. However, these methods are usually less efficient due to a lot of repetitive computation. Differently, some other researches are devoted to acquire multi-context from the inside of CNNs. They usually perform operations of multi-scale, multi-scale pooling or multi-kernel convolution, and then fuse the acquired multi-scale contexts in a direct stack manner. Nevertheless, this manner not only ignores the hierarchical dependencies among the objects and scenes in different scales, but also neglects the inherent semantic gaps in contexts of different-level information. In summary, although current CNN-based methods have achieved significant breakthroughs in semantic labeling, it is still difficult to label the VHR images in urban areas. The reasons are as follows: N) Most existing approaches are less efficient to acquire multi-scale contexts for confusing manmade objects recognition; N) Most existing strategies are less effective to utilize low-level features for accurate labeling, especially for fine-structured objects; N) Simultaneously fixing the above two issues with a single network is particularly difficult due to a lot of fitting residual in the network, which is caused by semantic gaps in different-level contexts and features. In this paper, we propose a novel self-cascaded convolutional neural network (ScasNet), as illustrated in Fig. _ref_ . The aim of this work is to further advance the state of the art on semantic labeling in VHR images. To this end, it is focused on three aspects: N) multi-scale contexts aggregation for distinguishing confusing manmade objects; N) utilization of low-level features for fine-structured objects refinement; N) residual correction for more effective multi-feature fusion. Specifically, a conventional CNN is adopted as an encoder to extract features of different levels. On the outputted by the encoder, global-to-local contexts are sequentially aggregated for confusing manmade objects recognition. Technically, multi-scale contexts are first captured by different convolutional operations, and then they are successively aggregated in a self-cascaded manner. With the acquired contextual information, a coarse-to-fine refinement strategy is performed to refine the fine-structured objects. It progressively reutilizes the low-level features learned by CNN's shallow layers with long-span connections. In addition, to correct the latent fitting residual caused by semantic gaps in multi-feature fusion, several residual correction schemes are employed throughout the network. As a result of residual correction, the above two different solutions could work collaboratively and effectively when they are integrated into a single network. Extensive experiments demonstrate the effectiveness of ScasNet. Moreover, the three submodules in ScasNet could not only provide good solutions for semantic labeling, but are also suitable for other tasks such as object detection and change detection, which will no doubt benefit the development of the remote sensing deep learning techniques. To sum up, the main contributions of this paper can be highlighted as follows: A shorter version of this paper appears in . Apart from extensive qualitative and quantitative evaluations on the original dataset, the main extensions in the current work are: The remainder of this paper is arranged as follows. The basic modules used in ScasNet are briefly introduced in Section _ref_ . Section _ref_ presents the details of the proposed semantic labeling method. Experimental evaluations between our method and the state-of-the-art methods, as well as detailed analyses of ScasNet are provided in Section _ref_ . Finally, the conclusion is outlined in Section _ref_ .