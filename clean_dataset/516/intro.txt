Human hand pose estimation is important for various applications in human-computer interaction. It has been studied in computer vision for decades~ _cite_ and regained tremendous research interests recently due to the emergence of commodity depth cameras~ _cite_ . The problem is challenging due to the highly articulated structure, significant self-occlusion and viewpoint changes. Existing methods can be categorized as two complementary paradigms, or . Model based methods synthesize the image observation from hand geometry, define an energy function to quantify the discrepancy between the synthesized and observed images, and optimize the function to obtain the hand pose~ _cite_ . The obtained pose could be highly accurate, at the expense of dedicated optimization~ _cite_ . Learning based methods learn a direct regression function that maps the image appearance to hand pose, using either random forests~ _cite_ or deep convolutional neutral networks~ _cite_ . Evaluating the regression function is usually much more efficient than model based optimization. The estimated pose is coarse and can serve as an initialization for model based optimization~ _cite_ . Most learning based methods do not exploit hand geometry such as kinematics and physical constraints. They simply represent the hand pose as a number of independent joints. Thus, the estimated hand joints could be physically invalid, e.g., the joint rotation angles are out of valid range and the phalange length varies during tracking the same hand. Some works alleviate this problem via a post processing, e.g., using inverse kinematics to optimize a hand skeleton from the joints~ _cite_ . Such post-processing is separated from training and is sub-optimal. Recently, the deep-prior approach~ _cite_ exploits PCA based hand pose prior in deep convolutional network. It inserts a linear layer in the network that projects the high dimensional hand joints into a low dimensional space. The layer is initialized with PCA and trained in the network in an end-to-end manner. The approach works better than its counterpart baseline without using such prior. Yet, the linear projection is only an approximation because the hand model kinematics is highly non-linear. It still suffers from invalid hand pose problem. In this work, we propose a model based deep learning approach that fully exploits the hand model geometry. We develop a new layer that realizes the non-linear forward kinematics, that is, mapping from the joint angles to joint locations. The layer is efficient, differentiable, parameter-free (unlike PCA) and servers as an intermediate representation in the network. The network is trained end-to-end via standard back-propagation, in a similar manner as in~ _cite_, using a loss function of joint locations. Our contributions are as follows: The framework of our approach is briefly illustrated in Figure~ _ref_ . Our code is public available at {\tt https: //github.com/tenstep/DeepModel}