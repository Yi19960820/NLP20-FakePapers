X-ray angiography is the most used imaging modality to visualise blood vessels for interventional purposes such as stenting of stenosed vessels or for diagnostic purposes such as assessment of myocardial perfusion or stenosis grading. To minimise ionising radiation exposure of the patient and medical personnel during image acquisition, low power X-Rays are used resulting in noisy and low contrast images. In the context of diagnosis, the main object of interest is the vascular tree, its branchings and variations in thickness. It is therefore necessary to accurately highlight the vessels in consecutive frames to reduce the noise and improve contrast. In addition, in interventional procedures, identifying interventional instruments (catheter, wires) is also needed in order to better plan and control their positioning. Efficiently discriminating between instruments and vessels as well as other anatomical structures that may have similar appearance is crucial during the interventions. Figure _ref_ (a-c) shows an example of an angiogram sequence. Note large non-rigid motion between frames as well as the ambiguity between vessels and the catheter. Figure _ref_ (e) shows a frame from a different sequence of the same patient but taken at different scan and angle and (f) shows a different patient. There is a significant difference in vessel as well as catheter locations in all three sequences, which we consider as independent examples. Figure _ref_ (d) shows the ground truth segmentation of the first frame. CNN based methods provide state of the art segmentation results but need to be trained with a large number of examples with ground truth segmentations that are typically obtained by manual annotation by experts. The presence of noise and low contrast make this task particularly challenging and methods with handcrafted features lead to inaccurate object detection. Neural networks were demonstrated to achieve outstanding performance in vision tasks when trained from well annotated and large datasets. This is in contrast to unsupervised training where limited success has been achieved so far. We make a step towards that direction by developing an approach to automatically generate annotated examples by exploiting the knowledge of the application context and the data. In this paper we present a multistage architecture based on Convolutional Neural Networks for semantic segmentation of instruments and vessel tree. We propose a method to automatically generate label proposals that are successively refined in a multistage process. This data is then used to train a CNN in a way that exploits spatial and temporal continuity. This results in a network capable of generating accurate segmentations. In summary, our main contributions are: