Video understanding is one of the core tasks in the field of computer vision. The YouTube-NM dataset _cite_ is a large-scale video understanding dataset consisting of over N million YouTube videos which are annotated with N, N tags from N vertical categories. The average number of labels per video is N In the Kaggle competition, Google Cloud \& YouTube-NM Video Understanding Challenge ({\tt https: //www.kaggle.com/c/youtubeNm}), the dataset is divided into three parts. The training set has N million videos, the validation set contains N million videos and the testing set contains N million samples. Moreover, the testing set is divided into two parts, one for public leaderboard evaluation and the other for private leaderboard evaluation. Participants submit their predictions on the whole test set but could only see the score on public set. The final score is determined by the score on the private testing set. In the competition, submissions are evaluated using Global Average Precision (GAP) at N. For each video, participants submit a list of predicted labels and their corresponding confidence scores and the evaluation server takes the predicted labels that have the highest N confidence scores for each video, then treats each prediction and the confidence score as an individual data point in a long list of global predictions, to compute the Average Precision across all of the predictions and all the videos. In detail, the evaluation metric (GAP) is calculated as: In the rest of our report, we summarize our detailed solution methods in the competition. Our baseline models are first introduced and evaluated. Then our methods on frame-level feature modelling and video-level feature classification are introduced. Our proposed approach mainly addresses the following three problems. At last, we give the ensemble method and models we adopt in our final submission. Finally, we summarize our contributions of our submission and propose future work.