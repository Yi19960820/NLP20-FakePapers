Laser illumination offers many advantages over incoherent light for imaging, including high power densities, efficient light generation, narrow spectral bandwidths, robust stability, long lifetimes, and fast triggering capabilities. Unfortunately, coherent illumination also introduces speckle artifacts that are caused by constructive and destructive interference between emitted wavefronts _cite_ . The poor image quality resulting from speckle noise prohibits lasers from being used in many widefield imaging applications. For example, commercial endoscopes utilize arc lamps or light-emitting diodes (LEDs) as illumination sources, and consequently require large-diameter light guides to transmit sufficient illumination power. Speckle noise also corrupts image quality in optical coherence tomography (OCT) _cite_, reflectance confocal microscopy _cite_, and ultrasound imaging _cite_ . To mitigate laser speckle noise, several optical methods have been explored _cite_ . In general, optical approaches add cost and complexity, reduce power throughput, and place fundamental limitations on imaging speed. While image processing methods for laser speckle reduction have been most prominently developed for OCT _cite_, conventional model-based algorithms may be applied to speckle reduction in widefield imaging. In general, these denoising approaches can be grouped into three categories: total variation-based, non-local methods, and sparse filtering. Rudin et al. first introduced the concept of Total Variation (TV) denoising _cite_, which has been shown to work extremely well on piecewise-like images, but often suffers from a characteristic "staircase effect" in non-constant regions of images. Abergel et al. expanded TV to include iterative conditional expectations _cite_, and more recent work incorporated a priori models for noise in TV _cite_ . Multiplicative Image Denoising by Augmented Lagrangian (MIDAL) _cite_ utilizes a multiplicative noise model (with knowledge of the noise standard deviation) and optimization through a Lagrangian framework, and generally mitigates noise with only some loss in image texture. Buades et al. were the first to propose a non-local algorithm for noise reduction, called Non-Local Means (NLM) _cite_ . NLM relies on the assumption that for each noisy feature in an image, there exists similar non-local features that may be combined to separate noise from the common, underlying image features. NLM has been adapted for a probabilistic Poisson noise model _cite_, and also paired with Principal Component Analysis (PCA) _cite_ as well as the Wiener filter _cite_ . Sparse filtering methods seek to maximize the variety of image features in a learned dictionary that is later averaged to reduce image noise. Aharon et al. introduced a joint K-mean clustering and Singular Value Decomposition (K-SVD) approach _cite_, which was further optimized by Rubenstein et al _cite_ . Block-Matching ND Filtering (BMND) and its variants are the de-facto state-of-the-art for image denoising using sparse filtering _cite_ . Similar to K-SVD, BMND relies on the aggregation of noisy blocks with comparable features for collaborative filtering and weighted averaging to reduce noise. This method was later expanded to RGB images by way of a transformation to the YUV image space _cite_ . An in-depth review of prior work in relevant image denoising techniques is provided by Meiniel et al _cite_ . In general, conventional image processing techniques are computationally complex, require parameter tuning, and degrade resolution or introduce artifacts as they reduce speckle. Machine learning approaches, on the other hand, serve as an alternative to image processing techniques, as they can generate complex transformation functions by training on datasets that contain example input and desired output images. Moreover, deep learning has emerged as a powerful technique to learn complex representations of imaging data using multi-layer neural networks. Here, we present a deep convolutional neural network for laser speckle reduction (\textquotesingle \textquotesingle) on widefield images formed from multi-wavelength, red-green-blue laser illumination. We describe a method for effectively learning the distribution of speckle artifacts to target and reduce noise in images not previously seen by the network. This technique relies on a training set of coherent-and incoherent-illuminated image pairs of a variety of objects to learn a transformation from speckled to speckle-free images. Previous efforts in OCT have explored shallow neural networks for estimating filter parameters in a speckle reduction model _cite_, and deep networks for speckle reduction using a set of registered and averaged volumes of retinal tissue as ground truth _cite_ . CNNs have previously been shown to be effective for recovering image information degraded by scattering media _cite_ . In widefield imaging, deep learning networks have been applied for general image denoising _cite_, but not specifically for speckle reduction. DeepLSR is novel in its use of a true incoherent source as a target ground truth, the use of a diverse set of objects for training a generalizable model, and in its application of deep learning to widefield laser-illumination images. We benchmark this approach against conventional speckle reduction methods on images of laser-illuminated objects previously unseen by the network. We further provide step-by-step instructions for adapting DeepLSR to new data sets contaminated with speckle noise (see Appendix) . Standard deep learning models employ handcrafted loss functions that utilize repeated pixel-wise comparisons between the model \textquotesingle s prediction and the ground truth for model refinement. However, such pixel-wise loss functions do not capture higher order statistics that exist in the training data, such as non-local dependencies _cite_ . To address relationships beyond the second order and to capture spatial relationships amongst distant pixels, recent focus has shifted to generative models to improve translations between higher dimensional data. Such methods have been used for image-to-image translation tasks with applications that include artistic style transfer _cite_, super-resolution imaging _cite_, and synthetic data refinement _cite_ . DeepLSR utilizes a conditional Generative Adversarial Network (cGAN) to reduce laser speckle by posing the problem as an image-to-image translation task _cite_ . The overall architecture involves simultaneously training a speckle-free image generator and a real-versus-fake image discriminator, given a conditional input (Fig. _ref_) . While the generator learns to generate a realistic mapping from an input speckled image to an output speckle-free image, the discriminator learns to classify pairs of input and generated output images as either real or fake. During this adversarial training, the discriminator provides feedback to the generator. The trained generator is then capable of reducing speckle noise in images it has never seen. Previous research in adversarial image-to-image translation has been challenged by instability caused by the complexity of back-and-forth training between the generator and the discriminator. Furthermore, this training paradigm can struggle with learning multiple sub-distributions of data that may exist within a certain distribution. This problem is often referred to as mode collapse. To overcome this challenge, we utilize spectral normalization instead of the more commonly used batch normalization for training DeepLSR _cite_ . With this adversarial framework, we trained networks to reduce speckle in images of a wide assortment of objects to evaluate robustness, and in images of tissue for evaluation in an endoscopic setting.