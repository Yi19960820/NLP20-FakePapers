Fully-supervised semantic segmentation has recently achieved prominent progress~ _cite_ while triggering a huge demand of dense annotated data. The conventional protocol~ _cite_ requires annotators to click along region boundaries until generating a closed polygon and eventually produce a pixel-level label map. Obviously, obtaining large corpus of accurate label maps requires expensive and tedious human labor, especially when confronted with objects that are not suitable for polygon representations (e.g., round sign board, sparse branches) . Besides, from a cognitive perspective~ _cite_, humans are not good at putting clicks on narrow boundaries, resulting in incorrect labelling. As report in ~ _cite_, annotating a single Np image from Cityscapes dataset with quality control averagely costs N hours. To make annotation more efficiently, _cite_ propose a semi-automatic CNN-RNN framework for sequentially predicting vertices of the polygon outlining the objects inside the given bounding box. It benefits human annotators via relieving their work load. However, it still suffers from the limitation of polygon representation and over-depends on the quality of box. Could we find an alternative to dense annotations? As _cite_ report, annotating coarsely not only allows annotators to easily draw on the region where they feel confident, but also accelerates N-N _inline_eq_ faster than polygon drawing. Coarse annotations provide various forms of user interactions to boost annotating efficiency, where some examples are shown in Figure _ref_ . However, directly applying those coarse annotations is hard to generate competitive results due to its sparse supervision. Facing a dilemma either to consume large amount of labor and time for dense supervision or carefully derive weakly-supervised models for propagating coarse annotations, in this paper, we open a new direction of coarse-to-fine annotation enrichment for generating sufficient reliable labels from coarse annotations with a low time cost. A generalized efficient framework is proposed to automatically generate dense annotations based on the original coarse annotations of images, where fine annotations are achieved with a negligible time cost. As Figure~ _ref_ shows, our framework firstly constructs the feature space and the affinity matrix on the raw image to preserve data structure. Then it propagates sparse user markups to update the beliefs of the classifier for unlabeled points. With the help of the nonlocal principle, we relax the binary constraint and formulate this framework as a convex problem with a closed-form solution. The proposed method could be even generalized for refining sparser and more challenging coarse annotations such as scribbles. Extensive experiments have been conducted on two public benchmark datasets, i.e., the Cityscapes and PASCAL VOC N, with various configurations to evaluate the effectiveness of the proposed methods from different perspectives. The experimental results have evidenced that our annotation enrichment framework can be a cost-effective and flexible solution for semantic segmentation learning. Our main contributions are summarized as follows: The rest of the paper is organized as follows. In Section N, related work including weakly-supervised segmentation and annotation refinement is presented. The problem definition and details of our proposed framework are provided in Section N, followed by comprehensive performance studies and a conclusion in Section N and N respectively.