Person re-identification (re-id) deals with the problem of re-associating a specific person across non-overlapping cameras. It has been receiving increasing popularity~ _cite_ due to its important applications in intelligent video surveillance. Existing methods mainly focus on addressing the single-shot person re-id problem. Given a probe image of one person taken from one camera, a typical scenario for single-shot person re-id is to identify this person in a set of gallery images taken from another camera. Usually, the identification results are based on ranking the similarities of the probe-gallery pairs. The performance of person re-id is measured by the rank-_inline_eq_ matching rate if the correct pair hits the retrieved top-_inline_eq_ ranking list. To increase the matching rate, state-of-the-art approaches either employ discriminative features in representing persons or apply distance metric learning methods to increase the similarity between matched image pairs. Numerous types of features have been explored to represent persons, including global features like color and texture histograms~ _cite_, local features such as SIFT~ _cite_ and LBP~ _cite_, and deep convolutional neural network (CNN) features~ _cite_ . In the meantime, a large number of metric learning approaches have been applied to person re-id task, such as LMNN~ _cite_, Mahalanobis distance metric~ _cite_, and RankSVM~ _cite_ . Despite the significant progress in recent years, the performance achieved by these methods do not fulfill the real-application requirement due to the following reasons. First, images captured by different cameras undergo large amount of appearance variations caused by illumination changes, heavy occlusion, background clutter, or human pose changes. More importantly, for real surveillance, persons always appear in a video rather than in a single-shot image. These single-shot based methods fail to make full use of the temporal sequence information in surveillance videos. Several algorithms have been proposed to tackle the multi-shot person re-id problem, i.e., to match human instances in the sequence level (these human patch sequences are usually obtained by visual detection and tracking) . To exploit the richer sequence information, existing methods mainly resort to: (N) key frame/fragment representation~ _cite_ ; (N) feature fusion/encoding~ _cite_ and (N) spatio-temporal appearance model~ _cite_ . Despite their favorable performance on recent benchmark datasets~ _cite_, we have the following observations on their limitations. First, key frame/fragment representation based algorithms~ _cite_ often assume the discriminative fragments to be located in the local minima and maxima of Flow Energy Profile~ _cite_, which may not be accurate. During the final matching, since only one fragment is selected to represent the whole sequence, richer information contained by the rest of the sequences is not fully utilized. Second, feature fusion/encoding methods~ _cite_ take bag-of-words approach to encode a set of frame-wise features into a global vector, but ignore the informative spatio-temporal information of human sequence. To overcome these shortages, the recently proposed method~ _cite_ employs the spatially and temporally aligned appearance of the person in a walking cycle for matching. However, such approach is extremely computationally inefficient and thus inappropriate for real applications. It is therefore of great importance to explore a more effective and efficient scheme to make full use of the richer sequence information for person re-id. The fundamental challenge of multi-shot person re-id is how to systematically aggregate both the frame-wise appearance information as well as temporal dynamics information along the human sequence to generate a more discriminative sequence level human representation. To this end, we propose a recurrent feature aggregation network (RFA-Net) that builds a sequence level representation from a temporally ordered sequence of frame-wise features, based on a typical version of recurrent neural network, namely, Long Short-Term Memory network~ _cite_ . Figure~ _ref_ shows an overview of the difference between our method and previous approaches. The proposed feature aggregation framework possesses various advantages. First, it allows discriminative information of frame-wise data to propagate along the temporal direction, and discriminative information could be accumulated from the first LSTM node to the deepest one, thus yielding a highly discriminative sequence level human representation. Second, during feature propagation, this framework can non-informative information from reaching the deep nodes, therefore it is robust to noisy features (due to occlusion, tracking/detection failure, or background clutter etc) . Third, the proposed fusion network is simple yet efficient, which is able to deal with sequences with variable length. The main contributions of this work lie in that we present a recurrent feature aggregation network to address the multi-shot person re-id problem. The proposed network jointly takes the feature fusion and spatio-temporal appearance model into account and makes full use of the temporal sequence information for multi-shot person re-id. With the use of the proposed network, hand-crafted low-level features can be augmented with temporal cues and significantly improve the accuracy of person re-id. Extensive experiments on two publicly available benchmark datasets demonstrate that the proposed person re-id method performs favorably against state-of-the-arts algorithms in terms of effectiveness and efficiency.