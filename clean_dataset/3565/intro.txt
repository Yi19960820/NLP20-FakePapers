Generative networks not only re-create observations, i.e., create whole probability distributions per observation (as opposed to, say, one number), they also promise to create, i.e., not seen before, observations. Currently, there are four major types of generative networks: flow-based, _cite_, _cite_, auto-regressive _cite_, variational auto-encoders (VAE-s), _cite_, _cite_ and generative adversarial nets (GAN-s), _cite_, _cite_ . For a full recent taxonomy, see for example _cite_ . Because biological brains use only a few dimensions for creativity, we will focus here on generative nets which allow for small dimensions and efficiency of creativity. Of the above types, only VAE-s and GAN-s are parallelizable (i.e., efficient) and allow for a small number of dimensions (GAN-s allow for a small dimensional, see _cite_) . In our experiments, we used only two dimensions per class, with uni-modal probability density for generation. Firstly, we propose in sub-section _ref_ to use of observations, when training the net. As a result, not all training observations are well reconstructed (reconstruction is a necessary condition for perturbation of that image) . An additional classifier is required to determine the weights of training observations and hence which training observation is well reconstructed. Because of this choice of training observations, the construct is not predictive in the usual statistical sense. Secondly, we propose in sub-section _ref_ to use the tentative empirical drift _inline_eq_ of well reconstructed images for generation, as opposed to drift _inline_eq_, as normally done. The knowledge of the tentative empirical drifts require that the net be optimized at least twice. This makes generative nets, in the sense that actual observation is required. That is how human creativity normally works: to be considered not pathological, it starts with some actual observation and deviates thereafter.