Image retrieval has long been a challenging task in computer vision, especially when the image amount gets continually increasing. The semantic gap between the low-level visual features and high-level semantics _cite_ and the intention gap between user's search intent and the query _cite_ have long been a big challenge. Numerous efforts have been made to counter this significant challenge, among which the convolutional neural network (CNN) has recently demonstrated impressive progress. Due to the extensive use of CNN, a lot of networks based on CNN obtained extremely high accuracy. Therefore, we leverage a successful classification network called GoogleNet _cite_ to generate semantic information of input images. For us, excellent classification results is the first step of the accurate image retrieval due to the exact semantic information has significant influence on feature representation. In this paper, we introduce a classification network to image semantic retrieval (NIST) framework based on deep learning to learn the probability of classification results, fuse the semantic feature matrix and use the matrix to compute the similarity between multi-label images in the semantic space. Figure N illustrates the NIST framework of three parts. Particularly, given a query image, our goal is to use several representative dimensions and the corresponding probabilities outputing from GoogleNet to represent the semantic information. Note that each semantic concept is viewed as a class, one or more classifiers are trained from the training data. Meanwhile, we use the probability of class to evaluate the integrating degree between input image and the class of the current dimension. After generating these structured outputs from the classification network, we leverage these results to construct a semantic feature matrix contains the serial number and corresponding probability of each class. When comparing two images, we firstly choose _inline_eq_ classes with the top _inline_eq_ highest probabilities to be a new matrix and then fuse the two matrixes by our fusion strategy to obtain a N-dimensional matrix. Finally, we compute the similarity of two images by the semantic distance computation algorithm. The contributions of this paper can be concluded as follows: (N) offering a train of thoughts from a convolutional neural network which efficiently process classification tasks to image semantic retrieval, designing a semantic distance computation algorithm according to semantic feature extracted from CNN; (N) proposing an efficient semantic feature. The feature matrix only uses less than N features to represent the semantic information of images, having significant influence on storage saving, time consumption and match efficiency. This new feature matrix can fuse with other image features to improve the retrieval accuracy.