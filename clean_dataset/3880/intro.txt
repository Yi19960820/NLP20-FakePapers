Human visual attention is attracted either by salient stimuli reflected from the environment or task demands where an observer is attracted to objects of interest . Researchers have noticed that human visual system does not perceive and process the whole visual information provided at once. Instead, humans selectively pay attention to different parts of the visual input to gather relevant information sequentially and try to combine information from each step over time to build an abstract representation of the entire input . Works done in neuroscience and cognitive science literature have revealed selection of regions of interest is highly dependent on two modes of visual attention: bottom-up and top-down. The bottom-up mode attends to low-level features of potential importance and attention is represented in the form of a saliency map . The top-down mode deals with task demands and goals which strongly influence scene parts to which humans should fixate . Attention models inspired by the human perception have shown good results in a variety of applications of computer vision such as object recognition and detection, video compression and virtual reality . Moreover, with the increased interest in deep learning paradigm in recent years, visual attention mechanisms incorporated in these methods have also shown astonishing results in a wide range of applications including, image captioning, machine translation, speech recognition and object recognition . Reinforcement learning is one of the most powerful frameworks in solving sequential decision making problems, where decision making is based on a sequence of observations of the task’s environment. Until recently, applying reinforcement learning to some real world applications where the input data is high dimensional (e.g., vision and speech) was a major challenge. Recent advances in deep learning has resulted in powerful tools for automatic feature extraction from raw data, e.g. raw pixels of an image. Research has shown that deep neural networks can be combined with reinforcement learning in order to learn useful representations. For example, Deep Q-Network (DQN) algorithm, which is a combination of Q-learning with a deep neural network, has achieved good performances on several games in the Atari N domain and in some games it can gain even higher scores than the human player. This combination, deep neural networks and reinforcement learning framework, has also been shown to achieve promising results in the computer vision domain, specifically in visual attention based models. The main challenge in sequential attention models is leaning where to look. Reinforcement learning techniques such as policy gradients are good choices to address this challenge . Overall, there are two types of attention models, the soft attention models and the hard attention models. The soft attention models are end-to-end approaches and differentiable deterministic mechanisms that can be learned by gradient based methods. However, the hard attention models are stochastic processes and not differentiable. Thus, they can be trained by using the REINFORCE algorithm in the reinforcement learning framework. In this paper, a soft attention mechanism is integrated into the deep Q-network (as shown in Figure _ref_) to enable a deep Q-learning agent to learn to play Atari N games by focusing on the most pertinent parts of its visual input. In fact, the model tries to learn the control actions and the attention locations simultaneously. To test our model, we compare predicted fixation locations with explicit attention judgements of people with a specific scenario as explained in section _ref_ . The results give better fixation prediction accuracy compared to two popular bottom-up (BU) saliency models: Itti-Koch’s saliency model and Graph-Based Visual Saliency (GBVS) model . We also demonstrate that the proposed model can learn how to play Atari N games (i.e. leaning the control actions of the game) and where to look (i.e. learning the fixation locations) on video game frames effectively.