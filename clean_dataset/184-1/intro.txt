With the profit from deep learning~ _cite_, object recognition~ _cite_ has gained great success in recent years. The premise of such success is that sufficient annotated samples for each considered object are available for supervised learning~ _cite_ . However, this is often difficult to comply with in real applications due to the prohibitive annotation cost or some harsh conditions for sample collection (\eg, samples in danger scene, newly emerging or identified) ~ _cite_ . Zero-short learning (ZSL) ~ _cite_ is a task proposed to address an extreme problem, where no annotated samples but only a semantic description are available for a class. In contrast to conventional supervised learning, ZSL attempts to recognize samples from {unseen classes} through exploiting the semantic connections between these classes and some other {seen classes} which have sufficient annotated training samples. In ZSL, each class is represented by a semantic vector (\eg, attributes~ _cite_, word vector~ _cite_, or even an encoding vector for a sentence~ _cite_), which composes the {semantic space} shared by both seen and unseen classes, and the visual representations of the visual samples constitute the {visual space} . Essentially, ZSL can be formulated as a cross-domain matching problem: after being projected into a joint embedding space, a visual sample will match against all candidate class-level semantic descriptions and be assigned to the nearest class. In this process, the embedding space underpins the success of matching and stimulates research on approaches to learn an effective embedding space. Generally, the embedding schemes can be categorized into two groups based on learning unidirectional mapping functions or bidirectional mapping functions. The former fixes either semantic space ~ _cite_ or visual space ~ _cite_ as the anchor space and learn a mapping function to align the other modality onto this space. These approaches are based on a common assumption that the chosen anchor space has sufficient discriminability to distinguish different classes either seen or unseen. But in practice, this assumption may not hold for state-of-the-art semantic representations or even for powerful deep features _cite_ trained on large-scale external dataset, as shown in Figure~ _ref_ (a) (d) . Another line of works project both visual samples and the class-level semantic descriptions into a latent intermediate space via fitting a compatibility function between two modalities in order that the visual samples can be successfully distinguished~ _cite_ . These approaches, however, suffer from a common drawback that they ignore the intra-class compactness and the resultant large intra-class variance thereon can hinder the generalization capacity in ZSL. In this paper, we posit that an ideal embedding space should satisfy two criteria: intra-class compactness and inter-class separability, which promote the generalization capacity in ZSL in different ways. While the former encourages the visual embeddings of a class to distribute tightly close to the semantic embedding of this class, the latter forces the embeddings crossing classes to be distinguishable. Towards this goal, we design a simple but effective two-branch network to simultaneously map the semantic descriptions and visual representations into a joint space. We design a new loss function which is composed of two terms: a regression term and a classification term. The regression term minimizes the absolute distance between the embeddings of a visual sample and its class-level semantic description. The classification term forces the embeddings crossing classes can be distinguished by learning an auxiliary classifier. Through learning the embedding space this way, a visual sample will be close to its class-level semantic identification and far away from identifications of other classes, thus enhancing the generalization capacity in ZSL, as shown in Figure~ _ref_ (b) (e) . Furthermore, we also extend our method to a transductive setting to better handle the model bias problem~ _cite_ in ZSL: a sample from unseen class has high probability to be assigned to a seen class. Specifically, we propose a pseudo labeling strategy to progressively incorporate the testing samples with pseudo labels into the training process, thus enabling the learned embeddings to better balance between seen and unseen classes, as shown in Figure~ _ref_ (c) (f) . Although our method employs the testing data, we require no other extra supervision information. A summary of existing embedding schemes and our embedding scheme for ZSL can be found in Table~ _ref_ . Experimental results on five standard ZSL datasets show the superior performance of the proposed method as well as its transductive extension.