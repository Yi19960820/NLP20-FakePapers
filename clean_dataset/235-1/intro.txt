Person re-identification deals with the task of matching identities across images captured from disjoint camera views. Given a query image, a person re-identification system determines whether the person has been observed by another camera at another time. Significant attention has been dedicated to person re-identification in the past few years, as the task is essential in video surveillance for cross-camera tracking, multi-camera event detection, and pedestrian retrieval. Albeit highly important, the re-identification problem poses significant challenges due to the viewpoint and pose changes, illumination variations, cluttered backgrounds, occlusions, and indiscriminative appearances across different cameras (or even for the same camera) . Moreover, re-identification task considers new identities at test time, therefore it requires a high generalization capability of the learned feature encodings. Existing research on person re-identification problem can be broadly divided into two mainstreams. (a) Methods that seek to learn a discriminative metric, which allows instances of the same identity to be closer while instances of different identities to be far away _cite_ . These metrics learning methods mainly adopt pairwise _cite_ or triplet _cite_ loss to obtain an embedding for each probe image and distinguish identities in the projected space. Along similar lines, _cite_ proposes a quadruplet ranking loss that is capable of achieving smaller intra-class variations and large inter-class distances, which results in an improved performance on the test set. (b) Methods that focus on designing robust visual descriptors to model the appearance of the person _cite_ . Among these techniques, handcrafted features found initial success _cite_ . More recently, automatically learned feature representation using deep architectures have shown excellent improvements _cite_ . The prevalent re-identification approaches belonging to these two research streams assume that the person bounding boxes are provided by a dedicated detector. However, such detections are not always perfect, resulting in problems such as the inclusion of excessive background in the object box, incomplete coverage of body and localization mismatch. This is exacerbated by the fact that there exist heavy occlusions partially masking the pedestrians in surveillance scenarios. Our intuition is that a desired capability that allows overcoming these challenges is to pay attention to important yet perhaps subtle local details alongside the supposedly prominent global cues. In this paper, we propose an automatic approach which learns to focus on local details as well as the global image descriptions using deep neural networks. This helps the identification algorithm to filter out the irrelevant image parts and concentrate on the regions that carry more valuable and discriminative cues for the identity prediction task. We formulate the proposed feature selection strategy as a soft-attention with in a deep network, which enables an end-to-end learning framework. In addition to avoiding the problems due to imperfect pedestrian detection windows, our network learns to resolve ambiguities (such as similar clothing of two different identities) by shifting attention towards more distinguishing aspects of the respective identities. To this end, we utilize already learned global discriminative features as a guidance and a dynamic selection mechanism to assign different importance weights to local feature representations. Recent deep learning based re-identification approaches perform training on the identity classification task and use the network features for the test set to perform retrieval _cite_ . This approach limits the representation capability of deep features since the end-task is different from the one used during learning. To overcome this shortcoming, we propose a multi-task loss formulation that considers both classification and ranking objectives during the training phase. The ranking loss enforces the locally attentive network outputs to take guidance from the predictions based on global features by introducing a margin violation penalty. Our results on three large-scale datasets demonstrate significant performance improvements. Our main contributions are threefold, as given below: The rest of this paper is organized as follows. Section N reviews and analyzes the related literature. Section N provides the details of our proposed network. Section N reports experimental results, and Section N concludes this paper with an outlook towards the future work.