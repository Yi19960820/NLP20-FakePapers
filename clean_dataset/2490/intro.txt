Diffusion imaging (DI) rapidly developed into one of the most important non-invasive tools for clinical brain research, due to its ability to reconstruct neural pathways in the human brain. However, long acquisition times, based on the high amount of acquired gradient directions, result in a rare usage of DI in clinical practice. To overcome this problem, recent methods demonstrated the strength of machine learning and in particular deep learning (DL), which is able to describe and reconstruct the tissue's underlying complex microstructure very accurately even if only a limited number of gradient directions are available~ _cite_ . Thus, scanning time can be greatly reduced. Despite these promising results, the application of DL in the field of DI is constrained, due to a non-uniform signal representation, resulting from diverging gradient directions and b-values during acquisition across subjects. Even if the same gradient directions remain identical within a study, scanner artifacts, subject motion or eddy currents will lead to distorted gradient directions~ _cite_ . To address this issue, a uniform and unique signal representation is necessary to apply DL in DI. Therefore, all signals must be transformed into a generic representation, e.g. spherical harmonics (SH) ~ _cite_ . This is further supported by the fact that SH coefficients normally average around zero, which is preferred for DL applications~ _cite_ . On the other hand, this representation is very susceptible to noise, as high orders commonly have very small coefficients. Therefore, fine structures and sharp contrasts within the signal cannot be learned, resulting in a smoothing effect on the signal. A simple way to address this issue could be to transform the signal back into the spherical surface space (which would be the q-space in case of DI), since all gradient directions can be assumed to be weighted equally. Furthermore, transforming the signal from SH into spherical surface space also opens the application of different loss functions, including relative approaches, which cannot be utilized if the average predicted value is close to zero. Another issue of spherical signals in DL is that spatial convolutions assume all gradient directions to be independent, while gradient neighborhood information is discarded. Furthermore, spatial convolutions merge multi-shell signals, which consist of multiple b-values, into a single signal. To make use of this additional information, a novel layer for DL in DI is introduced: the local spherical convolution (LSC) . This convolution utilizes cyclic kernels, which are applied to the surface of a spherical diffusion signal. Theses kernels are also extended to multi-shell signals to improve multi-shell predictions. To allow these extensions to be utilized in the field of deep learning, we implemented these layers efficiently on the GPU. The code for this paper is publicly available upon request.