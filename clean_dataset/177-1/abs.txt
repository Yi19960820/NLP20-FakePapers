Meaningful facial parts can convey key cues for both facial action unit detection and expression prediction. Textured ND face scan can provide both detailed ND geometric shape and ND texture appearance cues of the face which are beneficial for Facial Expression Recognition (FER) . However, accurate facial parts extraction as well as their fusion are challenging tasks. In this paper, a novel system for ND FER is designed based on accurate facial parts extraction and deep feature fusion of facial parts. In particular, each textured ND face scan is firstly represented as a ND texture map and a depth map with one-to-one dense correspondence. Then, the facial parts of both texture map and depth map are extracted using a novel N-stage process consists of facial landmark localization, facial rotation correction, facial resizing, facial parts bounding box extraction and post-processing procedures. Finally, deep fusion Convolutional Neural Networks (CNNs) features of all facial parts are learned from both texture maps and depth maps, respectively and nonlinear SVMs are used for expression prediction. Experiments are conducted on the BU-NDFE database, demonstrating the effectiveness of combing different facial parts, texture and depth cues and reporting the state-of-the-art results in comparison with all existing methods under the same setting.