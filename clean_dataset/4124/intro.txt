Convolutional Neural Networks are rapidly driving advances in semantic image segmentation _cite_, which aims to predict accurate and effective masks on different classes of targets. To fulfill this challenge, previous study focused on designing or finetuning different network architectures _cite_ . To our knowledge, all these frameworks adapt the estimator (i.e. loss) proposed in _cite_, which averages pixel-wise cross-entropy over prediction maps and ground truths of input batches. However, this kind of estimator only measures distances between predicitons and ground truths, neglecting the interactions between pixels of same category within their neighborhoods. Whereas, such interactions are crucial especially when the appearances of targets change due to the deformation, illumination variations, occlusion and so forth _cite_ . Previous loss functions for enhancing the intra-class features were designed for image classification _cite_, which usually measures batch costs between predicted classes and labels over batchs of images, such like contrastive loss _cite_, triplet loss _cite_ and center loss _cite_ . However, as mentioned in _cite_, the approaches, like contrastive loss and triplet loss, require image pairs or triplets for each training iteration, which result in the dramatic growth of training samples, and thus significantly increase the computational complexity. Center loss overcomes such problem by introducing k-nearest neighbor (k-NN) _cite_ algorithms into sfotmax cross-entropy. At each training iteration, it computes the distances between deep features and every class centers of the features over a mini-batch of images, and updates the centers after each iteration. Center loss can effectively minimize the intra-class variations while keeping the features of different classes separable. Even though, such kind of estimation is still computational expensive, let alone, for image segmentation tasks, each pixel is considered as a training sample. Moreover, most semantic segmentation datasets exhibit long tail distributions with few object categories, which means inter-and intra-classes are imbalanced, and consequently biasing networks training towards major classes _cite_ . To address class imbalance problem, in the realm of object detection, Lin et al. _cite_ modified standard cross entropy loss to down-weight the losses assigned to well-classified examples, and proposed focal loss. In this paper, we introduce a novel locally adaptive loss for semantic image segmentation by estimating selectively filtered predictions based on their categories. Figure _ref_ illustrates the training framework of our proposed method at a glance. The selective pooling filter slides over output feature maps and ground truths simultaneously, meanwhile at each striding step, it selectively pools predicted vectors into a merged one, then computes cost between the merged vector and center pixel's category label inside filer. Such operation is conducted on each valid pixel over input batches, and finally it computes a global loss for each input batch (see Figure _ref_) . During training, such loss layer emphasizes on the interactions from same category over neighborhood, which intuitively indicates that stochastic gradients descent (SGD) solver should optimize entire predictions on same category in a scale rather than per pixel. Such loss can effectively supervise networks to summarize features of the same category, meanwhile, indirectly enlarge the differences of inter-class features. Thus, the discriminative capabilities of learned models are significantly improved with higher robustness and object sensitivity. Via this loss, we trained deep neural networks (DNN), and demonstrate that our learned models outperforms against previous state-of-arts. In summary, we make the following contributions: The remainder of this paper has the following structure: Section _ref_ briefly summarizes related work. Section _ref_ constructs the locally adaptive loss. Section _ref_ illustrates and evaluates our locally adaptive loss via several numerical experiments using different training frameworks. Section _ref_ draws conclusions and proposes direction for future work.