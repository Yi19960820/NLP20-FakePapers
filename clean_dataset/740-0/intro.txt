\cutsectionafter Unsupervised and supervised learning have been two associated key topics in deep learning. One important application of deep unsupervised learning over the past decade was to pretrain a deep neural network, which was then finetuned with supervised tasks (such as classification) . Many deep unsupervised models were proposed, such as stacked (denoising) autoencoders~ _cite_, deep belief networks~, sparse encoder-decoders~ _cite_, and deep Boltzmann machines~ . These approaches significantly improved the performance of neural networks on supervised tasks when the amount of available labels were not large. However, over the past few years, supervised learning without any unsupervised pretraining has achieved even better performance, and it has become the dominating approach to train deep neural networks for real-world tasks, such as image classification and object detection . Purely supervised learning allowed more flexibility of network architectures, e.g., the inception unit and the residual structure, which were not limited by the modeling assumptions of unsupervised methods. Furthermore, the recently developed batch normalization (BN) method has made the neural network learning further easier. As a result, the once popular framework of unsupervised pretraining has become less significant and even overshadowed in the field. Several attempts (e.g.,) had been made to couple the unsupervised and supervised learning in the same phase, making unsupervised objectives able to impact the network training after supervised learning took place. These methods unleashed new potential of unsupervised learning, but they have not yet been shown to scale to large amounts of labeled and unlabeled data. recently proposed an architecture that is easy to couple with a classification network by extending the stacked denoising autoencoder with lateral connections, i.e., from encoder to the same stages of the decoder, and their methods showed promising semi-supervised learning results. Nonetheless, the existing validations were mostly on small-scale datasets like MNIST. Recently, proposed the ``what-where'' autoencoder (SWWAE) by extending the stacked convolutional autoencoder using 's ``unpooling'' operator, which recovers the locational details (which was lost due to max-pooling) using the pooling switches from the encoder. While achieving promising results on the CIFAR dataset with extended unlabeled data, SWWAE has not been demonstrated effective for larger-scale supervised tasks. In this paper, inspired by the recent trend toward simultaneous supervised and unsupervised neural network learning, we augment challenge-winning neural networks with decoding pathways for reconstruction, demonstrating the feasibility of improving high-capacity networks for large-scale image classification. Specifically, we take a segment of the classification network as the encoder and use the mirrored architecture as the decoding pathway to build several autoencoder variants. The autoencoder framework is easy to construct by augmenting an existing network without involving complicated components. Decoding pathways can be trained either separately from or together with the encoding/classification pathway by the standard stochastic gradient descent methods without special tricks, such as noise injection and activation normalization. This paper first investigates reconstruction properties of the large-scale deep neural networks. Inspired by, we use the auxiliary decoding pathway of the stacked autoencoder to reconstruct images from intermediate activations of the pretrained classification network. Using SWWAE, we demonstrate better image reconstruction qualities compared to the autoencoder using the unpooling operators with switches, which upsamples an activation to a fixed location within the kernel. This result suggests that the intermediate (even high-level) feature representations preserve nearly all the information of the input images except for the locational details ``neutralized'' by max-pooling layers. Based on the above observations, we further improve the quality of reconstruction, an indication of the mutual information between the input and the feature representations, by finetuning the augmented architecture with supervised and unsupervised objectives. In this setting, the image reconstruction loss can also impact the classification pathway. To the contrary of conventional beliefs in the field, we demonstrate that the unsupervised learning objective posed by the auxiliary autoencoder is an effective way to help the classification network obtain better local optimal solutions for supervised tasks. To the best of our knowledge, this work is the first to show that unsupervised objective can improve the image classification accuracy of deep convolutional neural networks on large-scale datasets, such as ImageNet . We summarize our main contributions as follows: