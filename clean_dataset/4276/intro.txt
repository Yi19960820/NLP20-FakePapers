Histology imaging on tissue slice is a critical method for pathology analysis, indicating further targeted therapies. Pathologists perform histological analysis and morphological assessment on microscopic structure and tissue organization to diagnose and grade the cancer type _cite_ . On histology images, discriminative features of a certain cancer type can be observed at nuclei-level, ductal-level, cellular-level and overall tissue organization _cite_ . The diagnosis of biopsy tissue is tedious and non-trivial. In-observer disagreement often exists between pathologists due to the complex diversity and distribution of discriminative features _cite_ . Therefore, developing an accurate computer-aided diagnosis (CAD) system to automatically classify histology images can greatly improve diagnosis efficiency and provides valuable diagnosis reference to pathologists with dissensions [_cite_] . In recent years, deep convolutional networks have achieved state-of-the-art performance on a large number of visual classification tasks {_cite_} . The success of deep CNN relies on the large available training set that is well labeled and is limited to the size of input image considering the high computational cost. However, for classification problems in biomedical images, the input is often high resolution images, such as breast cancer histology images. The challenges of developing a CNN for high resolution histology images classification include: (N) the distribution of discriminative features over a histology image is complex and one patch on a histology image does not necessarily contain discriminative features consistent with the image-wise label; (N) In most cases, only the image-wise ground truth label is given due to the high cost of annotation on high resolution images, which complicates the problem; (N) Dramatic down-sampling leads to the loss of discriminative details at nuclei-level and ductal-level, thus training a CNN on whole histology images is usually inappropriate. _cite_ proposed to divide a high resolution breast histology image into patches and train a VGG-like patch-wise CNN, from which the image-wise label can be inferred by voting on patch-wise predictions. _cite_ utilized deep CNNs for feature extraction and gradient boosted trees for classification, which achieved better performance. _cite_ developed a patch-based CNN and utilized a linear regression fusion model to predict image-wise labels. Compared to previous methods, in this paper, we propose to use a deep spatial fusion network to model the complex distribution of discriminative features over patches. We also investigate a more effective method to extract hierarchical discriminative features on patches. The proposed method outperforms previous state-of-the-art solutions and it is the first work that utilizes the spatial relationship between patches to improve image-wise prediction for breast cancer histology image classification.