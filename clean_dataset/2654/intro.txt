Cervical cytology is the most common and effective screening method for cervical cancer and premalignant cervical lesions _cite_, which is performed by a visual examination of cytopathological analysis under the microscope of the collected cells that have been smeared on a glass slide and stained and finally giving a diagnosis report according to the descriptive diagnosis method of the Bethesda system (TBS) _cite_ . Currently in developed countries, it has been widely used and has significantly reduced the number of deaths caused by related diseases, but it is still unavailable for population-wide screening in the developing countries _cite_, partly due to the fact that it is labor-intensive, time-consuming and expensive _cite_ . In addition, it is subjective and therefore has motivated lots of automated methods for the automation of cervical screening based on the image analysis techniques. Over the past N years extensive research has attempted to develop automation-assisted screening methods _cite_ . Most of them try to classify a single cell into various stages of carcinoma, which often consists three steps: cell (cytoplasm and nuclei) segmentation, feature extraction and classification. The performance of these methods, however, heavily depends on the accuracy of the segmentation and the effectiveness of the hand-crafted features. With the overwhelming success in a broad range of applications such as image classification _cite_, semantic segmentation _cite_, object detection _cite_ and medical imaging analysis _cite_, CNN has also been applied to the segmentation and classification of cervical cell _cite_ . The majority of them (e.g. _cite_) are trying to take advantage of CNN to improve the segmentation accuracy of cytoplasm and nuclei, but they do not provide the needed segmentation accuracy _cite_, whereas once the segmentation error are taken into account, the classification accuracy would drop _cite_ . To avoid the dependence on accurate segmentation, the patch-based methods (e.g. _cite_) try to use CNN to classify the image patches. However, the extraction of such patches still requires the segmentation of nuclei. The recent work _cite_ also adopts the patch-based strategy but during the inference the random-view aggregation and multiple crop testing are needed to produce the final prediction results and thereby is time-consuming. In this paper, we propose an efficient strategy to apply CNN for cervical cancer screening, any pre-segmentation step. Specifically, we exploit the contemporary CNN-based object detection methods _cite_ to detect the cervical cytological abnormalities directly. It is straightforward and has been successfully applied for other medical image analysis _cite_, but very few works try to apply CNN-based object detection for automated cervical cytology. We attribute this to the lack of the right cervical cancer microscopic image dataset for the detection task. CNN-based object detection methods often need sufficient annotated data to obtain good generalization, but for cervical cytological abnormalities detection, collecting the large amounts of data with careful and accurate annotation is difficult partially due to the limitation by laws, the scarcity of positive samples and especially the unanimous agreement between cytopathologists _cite_ . To alleviate the limited data problem, we propose the named, which migrate the idea of in one/few-shot learning for image classification _cite_ into CNN-based object detection, for cervical cancer detection. Specifically, we choose the state-of-the-art object detection method, Faster R-CNN _cite_ with FPN _cite_, as our baseline model and replace the original parameter classifier with a non-parametric one based on the idea of comparison with the prototype representations of each category, which is generated from reference samples. Furthermore, instead of manually choosing the reference images of the background category by some heuristic rules, we propose to learn them from the data. We also investigate several important factors including the generation of prototype representations of each category and the design of head model for cervical cell or cell clumps detection. Our algorithm directly operates on the whole image rather than the extracted patches based on the nuclei and hereby only need one forward propagation for each image, making the inference very efficient. In addition, the proposed method is to be integrated into other proposal-based methods. We collect a small dataset _inline_eq_ and a medium dataset _inline_eq_ which are directly dedicated to cervical cell/clumps detection, on which we evaluate the performance of the proposed Comparison detector. When the model is learned from the small dataset _inline_eq_, the performance of our method is significantly better than the baseline model, i.e. Comparison detector has a mAP N \% and an AR N \% but the baseline model only gains a mAP N \% and an AR N \%. When the model is learned from the medium dataset _inline_eq_, our Comparison detector achieves performance with a mAP of N \% compared to N \%, and improves nearly N points comparing to baseline model with AR. We summarize our contributions as follows: N) We propose an end-to-end object detection method called Comparison detector to deal with the limited data problem in cervical cell/clumps detection; N) We propose a strategy to directly learn the prototype representations of background and N) Our method performs much better than the baseline on both small and medium dataset and has the potential applications to the real automation-assisted cervical cancer screening systems.