<|startoftext|> Face hallucination, which is the task of generating a high-resolution face image from a low-resolution input image, is a well-studied problem that is useful in widespread application areas. Face hallucination is particularly challenging when the input face resolution is very low (e.g., _inline_eq_ pixels) and/or the image is captured in an uncontrolled setting with large pose and illumination variations. In this paper, we revisit the algorithm introduced in~ _cite_ and present a deep interpretation of this framework that achieves state-of-the-art under such challenging scenarios. In our deep network architecture the global and local constraints that define a face can be efficiently modeled and learned end-to-end using training data. Conceptually our network design can be partitioned into two sub-networks: the first one implements the holistic face reconstruction according to global constraints, and the second one enhances face-specific details and enforces local patch statistics. We optimize the deep network using a new loss function for super-resolution that combines reconstruction error with a learned face quality measure in adversarial setting, producing improved visual results. We conduct extensive experiments in both controlled and uncontrolled setups and show that our algorithm improves the state of the art both numerically and visually. <|endoftext|>
 
 
  <|startoftext|> Face synthesis remains a challenging and challenging problem due to many factors. For example the low-resolution face images often suffer from large pose and illumination variations. The main challenge is to produce a high-resolution face image that can match the original image quality and pose. The problem is particularly challenging in the high-resolution face images, where the input face is often too small to be captured accurately. The main problem is to produce a high-resolution face image that is close to the original face image, and the problem is especially challenging when it is captured in a restricted setting with large pose, illumination variations and limited lighting. The goal of this work is to solve this problem using a deep learning approach, which is able to generate realistic face images from a low-resolution input face image. We propose an end-to-end deep learning framework that learns the face-specific features directly from the input face. The main contributions of this work can be summarized as a three-stage framework. First we introduce a deep network architecture, which is able to learn the face-specific features directly from the input face image. This approach has two advantages: N) it allows for a more flexible training procedure that is easier to optimize. N) it can be extended to other applications, such as face recognition. N) it is possible to extend deep networks to other applications such as face recognition, as face reconstruction and face-specific face enhancement. In this work we focus on the problem of generating realistic face images that are close to the original face image. The main contributions of this work can be summarized as follows: N) it allows for a more flexible training procedure that is easier to optimize. N) it can be extended to other applications, such as face recognition and face-specific face enhancement. In this work we focus on the problem of generating realistic face images that are close to the original face image. The main contributions of this work can be summarized as as follows: N) it allows for a more flexible training procedure that is easier to optimize. N) it can be extended to other applications, such as face recognition, face reconstruction and face-specific face enhancement. In this work we focus on the problem of generating realistic face images that are close to the original face image. The main contributions of this work can be summarized as follows: N) it allows for a more flexible training procedure that is easier to optimize. N) it can be extended to other applications, such as face recognition, face reconstruction and face