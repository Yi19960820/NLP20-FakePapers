While there has been significant progress on supervised large-scale classification in recent years _cite_, the lack of sufficient annotated training data uniformly across all classes _cite_ has been a bottleneck in achieving acceptable performance. At a basic level, in these cases we encounter situations where we may have sufficient annotated training data for some of the classes and little or even no annotated data to train supervised classifiers for the other interesting classes. In this context, a fundamental question that arises is as to how to leverage training data for observed classes for recognition of rare or unobserved classes. One possible scenario is when we have data from a different domain that can be collected easily, as is assumed to be the case in zero-shot recognition (ZSR) . In ZSR we are given {\em source} and {\em target} domains as training data belonging to a sub-collection of classes, forming {\em seen} or observed classes. No training data is available for other {\em unseen} classes. The class information in source domain is described in a variety of ways such as attribute vectors _cite_, language words/phrases _cite_, or even learned classifiers _cite_ . Target domain is described by a joint distribution of data (\eg images or videos) and labels _cite_ . The challenge in ZSR lies in learning models based on seen-class data that can generalize to unseen classes. In this context, many perspectives for zero-shot learning (ZSL) have been proposed, including unseen classifier prediction from source domain data based on learning attribute classifiers~ _cite_, learning similarity functions between source and target domains to score similarity for unseen classes~ _cite_, and manifold embedding methods based on identifying inter-class relationships in source and target data that can be aligned during test time~ _cite_ . Nevertheless, the challenge posed by the relative sparseness of source domain descriptions in recognition has not been fully considered. In particular, the target-domain data exhibits significant intra-class variation (\eg appearance and poses) . On the other hand the source domain information is relatively sparse and typically amounting to a single attribute vector. This is generally insufficient to account for all of the intra-class variation. Fig. _ref_ illustrates this point. In the joint embedded feature space, the target-domain data distributions of certain classes (\eg ``dog'' class in the figure) are relatively flat and consist of data instances with large variation. This issue leads us to view the presented source domain vector as a ``mean-value'' over all candidate (or alternative) source vectors. During test time for a given target instance we optimize the matching over all possible source and target candidates in a neighborhood of the presented source and target instances. During training we propose learning a data-dependent feature transform chosen from a parameterized family of displacement functions that maximizes the similarity between an arbitrary source and target instances. We learn our similarity functions from training data using {\em latent structural SVMs} . As demonstration we design a specific algorithm under the proposed framework involving bilinear similarity functions and regularized least squares as penalties for displacement. To illustrate how this would work, consider again Fig.~ _ref_ . In test time our proposed approach manifests as new features (\ie empty `` _inline_eq_ '' in the figure) that adapt to the potential contents in target data instance. This leads to significantly richer representations than the provided source-domain vectors. Our proposed approach also induces displacements in the target domain data instances. These displaced features (\ie empty `` _inline_eq_ '' in the figure) in turn adapt to source domain features. This process is akin to de-noising of presented target-domain data/features. As we see, by using the new features, the dog face image is correctly classified based on similarity measure between the new data-dependent adapted features, as illustrated in Fig. _ref_ (b) . In this paper we introduce a novel {\em adaptive similarity function} for comparing an arbitrary pair of source and target domain data instances. This function, in test time and adaptively in a data-dependent way, determines the similarity between presented source and target instances. We propose considering optimizing over a parameterized bilinear family of functions for our cross-domain similarity measure. Alternating optimization is utilized to efficiently estimate (globally) best adapted features within a constrained family of displacements. In this context we show that the compatibility function defined in _cite_ is indeed a special case of our similarity function. To learn the parameters in our adaptive similarity function, we further propose formulating the ZSL problem using {\em latent structural SVMs} . The latent part comes from the adapted (latent) features, which are considered as the latent variables in the formulation. The structural part arises from the structures of label embeddings as did in~ _cite_ . We test our approach on four benchmark image datasets for ZSL/ZSR, namely, aP \&Y, AwA, CUB and SUN-attribute. Under both standard and transductive settings, our approach outperforms the state-of-the-art significantly. In general ZSL/ZSR approaches can be divided into two categories: standard setting and transductive setting. Recently zero-shot approaches have been successfully applied to several visual tasks such as event detection _cite_, action recognition _cite_, and image tagging _cite_ . Below we primarily describe learning approaches in this context. In test time, the source-domain descriptors for unseen classes are all given at once. Our task is to sequentially recognize target-domain instances as they are revealed {\em one at a time} . In this context, several works in the literature are based on training attribute classifiers which directly map target-domain data into source-domain attribute space _cite_ . The resulting attribute classifiers do not fully account for data noise in source (\eg ambiguity or mislabeling in attributes) and target (\eg large variation because of the changes of appearance, poses, \etc) domains. Linear and nonlinear embedding approaches _cite_ have attracted attention recently. The basic idea of these methods is to embed the source and target domain features into a Kronecker product embedding space. For instance, Akata \etal _cite_ proposed label embedding to map class labels into a high dimensional vector space (\eg source-domain attribute space), and measure cross-domain similarities using a bilinear function whose parameters are learned using structured SVMs. Zhang and Saligrama _cite_ proposed a joint learning framework to learn the latent embeddings for both domains and utilized them for similarity measure. Changpinyo \etal _cite_ proposed a learning method to generate synthesized classifiers for unseen classes. Bucher \etal _cite_ proposed a metric learning based formulation to improve semantic embedding consistency, achieving the best performance on the four benchmark datasets under the standard setting in the current literature, to our best knowledge. The underlying assumption behind such approaches is that there exist (hidden) corresponding matches between source-domain feature vectors and target-domain data distributions, \eg one-to-one match _cite_ or one-to-many match _cite_ . In this context there are other related proposed methods such as semantic transfer propagation _cite_, random forest based approaches _cite_, semantic manifold distance _cite_ approaches, and similarity calibration method _cite_ . Nevertheless, the issue of source-domain sparsity and the resulting imbalance with target-domain data is not fully accounted for in these methods. Our proposed method explicitly focuses on handling the scarcity issue of source-domain data by learning data-dependent latent features. This in turn accounts for the large data variation in target domain implicitly so that the cross-domain matches can be improved. Recently researchers have begun to incorporate test-time unseen-class data in target domain into ZSL/ZSR as unlabeled data analogous to the transductive setting. This has led to approaches that attempt to account for domain shift _cite_ . In this setting, during test time, we are given a list of all unlabelled target instances in addition to unseen-class source-domain descriptions. Potentially these methods can be used in conjunction with any similarity learning procedure trained on seen-class data, as demonstrated in _cite_, to score similarity between unseen classes and target domain data instances. While much of the focus of this paper is on the standard setting, in our experimental section we also test our learning algorithm in the transductive mode to benchmark our performance in the transductive setting.