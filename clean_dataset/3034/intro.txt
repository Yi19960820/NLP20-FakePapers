Semantic segmentation aims to assign a semantic label, e.g., person, dog, or road, to each pixel in images. This task is of essential importance to a wide range of applications, such as autonomous driving and image editing. Numerous methods have been proposed to tackle this task~ _cite_, and abundant benchmark datasets have been constructed~ _cite_ with focus on different sets of scene/object categories as well as various real-world applications. However, this task remains challenging because of large object/scene appearance variations, occlusions, and lack of context understanding. Convolutional Neural Network (CNN) based methods, such as the Fully Convolutional Network (FCN) ~ _cite_, have recently achieved significant improvement on the task of semantic segmentation, and most state-of-the-art algorithms are based on FCN and additional modules. Although CNN-based approaches have achieved astonishing performance, they require an enormous amount of training data. Different from image classification and object detection, semantic segmentation requires accurate per-pixel annotations for each training image, which can cost considerable expense and time. To ease the effort of acquiring high-quality data, semi/weakly-supervised methods have been applied to the task of semantic segmentation. These methods often assume that there are additional annotations on the image level~ _cite_, box level~ _cite_, or point level~ _cite_ . In this paper, we propose a semi-supervised semantic segmentation algorithm based on adversarial learning. The recent success of Generative Adversarial Networks (GANs) _cite_ facilitate effective unsupervised and semi-supervised learning in numerous tasks. A typical GAN consists of two sub-networks, i.e., generator and discriminator, in which these two sub-networks play a min-max game in the training process. The generator takes a sample vector and outputs a sample of the target data distribution, e.g., human faces, while the discriminator aims to differentiate generated samples from target ones. The generator is then trained to confuse the discriminator through back-propagation and therefore generates samples that are similar to those from the target distribution. In this paper, we apply a similar methodology and treat the segmentation network as the generator in a GAN framework. Different from the typical generators that are trained to generate images from noise vectors, our segmentation network outputs the probability maps of the semantic labels given an input image. Under this setting, we enforce the outputs of the segmentation network as close as possible to the ground truth label maps spatially. To this end, we adopt an adversarial learning scheme and propose a fully convolutional discriminator that learns to differentiate ground truth label maps from probability maps of segmentation predictions. Combined with the cross-entropy loss, our method uses an adversarial loss that encourages the segmentation network to produce predicted probability maps close to the ground truth label maps in a high-order structure. The idea is similar to the use of probabilistic graphical models such as Conditional Random Fields (CRFs) _cite_, but without the extra post-processing module during the testing phase. In addition, the discriminator is not required during inference, and thus the proposed framework does not increase any computational load during testing. By employing the adversarial learning, we further exploit the proposed scheme under the semi-supervised setting. In this work, we combine two semi-supervised loss terms to leverage the unlabeled data. First, we utilize the confidence maps generated by our discriminator network as the supervisory signal to guide the cross-entropy loss in a self-taught manner. The confidence maps indicate which regions of the prediction distribution are close to the ground truth label distribution so that these predictions can be trusted and trained by the segmentation network via a masked cross-entropy loss. Second, we apply the adversarial loss on unlabeled data as adopted in the supervised setting, which encourages the model to predict segmentation outputs of unlabeled data close to the ground truth distributions. The contributions of this work are summarized as follows. First, we develop an adversarial framework that improves semantic segmentation accuracy without requiring additional computation loads during inference. Second, we propose a semi-supervised framework and show that the segmentation accuracy can be further improved by adding images without any annotations. Third, we facilitate the semi-supervised learning by leveraging the discriminator network response of unlabeled images to discover trustworthy regions that facilitate the training process for segmentation. Experimental results on the PASCAL VOC N~ _cite_ and Cityscapes~ _cite_ datasets validate the effectiveness of the proposed adversarial framework for semi-supervised semantic segmentation.