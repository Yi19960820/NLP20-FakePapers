Automatic speech recognition (ASR) is witnessing a renaissance, which can largely be attributed to the advent of deep learning architectures. Methods such as Connectionist Temporal Classification (CTC) and attentional encoder-decoder facilitate ASR training by eliminating the need of frame-level senone labelling, _cite_ _cite_ while novel approaches deploying words as recognition units are challenging the conventional wisdom of using senones as recognition units, _cite_ _cite_ _cite_ _cite_ . In parallel, architectures and learning algorithms initially proposed for audio-based ASR are combined with powerful computer vision models and are finding their way to lipreading and audiovisual ASR, _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ . Motivated by this recent direction in acoustic LVCSR of considering words as recognition units, we examine the capacity of deep architectures for lipreading in extracting word embeddings. Yet, we do not merely address word identification with large amounts of training instances per target word; we are also interested in assessing the {\em generalizability} of these embeddings to words unseen during training. This property is crucial, since collecting several hundreds of training instances for all the words in the dictionary is impossible. To this end, we train and test our architecture on the LipReading in-the-Wild database (LRW, _cite_), which combines several desired properties, such as relatively high number of target words (N), high number or training examples per word (between N and N), high speaker and pose variability, non-laboratory recording conditions (excerpts from BBC-TV) and target words that are part of segments of continuous speech of fixed N duration. We examine two settings; standard closed-set word {\it identification} using the full set of training instances per target word, and {\em low-shot learning} where the training and test words come from disjoint sets. For the latter setting, a PLDA model is used on the embedding domain that enables us to estimate class (i.e. word) conditional densities and evaluate likelihood ratios. Our proposed architecture is an improvement of the one we recently introduced in _cite_ which obtains state-of-the-art results on LRW even without the use of word boundaries. The rest of the paper is organized as follows. In Sect. _ref_ we provide a detailed description of the architecture, together with information about the training strategy and the use of word boundaries. In Sect. _ref_ we show results on word identification obtained when the model is training on all available instances, while in Sect. _ref_ we present results on two low-shot learning experiments. Finally, conclusion and directions for future work are given in Sect. _ref_ .