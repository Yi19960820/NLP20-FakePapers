Online display advertising generates a significant amount of revenue by showing textual or image ads on various web pages _cite_ . The ad publishers like Google and Yahoo sell ad zones on different web pages to advertisers who want to show their ads to users. And then Publishers get paid by advertisers every time the ad display leads to some desired action such as clicking or purchasing according to the payment options such as cost-per-click (CPC) or cost-per-conversion (CPA) _cite_ . The expected revenue for publishers is the product of the bid price and click-through rate (CTR) or conversion rate (CVR) . Recently, more and more advertisers prefer displaying image ads _cite_ (Figure _ref_) because they are more attractive and comprehensible compared with textual ads. To maximize the revenue of publishers, this has led to a huge demand on approaches that are able to choose the most proper image ad to show for a particular user when he or she is visiting a web page so that to maximize the CTR or CVR. Therefore, in most online advertising systems, predicting the CTR or CVR is the core task of ads allocation. In this paper, we focus on CPC and predict the CTR of display ads. Typically an ads system predicts and ranks the CTR of available ads based on contextual information, and then shows the top _inline_eq_ ads to the users. In general, prediction models are learned from past click data based on machine learning techniques _cite_ . Features that are used to represent an ad are extremely important in a machine learning model. In recent years, to make the CTR prediction model more accurate, many researchers use millions of features to describe a user's response record (we call it an ad impression) . Typically, an image ad impression has basic features and visual features. The basic features are information about users, products and ad positions in a web page, etc. Visual features describe the visual appearance of an image ad at different levels. For example, color and texture are low level features, while face and other contextual objects are high level features. Low level and high level features may both have the power to influence the CTR of an image ad (Figure _ref_) . Traditionally, researchers lack effective method to extract high-level visual features. The importance of visual features is also usually under estimated. However, as we can see from Figure _ref_, ads with same basic features may have largely different CTRs due to different ad images. As a consequence, How to use the visual features in machine learning models effectively becomes an urgent task. Among different machine learning models that have been applied to predict ads CTR using the above features, Logistic regression (LR) is the mostly well-known and widely-used one due to its simplicity and effectiveness. Also, LR is easy to be parallelized on a distributed computing system thus it is not challenging to make it work on billions of samples _cite_ . Being able to handle big data efficiently is necessary for a typical advertising system especially when the prediction model needs to be updated frequently to deal with new ads. However, LR is a linear model which is inferior in extracting complex and effective nonlinear features from handcrafted feature pools. Though one can mitigate this issue by computing the second-order conjunctions of the features, it still can not extract higher-order nonlinear representative features and may cause feature explosion if we continue increasing the conjunction order. To address these problems, other methods such as factorization machine _cite_, decision tree _cite_, neural network _cite_ are widely used. Though these methods can extract non-linear features, they only deal with basic features and handcrafted visual features, which are inferior in describing images. In this paper, we propose a deep neural network (DNN) to directly predict the CTR of an image ad from raw pixels and other basic features. Our DNN model contains convolution layers to extract representative visual features and then fully-connected layers that can learn the complex and effective nonlinear features among basic and visual features. The main contributions of this work can be summarized as follows: The paper is organized as follows. Section N introduces the related work, followed by an overview of our scheme in Section N. In Section N, we describe the proposed DNN model in detail, and we show the challenges in the training stage as well as our solutions in Section N. Section N presents the experimental results and discussion, and then Section N is the conclusion.