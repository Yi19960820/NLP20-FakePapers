Automatic facial expression recognition is an active research topic in computer vision, having many applications including human behavior understanding, detection of mental disorders, human-computer interaction, among others. In the past few years, most works~ _cite_ have focused on building and training deep neural networks in order to achieve state-of-the-art results. Engineered models based on handcrafted features~ _cite_ have drawn very little attention, since such models usually yield less accurate results compared to deep learning models. In this paper, we show that we can surpass the current state-of-the-art systems by combining automatic features learned by convolutional neural networks (CNN) and handcrafted features computed by the bag-of-visual-words (BOVW) model, especially when we employ local learning in the training phase. In order to obtain automatic features, we experiment with multiple CNN architectures, such as VGG-face~ _cite_, VGG-f~ _cite_ and VGG-N~ _cite_, some of which are pre-trained on other computer vision tasks such as object class recognition~ _cite_ or face recognition~ _cite_ . We also fine-tune these CNN models using a novel training procedure known as Dense-Sparse-Dense (DSD) ~ _cite_ . To our knowledge, we are the first to successfully apply DSD to train CNN models for facial expression recognition. In order to obtain handcrafted features, we use a standard BOVW model, which is based on a variant of dense Scale-Invariant Feature Transform (SIFT) features~ _cite_ extracted at multiple scales, known as Pyramid Histogram of Visual Words (PHOW) ~ _cite_ . We use automatic and handcrafted features both independently and together. For the independent models, we use either softmax (for the fine-tuned CNN models) or Support Vector Machines (SVM) based on the one-versus-all scheme. For the combined models, the one-versus-all SVM is used both as a global learning method (trained on all training samples) or as a local learning method (trained on a subset of training samples, selected specifically for each test sample using a nearest neighbors scheme) . We combine the automatic and handcrafted features by concatenating the corresponding feature vectors, before the learning stage. For the combined models, we explore only global or local SVM alternatives. We perform a thorough experimental study on the N Facial Expression Recognition (FER) Challenge data set~ _cite_, the FER + data set~ _cite_, and the AffectNet~ _cite_ data set, comparing our combined deep and handcrafted models with recent and relevant state-of-the-art approaches~ _cite_ . We report top results on each and every data set with our combination of automatic and handcrafted features, especially when local SVM is employed in the learning phase. With a top accuracy of _inline_eq_ on the FER N data set, we surpass the state-of-the-art accuracy~ _cite_ by _inline_eq_ . We also surpass the best method~ _cite_ on the FER + data set by _inline_eq_, reaching the best accuracy of _inline_eq_ . The evaluation on AffectNet is typically conducted using N-way classification~ _cite_ or N-way classification~ _cite_ (the class corresponding to contempt being removed) . We attain the best results in both settings, surpassing Mollahosseini et al.~ _cite_ by _inline_eq_ in the N-way classification task, and Hua et al.~ _cite_ by _inline_eq_ in the N-way classification task. We also include ablation results in the paper, which indicate that the proposed model combination yields superior performance compare to each and every component. Although automatic and handcrafted features have been combined before in the context of facial expression recognition~ _cite_, different from the related art, _inline_eq_ we include various CNN architectures and a single handcrafted model, and _inline_eq_ we employ a local learning strategy that leads to superior results. To the best of our knowledge, our previous work based on the BOVW model~ _cite_ is the only one to explore local learning for facial expression recognition. In this paper, we extend our previous work~ _cite_ and propose to combine local learning with automatic features learned by deep CNN models. Compared to the best accuracy reported in~ _cite_ for FER N, which is _inline_eq_, we report an improvement of almost _inline_eq_ . In summary, our contributions consist of _inline_eq_ successfully training CNN models for facial expression recognition using Dense-Sparse-Dense~ _cite_, _inline_eq_ successfully combining automatic and handcrafted features with local learning, _inline_eq_ conducting an extensive empirical evaluation with various deep, engineered and combined facial expression recognition models, and _inline_eq_ reporting state-of-the-art results on three benchmark data sets. The rest of the paper is organized as follows. We present recent related art in Section~ _ref_ . We describe the automatic and handcrafted features, as well as the learning methods, in Section~ _ref_ . We present the experiments on facial expression recognition in Section~ _ref_ . Finally, we draw our conclusions in Section~ _ref_ .