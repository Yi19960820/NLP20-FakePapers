In the midst of data-driven, annotation-intensive deep learning methods, we propose a learning-free, model-based technique, that reasons about correspondences in the underlying shape space of the scene objects to enable disparate image matching. While applications of mainstream deep learning-based models have experienced tremendous success in several computer vision problems, this success has come at a hefty cost; the cost of gathering and annotating training data is excessive at the very least, and can be quite exorbitant in some cases. This motivates us to revisit learning-free, model-based techniques, especially in the context of correspondence determination for disparate image matching. The proposed deep spectral correspondence (DSC) estimation scheme is based on discovery of underlying shape representations using low-level edge-based features and integration of the representational power of high-level shape cues with the robustness of low-level edge features, without recourse to explicit learning. Image matching is one of the most fundamental problems in the field of computer vision and, despite significant advances in the field, is still far from being solved. It is imperative to address this problem effectively, since doing so would impact a wide range of computer vision applications such as structure-from-motion (SfM), simultaneous localization and mapping (SLAM), structure-from-stereo (SfS), object localization, fine-grained object categorization, shape-based image retrieval and image registration, just to name just a few. In spite of the large volume of research over the past couple of decades devoted to tackling this problem, determining a reliable correspondence even between image pairs that exhibit modest variations in viewing conditions, is still immensely challenging~ . In this paper we tackle a specific subproblem within the larger category of image matching problems, i.e., matching of disparate image pairs. Matching images that are significantly disparate in nature, i.e., images that exhibit extreme variations in viewing conditions characterized by scale, orientation, viewpoint, illumination and affine projection parameters, further complicates the already challenging image matching problem. The formulation of an accurate, efficient and robust solution to the disparate image matching problem is of utmost importance on account to its direct applicability to several real-world problems such as enabling night vision in autonomous cars, generating ND reconstructions of historical landmarks from internet-scale images to enable photo-tourism, browsing and searching large-scale image repositories, to cite a few. Appearance similarity measures computed between disparate images using local point-based features exhibit significant inconsistencies on account of the fact that correspondence determination by local feature matching is highly inaccurate~ . To address the above issue, we propose a correspondence determination scheme for matching disparate images that is based on the extraction of a latent shape representation from the underlying images. A major drawback of most global or holistic shape representations is their inability to deal with high levels of deformation, articulation and scene occlusion~ . In contrast, local keypoint-based image matching techniques are more robust to high levels of deformation and articulation and instances of partial occlusion~ . However, the inability to reason about shape as a holistic entity, causes most local shape representation techniques to perform poorly when faced with significant variations in the viewpoint and affine projection parameters. Typically, matching image pairs involves identifying salient regions or keypoints (also referred to as interest points) in the images~ followed by direct correspondence determination between the images using a suitable interest point descriptor-based similarity measure~ . In some cases, it is possible to exploit location-based dependencies between the interest points to improve the robustness of the correspondence using model-fitting techniques such as the random sample consensus (RANSAC) algorithm~ . While the above approach is computationally efficient and often finds practical application in several structure-from-motion (SfM), structure-from-stereo (SfS) and image registration algorithms, it arguably fails to reason about the scene objects or structures at a global level since the entire image is treated as a set of independent interest points~ . In more recent interest-point-based approaches, reasoning about the scene objects or structures is facilitated by the construction of constellations of known interest points~ or regions~ to represent scene objects or structures positioned within the image against a common background. Such reasoning allows one to learn more complex higher-level shape representations~, which, in turn, allow one to tackle more effectively, instances of partial occlusion, object articulation or object deformation in the underlying images. In recent years, modeling of object shapes has been explored extensively and employed successfully in tasks such as object detection and image segmentation~ . Classical methods for shape matching can be categorized typically based on the granularity of the extracted features. While global feature-based shape matching methods~ lack the ability to handle strong articulations and occlusions, their local feature-based counterparts~ fall short of generating optimal results when faced with variations in illumination, viewpoint, scale and orientation. Real world images differ from images of objects captured in a highly controlled environment in that the latter tend to focus on the most prominent scene object. Images captured in highly controlled environments tend to place the most important object under consideration close to the image center, a characteristic which may not necessarily be shared by real-world images. Most existing shape-based image matching techniques can be classified into two broad categories; (a) techniques that exploit a {\it global} shape-based similarity measure for the underlying objects and, (b) techniques that compute a measure of correspondence based on matching of {\it local} interest points which is then used to reason about the underlying object shapes. Techniques in the former category follow a top-down approach that implicitly models the holistic shape (s) of the underlying object (s) whereas techniques in the the latter category use a bottom-up strategy that connects the detected interest points to explicitly reason about the global object shape. Modeling an object shape explicitly using a set of interest points allows for a straightforward representation and simplistic reasoning about the shape~ _cite_ . The shape can be conceived as a set of ND interest points connected by a contour or as a constellation of interest points where the relative positions of the interest points describes the underlying shape~ . Consequently, shape deformations that can be attributed to variations in viewing conditions and/or articulation, are captured explicitly by reasoning about the interest point positions and their variations~ . While such a shape representation is reasonable, it entails the learning of a shape prior. Moreover, representing a complex shape merely as a set of connected points results in an oversimplified shape representation. Global representation techniques that model the shape implicitly, typically transform the underlying shape into a lower-dimensional representation. Shape reasoning is then performed primarily in this lower-dimensional representational space. The proposed DSC determination scheme does not rely solely on either global shape features or local point-based features; instead, the descriptive power of local interest points is harnessed to generate an implicit global representation of the underlying shape. This implicit global representation is then exploited for the purpose of matching scene structures in disparate image pairs. In recent times, deep learning approaches have been shown to be very successful in a wide variety computer vision applications. Several recent research works have attempted to leverage the advantages of deep learning for the purpose of matching disparate image pairs. These attempts include the formulation of deep neural networks (DNNs) trained end-to-end as well as extraction of deep-learned features for image matching~ . In this paper, we harness the power of deep-learned features, and use them in conjunction with a traditional ND shape representation, to match disparate images in a suitably defined shape eigenspace. We leverage the sophisticated representation offered by deep-learned features to reason about scene objects in a low-dimensional shape eigenspace obtained by computing the eigenspectrum defined over a suitably defined graph embedding distance space. This low-dimensional representation of image structures has been shown to capture persistent shape cues more effectively than most keypoint-based shape matching approaches~ . In our previous work we proposed a partial shape matching technique using joint spectral embedding (JSE), where we construct a joint image graph that captures the degree of patch-wise similarity between image structures~ . In this paper, we extend our previous work to formulate a saliency-aware and deep learning-based spectral correspondence (DSC) determination scheme, for matching images in shape eigen-space. To this end, we first obtain a low-dimensional representation of the joint image graph via a process of eigenspectral decomposition. This low-dimensional representation is then used to determine shape-based correspondences between image structures in a disparate image pair. Correspondence determination between two image structures in this low-dimensional joint shape eigenspace has two major advantages: (a) the resulting shape cues are more robust to variations in viewing conditions thus yielding a more robust image matching procedure, and (b) the joint representation enables extraction of shape cues that exist across both images, alleviating the burden of matching independently extracted eigenvectors from two distinct eigen representations. Figure~ _ref_ depicts the overall computational pipeline for the proposed scheme for disparate image matching. The primary contributions of the paper can be summarized as follows: The rest of the paper is organized as follows: We review related work in Section~ _ref_ followed by the problem statement in Section~ _ref_ . In Section~ _ref_, we present the formulation of the problem, including a formal exposition of the joint spectral embedding (JSE) problem (Section~ _ref_), incorporation of the saliency term (Section~ _ref_) and the regularization term (Section~ _ref_) and formulation of the objective function and optimization procedure for the proposed deep spectral correspondence (DSC) determination (Section~ _ref_) . In Section~ _ref_, we introduce and describe a new benchmark dataset DispScenes that is designed specifically for the testing and evaluation of disparate image matching algorithms. In Section~ _ref_, we detail the performance evaluation metrics for the proposed DSC determination scheme (Section~ _ref_) followed by an experimental comparison of the proposed DSC determination framework to state-of-the-art image matching techniques (Section~ _ref_) . Finally, we conclude the paper in Section~ _ref_ with an outline of directions for future work.