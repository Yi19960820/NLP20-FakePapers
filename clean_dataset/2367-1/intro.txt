Breast cancer is the second leading cause of cancer death among women, but early diagnosis significantly increases treatment success. Ductal carcinoma, which N \% of breast cancers begin as, has survival rates of nearly N \% if the growing tumor is resected before it has a chance to spread. The foremost technique for diagnosis is based on a specialist's evaluation of hematoxylin and eosin (H \&E) stained breast histopathology images, which are thin N micron slices of tissue that have been resected from the patient, and give a Nd representation of the cellular and stromal activity inside the tissue. However, the sheer amount of H \&E data generated from even a small block of tissue is enormous, and this poses intrinsic challenges to human pathologists. Firstly, the H \&E sections contain biological information that exists at many scales and across a very large spatial area, from cell-to-cell interaction (microns), to the dynamics of a group of cells (tens of microns), to the organization of the tissue as a whole (millimeters) . Humans are instead naturally suited to rationalizing single events in a cause and effect manner, using concepts derived from an internal mental model. The typical trained human pathologist resorts to sampling the H \&E data, focusing first on selected spatial locations, and then gathering an impression of the overall state of the tissue, in order to finally use a set of knowledge-based and experience-based heuristics that guide him or her towards a diagnosis. Given the scale and detail of the data, automated Computer Aided Diagnosis (CAD) technologies provide an intriguing alternative that is able both to utilize both, significantly larger quantities of data, and correlations between data that exist across different scales and different spatial locations. We restrict the following discussion to the particulars of breast cancer. From a diagnostic perspective, CAD technologies could provide reliable, quantitative metrics for grading the aggresiveness of a tumor, which is traditionally based in the Nottingham Grading System. A weakness in the current grading system is that it is a qualitative score (low, moderate, strong) limited by N) the medical practitioner's own biases N) his inability to completely review massive amounts of histological data. A CAD-based method would standardize the criteria used for identifying the aggresiveness of a tumor, while also providing improved medical recommendations using information across different spatial-scales that a human would not be able to interpret. We develop a three-step framework for quantitative and unsupervised learning on the breast cancer H \&E stained images. The first involves normalizing the stain appearance of H \&E images to a fixed reference stain appearance. For this purpose, we train an optimized convolutional neural network on pools of images, each with a single stain style. The network learns to correlate spatial featues in each image with their corresponding color characteristics. Each network can then be used to recolorize grayscale images into its learned stain style. After stain normalization, we train a U-net type neural network to segment out nuclei from the H \&E images. We train the segmentation network on a publicly available dataset and then show that stain normalization allows for improved numerical segmentation results. In the final step of our framework, we segment cell nuclei in stain-normalized breast cancer histology images, and then perform classification of these nuclei using an unsupervised approach that has its roots in the Information Generative Adversarial Network (InfoGAN) architectures developed by ~ _cite_ . This architecture is similar to the basic GAN architecture with two additions: (N) A Lipschitz gradient penalty and the use of the approximate Wasserstein distance in the loss function (N) A mutual information loss term that encourages the generator to learn representations that the discriminator can then cluster into different classes.