Structured prediction, where one wishes to predict structured states given structured observations, is an interesting and challenge problem that is important in a number of different applications, with one of them being object silhouette tracking. The goal of object silhouette tracking is to identify the silhouette of the same object over a video sequence, and is very challenging due to a number of factors such as occlusion, object motion changing dynamically over a video sequence, and object silhouette changing drastically over time. Much of early literature in object tracking have consisted of generative tracking methods, where the joint distribution of states and observations is modeled. The classical example is the use of Kalman filters~ _cite_, where predictions of the object are made with Gaussian assumptions made on both states and observations based on predefined linear system dynamics. However, since object motion do not follow Gaussian behaviour and have non-linear system dynamics, the use of Kalman filters can often lead to poor prediction performance for object tracking. To address the issue of non-linear system dynamics, researchers have made use of modified Kalman filters such as the extended Kalman filter~ _cite_ and unscented Kalman filter~ _cite_, but these do not resolve issues associated with non-Gaussian behaviour of objection motion. To address both the issue of non-linear system dynamics and non-Gaussian behaviour, a lot of attention has been paid to the use of particle filters~ _cite_, which are non-parametric posterior density estimation methods that can model arbitrary statistical distributions. However, the use of particle filters for object tracking is not only computationally expensive, but difficult to learn especially for the case of object silhouette tracking where motion and silhouette appearance can change drastically and dynamically over time. Recently, there has been significant interest in the use of discriminative methods for object tracking over the use of generative methods. In contrast to generative methods, discriminative methods directly model the conditional probability distribution of states given observations, and relax the conditional independence assumption made by generative methods. In particular, conditional random fields (CRF) are the most well-known discriminative graphical models used for the purpose of structured prediction, and have shown in a large number of studies to outperform generative models such as . Motivated by this, a number of CRF-based methods have been proposed for the purpose of object tracking. Taycher~ \ea~ _cite_ proposed a human tracking approach using CRFs, with an _inline_eq_ similarity space corresponding to the potential functions. Different poses were considered as tracked states within a video sequence, where as the number of states must be predefined by the user. Sigal~ \ea~ _cite_ used two-layer spatio-temporal models for component-based detection and object tracking in video sequences. In that work, each object or component of an object was considered as a node in the graphical model at any given time. Moreover, the graph edges correspond to learned spatial and temporal constraints. Following this work, proposed a layered graphical model for the purpose of partially-occluded object tracking. A layered image plane was used to represent motion surrounding a known object that is associated with a pre-computed graphical model. CRFs have also been applied to image-sequence segmentation~ _cite_, where the random fields are modeled using spatial and temporal dependencies. proposed the concept of temporal conditional random fields (TCRF) for the purpose of object tracking, where the object's next position is estimated based on the current video frame, and then subsequently refined via template matching based on a subsequent video frame. The use of CRFs specifically related to object silhouette tracking is more recent and as such more limited in existing literature. Ren and Malik~ _cite_ proposed the use of CRFs for object silhouette segmentation in video sequences where the background and foreground distributions are updated over time. In the work by Boudoukh~ \ea _cite_, a target silhouette is tracked on a video sequence by fusing different visual cues through the use of a CRF. In particular, temporal color similarity, spatial color continuity, and spatial motion continuity were considered as the CRF feature functions. The key advantage of this method for object silhouette tracking is that pixel-wise resolution can be achieved. While such CRF-based approaches to object silhouette tracking shows significant promise, one inherent limitation that is faced is that the existing CRF models used to predict the object silhouettes for one video frame are limited in their ability to take greater advantage of information from other video frames. One can use more complex CRF models to increase modeling power to address these limitations for improved object silhouette tracking, but it would also significantly increase computational complexity as well as model learning complexity. Recently, the concept of deep-structured models have been proposed to facilitate for increased modeling power without the significant increase in computational complexity and model learning complexity incurred by complex CRF models. Deep-structured CRF models make use of intermediate state layers to improve structured prediction performance, where there is an inter-layer dependency between each layer on its previous layer. Ratajczak et al.~ _cite_ proposed a context-specific deep CRF model where the local factors in linear-chain CRFs are replaced with sum-product networks. Yu et al.~ _cite_ proposed a deep-structured CRF model composed of multiple layers of simple CRFs, with each layer's input consisting of the previous layer's input and the resulting marginal probabilities. Given that the problem of object silhouette tracking is one where a set of video frames can contribute to predicting the object silhouette in a new video frame, one is motivated to investigate the efficacy of deep-structured CRF models for solving this problem. In this work, we propose an alternative framework for state-based object silhouette tracking based on the concept of deep-structured discriminative modeling. In particular, we introduce a deep-structured conditional random field (DS-CRF) model consisting of a series of state layers, with each state layer spatially characterizes the object silhouette at a particular point in time. The interactions between adjacent state layers are established by inter-layer connectivity dynamically determined based on inter-frame optical flow. By incorporate both spatial and temporal context in a dynamic fashion within such a deep-structured probabilistic graphical model, the proposed DS-CRF model allows us to develop a framework that can accurately and efficiently track object silhouettes that can change greatly over time. Furthermore, such a modeling framework does not require distinct stages for prediction and update, and does not require independent training for the dynamics of each object silhouette being tracked. Experimental results show that the proposed framework can estimate object silhouettes over time in situations where there is occlusion as well as large changes in object silhouette appearance over time.