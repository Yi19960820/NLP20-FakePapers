Image classification and recognition has been an active research spot for many years with explosive growth of image data from daily life and internet. The far-reaching study can be employed in practical applications, including face recognition, species categorization, object detection, for a more intellective world. However, there exist threefold challenges in this research. The first is to extract numerical feature representation from images since original image cannot be exploited directly. Extensive studies have explored this area _cite_ . Classical methods for feature extraction include Haar-like feature _cite_, Scale-invariant feature transform (SIFT) _cite_, Histograms of Oriented Gradients (HOG) _cite_, Local binary pattern (LBP) _cite_, Speeded up robust feature (SURF) _cite_, etc. The above methods can be classified into two kinds: single feature vector representation (HAAR, HOG, LBP) and bag-of-words representation (SIFT, SURF, patches of LBP and HOG) . The difference between the two kinds features is that a image is represented by a single vector or a bag of instances, leading to two areas in machine learning, standard classification and multi-instance learning. As that the contents in a image are not distributed uniformly or regularly, bag-of-words representation has the advantage that every word expresses a image's key feature independently, without the negative impact of unfixed locations of these key features in a single vector. The second challenge is to integrate the information from multiple sources or multiple feature sets. In fact, the extracted features from different methods are complementary to each other and can be combined to improve the performance of image recognition, which is in the scope of multi-view learning. Multi-view learning has been developed from co-training, to multiple kernel learning and subspace learning _cite_ . Extensive experiments have verified that information form multiple views can boost the performance of methods in machine learning. The third key challenge is to design an efficient data-dependent distance function to show the image relationships and distributions in feature space. The researchers in distance metric learning has proposed many algorithms to improve the performance of distance related methods based on the idea that a desired metric should shrink the distance between similar points and expand the distance between dissimilar points as much as possible _cite_ . The distance between images has been seldom studied when multi-instance features are extracted from images. However, in practical, the features of image can be extracted from multiple views, each view consists of multi-instance features. It is worthy and important to unify the information from multiple views, investigating the relationship between different views and different bags in the same view. It is much more interesting to explore multiple data-dependent metrics in multi-instance task with multiple views. In this paper, we propose a new approach to improve the performance of image classification, named MVML. For each image, multi-instance features are extracted due to the merits of bag-of-words representation and different feature extraction methods are implemented to constructed multiple views. To combine the features from multi-view effectively, we first define a new distance function for bags and then seek for a instance-dependent metric by maximizing the average conditional probability that every image is similar with its nearest image. The distance between images is computed by the weighted sum of the distance between bags from each single view. So the metrics and weights are both needed to be optimized. The tricks of gradient descent and alternate optimization are used to solve our approach. The efficiency of our novel method in making image classification, compared with single view multi-instance learning, has been demonstrated in the numerical experiments. In summary, the main contributions of our work are as follows: The followings of the paper are organized in this way. In Section _ref_, we will introduce previous related works about metric learning, multi-view learning and multi-instance classification. Our model, including multi-instance problem with multi-view, distance function for bags and the probability framework will be provided in Section _ref_ . Then we will optimize our approach in this Section. In Section _ref_, numerical experiments will be made to demonstrate that our model can deal with multi-instance classification effectively and efficiently. The conclusions will be summarized in Section _ref_ .