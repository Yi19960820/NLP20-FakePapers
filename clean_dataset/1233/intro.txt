Motion blur is often unavoidable when capturing images with a fast moving camera. It not only degrades the visual quality but it also has a negative impact on applications such as visual odometry, augmented reality (AR) and simultaneous localization and mapping (SLAM) . Even though the blind deblurring methods have improved significantly over the years, they generally struggle with strong and spatially-variant motion blur. We intend to overcome these limitations by utilizing inertial measurements. Blind deconvolution methods aim to recover the sharp image without any additional information about the motion blur. This is an ill-posed problem since the blurred image only provides a partial constraint on the solution. Promising results have been obtained with recent deep learning based approaches _cite_ . These methods are especially good at generating perceptually convincing images while avoiding deblurring artifacts. To simplify the problem, the existing methods typically assume a spatially-invariant blur, which may not hold in practice. An example of such case is shown in Figure _ref_ . Mobile devices are often equipped with an inertial measurement unit (IMU), which provides information about the motion blur. Accelerometers and gyroscopes have been successfully used in motion deblurring _cite_ . Most of these methods focus on the removal of the camera shake blur. An application such as SLAM may involve a fast moving camera, which generally results in much stronger motion blur. The existing methods are also not capable of running in real-time, apart from _cite_ . What further complicates the problem is that inertial-based blur estimates may be inaccurate. This can be due to noisy IMU readings, temporal misalignment between the camera and IMU, unknown scene depth or translation. These limitations should be considered in order to avoid deblurring artifacts. We propose a deblurring method that incorporates gyroscope measurements into a convolutional neural network (CNN) . It can handle extremely strong and spatially-variant motion blur as illustrated in Figure _ref_ . When computing the gyro-based blur estimates, we take into account that mobile devices are usually equipped with a rolling shutter camera. The method naturally overcomes the limitations of gyro-based blur estimation by utilizing image data. We also introduce a novel data generation scheme, which is an essential component needed to train our network. The evaluation on real-world images shows a clear improvement in visual quality over the state-of-the-art while achieving real-time performance. The method will also improve the robustness of existing feature detectors and descriptors against motion blur as indicated by the higher repeatability and better matching performance.