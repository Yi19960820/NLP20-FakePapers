In the context of image interpretation, numerous methods have been developed to extract meaningful information. Among them, generative models have received a particular attention due to their strong theoretical background and the great convenience they offer in term of interpretation of the fitted models compared to some model-free methods such as deep neural networks. These methods are based on an explicit statistical modeling of the data which allows very task-specific model to be derived~ _cite_, or either more general models to be implemented to solve generic tasks, such as Gaussian mixture model for classification~ _cite_ . Task-specific and classification-like models are two different ways to reach an interpretable description of the data with respect to a particular applicative non-semantic issue. For instance, when analyzing images, task-specific models aim at recovering the latent (possibly physics-based) structures underlying each pixel-wise measurement _cite_ while classification provides a high-level information, reducing the pixel characterization to a unique label _cite_ . Classification is probably one of the most common way to interpret data, whatever the application field of interest~ _cite_ . This undeniable appeal has been motivated by the simplicity of the resulting output. This simplicity induces the appreciable possibility of benefiting from training data at a relatively low cost. Indeed, in general, experts can generally produce a ground-truth equivalent to the expected results of the classification for some amount of the data. This supervised approach allows a priori knowledge to be easily incorporated to improve the quality of the inferred classification model. Nevertheless, supervised methods are significantly influenced by the size of the training set, its representativeness and reliability~ _cite_ . Moreover, in some extent, modeling the pixel-wise data by a single descriptor may appear as somehow limited. It is the reason why the user-defined classes often refer to some rather vague semantic meaning with a possible large intra-class variability. To overcome these issues, while simultaneously facing with theoretical limitations of the expected classifier ability of generalization _cite_, an approach consists in preceding the training stage with feature extraction _cite_ . These feature extraction techniques, whether parametric or nonparametric, have also the great advantage of simultaneously and significantly reducing the data volume to be handled as well as the dimension of the space in which the training should be subsequently conducted. Unfortunately, they are generally conducted in a separate manner before the classification task, i.e., without benefiting from any prior knowledge available as training data. Thus, a possible strategy is to consider a (possibly huge) set of features and selecting the relevant ones by appropriate optimization schemes _cite_ . This observation illustrates the difficulty of incorporating ground-truthed information into a feature extraction step or, more generally, into a latent (i.e., unobserved) structure analysis. Due to the versatility of the data description, producing expert ground-truth with such degrees of accuracy and flexibility would be time-consuming and thus prohibitive. For example, for a research problem as important and well-documented as that of source separation, only very few and recent attempts have been made to incorporate supervised knowledge provided by an end-user _cite_ . Nonetheless, latent structure analysis may offer a relevant and meaningful interpretation of the data, since various conceptual yet structured knowledge to be inferred can be incorporated into the modeling. In particular, when dealing with measurements provided by a sensor, task-related biophysical considerations may guide the model derivation~ _cite_ . This is typically the case when spectral mixture analysis is conducted to interpret hyperspectral images whose pixel measurements are modeled as combinations of elementary spectra corresponding to physical elementary components~ _cite_ . The contribution of this paper lies in the derivation of a unified framework able to perform classification and latent structure modeling jointly. First, this framework has the primary advantage of recovering consistent high and low level image descriptions, explicitly conducting hierarchical image analysis. Moreover, improvements in the results associated with both methods may be expected thanks to the complementarity of the two approaches. The use of ground-truthed training data is not limited to driving the high level analysis, i.e., the classification task. Indeed, it also makes it possible to inform the low level analysis, i.e., the latent structure modeling, which usually does not benefit well from such prior knowledge. On the other hand, the latent modeling inferred from each data as low level description can be used as features for classification. A direct and expected side effect is the explicit dimension reduction operated on the data before classification~ _cite_ . Finally, the proposed hierarchical framework allows the classification to be robust to corruption of the ground-truth. As mentioned previously, performance of supervised classification may be questioned by the reliability in the training dataset since it is generally built by human expert and thus probably corrupted by label errors resulting from ambiguity or human mistakes. For this reason, the problem of developing classification methods robust to label errors has been widely considered in the community~ _cite_ . Pursuing this objective, the proposed framework also allows training data to be corrected if necessary. The interaction between the low and high level models is handled by the use of non-homogeneous Markov random fields (MRF) ~ _cite_ . MRFs are probabilistic models widely-used to describe spatial interactions. Thus, when used to derive a prior model within a Bayesian approach, they are particularly well-adapted to capture spatial dependencies between the latent structures underlying images~ _cite_ . For example, Chen ~ _cite_ proposed to use MRFs to perform clustering. The proposed framework incorporates two instances of MRF, ensuring consistency between the low and high level modeling, consistency with external data available as prior knowledge and a more classical spatial regularization. The remaining of the article is organized as follows. Section~ _ref_ presents the hierarchical Bayesian model proposed as a unifying framework to conduct low-level and high-level image interpretation. A Markov chain Monte Carlo (MCMC) method is derived in Section~ _ref_ to sample according to the joint posterior distribution of the resulting model parameters. Then, a particular and illustrative instance of the proposed framework is presented in Section~ _ref_ where hyperspectral images are analyzed under the dual scope of unmixing and classification. Finally, Section~ _ref_ concludes the paper and opens some research perspectives to this work.