``Attention'' mechanisms are a critical component to brain's cognitive performance. Such mechanisms enable the brain to process overwhelming visual stimuli with limited capacity by selectively enhancing the information relevant to one's current behaviour _cite_ . With the massive growth of digital image data due to social media, surveillance camera, among others, there is a growing demand for computing platforms to perform cognitive tasks. Most of these computing platforms have limited resources in terms of processing power and battery life. Hence, researchers have been strongly motivated to design efficient large-scale image recognition methods to enable resource constrained IoT (Internet of Things) devices with cognitive intelligence _cite_ . Several brain-inspired computing models including Support Vector Machines (SVM) _cite_, random forest _cite_, and Adaboost _cite_ have proven to be very successful for image recognition. However, these classifiers do not scale well with increasing number of image categories. Deep Learning Networks like ConvNets _cite_ have achieved state-of-the-art accuracies, even surpassing human performance _cite_ for Imagenet dataset. However, they have been criticized for their enormous training cost and computational complexity. Similarly, the one-versus-all linear SVM, one of the most popular classifiers for large-scale classification, is computationally inefficient as its complexity increases linearly with the number of categories. While these classifiers are modeled to mimic the brain-like cognitive abilities, they lack the remarkable energy-efficient processing capability of the brain. The brain carries out enormously diverse and complex information processing to deal with a constantly varying world at a power budget of about ~N-N W _cite_ . Seeking to attain the brainâ€™s efficiency, we draw inspiration from its underlying processing mechanisms to design a multi-class classification method that is both accurate and computationally efficient. One such mechanism known as ``saliency based selective attention'' shown in Fig. N (left) simplifies complex visual tasks into characteristic features and then selectively activates particular areas of the brain based on the feature information in the input _cite_ . When presented with new visual images, the brain associates the already learnt features to the visual appearance of the new object types to perform recognition _cite_ . This facilitates the brain to learn a host of new information with limited capacity and also speeds up the recognition process. Interestingly, we note that there is significant similarity among underlying characteristic features (like color or texture) of images across multiple objects in real world applications. This presents us with an opportunity to build an efficient visual recognition system incorporating inter-class feature similarities and relationships. In this work, we propose a computationally efficient multi-class classification method: Attention Tree (ATree) that exploits the feature similarity among multiple classes in the dataset to build a hierarchical tree structure composed of binary classifiers. The resultant ATree learns a hierarchy of features that transition from general to specific as we go deeper into the tree in a top-down manner. This is similar to the state-of-the-art Deep Learning convolutional Networks (DLNs) where the convolutional layers exhibit a generic-to-specific transition in the learnt features _cite_ . In case of DLNs, the entire network is utilized for the recognition of a particular test input. In contrast, the construction of the attention tree incorporates effective and active pruning of the dataset during training of the individual tree nodes resulting in an efficient instance-specific classification path. In addition, as we will see in later sections, our attention model captures both inter and intra class feature similarity to build a tree hierarchy with decision paths of varying lengths even for the same class. This provides substantial benefits in test speed and computational efficiency for large-scale problems while maintaining competitive classification accuracy. Fig. N (right) shows a toy example of an ATree based on real-world broad semantic categories for different object classes. For example, to recognise a car, it is not sensible to learn all the specific appearance details. Instead, first we learn the general vehicle-type features (wheels, shape etc) and then learn more discriminative details (brand symbol) . Thus, we learn a hierarchy of features generalizing over object instances like: Wheeled vehicle _inline_eq_ Motor vehicles _inline_eq_ Cars _inline_eq_ BMW. If presented with new motorbike object types, the attention hierarchy now associates this new category of objects to the already learnt "Wheeled vehicle" features and then learns more discriminative details corresponding to the motorbike types. Each node of the ATree is then associated with different features based on inter-class relationships. It is evident from Fig. N that the attention tree method bears resemblance to the selective attention mechanism of the brain (Fig. N left) by exploiting feature similarity and the implicit relationships among different visual data to learn a meaningful hierarchy for recognition.