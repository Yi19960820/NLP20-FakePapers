Understanding the world from images or videos requires reasoning about ambiguous and uncertain information. For example, when an object is occluded we receive only partial information about it, making our resulting inferences about the object class, shape, location, or material uncertain. To represent this uncertainty in a coherent manner we can use probabilistic models. A key distinction is between and probabilistic models, see _cite_ . represent a joint distribution _inline_eq_ over an observation _inline_eq_ and a quantity _inline_eq_ that we would like to infer. We can inspect a generative model by drawing samples _inline_eq_ (see Fig.~ _ref_), and we can make predictions by conditioning, evaluating _inline_eq_ . In contrast, directly model the distribution _inline_eq_, always assuming that _inline_eq_ is observed. We can make predictions but no longer inspect the internals of the model through sampling. Discriminative models often outperform generative models on prediction tasks where a large amount of labeled data is available. Conversely, generative models have the advantage that in principle they can make use of abundant unlabeled data, but in practice there are computational challenges. Today, the majority of popular computer vision models are discriminative, but recently deep learning revolutionized how we build generative models and perform inference in them. In particular, current works on (GANs) (_cite_) and (VAEs) ~ (_cite_) allow for rich and tractable generative models. In the current study, we extend the generative VAE framework to represent a joint distribution _inline_eq_ and derive a generative-discriminative hybrid making use of abundant unlabeled data. To derive our hybrid model we start with a generative VAE model of the form _inline_eq_, where _inline_eq_ are neural network parameters. Since labeled data is costly, we assume that only a small subset of the training instances is labeled _inline_eq_, while a much larger training subset contains a collection of unlabeled observations _inline_eq_ only. To allow learning from the unlabeled set we consider the _inline_eq_ and derive a tractable variational lower bound. Interestingly, through a particular choice in the derivation of this lower bound we can create an auxiliary discriminative neural network model _inline_eq_ . With the help of the bound the maximum likelihood learning objective for our generative model now becomes the sum of the full likelihood and the marginal likelihood. The benefit of this hybrid approach is that it allows learning from partial observations in a principled manner and scales to realistic computer vision applications. In summary, our contributions are: