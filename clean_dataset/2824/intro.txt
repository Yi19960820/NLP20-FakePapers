Object detection is an essential problem in computer vision which aims to detect the locations of semantic objects in videos or digital images. Object detection is widely used in areas such as image retrieval, object identification, video surveillance, etc. Pedestrian detection is a branch of object detection problem which deals with detecting the specific human class. It has applications in various topics such as advanced driver assistance systems, person identification, face recognition, etc. The pedestrian detection problem can be decomposed into region proposal generation, feature extraction, and pedestrian verification. In general, object detection involves generating candidates for bounding boxes enclosing the objects of interest, extracting robust features as high level representations of the candidates, and verifying each candidate to be a true or a false positive. In recent years, convolutional neural network based techniques have successfully been applied to pedestrian detection and achieved better performances in many challenging scenarios. Li et al. _cite_ trained multiple Fast R-CNN _cite_ based networks to detect pedestrians with different scales and combined results from all networks to generate the final results. Hosang et al. _cite_ used the SquaresChnFtrs _cite_ method to generate pedestrian proposals and trained AlexNet _cite_ to perform pedestrian verification. Zhang et al. _cite_ used a Region Proposal Network (RPN) _cite_ to compute pedestrian candidates and a cascaded Boosted Forest _cite_ to perform sample re-weighting to classify the candidates. In this paper, we propose a deep neural network fusion architecture to address the pedestrian detection problem, called Fused Deep Neural Network. Compared to previous methods, our proposed system is faster while achieving better detection accuracy. The architecture consists of a pedestrian candidate generator, which is obtained by training a deep convolutional neural network trained as a single shot detector (SSD) with a high detection rate, albeit a large false positive rate. A novel soft-rejection strategy is used to adjust the confidence in the detector candidates by fusion with a classification network employing an ensemble learning approach, and semantic segmentation network which provides pixel-wise labeling. The classification network deploys an ensemble of deep neural networks trained independently as verification networks, and their results are softly fused together with the detection results using the novel soft-rejection method. To prepare the training data for the verification networks, we devise a novel soft-label method to assign floating point labels to the detected candidates. Unlike traditional hard-label method for object verification, where binary labels are used, the value of the our soft-label is set to be the largest overlap ratio between the current detected bounding box and all the ground-truth bounding boxes, and is adjusted to saturate to the binary values. Additional accuracy improvements can be achieved at the expense of speed by the parallel semantic segmentation network which provides pixel-wise labels to generate a segmentation mask that delivers another soft confidence vote on the generated pedestrian candidates, and are further fused within the soft fusion framework. The proposed network architecture is shown in Figure~ _ref_ . Some of the ideas in this paper were presented at the N IEEE WACV _cite_ . In this paper, we provide more detailed analysis of these ideas, show results on more datasets, and provide additional enhancements that improved the performance over that presented at the N IEEE WACV _cite_ . The new techniques which we present here and helped provide the additional gains over _cite_ are the soft-label method for training classification methods, learning the parameters of soft-rejection fusion by an additional fusion network, and the new kernel based method to fuse the results of the semantic segmentation system and the detection system. The new techniques of this paper helped to significantly increase the detection accuracy on the Caltech dataset from _inline_eq_ to _inline_eq_ . We also extend the model to work on more classes besides pedestrians, such as cars and cyclists. Besides the Caltech Pedestrian dataset, we evaluated on three more popular pedestrian detection datasets: INRIA, ETH, and KITTI. Our techniques performed better than all the previous state-of-the-arts on Caltech, INRIA, and ETH in both accuracy and speed, and achieved comparable results on KITTI. More ablation analysis is conducted to explain the effectiveness of our system. The rest of this paper is organized as follows. Section _inline_eq_ provides a detailed description of the pedestrian detection system. Section _inline_eq_ describes the semantic segmentation system and how it helps to refine the detection results. Section _inline_eq_ discusses the experiment results and explores the effectiveness of each component of the system. Section _inline_eq_ draws conclusions on this work.