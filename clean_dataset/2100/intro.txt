Image colorization is a process that adds color to black-and-white images, requiring an extensive amount of user intervention. Traditionally, the colorization process is very tedious, time consuming and requires _inline_eq_ knowledge and artistic skills to assign the appropriate colors to the grayscale image. Recently, several colorization algorithms~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ have been proposed to reduce the user efforts required for image colorization, significantly. However, it still requires a considerable amount of manual efforts to generate satisfactory results for a broad range of images. The colorization process involves assigning an appropriate three-dimensional value (RGB) to a pixel in a grayscale image by using only one-dimensional information (luminance or Intensity) . The problem is ill-posed since several color values may have the same intensity value. Due to this reason, there is no unique solution for the colorization problem and the human interaction plays an important role in colorization process. Colorization methods can be roughly divided into two categories: interactive colorization methods and automatic colorization methods. The interactive colorization techniques~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ require user input such as manually marked color scribbles or the pre-segmented regions. The color scribbles or the pre-segmented masks are used to provide the color information at high confidence image points and then these color values are used to spread the color into the whole grayscale image by using an optimization based framework. Instead of using user-specified color information, automatic colorization methods~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ use one or more similar reference color images to transfer the color information to input grayscale image automatically. These algorithms either use the local image information of a pixel or a global optimization framework to automatically assign the suitable color value to each grayscale image pixel. In this paper, we proposed a learning-based color transfer algorithm which transfers the colors from one or more reference color images to the grayscale image without any user intervention. The algorithm uses the reference color images to learn the relationship between different image features and their corresponding color values. This information is then used to predict the possible color values of grayscale image pixels. Unlike the previous techniques, which require dozens of carefully placed color scribbles~ _cite_ ~ _cite_ ~ _cite_, the partially segmented example color image~ _cite_ or the segmented foreground and background grayscale image~ _cite_, the proposed colorization technique requires considerable less amount of user inputs which involve supplying one or more references color images only. Rather than working on an individual image pixel, the proposed algorithm uses the superpixel~ _cite_ representation of input grayscale image and the reference color images which reduces the complexity of the algorithm by grouping the image pixels that exhibit similar image properties. Based on the local appearance of these superpixels and their neighboring superpixels, we compute a set of image features for each of these superpixels. We quantize the average color values of the reference color image superpixels to compute a color label for each of these superpixels. The image features computed for reference image superpixels and their corresponding color labels are then used to train a randomize decision forest. After the training, this randomized decision forest is used to predict the color labels of input gray image superpixels. While transferring the color values corresponding to the color labels, we transfer only chromaticity values as a at the centroid of the grayscale image superpixels and then refine these by using a voting-based approach. To smoothly spread these across the superpixel, we use an optimization-based colorization technique to generate the final colorized result. The rest of paper is structured as follows: In Section N, we briefly cover the related work; Section N describes the proposed colorization algorithm. Section N presents the colorization results and a detailed comparison with other state-of-the-art colorization algorithms. Section N concludes our paper.