Liver cancer is among the top three most deadly cancers in the modern world and contrast-enhanced computed tomography (CT) is the most commonly used modality for liver cancer screening. Segmentation of liver lesions can help oncologists diagnose the cancer, determine treatment options, and evaluate the effectiveness of cancer treatments. Manual segmentation of liver lesions from a ND CT image is very time-consuming and prone to inter-and intra-rater variations. Therefore, automatic segmentation methods are highly desirable in clinical practice. Automatic liver lesion segmentation is a very challenging problem due to significant variations in location, size, shape, intensity, texture, and the number of occurrences of lesions across different patients. In addition, CT images usually have low soft-tissue contrast and suffer from noise and other artifacts. Existing lesion segmentation methods based on intensity clustering, region growing, or deformable models have shown limited success in solving this difficult problem. Recent developments of deep learning have revolutionized the field of artificial intelligence. Deep learning algorithms, especially deep convolutional neural networks (DCNN), have rapidly become a popular methodology for processing medical images as well, including lesion detection, segmentation, and classification~ _cite_ . For example, Christ et al.~ _cite_ have designed a two-step U-Net approach for automatic liver lesion segmentation, and reported a very high accuracy (Dice score above N) on their test data. In this work, we also aim to exploit the advancements in deep learning and have designed another DCNN model for fully automatic liver lesion segmentation. There are two major considerations in the design of the final model. First of all, we would like to combine important features of two very successful DCNN architectures proposed in the field: the U-Net~ _cite_ and the ResNet~ _cite_ . Second, considering the limitation of available GPU memory and limited training data, we design the DCNN model in N: the input to the model consists of several adjacent axial slices and the output is a ND segmentation map corresponding to the center slice of the input stack. Even though a ND DCNN model may be a more natural choice for segmenting ND images, model capacity and input image size are restricted by available GPU memory. We believe it is more beneficial to use a larger ND context, and a few adjacent slices can provide sufficient complementary information in the third dimension. This is especially the case since CT images usually have much coarser resolution in the _inline_eq_-direction.