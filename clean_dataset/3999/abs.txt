This paper proposes a two-stream convolution network to extract spatial and temporal cues for video based person Re-Identification (ReID) . A temporal stream in this network is constructed by inserting several Multi-scale ND (MND) convolution layers into a ND CNN network. The resulting MND convolution network introduces a fraction of parameters into the ND CNN, but gains the ability of multi-scale temporal feature learning. With this compact architecture, MND convolution network is also more efficient and easier to optimize than existing ND convolution networks. The temporal stream further involves Residual Attention Layers (RAL) to refine the temporal features. By jointly learning spatial-temporal attention masks in a residual manner, RAL identifies the discriminative spatial regions and temporal cues. The other stream in our network is implemented with a ND CNN for spatial feature extraction. The spatial and temporal features from two streams are finally fused for the video based person ReID. Evaluations on three widely used benchmarks datasets,,,, and demonstrate the substantial advantages of our method over existing ND convolution networks and state-of-art methods.