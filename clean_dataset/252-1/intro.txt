In various domains researchers work with gigapixel images which contain both global contextual information and local details, for example defense research with satellite imagery and pathology with histology slides. Training convolutional neural networks (CNNs) with those images typically involves one of two approaches: downsizing them significantly or training on image patches. The former results in a loss of local details, whereas the latter results in losing global spatial information. Additionally, when training on image patches, there needs to be labels for every patch which can be time-intensive to produce. The main bottleneck of training with large images is the size of the original image that needs to be copied to the accelerator card, typically a graphics processing units (GPU), and the resulting activation maps of the network layers which need to be kept in memory for the backward pass. This puts constraints on state-of-the-art architectures, often only allowing to train with a mini-batch size of just one image. Recently, Gomez et al. _cite_ published a method to train deep residual neural networks without storing all activations, termed the Reversible Residual Network (RevNet) . With RevNets only some layer activations can be recomputed from others. Another method to reduce memory usage is to recover intermediate activations by doing partial forward passes during backpropagation _cite_ . We show that an intermediate activation map of a convolutional neural network can be reconstructed by doing partial forward passes with smaller parts, tiles, of the whole image up until the activation maps at a layer of choice (Figure Nb) . This reconstructed activation map can then be fed as a whole through the rest of the neural network resulting in a final output. This output can then also be backpropagated to the individual tiles. We call this approach streaming stochastic gradient descent (SSGD) . We will provide an implementation for SSGD and show that it is numerically equivalent to regular stochastic gradient descent. Furthermore, we will train CNN with N megapixel input images to show the potential of SSGD in reducing the network memory footprint.