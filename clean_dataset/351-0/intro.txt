Multi-label image classification is an important task in computer vision with various applications, such as scene recognition _cite_, multi-object recognition _cite_, human attribute recognition _cite_, \etc. Compared to single-label image classification _cite_, which has been extensively studied, multi-label problem is more practical and challenging, as real-world images are usually associated with multiple labels, such as objects or attributes. Binary relevance method _cite_ is an easy way to extend single-label algorithms to solve multi-label classification, which simply trains one binary classifier for each label. Various loss functions have been investigated in _cite_ . To cope with the problem that labels may relate to different visual regions over the whole image, proposal-based approaches _cite_ are proposed to transform multi-label classification problem into multiple single-label classification tasks. However, these modifications of existing single-label algorithms ignored semantic relations of labels. Recent progress on multi-label image classification mainly focused on capturing semantic relations between labels. Such relations or dependency can be modeled by probabilistic graphical models _cite_, structured inference neural network _cite_, or Recurrent Neural Networks (RNNs) _cite_ . Despite the great improvements achieved by exploiting semantic relations, existing methods cannot capture spatial relations of labels, because their spatial locations are not annotated for training. In this paper, we propose to capture both semantic and spatial relations of labels by a Spatial Regularization Network in a unified framework (Figure _ref_), which can be trained end-to-end with only image-level supervisions, thus requires no additional annotations. Deep Convolution Neural Networks (CNNs) _cite_ have achieved great success on single-label image classification in recent years. Because of their strong capability in learning discriminative features, deep CNN models pre-trained on large datasets can be easily transferred to solve other tasks and boost their performance. However, the feature representations might not be optimal for images with multiple labels, since a ground truth label might semantically relate to only a small region of the image. The diverse and complex contents in multi-label images make it difficult to learn effective feature representations and classifiers. Inspired by recent success of attention mechanism in many vision tasks _cite_, we propose a deep neural network for multi-label classification, which consists of a sub-network, Spatial Regularization Net (SRN), to learn spatial regularizations between labels with only image-level supervisions. The SRN learns an attention map for each label, which associates related image regions to each label. By performing learnable convolutions on the attention maps of all labels, the SRN captures the underlying semantic and spatial relations between labels and act as spatial regularizations for multi-label classification. The contribution of this paper is as follows. N) We propose an end-to-end deep neural network for multi-label image classification, which exploits both semantic and spatial relations of labels by training learnable convolutions on the attention maps of labels. Such relations are learned with only image-level supervisions. Investigation and visualization of learned models demonstrate that our model can effectively capture semantic and spatial relations of labels. N) Our proposed algorithm has great generalization capability and works well on data with different types of labels. We comprehensively evaluate our method on N publicly available datasets, NUS-WIDE _cite_ (N concept labels), MS-COCO _cite_ (N object labels), and WIDER-Attribute _cite_ (N human attribute labels), showing significant improvements over state-of-the-art approaches.