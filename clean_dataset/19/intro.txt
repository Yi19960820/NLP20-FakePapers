Image segmentation is a fundamental problem in medical image analysis. Classic segmentation algorithms _cite_ are usually formulated as optimization problems relying on cues from low-level image features. In recent years, deep learning has made much progress on image segmentation tasks (e.g., FCN _cite_, HED _cite_), achieved dominant performances on many medical image segmentation benchmarks, e.g., UNet _cite_ is competitive enough for many applications. The success of deep learning based segmentation requires supervised learning on large manually annotated data. However, expert annotations on big medical datasets are expensive to obtain or even unavailable. For example, manual annotation of hundreds of cysts in CT volume dataset (examples shown in Fig. _ref_) is not feasible for a recent large-sized clinical study of lymphangioleiomyomatosis (LAM) _cite_ . To alleviate the annotation burden, researchers exploit weakly supervised methods for deep learning based segmentation. One direction is to reduce the effort (e.g., time, expertise) for annotation. By combining FCN and active learning, N \% training data is needed to train a model with comparable performance as training on all data _cite_ . Another direction applies image-level annotation by incorporating FCN in a multiple instance learning framework _cite_ . However, expertise from physicians are still needed, such as assigning image-level annotations and estimating the lesion size. Recently, deep learning has shown a potential to beat the teacher (i.e., perform better than the training data labels) _cite_ or even self-learn to be an expert without human knowledge in AlphaGo Zero _cite_ . Specifically, for some classification _cite_ and semantic segmentation _cite_ tasks, when provided with data labels with certain amount of errors, deep learning could produce lower errors than the original erroneous labels. In addition, with assisting by domain-specific algorithm (e.g., Monte Carlo tree search in Go game _cite_ ; GrabCut in image segmentation _cite_), training samples/labels can be generated to iteratively or recursively update the neural network parameters to achieve better performance. In this paper, we propose a very weakly supervised approach for LAM cyst detection and segmentation. As shown in Fig. _ref_, the detection and segmentation of cysts is a challenging task due to the large number of cysts, greatly variation of cyst sizes, severe touching of cysts, inconsistent image quality, and image noise and motion artifact, etc. Moreover, it is infeasible to obtain manual segmentation on LAM studies. Our method, differs from weakly supervised methods, can automatically learn from medical images without any manual pixel-_cite_, sparse-_cite_, or image-level _cite_ annotation and without pre-training a segmentation network on other labeled datasets _cite_ . Starting from classic segmentation techniques, specifically unsupervised _inline_eq_-means clustering with spatial information followed by graph cuts _cite_ refinement, the initial annotation is generated and serves as labels for a segmentation network (UNet _cite_ in this paper) learning. New networks are then recursively trained with the previous network predictions as training labels. An improved segmentation network could be trained under two hypotheses: N) deep learning might generate better predictions than the training data labels _cite_, and N) better training data labels produce better predictions _cite_ . Note that the value of _inline_eq_ in _inline_eq_-means clustering is the only value provided to the framework.