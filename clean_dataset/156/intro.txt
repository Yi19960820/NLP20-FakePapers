Recognizing multiple labels of images is a fundamental yet practical problem in computer vision, as real-world images always contain rich and diverse semantic information. Besides the challenges shared with single-label image classification (e.g., large intra-class variation caused by viewpoint, scale, occlusion, illumination), multi-label image classification is much more difficult since accurately predicting the presence of multiple object categories usually needs understanding the image in depth (e.g., associating semantic labels with regions and capturing their dependencies) . Recently, convolutional neural networks (CNNs) _cite_ achieve great success in visual recognition/classification tasks by learning powerful feature representations from raw images, and they have been also applied to the problem of multi-label image classification by combining with some object localization techniques _cite_ . The resulting common pipeline usually involves two steps. A batch of hypothesis regions are first produced by either exploiting bottom-up image cues _cite_ or casting extra detectors _cite_, and these regions are assumed to contain all possible foreground objects in the image. A classifier or neural network is then trained to predict the label score on these hypothesis regions, and these predictions are aggregated to achieve the multi-label classification results. Despite acknowledged successes, these methods take the redundant computational cost of extracting region proposals and usually over-simplify the contextual dependencies among foreground objects, leading to a sub-optimal performance in complex scenarios. Recently, Wang et al. _cite_ proposed to jointly characterize the semantic label dependency and the image-label relevance by combining recurrent neural networks (RNNs) with CNNs. However, their model disregards the explicit associations between semantic labels and image contents, and lacks fully exploiting the spatial context in images. In contrast to all these mentioned methods, we introduce an end-to-end trainable framework that explicitly discovers attentional regions over image scales corresponding to multiple semantic labels and captures the contextual dependencies of these regions from a global perspective. No extra step of extracting hypothesis regions is needed in our approach. Two examples generated by our approach are illustrated in Figure _ref_ . To search for meaningful and discriminative regions in terms of multi-label classification, we propose a novel recurrent memorized-attention module, which is combined with convolutional neural networks in our framework. Specifically, this module consists of two components: i) a spatial transformer layer to locate attentional regions on the convolutional maps and ii) an LSTM (Long-Short Term Memory) sub-network to sequentially predict the labeling scores over the attentional regions and output the parameters of the spatial transformer layer. Notably, the global contextual dependencies among the attentional regions are naturally captured (i.e., memorized) together with the LSTM sequential encoding. And the two components are alternately performed during the recurrent learning. In this way, our approach enables to learn a contextualized and interpretable region-label relevance while improving the discriminability for multi-label classification. The main contributions of this work are three-fold. {\flushleft _inline_eq_} We develop a proposal-free pipeline for multi-label image recognition, which is capable of automatically discovering semantic-aware regions over image scales and simultaneously capturing their long-range contextual dependencies. {\flushleft _inline_eq_} We further propose three novel constraints on the spatial transformer, which help to learn more meaningful and interpretable regions, and in turn, facilitate multi-label classification. {\flushleft _inline_eq_} We conduct extensive experiments and evaluations on large-scale benchmarks such as PASCAL VOC _cite_ and Microsoft COCO _cite_, and demonstrate the superiority of our proposed model in both recognition accuracy and efficiency over other leading multi-label image classification methods.