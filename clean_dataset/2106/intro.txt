The availability of various imaging modalities such as X-ray, CT, MRI, PET, US etc., for capturing the different tissue characteristics, has led the researchers to look for methods that perform subject specific synthesis, without the need for an actual acquisition.With potential for applications in image super resolution _cite_ _cite_, building virtual models, atlas construction _cite_, multimodal registration _cite_, segmentation _cite_, and radiation therapy planning _cite_ etc. The atlas based method uses an atlas of source images, for synthesis of target image.By mapping the attenuation maps of a source image to the estimated attenuation map _cite_ _cite_ .The disadvantage of this method is that, the results of the reconstruction is dependent on the registration accuracy. Since the registration quality has a direct impact on the synthesis results.The data base driven methods operate by using a database of images with arbitrary source and target modalities for image synthesis. The target modality is estimated, by performing a local patch based search at each point in the target image using nearest neighbor information value at the given point _cite_ . However, the method restricts nearest neighbor search to a small window and ignores the spatial information, needed for accurate synthesis.The learning based methods work by learning a non-linear relationship between the source and the target images for the synthesis task _cite_ _cite_ . Though, these methods outperform the previous methods, the reconstruction quality is dependent on the quality of feature extraction. Recently, deep learning models such as the CNN _cite_ _cite_ _cite_ are gaining a lot of popularity in computer vision and medical imaging fields, for their capability to learn a hierarchy of features.As a multilayer and fully trainable model, CNNâ€™s can capture the non-linear mapping by learning from high level features built upon low level features. The method presented in _cite_ learns a non-linear mapping from MR to CT images using patch based ND fully convolutional network. However, since the method is patch based, it does not take into consideration the contextual features of the whole image. Also, the training time and prediction speed of the network is very high. In this paper, we propose a variant of F-CNN for image synthesis and call it the SynNet. The proposed architecture is end to end without any pre-and post-processing of data and heuristics. The main contributions of this paper is to Investigate an end-to-end fully convolutional network architecture for cross modal image synthesis by using the contextual information of the whole image.Extend the proposed architecture for various input and output configurations.Single input single output (SISO), Multiple input single output (MISO) and Multiple input multiple output (MIMO) . Investigate the proposed custom loss function for cross modal image synthesis.