A key task in computer vision is image recognition, for which the ultimate goal is to recognize all elements in an image. At a high level these elements can be divided into two categories: things and stuff _cite_ . Things are usually countable objects, such as vehicles, persons and furniture items. On the other hand, stuff is the set of remanining elements, usually not countable, such as sky, road and water. Within image recognition, many tasks have been introduced to identify these elements in images. Instance segmentation and semantic segmentation are two of such tasks that have become very prominent, with state-of-the-art methods _cite_ and _cite_, respectively. The first task, instance segmentation, focuses on the detection and segmentation of things . If an object is detected, a pixel mask is predicted for this object, and the output of such a method is a set of pixel masks. By design, this method does not account for all elements in an image, as it does not consider stuff classes. The second task, semantic segmentation, does consider all elements, as the aim is to make a class prediction for each pixel in an image, for both things and stuff classes. However, the semantic segmentation output does not differentiate between different instances of things classes. As a result, both methods lack the ability to fully describe the contents of an image. To fill this gap, the task of panoptic segmentation is introduced in _cite_ . For this task, each pixel of an image must be assigned with a class label and an instance id . For things classes, the instance id is used to distinguiscoh between different objects. On the other hand, for the stuff classes, it is not necessary--and sometimes not even possible--to distinguish between different instances. Therefore, pixels in these classes always get the same instance id. In _cite_, a baseline method for this task is presented, for which they take the outputs of the best scoring instance segmentation and semantic segmentation networks, and combine them using basic heuristics to generate an output in the panoptic format. Before the task of panoptic segmentation was formally introduced, there were already some publications that focused on exactly this task. In _cite_, depth layering and direction predictions are used to detect different instances of objects in a semantic segmentation map. In _cite_, a Dynamically Instantiated Network is used to combine the outputs from an external object detector and an internal semantic segmentation network to form a panoptic-like output. In this report, we present a single network that makes both instance segmentation and semantic segmentation predictions, using a shared feature extractor. These predictions are combined to form panoptic segmentation outputs using heuristics, augmenting those in _cite_ . The main contribution of our approach is the fact that we apply a single network to make panoptic segmentation predictions.