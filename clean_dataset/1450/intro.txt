this paper, we address the challenges in long-term tracking of multiple persons in a complex scene captured by a single, uncalibrated camera with an aim of achieving consistent person identity tracking (i.e. no identity switches) . This is a challenging problem due to many sources of uncertainty, such as clutter, serious occlusions, targets interactions, and camera motion. Recently, significant progress has been reported in human detection _cite_, and this promotes the popular tracking paradigm: detect-then-track _cite_ . The main idea is that a human detector is run on each frame to detect targets of interest, and then detection responses are linked across multi-frames to obtain target trajectories. In _cite_, the authors formulate the multi-target data association as a network flow optimization problem. Zhang et al. _cite_ use a push-relabel method _cite_ to solve the min-cost flow problem. Berclaz et al. _cite_ and Pirsiavash et al. _cite_ propose to use successive shortest path algorithms, which can achieve roughly the same tracking results with less computation cost. In a more recent paper, Butt et al. _cite_ incorporate higher-order track smoothness constraints, such as constant velocity, for multi-target tracking. However, due to the limitation of the appearance cues used for tracking, the methods mentioned above usually cannot deal with longer term tracking to obtain a complete trajectory of a target. This is because prolonged occlusions and target-to-target interactions will result in fragmentation of a trajectory. By using of the information from previous, current, and subsequent frames, trajectory can be recovered from the fragments and tracking errors such as missed tracks or identity switches can be corrected. In our earlier work _cite_, we advocate a discriminative target-specific appearance-based affinity model to reinforce the appearance cues for multi-person tracking. Unlike the PIRMPT system proposed by _cite_, which requires off-line learned local descriptors, our target-specific metrics are online learned during tracking. In _cite_, we utilized a motion constraint based on heuristics. In this paper, we exploit motion dynamics to further improve tracking of target's identity. Furthermore, we study the significance of the appearance and motion cues on tracking performance independently. Different from previous works _cite_, which simply multiply the motion and appearance affinities to obtain the linking probabilities of two tracklets, we separately develop a learning algorithm to automatically learn the weights of the two terms from labeled training data. The learned weights can enhance the tracking cues with strong discriminative power and suppress the tracking cues with weak discriminative power. As a result, the weighted tracking cues can disambiguate the targets' respective identities better even in situations such as the one depicted in Figure _ref_ . A typical way of implementing the popular ``detect-then-track" paradigm is to track multiple targets frame by frame, which often encounters irrecoverable errors if a target is undetected in one or more successive frames or if two detections are erroneously linked. To overcome this weakness, global trajectory optimization over batches of frames have been proposed in recent years, using methods such as Linear Programming _cite_ and Dynamic Programming _cite_ . These methods are often based on graphical network optimization in which the nodes are represented by detection responses. Such methods often fail to handle the problems of long-term tracking in crowded scenes well. To alleviate this, some researchers _cite_ try to use the track fragments (tracklets) as graph nodes aiming at linking tracklets into long trajectories. This kind of Tracklet Association-based Tracking (TAT) methods can increase robustness and reduce the computation complexity of the graph optimization. There are two key components of a TAT approach: (N) The tracklet affinity model that estimates the likelihood of two tracklets belonging to the same target; (N) The global optimization framework for tracklet association that determines the links of the tracklets based on their affinity scores. In this paper, we report our algorithm applied to tracking pedestrians in real scenes, but it can be generalized to tracking any other objects in diverse situations. The framework of this approach is shown in Figure _ref_ . Given a video sequence, we first detect pedestrians in each frame by an existing detector, such as the Deformable Part Models (DPM) detector _cite_ . We utilize the strategy introduced in Section _ref_ to generate the initial tracklets, which are mostly reliable. But some errors, though very little, could still exist in initial tracklets. We introduce our target-specific metric learning on these initial tracklets. Then we use the online learned target-specific metrics to refine these initial tracklets for reliable tracklets. The cost-flow network is based on the reliable tracklets and its optimization yields the long-term trajectories of multiple persons. Estimating the transition costs is the key factor in the min-cost network flow optimization. We propose to learn tracklet affinity models, which include weighted discriminative appearance and motion cues, in an online manner for estimating the transition costs. The main contributions of this paper are: (N) Online learning of target-specific metrics with strong discriminative power through a two-step target-specific metric learning and metric refinement processes. (N) Utilizing both appearance and motion dynamics in the tracklet affinity models, which are updated within each local segment for reduced computation and locally adaptive affinity models. (N) A learning algorithm to learn the weights of motion and appearance tracking cues for tracklet affinity models. The rest of this paper is organized as follows: Section N describes the cost-flow network formulation. Section N presents the online learning of the tracklet affinity models. The learning of weights is presented in section N. Experimental results and comparisons are shown in section N. Section N concludes the paper.