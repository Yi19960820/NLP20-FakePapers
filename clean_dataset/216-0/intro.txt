In many practical machine learning scenarios, the test samples are drawn from a different distribution from the training ones, due to varying acquisition conditions, such as different data sources, illumination conditions and cameras, in the context of visual recognition. Over the years, great progress has been achieved to tackle this problem, known has the domain shift. In particular, many methods aim to align the source (i.e., training) and target (i.e., test) distributions by learning domain-invariant embeddings~, the most recent approaches relying on deep networks~ . While effective, these methods work under the assumption that the source and target data contain exactly the same classes. In practice, however, this assumption may easily be violated, as the target data will often contain additional classes that were not present within the source data. For example, when training a model to recognize office objects from images, as with the popular Office dataset~, one should still expect to see new objects, unobserved during training, when deploying the model in the real world. While one should not expect the model to recognize the specific class of such objects, at least in unsupervised domain adaptation where no target labels are provided, it would nonetheless be beneficial to identify these objects as unknown instead of misclassifying them. This was the task addressed by~ _cite_ in their so-called domain adaptation approach. This method aims to learn a mapping from the source samples to a subset of the target ones corresponding to those identified as coming from known classes. While reasonably effective, this procedure involves alternatively solving for the mapping and the assignment of source and target samples to known/unknown classes, which, as discussed in our experiments, can be relatively costly. In this paper, we introduce a novel approach to open-set domain adaptation based on learning a factorized representation of the source and target data. In essence, we seek to model the samples from the known classes with a low-dimensional subspace, shared by the source and target domains, and the target samples from unknown classes with another subspace, specific to the target domain. We then make use of group sparsity to encourage each target sample to be reconstructed by only one of these subspaces, which in turns lets us identify if this sample corresponds to a known or unknown class. We further show that we can obtain a more discriminative shared representation by jointly learning a linear classifier within our framework. Ultimately, our approach therefore allows us to jointly separate the target samples between known and unknown classes and represent the source and target samples within a consistent, shared latent space. We demonstrate the effectiveness of our approach on several open set domain adaptation benchmarks for visual object recognition. Our method consistently and significantly outperforms the state-of-the-art technique of~ _cite_, thus showing the benefits of learning shared and private representations corresponding to the known and unknown classes, respectively. Furthermore, it is faster than the algorithm of~ _cite_ by an order of magnitude.