According to the skin Cancer Foundation Statistics, the percentage of both melanoma and non-melanoma skin cancers has been increasing rapidly over the last few years~ _cite_ . Dermoscopy, non-invasive dermatology imaging methods, can help the specialists to inspect the pigmented skin lesions and diagnose malignant melanoma at an initial-stage _cite_ . Even the professional dermatologist can not properly classify the melanoma only by relying on their perception and vision. Sometimes, human tiredness and other distractions during visual diagnosis can also yield high number of false positives _cite_ . Therefore, a Computer-Aided Decision system (CAD) is needed to assist the dermatologists to properly analyze the dermoscopic images and accurately segment the melanomas. Many attempts of melanoma segmentation have been proposed in the literature. An overview of the different melanoma segmentation techniques is presented in {_cite_} . However, this task is still a challenge, since the dermoscopic images has various characteristics including different sizes and shapes, fuzzy boundaries, different colors, and the presence of hair _cite_ . In last few decades, many approaches have been proposed to cope with the aforementioned challenges. Most of these methods are based on thresholding, edge-based and/or region-based active contour models, clustering and supervised learning _cite_ . However, these methods are unreliable when dermoscopic images are inhomogeneous and/or lesions have fuzzy or blurred boundaries _cite_ . Furthermore, their performance relies on efficient pre-processing algorithms, such as filtering, illumination correction and hair removal, which badly affect the generalizability of these models. Recently, deep learning methods applied to image analysis, specially Convolutional Neural Networks (CNNs) have been used to solve the image segmentation problem _cite_ . These CNN-based methods can automatically learn features from raw pixels to distinguish between background and foreground objects to attain the final segmentation. Most of these approaches generally are based on encoder-decoder networks~ _cite_ . These networks learn to map the features of an image to a segmented image. The encoder networks are used for extracting the features from the input images, in turn the decoder ones used to construct the segmented image. The U-net network proposed in~ _cite_ has been particularly designed for biomedical image segmentation based on the concept of Fully Convolutional Networks (FCN) ~ _cite_ . The U-net model reuses the feature maps of the encoder layers to the corresponding decoders and concatenates them to upsampled (via deconvolution) decoder feature maps called ``skip-connections''. The U-Net model for SLS outperformed many classical clustering techniques~ _cite_ . In addition, the deep residual network (ResNet) model~ _cite_ is a N-layers network designed for segmentation tasks. ResNet blocks are used to boost the overall depth of the networks and allow more accurate segmentation depending on more significant image features. Moreover, Dilated Residual Networks (DRNs) proposed in~ _cite_ increase the resolution of the ResNet blocksâ€™s output by replacing a subset of interior subsampling layers by dilation~ _cite_ . DRNs outperform the normal ResNet without adding algorithmic complexity to the model. DRNs are able to represent both tiny and large image features. Furthermore, Zhao et. al.~ _cite_ proposed a Pyramid Pooling Network (PPN) that is able to extract additional contextual information based on a multi-scale scheme. Inspired by the success of the aforementioned deep models for semantic segmentation, we propose a model combining skip-connections, dilated residual and pyramid pooling networks for SLS with different improvements. In our model, the encoder network depends on DRNs layers, in turn the decoder depends on a PPN layer along with their corresponding connecting layers. More features can be extracted from the input dermoscopic images by combining DRNs with PPN, in turn it also enhances the performance of the final network. Finally, our SLS segmentation model uses a new loss function, which combines Negative Log Likelihood (NLL) and End Point Error (EPE) ~ _cite_ . Mainly, cross-entropy is used for multi-class segmentation models, however it is not as useful as NLL in binary class segmentation. Thus, in such melanoma segmentation, we propose to use NLL as a loss function. In addition, for preserving the melanoma boundaries, EPE is used as a content loss function. Consequently, this paper aims at developing an automated deep SLS model with two main contributions: