Natural scenes have a large range of intensity values (thus a large dynamic range) and conventional non-HDR cameras cannot capture this range in a single image. By controlling various factors, one of them being the exposure time of the shot we can capture a particular window in the total dynamic range of the scene. So we need multiple "Low dynamic range" images of the scene to get the complete information of the scene. Fig.N illustrates an example. The internal processing pipeline of the camera is highly non linear i.e. the pixel intensity value at location _inline_eq_, _inline_eq_ is equal to _inline_eq_ where _inline_eq_ is the exposure time of the shot and _inline_eq_ is the irradiance value at location _inline_eq_ . _inline_eq_ is known as the camera response function of that particular camera which is a non linear function. Given the values of _inline_eq_ for differently exposed images of the same scene we can get a robust, noise free estimate of the _inline_eq_ 's (methods like Debevec et. al. (N) use a weighted average of the _inline_eq_ to get a robust estimate of the corresponding _inline_eq_ . We use a deep neural network to estimate the function taking as input the LDR pixel intensities of N LDR images of a static scene to estimate the irradiance values, i.e. the HDR map of the scene. Fig N. shows the camera acquisition pipeline in modern cameras and the non-linear transforms involved. We further conduct experiments of getting another similar convolutional neural network to approximate a tone mapping operator. Our training set includes HDR images of scenes and their corresponding tone mapped images generated by one of the Tone mapping operators provided in MATLAB's HDR-Toolbox (Banterle et al. N) which gives the highest value of the TMQI metric (Yeganeh et al. N) . We try further experiments to improve the results, details of which are provided in the main report.