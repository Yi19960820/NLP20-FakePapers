Visual recognition of human-object interactions (HOI) (e.g. ``riding a horse'', ``eating a sandwich'') is a fundamental problem in computer vision. Successful HOI recognition could identify not only objects but also the relationships between them, providing a deeper understanding of the semantics of visual scenes than just object recognition _cite_ or object detection _cite_ . Without HOI recognition, an image can only be interpreted as a collection of object bounding boxes. An AI system can only pick up information such as ``A baseball bat is in the right corner'' and ``A boy is close to the baseball bat'', but not ``A boy wearing a cap is swinging a baseball bat''. HOI recognition has recently attracted increasing attention in the field of computer vision _cite_ . While significant progress has been made, the problem of HOI recognition is still far from being solved. A key issue is that these approaches have been evaluated using small datasets with limited HOI categories, e.g. N categories in PASCAL VOC _cite_ and N categories in Stanford N Actions _cite_ . Furthermore, these datasets offer only a limited variety of interaction classes for each object category. For example, in Stanford N Actions, ``repairing a car'' is the only HOI category involving the object ``car''. It is unclear whether a successful algorithm can really recognize the interaction (e.g. ``repairing''), or whether it simply recognizes the present object (e.g. ``car'') . This issue has recently been addressed by _cite_, which introduced ``Humans interacting with Common Objects'' (HICO), a large image dataset containing N HOI categories over N common object categories and featuring a diverse set of interactions for each object category. HICO was used in _cite_ to provide the first benchmark for image-level HOI classification, i.e. classifying whether an HOI class is present in an image. While the introduction of HICO may facilitate progress in the study of HOI classification, HOI recognition still cannot be fully addressed, since with only HOI classification computers are not able to accurately localize the present interactions in images. To be able to ground HOIs to image regions, we propose studying a new problem: detecting human-object interactions in static images. The goal of HOI detection is not only to determine the presence of HOIs, but also to estimate their locations. Formally, we define the problem of HOI detection as predicting a pair of bounding boxes---first for a person and second for an object---and identifying the interaction class, as illustrated in Fig.~ _ref_ . This is different from conventional object detection, where the output is only a single bounding box with a class label. Addressing HOI detection will bridge the gap between HOI classification and object detection by identifying the interaction relations between detected objects. The contributions of this paper are two-fold: (N) We introduce HICO-DET, the first large benchmark for HOI detection, by augmenting the current HICO classification benchmark with instance annotations. HICO-DET offers more than NK annotated instances of human-object pairs, spanning the N HOI categories in HICO, i.e. an average of N instances per HOI category. (N) We propose Human-Object Region-based Convolutional Neural Networks (HO-RCNN), a DNN-based framework that extends state-of-the-art region-based object detectors _cite_ from detecting a single bounding box to a pair of bounding boxes. At the core of our HO-RCNN is the Interaction Pattern, a novel DNN input that characterizes the spatial relations between two bounding boxes. Experiments on HICO-DET demonstrate that our HO-RCNN, by exploiting human-object spatial relations through Interaction Patterns, significantly improves the performance of HOI detection over baseline approaches. The dataset and code are publicly available at .