In many real life problems, such as overhead (aerial or satellite) or biomedical image analysis, there are no dominant up-down or left-right relationships. For example, when detecting cars in aerial images, the object's absolute orientation is not a discriminant feature. If the absolute orientation of the image is changed, e.g. by following a different flightpath, we would expect the car detector to score the exact same values over the same cars, just in their new position on the rotated image, independently from their new orientation along the image axes. In this case, we say that the problem is rotation: rotating the input is expected to result in the same rotation in the output. On the other hand, if we were confronted with a classification setting in which we are only interested in the presence or absence of cars in the whole scene, the classification score should remain the same, no matter the absolute orientation of the input scene. In this case the problem is rotation . The more general case would be rotation, in which the output changes as a function of the rotation of the input, with some predefined behavior. Taking again the cars example, a rotation covariant problem would be to retrieve the absolute orientation of cars with respect to longitude and latitude: in this case, a rotation of the image should produce a change of the predicted angle. Throughout this article we will make use of the terms equivariance, invariance and covariance of a function _inline_eq_ with respect to a transformation _inline_eq_ in the following sense: where _inline_eq_ is a second transformation, which is itself a function of _inline_eq_ . With the above definitions, equivariance and invariance are special cases of covariance. We illustrate these properties in Fig.~ _ref_ . In this paper, we propose a CNN architecture that naturally encodes these three properties: RotEqNet. In the following, we will recall how CNNs achieve translation invariance, before discussing our own proposition. The success of CNNs is partly due to the translation equivariant nature of the convolution operation. The convolution of an image _inline_eq_ with a filter _inline_eq_, written _inline_eq_, is obtained by applying the same scalar product operation over all overlapping _inline_eq_ windows (unit stride) on _inline_eq_ . If _inline_eq_ undergoes an integer translation in the horizontal and vertical directions by _inline_eq_ pixels, the same pixel neighborhoods in _inline_eq_ will exist in the translated _inline_eq_, but again translated by _inline_eq_ pixels. Therefore, any operation involving fixed neighborhoods such as the convolution is translation equivariant. A crucial consequence of learning convolution weights is a drastic reduction in the number of parameters. Without the translation equivariance assumption, each local window would have a different set of weights. Forcing weights to be shared across locations, known as, reduces the number of learnable parameters proportionally to the number of pixels in the image and hardcodes translation equivariance within the model. This fact is vital for the applicability of deep neural networks to images~ _cite_ . RotEqNet shows similar advantageous characteristics when dealing with rotations: by encoding equivariance, we are able to strongly reduce the number of parameters while keeping similar or better accuracy across different tasks. However, applying the exact same reasoning of weight tying for rotations is not straightforward. To follow the same logic, one should apply _inline_eq_ rotated versions of each convolutional filter, resulting in _inline_eq_ feature maps per filter. The dimensionality of subsequent filters would therefore increase with _inline_eq_, strongly increasing model size and requirements for runtime memory usage. One way of reducing the size of the model while keeping rotation equivariance would be to propagate only the maximum value occurring across _inline_eq_ feature maps. However, deeper layers would have no information about the orientation of features at previous layers. We propose a trade-off between these two approaches by keeping the maximum value across the _inline_eq_ feature maps, but in the form of a ND vector field that captures its and and propagates it through all the layers of the network.