Modern detection methods, such as~ _cite_, based on convolutional neural networks (CNNs) have achieved state-of-the-art results on benchmarks such as PASCAL VOC~ _cite_ and COCO~ _cite_ . This, however, comes with a high training time to learn the models. Furthermore, in an era where datasets are evolving regularly, with new classes and samples, it is necessary to develop incremental learning methods. A popular way to mitigate this is to use CNNs pretrained on a certain dataset for a task, and adapt them to new datasets or tasks, rather than train the entire network from scratch. Fine-tuning~ _cite_ is one approach to adapt a network to new data or tasks. Here, the output layer of the original network is adjusted, either by replacing it with classes corresponding to the new task, or by adding new classes to the existing ones. The weights in this layer are then randomly initialized, and all the parameters of the network are tuned with the objective for the new task. While this framework is very successful on the new classes, its performance on the old ones suffers dramatically, if the network is not trained on all the classes jointly. This issue, where a neural network forgets previously learned knowledge when adapted to a new task, is referred to as catastrophic interference or forgetting. It has been known for over a couple of decades in the context of feedforward fully connected networks~ _cite_, and needs to be addressed in the current state-of-the-art object detector networks, if we want to do incremental learning. Consider the example in Figure~ _ref_ . It illustrates catastrophic forgetting when incrementally adding a class, {\it horse} in this object detection example. The first CNN (top) is trained on three classes, including {\it person}, and localizes the rider in the image. The second CNN (bottom) is an incrementally trained version of the first one for the category {\it horse} . In other words, the original network is adapted with images from only this new class. This adapted network localizes the horse in the image, but fails to detect the rider, which it was capable of originally, and despite the fact that the {\it person} class was not updated. In this paper, we present a method to alleviate this issue. Using only the training samples for the new classes, we propose a method for not only adapting the old network to the new classes, but also ensuring performance on the old classes does not degrade. The core of our approach is a loss function balancing the interplay between predictions on the new classes, i.e., cross-entropy loss, and a new distillation loss which minimizes the discrepancy between responses for old classes from the original and the new networks. The overall approach is illustrated in Figure~ _ref_ . We use a frozen copy of the original detection network to compute the distillation loss. This loss is related to the concept of ``knowledge distillation'' proposed in~ _cite_, but our application of it is significantly different from this previous work, as discussed in Section~ _ref_ . We specifically target the problem of object detection, which has the additional challenge of localizing objects with bounding boxes, unlike other attempts~ _cite_ limited to the image classification task. We demonstrate experimental results on the PASCAL VOC and COCO datasets using Fast R-CNN~ _cite_ as the network. Our results show that we can add new classes incrementally to an existing network without forgetting the original classes, and with no access to the original training data. We also evaluate variants of our method empirically, and show the influence of distillation and the loss function. Note that our framework is general and can be applied to any other CNN-based object detectors where proposals are computed externally, or static sliding windows are used.