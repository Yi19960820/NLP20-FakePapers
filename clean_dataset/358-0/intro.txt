With the fast growth of on-line fashion sales, fashion related applications, such as clothing recognition and retrieval~ _cite_, automatic product suggestions~ _cite_, have shown huge potential in e-commerce. Among them, human parsing, namely decomposing a human image into semantic fashion/body regions, serves as the basis of many high-level applications, and has drawn much research attention in recent years _cite_ ~ _cite_ . However, there are still some problems with existing algorithms. Firstly, some previous works often take the reliable human pose estimation~ _cite_ as the prerequisite~ _cite_ ~ _cite_ ~ _cite_ . However, the possibly bad result from pose estimation shall degrade the performance of human parsing. Secondly, some parsing methods, such as parselets~ _cite_ and co-parsing~ _cite_, which take advantage of the bottom-up hypotheses generation methods~ _cite_, are implemented based on a critical assumption that the objects or semantic regions have a large probability to be tightly covered by at least one of the generated hypotheses. This assumption does not always hold. When the semantic regions appear with larger appearance diversity, it is very difficult to obtain a single hypothesis to cover the whole region, as the object hypotheses by the over-segmentation tend to capture the appearance consistency other than the semantic meanings. Thirdly, all existing methods do not sufficiently capture the complex contextual information among the key elements of human parsing, including semantic labels, label masks and their spatial layouts. We argue that human parsing can greatly benefit from the structural information among these elements. As shown in Figure~ _ref_, the presence of the skirt (i.e. its visibility) will hinder the probability of the dress/pants, and meanwhile encourage the visibilities and constrain the locations of left/right legs in (a) . For example, the mask of a specific label can also provide the informative guidance for predicting the masks and locations of other labels, especially for the neighboring regions. The mask of the upper-clothes is a single segment due to the presence of the skirt in (c), while the upper-clothes mask is composed of two separate regions due to the dress in (b) . Without capturing such structure information, the methods based on low level pixel or region hypotheses are not fully capable of accurately predicting the masks of different labels. Different from these previous works, we propose a novel end-to-end framework for human parsing and formulate it as an Active Template Regression (ATR) problem. Instead of assigning a label to each pixel or hypothesis, we directly predict and locate the mask of each label. The parsing result for the test image is represented by the set of semantic regions (as in Figure~ _ref_), which are morphed by the normalized masks with the corresponding active shape parameters, including the position, scale and visibility. In terms of the label mask generation, we first collect all the binary masks of the training images and then learn a batch of mask bases to construct the template dictionary for each label. Intuitively, the template dictionaries can be used to span the subspaces of label masks, which encode the shape priors of each label mask. Any mask with the specific shapes can be generated by adjusting the corresponding template coefficients, inspired by the classic Active Appearance Model (AAM) ~ _cite_ and Active Shape Model (ASM) ~ _cite_ . In this way, our representation is able to capture the natural variability within a set of mask templates for each label. The normalized mask of each label is thus expressed as the linear combination of the mask template dictionary and parameterized by the template coefficients. In terms of active shape parameters, we predict the positions, scales of each semantic region and the visibility flag which indicates whether the specific label appears in the image or not. In this paper, we denote the template coefficients and active shape parameters for each label as two types of structure outputs. Our active template regression framework targets on effectively regressing these structure outputs. Inspired by its outstanding performance on traditional classification and detection tasks~ _cite_ _cite_ _cite_, we utilize the deep Convolutional Neural Network (CNN) to build the end-to-end relation between the input human image and the structure outputs for human parsing, including the mask template coefficients and the active shape parameters. To predict the template coefficients, we aim to find the best linear combination of the learned mask templates. Larger coefficients indicate higher similarities between the label masks and the corresponding templates. The active shape parameters can be predicted similarly as the CNN-based detection task~ _cite_ . We thus use two separate networks, namely active template network and active shape network, to predict the structure outputs. First, the template coefficients of all labels are together regressed by using the designed active template network which is capable of capturing the contextual correlations among all label masks. Second, the active shape network is designed to predict the position, scale and visibility of each label. To make our active shape network sensitive to position variance, we eliminate the max-pooling layer in the traditional CNN infrastructure~ _cite_, which is often designed to be invariant to scale and translation changes. For a new photo, the structure outputs of the two networks are fused to generate the probability of each label for each pixel. The super-pixel smoothing is finally used to refine the parsing result. To effectively train our networks, we conduct the experiments on a large dataset combining three public parsing dataset and our collected human parsing dataset. Comprehensive evaluations and comparisons well demonstrate the significant superiority of the ATR framework over other state-of-the-arts for human parsing. Furthermore, we also visualize our learned label masks, which demonstrate that our model can generate label masks with strong semantic meanings. Our contributions can be summarized as