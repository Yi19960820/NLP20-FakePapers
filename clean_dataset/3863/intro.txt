In today's age of social media, it is becoming more important to capture good-looking photos. Due to the outreach of social media sites, the photos get spread around quickly. It is common to retouch the photo after capturing to improve its appearance. The photo-retouching tools have made significant progress in recent years. There exist sophisticated tools such as Adobe Photoshop as well as one-touch enhancement tools such as Picasa, Windows Live Gallery and Apple's auto-enhance. However, one-touch enhancement tools neither offer personalization nor content-based image enhancement. For example, an indoor image may need a different style of enhancement than an outdoor image. Adobe Photoshop offers large variety of enhancement operations but can be complex and time-consuming for an amateur photographer. This underlines the need for better and automated image enhancement tools. Enhancement operations are performed on various aspects of an image, e.g. saturation, contrast, brightness, sharpness, etc. Hence the space of possible combinations of enhancement parameters is huge. This work focuses on content-based image enhancement by using content-similar high-quality images as reference. Training-based methods have recently been explored for image enhancement, where pairs consisting of a low-quality image and its enhanced counterpart are used for training _cite_ . The enhancements are done by expert users. Such a training set allows learning of a regression/ranking function which maps the input feature to the optimal enhancement parameters. For a regression function, it learns a mapping between the input parameters (could be pixel values) to the parameters in the corresponding enhanced image. The ranking function assigns a score to each feature vector. The enhancement parameter which gets the highest score is selected as the best enhanced version of the input image. However, such schemes do not scale well, owing to the need of expert-enhanced training images. Per our knowledge, the largest such publicly available training database is MIT-Adobe NK _cite_, consisting of N enhanced versions per image and N images. In reality, we have millions of high-quality images available on the Web which, if properly utilized, can improve the performance significantly. Further, since the previous approaches need low-quality and its enhanced counterparts, it is difficult to customize the system according to the individual's preferences. Our approach can handle a non-corresponding pair of a low-quality image and a high-quality reference image. We can possibly retrieve popular images from a user's Flickr/Instagram account to customize the enhancement preferences. To the best of our knowledge, only our approach considers both of the above aspects simultaneously. It is a challenge to find optimal enhancement parameters with non-corresponding pair of input and output images. The visual features are not corresponding to each other to build a regression or a simple ranking function. Usually, the optimal parameters of low-quality image are explored near the parameter space of its enhanced counterpart. In this case, the search for possible space of enhancement parameters is extremely difficult due to non-correspondence of input and output. To remedy this, we define a novel parameter sampling scheme and a multi-level ranking model which uses simple visual features along with derived image parameter features (such as brightness, contrast and saturation) . We build a multi-level ranking relation from the partial ordering available between the visual feature and parameter vectors of low-quality input and high-quality reference images. A learning-to-rank approach has already been proposed in _cite_ . Unlike us, they need the corresponding pairs of input and output images generated by an expert user along with a record of the intermediate enhancement steps. This limits the possible applications of their approach as discussed before. We show superiority of our method over one-touch enhancement tools and the state-of-art ranking-based enhancement approach _cite_ .