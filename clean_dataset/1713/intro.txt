Recently, deep learning methods such as Fully-connected Neural Networks (FCN) ~ _cite_, Convolutional Neural Networks (CNN) ~ _cite_, and Long Short-Term Memory (LSTM) ~ _cite_ have shown considerable improvements of performance in speech emotion recognition (SER) . As a potential way to improve performance, representation learning has been used to build high-level features from low-level features through several layers _cite_ . However, learning sequential structures of spectrogram representations appeared to be still challenging _cite_ . CNN-based methods have been investigated to this end~ _cite_ . Although a hybrid of CNN and LSTM can be a promising method to deal with spectral variations and temporal dependencies, LSTM has the limitation of increasing depth caused by the great number of parameters. Hence, learning temporal dynamics of spectral properties for SER remains a challenge. In this paper, we propose to learn spectro-temporal features using deep ND CNNs. ND CNNs are able to extract spatio-temporal features in a seamless way and have shown promising performances in computer vision tasks~ _cite_ . For the task of SER, our proposed method composes a temporal series of ND spectral feature maps and models both short and long-term dependencies simultaneously. Using large-scale datasets (N representative, aggregated corpora) and speaker-independent classification experiments, we evaluated our proposed ND CNNs for SER in a way that is representative of challenges for SER ``in the wild''. We found that N) homogeneous layers with shallow temporal but deep spectral kernels work best among the limited set of explored architectures, and that N) our proposed ND CNNs are more effective and efficient for spectro-temporal feature learning in SER compared to other CNN-based methods. This paper is structured as follows. We first introduce related studies in Section _ref_ . Next, we present corpora in Section~ _ref_, and describe our proposed learning method in Section _ref_ . The results will be reported in Section~ _ref_ and concluded in Section~ _ref_ .