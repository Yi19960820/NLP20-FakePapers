Semantic segmentation is one of the fundamental problems in computer vision which implies a wide range of applications. Recent years, with the rapid development of deep learning~ _cite_, researchers have designed powerful segmentation models~ _cite_ which are mostly equipped with an encoder-decoder architecture. These models have achieved success in various image domains, including medical image analysis, in particular organ and soft-tissue segmentation, which forms an important prerequisite of computer-assisted diagnosis~ _cite_ . Medical images can appear in more than one {\em phases}, each of which corresponds to a specific way of data sampling and scanning. It has been well acknowledged that incorporating multi-phase information improves visual recognition~ _cite_ . Nevertheless, there have fewer studies on this problem. There are two possible reasons--one of them lies in the lack of multi-phase training data, and the other refers to the difficulty in aligning multi-phase data and digging complementary information out from them. In this paper, we study this issue in the field of CT scans, for which we construct a large-scale dataset of _inline_eq_ patients. For each case, two ND volumes were collected from the {\em arterial} and {\em venous} phases, and the radiologists in our team manually annotated several abdominal targets, including organs and blood vessels. This is to say, in our dataset, each sample is composed of two paired images from {\em arterial} and {\em venous} phase, respectively. Note that the images scanned at the same position can be largely different, due to the difference of radiation in scanning. Plus, although they are scanned from the same patient, the organs and vessels are not corresponded in pixel level due to their motion in the human body (see Figure~ _ref_) . This causes huge difficulties in registrations _cite_ between the two phases. Our goal is to train a model that leverages the information from both phases in a collaborative way and improves the segmentation, while conventional approaches dealt with data in either phase, but missed the inter-phase connection. To model the inter-phase relation without the need of inter-phase registration, the problem refers to domain transfer and domain adaptation. However, as shown in Table~ _ref_, our setting is clearly different from that of existing approaches. More specifically, the knowledge from two phases needs to `help each other' during training and testing--we call it {\bf phase collaboration} . To this end, we propose an end-to-end framework named Phase Collaborative Network (PCN), which formulates the joint distribution of two-phase-image data and their semantic labels. The major contribution of this work lies in decomposing this distribution into two parts, namely, a data-to-label relation and a phase-to-phase relation. In practice, the former term is implemented as a discriminative model ({\em e.g.}, a segmentation network), and the latter one as a generative model ({\em e.g.}, a Generative Adversarial Network _cite_ which can transfer the image style across different phases) . We adopt a multi-stage strategy to train PCN, so as to facilitate the two modules to cooperate while guaranteeing the stability of optimization. We evaluate PCN on two sources of data, including our own two-phase dataset and two public one-phase datasets. In our own data, PCN learns two functions for {\em arterial}-to-{\em venous} and {\em venous}-to-{\em arterial} transfer, respectively, so that the segmentation in each phase can be assisted by another one, and the accuracy is boosted consistently. In particular, when the target is difficult ({\em e.g.}, a small target like the {\em adrenal gland}) or less discriminative under the specific phase ({\em e.g.}, an {\em artery} in the {\em venous} phase), significant accuracy gain is obtained. In public datasets where only the {\em venous} phase is present, PCN takes advantage of the {\em venous}-to-{\em arterial} transfer function learned from the two-phase dataset and generates {\em arterial} data as extra knowledge. This helps PCN outperform existing approaches that use only single-phase information. This demonstrates the potential of PCN, which can be trained at one time with paired two-phase training data, and freely applied to other one-phase scenarios. The remainder of this paper is organized as follows. Section~ _ref_ briefly reviews related work, and Section~ _ref_ introduces the problem setting. The core part, Phase Collaborative Network, is described in Section~ _ref_ . Experiments are shown in Section~ _ref_, and the conclusions drawn in Section~ _ref_ .