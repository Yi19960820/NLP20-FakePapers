Deep neural networks have been extensively used in medical image analysis and have outperformed the conventional methods for specific tasks such as segmentation, classification and detection _cite_ . For instance on brain MR analysis, convolutional neural networks (CNN) have been shown to achieve outstanding performance for various tasks including white matter hyperintensities (WMH) segmentation _cite_, tumor segmentation _cite_, microbleed detection _cite_, and lacune detection _cite_ . Although many studies report excellent results on specific domains and image acquisition protocols, the generalizability of these models on test data with different distributions are often not investigated and evaluated. Therefore, to ensure the usability of the trained models in real world practice, which involves imaging data from various scanners and protocols, domain adaptation remains a valuable field of study. This becomes even more important when dealing with Magnetic Resonance Imaging (MRI), which demonstrates high variations in soft tissue appearances and contrasts among different protocols and settings. Mathematically, a domain _inline_eq_ can be expressed by a feature space _inline_eq_ \chi _inline_eq_ and a marginal probability distribution _inline_eq_, where _inline_eq_ \chi _inline_eq_ _cite_ . A supervised learning task on a specific domain _inline_eq_ \chi _inline_eq_, consists of a pair of a label space _inline_eq_ and an objective predictive function _inline_eq_ (denoted by _inline_eq_) . The objective function _inline_eq_ can be learned from the training data, which consists of pairs _inline_eq_, where _inline_eq_ and _inline_eq_ . After the training process, the learned model denoted by _inline_eq_ is used to predict the label for a new instance _inline_eq_ . Given a source domain _inline_eq_ with a learning task _inline_eq_ and a target domain _inline_eq_ with learning task _inline_eq_, transfer learning is defined as the process of improving the learning of the target predictive function _inline_eq_ in _inline_eq_ using the information in _inline_eq_ and _inline_eq_, where _inline_eq_, or _inline_eq_ _cite_ . We denote _inline_eq_ as the predictive model initially trained on the source domain _inline_eq_, and domain-adapted to the target domain _inline_eq_ . In the medical image analysis literature, transfer classifiers such as adaptive SVM and transfer AdaBoost, are shown to outperform the common supervised learning approaches in segmenting brain MRI, trained only on a small set of target domain images _cite_ . In another study a machine learning based sample weighting strategy was shown to be capable of handling multi-center chronic obstructive pulmonary disease images _cite_ . Recently, also several studies have investigated transfer learning methodologies on deep neural networks applied to medical image analysis tasks. A number of studies used networks pre-trained on natural images to extract features and followed by another classifier, such as a Support Vector Machine (SVM) or a random forest~ _cite_ . Other studies~ _cite_ performed layer fine-tuning on the pre-trained networks for adapting the learned features to the target domain. Considering the hierarchical feature learning fashion in CNN, we expect the first few layers to learn features for general simple visual building blocks, such as edges, corners and simple blob-like structures, while the deeper layers learn more complicated abstract task-dependent features. In general, the ability to learn domain-dependent high-level representations is an advantage enabling CNNs to achieve great recognition capabilities. However, it is not obvious how these qualities are preserved during the transfer learning process for domain adaptation. For example, it would be practically important to determine how much data on the target domain is required for domain adaptation with sufficient accuracy for a given task, or how many layers from a model fitted on the source domain can be effectively transferred to the target domain. Or more interestingly, given a number of available samples on the target domain, what layer types and how many of those can we afford to fine-tune. Moreover, there is a common scenario in which a large set of annotated legacy data is available, often collected in a time-consuming and costly process. Upgrades in the scanners, acquisition protocols, etc., as we will show, might make the direct application of models trained on the legacy data unsuccessful. To what extent these legacy data can contribute to a better analysis of new datasets, or vice versa, is another question worth investigating. In this study, we aim towards answering the questions discussed above. We use transfer learning methodology for domain adaptation of models trained on legacy MRI data on brain WMH segmentation.