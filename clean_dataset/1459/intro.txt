Most conventional object detections, such as cascade detector _cite_ and deformable part-based models _cite_, adopt the sliding window strategy, which means classifiers are applied on all possible locations over the entire image. They are not efficient obviously because the computation resource is distributed equally among the salient regions and the vast majority of background regions. Recently, neural network methods have achieved great success in object detection. Region proposal based methods _cite_ first extract many salient regions, from which the bounding boxes are predicted. But too many proposals slow down the detector. Moreover, the precision is limited by the performance of region proposal methods. Single-shot approaches _cite_ has achieved the state-of-the-art precision and speed, utilizing regression and grid strategies directly. However, it is difficult to detect small objects or those with unusual aspect ratios. Besides, the precision of one-shot process cannot be improved by easily recurrent operations, while the simple strategy of glimpsing more steps is adopted by human to obtain more accurate locations. Human localizes and recognizes an object by several glimpses, each of which contains only details of a small region and rough contextual information _cite_, instead of regularly scanning. In addition, contextual information is significant to efficiently localize and recognize the objects in real-world environment _cite_ . Especially, the detection of the small object lacking appearance information depends more on the context _cite_, such as a far and forward car on the highway can be localized by the sky, the ground, the lane lines, and other cars etc. Multi-fixation glimpses are an effective and flexible way to model the relationships between the objects and their context. We thus propose a novel structure named Recurrent Attention to Detection and Classification Network shown in Fig. _ref_ . It detects and classifies the object by recurrent glimpses, and contains three modules at each step: attentional representation extractor (ARE), information fusion network (IFN) and multi-task actions (MTA) . Given the input image and the fixation point, ARE mimics the retina to extract multi-scale local regions of detailed appearance and rough context. Following this, it applies Convolutional Neural Network (CNN) learners, acting as the VN area of the brain, to learn effective appearance representations. In IFN, appearance and attentional location information are fused to form a local observation by fully-connected layers. Then N-layer LSTMs are used to simulate the memory ability of the cerebral cortex, which can fuse multi-fixation local observations and generate a vector of hidden states. MTA receives the vector and executes three tasks: the detection and classification of the object, and the prediction of the next fixation point. These tasks are finished by fully-connected layers and limitations of the value range. On training, we propose a multi-task loss function to optimize the network end-to-end, and combine stochastic and object-awareness (SA) strategy for learning fixation prediction. The stochastic strategy (S) samples the next fixation randomly over a distribution, which enlarges the diversity of samples, and present better results as early as possible by policy-reward method. The object-awareness strategy (A) means the last fixation close to the object under LN criterion, which is beneficial to the stability of optimization and prediction. Besides, we build a real-world dataset named FCAR, which provides annotations of the forward cars, and can be utilized to train and evaluate the detector of object of interest. .