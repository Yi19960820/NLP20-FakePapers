The seminal work of Gatys et al.~ _cite_ opened up a new field called Neural Style Transfer (NST) . NST is the process of using Convolutional Neural Networks (CNN) to render an image in different styles. NST methods are capable of stylizing a content image by generalizing the abstractions of style, as they are expressed in a given style image, into the original content of the input image. NST is capable of producing spectacular stylized images according to vastly different styles and, as a result, it has become a trending topic that has attracted wide attention from both academia and industry. Early NST methods achieved quite impressive results, but, at the same time, required a slow iterative optimization step~ _cite_ . Another category of NST approaches, the so-called feed-forward methods, were capable of accelerating NST, without requiring solving a new optimization problem for each input image. However, these methods are limited to transferring a specific style (or a small number of styles) for which they were pre-trained~ _cite_ . The aforementioned limitations were recently resolved by universal style transfer methods that employ one single trainable model to transfer arbitrary artistic styles via feature manipulations using a shared high-level feature space _cite_ . Even though these universal style transfer approaches are capable of performing style transfer of arbitrary styles in a style-agnostic manner via feature transforms in (almost) real-time, they usually lead to less impressive results than the other algorithms~ _cite_ . Existing universal style transfer approaches assume that the content and style representations extracted by a pre-trained CNN can be described by a single multivariate Gaussian distribution and then perform style transfer by appropriately manipulating the feature statistics of the content image to match those of the target style style. Even though modeling the features using a single Gaussian distribution has been proven adequate to transfer a single style from relatively simple images, this approach is usually not enough to transfer more complex styles from more sophisticated images, e.g., paintings. This is better illustrated in Fig.~ _ref_, where a state-of-the-art feature transformation method, that is based on the Whitening Coloring Transformation (WCT) ~ _cite_, was used for transferring the style. Note that the WCT-based method produces artifacts, e.g., the color of the rocks leaks into the sea, due to its inability to adequately model the separate sub-styles that exist in the style image. Therefore, we argue that modeling the statistics of the sub-styles that exist in an image can improve the quality of neural style transfer. This is illustrated in Fig.~ _ref_, where the sub-styles, that were (automatically) detected and modeled, were used to (automatically) stylize the appropriate parts of the content image. Note that the previous artifacts disappeared, while the overall quality of the stylized image improved, e.g., the texture of the rocks is now more detailed. The main contribution of this paper is the proposal of a feature transformation-based method for universal neural style transfer that separately models each sub-style that exists in a given style image (or a collection of style images), as shown in Fig.~ _ref_ . This allows for better modeling the subtle style differences within the same style image and then uses the most appropriate sub-style (or mixtures of different sub-styles) to stylize the content image. More specifically, the proposed method is capable of: The ability of the proposed approach to a) perform a wide range of different stylizations using the sub-styles that exist in one style image, while giving the ability to the user to appropriate mix the different sub-styles, b) automatically match the most appropriate sub-style to different semantic regions of the content image, improving the existing state-of-the-art universal NST approaches, and c) detecting and transferring the sub-styles from collections of images are demonstrated though extensive experiments. Note that the proposed approach is orthogonal to existing NST methods, i.e., it can be readily combined with most of them, providing a powerful framework that can be used towards a better understanding of NST by decomposing the style of images, while giving the opportunity to the users to interfere with the final result, providing a practical NST tool. The rest of the paper is structured as follows. The related work is discussed in Section~ _ref_ . Then, the proposed style decomposition, mixture and transfer approaches are presented in detail in Section~ _ref_ . Finally, the experimental evaluation of the proposed approach is provided in Section~ _ref_, while conclusions are drawn in Section~ _ref_ .