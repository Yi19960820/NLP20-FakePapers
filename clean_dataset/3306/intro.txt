The advent of Deep Learning has led to multiple breakthroughs in image representation including: super-resolution, image compression, image enhancement and image generation. We present a unified model that can perform two tasks: N-artifact removal for JPEG images and N-image compression for new images. Our model uses deep learning and legacy JPEG compression routines. JPEG divides images into _inline_eq_ blocks and compresses each block independently. This causes block-wise compression artifact (Figure~ _ref_) . We show that the statistics of a pixel's artifact depends on where it is placed in the block (Figure~ _ref_) . As a result, an artifact removal technique that has a prior about the pixel's location has an advantage. Our model acts on _inline_eq_ blocks in order to gain from this prior. Also, this let us reuse JPEG compression. For image compression, we examine image blocks in a sequence. When each block is being compressed, we first try to predict the block's image according to its neighbouring blocks~ (Figure~ _ref_) . Our prediction has a residual with respect to the original block. We store this residual which requires less space than the original block. We compress this residual using legacy JPEG techniques. We can trade off quality versus space using JPEG compression ratio. Our image prediction is a deterministic process. Therefore, during decompression, we first try to predict a block's content and then add up the stored residual. After decompression, we perform artifact removal to further improve the quality of the restored image. With this technique we get a superior quality-space trade-off. JPEG _cite_ compresses _inline_eq_ blocks using quantized cosine coefficients. JPEG compression could lead to unwanted compression artifacts. Several techniques are developed to reduce artifacts and improve compression: