Convolutional neural network (CNN) is one of the most prominent architectures and algorithm in Deep Learning. It shows a remarkable improvement in the recognition and classification of objects. This method has also been proven to be very effective in a variety of computer vision and machine learning problems. As in other deep learning, however, training the CNN is interesting yet challenging. Recently, some metaheuristic algorithms have been used to optimize CNN using Genetic Algorithm, Particle Swarm Optimization, Simulated Annealing and Harmony Search. In this paper, another type of metaheuristic algorithms with different strategy has been proposed, i.e. Microcanonical Annealing to optimize Convolutional Neural Network. The performance of the proposed method is tested using the MNIST and CIFAR-N datasets. Although experiment results of MNIST dataset indicate the increase in computation time (N-N), nevertheless this proposed method can considerably enhance the performance of the original CNN (up to N \%) . On the CIFARN dataset, currently, state of the art is N \% using fractional pooling, while this proposed method achieves N \%. \bigskip \noindent