The work presented here applies deep learning to the task of automated cardiac auscultation, i.e.~recognizing abnormalities in heart sounds. We describe an automated heart sound classification algorithm that combines the use of time-frequency heat map representations with a deep convolutional neural network (CNN) . Given the cost-sensitive nature of misclassification, our CNN architecture is trained using a modified loss function that directly optimizes the trade-off between sensitivity and specificity. We evaluated our algorithm at the N PhysioNet Computing in Cardiology challenge where the objective was to accurately classify normal and abnormal heart sounds from single, short, potentially noisy recordings. Our entry to the challenge achieved a final specificity of N, sensitivity of N and overall score of N We achieved the greatest specificity score out of all challenge entries and, using just a single CNN, our algorithm differed in overall score by only N compared to the top place finisher, which used an ensemble approach.