For years, the design of neural network architectures was thought to be solely a duty of a human expert-it was her responsibility to specify which type of architecture to use, how many layers should there be, how many channels should convolutional layers have and etc. This is no longer the case as the automated neural architecture search-a way of predicting the neural network structure via a non-human expert (an algorithm)-is fast-growing. Potentially, this may well mean that instead of manually adapting a single state-of-the-art architecture for a new task at hand, the algorithm would discover a set of best-suited and high-performing architectures on given data. Few decades ago, such an algorithm was based on evolutionary programming strategies where best seen so far architectures underwent mutations and their most promising off-springs were bound to continue evolving~ _cite_ . Now, we have reached the stage where a secondary neural network, oftentimes called, replaces a human in the loop, by iteratively searching among possible architecture candidates and maximising the expected score on the held-out set~ _cite_ . While there is a lack of theoretical work behind this latter approach, several promising empirical breakthroughs have already been achieved~ _cite_ . At this point, it is important to emphasise the fact that such accomplishments required an excessive amount of computational resources---more than _inline_eq_ GPU-days for the work of Zoph and Le~ _cite_ and _inline_eq_ for Zoph~ \etal~ _cite_ . Although a few works have reduced those to single digit numbers on image classification and language processing tasks~ _cite_, we consider more challenging dense per-pixel tasks that produce an output for each pixel in the input image and for which no efficient training regimes have been previously presented. Although here we concentrate only on semantic image segmentation, our proposed methodology can immediately be applied to other per-pixel prediction tasks, such as depth estimation and pose estimation. In our experiments, we demonstrate the transferability of the discovered segmentation architecture to the latter problems. Notably, all of them play an important role in computer vision and robotic applications and so far have been relying on manually designed accurate low-latency models for real-world scenarios. The focus of our work is to automatically discover compact high-performing fully convolutional architectures, able to run in real-time on a low-computational budget, for example, on the Jetson platform. To this end, we are explicitly looking for structures that not only improve the performance on the held-out set, but also facilitate the optimisation during the training stage. Concretely, we consider the encoder-decoder type of a fully-convolutional network~ _cite_, where encoder is represented by a pre-trained image classifier, and the decoder structure is emitted by the controller network. The controller generates the connectivity structure between encoder and decoder, as well as the sequence of operations (that form the so-called) to be applied on each connected path. The same cell structure is used to form an auxiliary classifier, the goal of which is to provide intermediate supervision and to implicitly over-parameterise the model. Over-parameterisation is believed to be the primary reason behind the successes of deep learning models, and a few theoretical works have already addressed it in simplified cases~ _cite_ . Along with empirical results, this is the primary motivation behind the described approach. Last, but not least, we devise a search strategy that permits to find high-performing architectures within a small number of days using only few GPUs. Concretely, we pursue two goals here: To tackle the first goal, we divide the training process during the search into two stages. During the first stage, we fix the encoder's weights and pre-compute its outputs, while only training the decoder part. For the second stage, we train the whole model end-to-end. We validate the performance after the first stage and terminate the training of non-promising architectures. For the second goal, we employ Polyak averaging~ _cite_ and knowledge distillation~ _cite_ to speed-up convergence. To summarise, our contributions in this work are to propose an efficient neural architecture search strategy for dense-per-pixel tasks that (i.) allows to sample compact high-performing architectures, and (ii.) can be used in real-time on low-computing platforms, such as JetsonTXN. In particular, the above points are made possible by: