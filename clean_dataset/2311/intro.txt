The presence of clouds due to climate factors limits the clear acquisition of content information from the Earth surface for almost all optical sensors. Ultimately, this reduces the visibility and affects adversely the processing of data for many remote sensing applications such as classification, segmentation and change detection etc. Hence, detection/elimination of cloudy coverages constitutes an important pre-processing step for remote sensing. In particular, RGB color bands are more sensitive to these atmospheric scattering conditions compared to the high wavelength sensors (i.e. infrared/multi-spectral) ~ _cite_ . Thus, this problem becomes even harder and the spatial content of the image needs to be leveraged rather than singly spectral properties of clouds as in multi-spectral/infrared sensors. For this reason, addressing the problem from the perspective of object segmentation and classification can yield more intuitive results. Moreover, more generalized solutions, i.e. instead of sensor-specific rules/thresholds, can be presented~ _cite_ . In this paper, we tackle the cloud detection problem by presenting a framework based on deep pyramid network architecture (DPN) ~ _cite_ . Compared to the existing rule-based methods~ _cite_, the proposed method exploits texture information exhibited from cloudy/non-cloudy pixels with high-level features. This improves classification decisions without the need of any specific spectral information, since a pre-trained encoder network is capable of extracting rich and distinct high-level representations for visual objects in the images. Moreover, due to the architecture, the network is concurrently optimized for both segmentation and classification phases. Lastly, since the ground truth cloud masks are quite noisy (i.e. achieving perfect pixel-level annotations is quite difficult~ _cite_), use of a pre-trained model for the abstract representation of an input provides robustness to the overall segmentation and classification phases. Rest of the paper is organized as follows: related works are reviewed in Section N. Section N is reserved for the detail of the proposed method and the problem statement. Experimental results, dataset and baseline methods are explained in Section N and the paper is concluded in Section N.