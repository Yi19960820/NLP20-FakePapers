Super-resolution is the problem of reconstructing a high resolution image from one or several low resolution images _cite_ . It has many potential applications like enhancing the image quality of low-cost imaging sensors (e.g., cell phone cameras) and increasing the resolution of standard definition (SD) movies to display them on high definition (HD) TVs, to name a few. Prior to SR methods, the usual way to increase resolution of images was to use simple interpolation-based methods such as bilinear, bicubic and more recently the resampling method described in _cite_ among many others. However all these methods suffer from blurring high-frequency details of the image especially for large upscaling factors (the amount by which the resolution of image is increased in each dimension) . Thus, over the last few years, a large number of SR algorithms have been proposed _cite_ . These methods can be classified into two categories: multi-image SR, and single-image SR. Since the seminal work by Tsai and Huang _cite_ in N, many multi-image SR techniques were proposed _cite_ . In the conventional SR problem, multiple images of the same scene with subpixel motion are required to generate the HR image. However the performance of these SR methods are only acceptable for small upscaling factors (usually smaller than N) . As the upscaling factor increases, the SR problem becomes severely ill-conditioned and a large number of LR images are needed to recover the HR image with acceptable quality. To address this problem, example-based SR techniques were developed which require only a single LR image as input _cite_ . In these methods, an external training database is used to learn the correspondence between manifolds of LR and HR image patches. In some approaches, instead of using an external database, the patches extracted from the LR image itself across different resolutions are used _cite_ . In _cite_ Freeman et al. used a Markov network model for super-resolution. Inspired by the ideas in locally linear embedding (LLE) _cite_, the authors of _cite_ used the similarity between manifolds of HR patches and LR patches to estimate HR image patches. Motivated by results of compressive sensing _cite_, Yang et al. in _cite_ and _cite_ used sparse representation for SR. In _cite_ they introduced coupled dictionary training in which the sparse representation of LR image patches better reconstructs the HR patches. Recently, joint and coupled learning methods are utilized for efficient modeling of correlated sparsity structures _cite_ . However joint learning methods and the coupled learning methods proposed in _cite_ still does not guarantee that the sparse representation of HR image patches over the HR dictionary is the same as the sparse representation of LR patches over LR dictionary. To address this problem, in this paper we propose a direct way to train the dictionaries that enforces the same sparse representation for LR and HR patches. Moreover since the HR dictionary is trained by minimizing the final error in reconstruction of HR patches, the reconstruction error in our method is smaller. The rest of this paper is organized as follows. In section N, Yang's method for super-resolution via sparse representation is reviewed. In section N, a flaw in Yang's method is discussed, and our method to solve this problem is presented. Finally, section N is devoted to simulation results.