The detection and treatment of cancer are still very challenging. The normal process of cancer detection is from certain signs and symptoms to the further investigation by medical imaging and at last confirmed by biopsy _cite_ . The diagnosis of breast cancer usually uses the biopsy tissue. The pathologists can histologically assess the microscopic structure and elements of the tissue from breast tissue biopsies _cite_ . One of the most important method for tumor histological examination in pathology is Hematoxylin and eosin (H \&E) staining _cite_ . However, manual analysis is experience based, qualitative and always causes intra-or inter-observers variation even for experienced pathologists _cite_ . Hence developing a more efficient, accurate, quantitative and automated system is necessary and urgent. Due to the high performance of deep learning networks, more and more studies used deep learning for the classification of breast cancer images _cite_ . However, the number of images available has always been an obstacle for the use of deep learning. Many studies divide images into patches for data augmentation, but the new problem is that there are no label information for patches. In this paper, transfer learning without fine-tuning is proposed to solve the above problems. Six different feature extractors are compared, including five deep learning architectures and a traditional feature extractor combining PFTAS (Parameter-Free Threshold Adjacency Statistics) and GLCM (Gray Level Co-Occurrence Matrices) features. When all features are combined, there are mainly three challenges from the machine learning point of view: (i) small sample size: size: like most other medical applications, the number of breast cancer histology images is very small (N images) ; (ii) high dimensional feature space: as six groups of features may be combined, the size of the feature space may be up to N, which is over N times bigger than the sample size; (iii) multiple feature groups: it may be hard to improve the learning performance by exploiting the complementary information that different groups contain _cite_ . To deal with these three challenges, we propose to treat breast cancer histology image classification as a multi-view learning problem. A multi-view RFSVM method proposed in our previous work _cite_ is then used as a solution. The remainder of this paper is organized as follows: the six feature extractors are detailed in Section ; in Section, the dissimilarity based multi-view learning solution is introduced; we describe in Section the data sets chosen in this study and provide the protocol of our experimental method; we analyze in Section the results of our experiments; the final conclusion and future works are drawn in Section . \iffalse We compare the performance of handcrafted features with deep learning feature extractors pretrained on ImageNet. We find out that the networks trained on ImageNet are also good feature extractors for breast cancer histology images and have better performance than handcrafted features. With random forest dissimilarity based integration method RFSVM to integrate N feature groups, we are able to improve significantly the classification performance., which is over N times bigger than the sample size