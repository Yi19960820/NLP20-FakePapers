Dictionary learning aims to learn a set of atoms such that a given signal can be well approximated by a sparse linear combination of these atoms. The standard dictionary learning problem is formulated as where _inline_eq_ is the data matrix, _inline_eq_ contains the sparse representations and _inline_eq_ is an over-complete dictionary with normalized columns (atoms) . Despite the popularity of standard dictionary learning methods in many domains, their performance in classification tasks is sub-optimal, since an accurate reconstruction is not as important for classification as the discrimination capability of the dictionary. This motivates the emergence of supervised dictionary learning techniques, exploiting both the existing label information and the underlying structure of the data. Some of these methods attempt to learn a separate sub-dictionary for each class (e.g. _cite_) . Consequently, the sparse codes over the learned dictionary are used as features on which a classifier is trained. More sophisticated approaches (e.g. _cite_) learn a discriminative dictionary by introducing a classification-error term into the objective function, and enforcing some discriminative criteria on the optimized sparse coefficients. By doing so, these methods form a unified learning problem and learn the dictionary and classifier jointly. Of the latter category, we focus on the Label Consistent K-SVD (LC-KSVD) method _cite_ for joint learning of an over-complete dictionary _inline_eq_ and an optimal linear classifier _inline_eq_: where _inline_eq_ is a binary matrix containing the labels of the training data (out of _inline_eq_ possible classes), and _inline_eq_ associates label information with each dictionary atom, thus forcing signals from the same class to have similar sparse representations. The minimized objective hence balances between the reconstruction error _inline_eq_, the label consistency _inline_eq_ and the classification error _inline_eq_ . These terms can be fused together, leading to a standard formulation: where _inline_eq_ and _inline_eq_ . Equation~ can be efficiently solved using the K-SVD algorithm _cite_, which iteratively alternates between a sparse coding step (optimization over _inline_eq_) and a dictionary update step (that updates each dictionary atom in _inline_eq_ along with its related coefficients from _inline_eq_) . Having completed the training process, the individual components _inline_eq_ and _inline_eq_ can be recovered from _inline_eq_ . Consequently, classification of a new signal is simply performed by sparse coding over the dictionary _inline_eq_ and applying the learned classifier _inline_eq_ on the resulting sparse coefficient vector, choosing the class that yields the highest score. \newline In _cite_, we have suggested an unsupervised dictionary learning algorithm for graph signals. The algorithm takes into account the underlying structure of the data in both the feature and the manifold domains using graph smoothness constraints. Furthermore, the underlying structure, encapsulated by a graph Laplacian matrix, can be learned within the dictionary learning process to promote the desired smoothness. In this paper, we propose an extension of our dual graph regularized dictionary learning algorithm to a supervised setting by applying the same ideas to the LC-KSVD approach _cite_ . The novelty of the LC-KSVD algorithm lies in the requirement that objects from the same class have similar sparse codes over some dictionary. While this method was shown to yield satisfactory classification results, we argue that optimizing a separate sub-dictionary for each class or directly relating the dictionary atoms with specific classes is overly restrictive and highly sensitive to the initialization of the algorithm. We therefore replace the label consistency constraint with a graph-based smoothness regularization that leverages the label information and promotes the discriminative nature of the sparse codes. Additionally, we propose to simultaneously take into account the underlying structure of the training data in the feature domain such that the feature dependencies are preserved in the learned dictionary atoms. In the sequel, we describe the proposed algorithm and demonstrate its efficiency in simulations.