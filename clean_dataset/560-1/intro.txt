Object pose estimation is the task of estimating the relative rigid transformation between the camera and the object in an image. This is an old and fundamental problem in computer vision and a stepping stone for many other problems such as ND scene understanding and reconstruction. Recently, this problem has enjoyed renewed interest due to the emergence of applications in autonomous driving and augmented reality, where the ability to reason about objects in ND is key. As with many computer vision tasks, methods based on convolutional neural networks (CNNs) have been shown to work really well for object pose estimation _cite_ . However, these methods often assume knowledge about the object category and its ND localization in the image. In this paper, we relax one of these constraints and propose to solve the problem of joint object category and ND pose estimation from ND images assuming known localization of the object in the image. More specifically, we assume that the bounding box around an object in the image is provided to us by an oracle and we learn a deep network that predicts the category label and ND pose of the object, as illustrated in Fig.~ _ref_ . One approach to object category and ND pose estimation is to learn independent networks for each task, as illustrated in Fig.~ _ref_ a. However, this approach does not exploit the fact that some parts of the representation could be shared across multiple tasks _cite_ . To address this issue, _cite_ designs independent pose and category networks, but each one is built on top of a feature network that is shared by both tasks, as shown in Fig.~ _ref_ b. However, one issue with both independent and shared networks is that they predict pose in a category agnostic manner, which may not always be possible because in some cases it may be difficult to define a universal reference frame (or characteristic pose) for all object categories. To address this issue, we could train a category dependent pose network, i.e., a collection of pose networks (one per object category), each of which takes as input the ND image and predicts a ND pose, as shown in Fig.~Nc. The final ND pose predicted by this sequential network is the pose predicted by the network corresponding to the predicted category label. However, as is the case for independent networks, sequential networks do not take advantage of shared representations. We propose an integrated architecture that provides the best of both worlds by integrating (N) a shared feature representation for both tasks and (N) a category dependent pose network. The proposed architecture consists of a shared feature network, whose output is used as an input to both a category network and a category dependent pose network, as shown in Fig.~Nd. The feature network is a residual network learned so that it captures properties of the image that are relevant to both categorization and pose estimation. The category network is also a residual network applied to the output of the feature network. Finally, the category dependent pose network is a collection of fully connected networks (one per object category) that receives the outputs of both the feature and categorization networks as inputs. Since the latter is a class probability vector, it can be used to predict the final pose by fusing pose from individual categories, thereby being potentially more robust to errors in the estimation of the object category. We also devise a new training algorithm for our proposed architecture. Our experiments show that the proposed approach achieves state-of-the-art performance on the challenging PascalND + _cite_ dataset for the joint categorization and pose estimation task; which is comparable to the performance of state-of-the-art methods on the simpler ND pose estimation with known object category task. We also present an ablative analysis that provides empirical justification for our design choices such as (i) network architecture, (ii) feature representations, (iii) training method, etc. To the best of our knowledge, our work is the first to use residual networks _cite_--that have worked very well for the task of image classification--for ND pose estimation. We do note that _cite_ also use residual networks but for azimuth or orientation estimation. We first review related work in \S _ref_ . We then describe our model for joint object category and ND pose estimation in \S _ref_, including the proposed architecture in \S _ref_, loss functions in \S _ref_, and training procedure in \S _ref_ . Finally, we describe our experimental evaluation and analysis in \S _ref_ .