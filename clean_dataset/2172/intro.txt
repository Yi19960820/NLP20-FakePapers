object classification has attracted lots of attention from multimedia and computer vision communities, which aims to distinguish categories that are both visually and semantically very similar within a general category, e.g., various species of birds~ _cite_, dogs~ _cite_ and different classes of cars~ _cite_ . Fine-grained object classification is especially beneficial for multimedia information retrieval and content analysis. Examples include fine-grained image search~ _cite_, clothing retrieval and recommendation~ _cite_, food recognition~ _cite_, animal recognition~ _cite_, landmark classification~ _cite_, and so on. Unfortunately, it is an extremely challenging task, because objects from similar subordinate categories may have marginal visual difference that is even difficult for humans to recognize. In addition, objects within the same subordinate category may present large appearance variations due to changes of scales, viewpoints, complex backgrounds and occlusions. An important observation on fine-grained classification is that some local parts of objects usually play an important role in differentiating sub-categories. For instance, the heads of dogs are crucial for distinguishing many species of dogs. Motivated by this observation, most existing fine-grained classification approaches (e.g., _cite_) first localize the foreground objects or object parts, and then extract discriminative features for classification. Region localization approaches~ _cite_ mainly employ unsupervised approaches to identify the possible object regions, while others (e.g., _cite_) alternatively use the available bounding box and/or part annotations. Unfortunately, these approaches suffer from some limitations. First, manually defined parts may not be optimal for the final classification task. Second, annotating parts is significantly more difficult than collecting image labels. Besides, manually cropping the objects and marking their parts are time consuming and labor intensive, which is not feasible for practical use. Third, the unsupervised object region proposal approaches generate a large number of proposals (up to several thousands), which is computationally expensive to process and classify the candidate regions. Meanwhile, psychological research has also shown that humans tend to focus their attentions selectively on parts of the visual space, instead of processing the whole scene at once when recognizing objects, and different fixations over time are combined to build up an internal representation of the scene~ _cite_ . Such a visual attention mechanism is naturally applicable to fine-grained object classification. Therefore, many visual attention based networks have been proposed in recent years~ _cite_ and achieved promising results. However, it is difficult for existing visual attention models to find multiple visually discriminative regions at once. Besides, we also notice that the inter-class differences usually exist in small regions of an object, such as the beak or the legs for bird images. It is difficult for existing attention models to exactly localize them due to their small sizes. Therefore, zooming in these regions will be helpful for the attention model. In this paper, we convert the problem of finding different attentive regions simultaneously to find them in multiple times. Owing to the capability of learning long-term dependencies in a recurrent manner, ~ _cite_ has been widely used in many deep neural networks for learning from experience to classify, process and predict time series. Therefore, LSTM is adopted to simulate the process of finding and learning multiple attentive regions of a fine-grained object. Moreover, to solve the problem of small attention regions, a diversified attention canvas generation module is designed in our proposed DVAN. Given an image, multiple attention canvases are first generated with different locations and scales. Some of the canvases depict the whole object while others only contain certain local parts. An incremental representation for objects is dynamically built up by combining a coarse-grained global view and fine-grained diversified local parts. With this representation, the general picture and the local details of the objects can be captured to facilitate fine-grained object classification. Fig.~ _ref_ illustrates two species of birds with similar appearance. The main differences exist in the regions of eyes, breast and wings. Our diversified visual attention model can automatically discover and locate the subtle differences of these two species of birds on multiple attention canvases with location and scale variations. Another prominent merit of the proposed approach is that it does not need any bounding box or part information for both training and testing, which reduces the difficulty of large-scale fine-grained object classification. The main contributions of this work are summarized as follows: The rest of the paper is organized as follows. Related work is reviewed in Section~ _ref_ . The proposed diversified visual attention network is elaborated in Section~ _ref_ . Experimental evaluation and analysis are presented in Section~ _ref_ . Finally, we conclude this work in Section~ _ref_ .