Colours enhance the information as well as the expressiveness of an image. Colour images contain more visual information than a gray-scale image and is useful for extracting information for high-level tasks. Humans have the ability to manually fill gray-scale images with colours taking into consideration the contextual cues. This clearly indicates that black-and-white images contain some latent information sufficient for the task of colourization. The modelling of this latent information to generate chrominance values of pixels of a target gray-scale image is called colourization. Image colourization is a daunting problem because a colour image consists of multi-dimensional data according to defined colour-spaces whereas a gray-scale image is just single-dimensional. The main obstacle is that different colour compositions can lead to a single gray level but the reverse is not true. For example, multiple shades of blue are possible for the sky, leaves of trees attain colours according to seasons, different colours of a pocket billiards (pool) ball. The aim of the colourization process is not to hallucinate the exact colour of an object (See Fig. _ref_), but to transfer colours plausible enough to fool the human mind. Image colourization is a widely used technique in commercial applications and a hot researched topic in the academia world due to its application in heritage preservation, image stylization and image processing. In the last few years, Convolutional Neural Networks (CNNs) have emerged as compelling new state-of-the-art learning frameworks for Computer Vision and Pattern Recognition _cite_ ; _cite_ applications. With the recent advent of Generative Adversarial Networks (GANs) _cite_, the problem of transferring colours have also been explored in the context of GANs using Deep Convolutional Neural Networks _cite_ ; _cite_ . The proposed method involves utilizing conditional Generative Adversarial Networks (cGANs) modelled as an image-to-image translation framework. \indent The main contribution of this paper is proposing a variant of Conditional-GANs which tries to learn a functional mapping from input grayscale image to output colourized image by minimizing the adversarial loss, per pixel loss, classification loss and the high-level perceptual loss. The proposed model is validated using an elaborate qualitative and quantitative comparison with existing methods. A detailed ablation study which demonstrates the efficiency and potential of our model over baselines is also presented. The rest of this paper is arranged as Section _ref_ describes previous works described in literature. Section _ref_ describes our proposed Perceptual-cGAN. Section _ref_ demonstrates a detailed qualitative and quantitative analysis of images colourized by our proposed system along with ablation studies of different objective functions. The final Section _ref_ consists of concluding remarks.