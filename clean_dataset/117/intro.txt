With the prevalence of deep neural network in visual data nowadays, detecting patterns or recognizing objects from an image dataset has become less mysterious than it used to be. Given a manually labeled training data with sufficient images, we can tune the parameters of a convolutional neural network that yields near-perfect performance. However, those concepts are typically learned in a supervised setting. It's still time consuming and expensive to organize such a large volume of manual work to label the training data, especially that the amount of images generated by smart devices during a single day is significantly beyond the capacity of manual labor. We are wondering if those newly generated, unlabeled images can be classified, recognized, or labeled automatically, so that they can either be utilized for large-scale training purposes, or simply be better documented and organized in local devices. In this paper, we combine AlexNet and Latent Dirichlet Allocation (LDA) to form a hybrid supervised-unsupervised method to extract topics (visual concepts) from unlabeled datasets, see Fig.~ _ref_ . The idea is to construct the embedding for each image from a universal pre-trained model, and then apply the topic model by grouping salient semantic features into visual topics. Concretely, we consider two scenarios. First, we take the challenge from a life-logging dataset. Life-logging cameras create huge collections of photos, even for a single person on a single day ~ _cite_, which makes it difficult for users to browse or organize their photos effectively. Unlike text corpora in which words create intermediate representations that carry semantic meaning for higher-level concepts such as topics, images have no such obvious intermediate representation in between. Egocentric photos are particularly challenging because they were taken opportunistically, so they are often blurry and poorly-composed compared to consumer-style images. We use this method to ``summarize" a subject's living genre from an egocentric life-logging dataset. Second, we use COCO dataset, a labeled dataset as ground truth to evaluate the hybrid method in terms of consistent rate. We apply LDA on top of the bag-of-word representation from a pre-trained AlexNet and get the topic assignment matrix over all images. By defining a concept of consistent rate, we compare the ground truth labels and ``concept clusters" from our method, and measure the consistency of those clusters. It shows that the space with _inline_eq_ ``irrelevant" dimensions suffice a dissimilarity measurement of image data by achieving an average consistent rate of _inline_eq_ . We also apply Harp-LDA ~ _cite_, a parallel LDA based on sparse matrix decomposition, on the state of the art Intel Knights Landing cluster for parallization, which shows the feasibility for potential applications on scaled up experiment settings. The method provides a hybrid way to extract image topics with a pre-trained AlexNet and a probabilistic topic model. It automatically labels images before manually double-checking, instead of having people label the entire image dataset; the living genre extracted from egocentric images can be used in potential psychological research; it can also detect duplicated images and organize photo albums in local computers. We describe the related work in section _inline_eq_, data in section _inline_eq_, methods in section _inline_eq_, experiment and results in section _inline_eq_, and summarize the work in section _inline_eq_ .