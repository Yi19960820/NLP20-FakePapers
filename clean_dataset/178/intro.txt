Person re-identification is a problem of associating the persons captured from different cameras located at different physical sites. If the camera views are overlapped, the solution is trivial: the temporal information is reliable to solve the problem. In some real cases, the camera views are significantly disjoint and the temporal transition time between cameras varies greatly, making the temporal information not enough to solve the problem, and thus this problem becomes more challenging. Therefore, a lot of solutions exploiting various cues, such as appearance~ _cite_, which is also the interest in this paper, have been developed. Recently, deep neural networks have been becoming a dominate solution for the appearance representation. The straightforward way is to extract a global representation~ _cite_, using the deep network pretrained over ImageNet and optionally fine-tuned over the person re-identification dataset. Local representations are computed typically by partitioning the person bounding box into cells, e.g., dividing the images into horizontal stripes~ _cite_ or grids~ _cite_, and extracting deep features over the cells. These solutions are based on the assumption that the human poses and the spatial distributions of the human body in the bounding box are similar. In real cases, for example, the bounding box is detected rather than manually labeled and thus the human may be at different positions, or the human poses are different, such an assumption does not hold. In other words, spatial partition is not well aligned with human body parts. Thus, person re-identification, even with subsequent complex matching techniques (e.g., ~ _cite_) to eliminate the misalignment, is often not quite reliable. Figure~ _ref_ provides illustrative examples. In this paper, we propose a part-aligned human representation, which addresses the above problem instead in the representation learning stage. The key idea is straightforward: detect the human body regions that are discriminative for person matching, compute the representations over the parts, and then aggregate the similarities that are computed between the corresponding parts. Inspired by attention models~ _cite_, we present a deep neural network method, which jointly models body part extraction and representation computation, and learns model parameters through maximizing the re-identification quality in an end-to-end manner, without requiring the labeling information about human body parts. In contrast to spatial partition, our approach performs human body part partition, thus is more robust to human pose changes and various human spatial distributions in the bounding box. Empirical results demonstrate that our approach achieves competitive/superior performance over standard datasets: Market-_inline_eq_, CUHK _inline_eq_, CUHK _inline_eq_ and VIPeR.