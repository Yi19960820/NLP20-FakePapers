Relational reasoning between distant regions of arbitrary shape is crucial for many computer vision tasks like image classification~ _cite_, segmentation~ _cite_ and action recognition~ _cite_ . Humans can easily understand the relations among different regions of an image/video, as shown in Figure~ _ref_ (a) . However, deep CNNs cannot capture such relations without stacking multiple convolution layers, since an individual layer can only capture information locally. This is very inefficient, since relations between distant regions of arbitrary shape on the feature map can only be captured by a near-top layer with a sufficiently large receptive field to cover all the regions of interest. For instance, in ResNet-N~ _cite_ with N residual units, the receptive field is gradually increased to cover the entire the image of size _inline_eq_ at Nth unit (the near-end of ResN) . To solve this problem, we propose a unit to directly perform global relation reasoning by projecting features from regions of interest to an interaction space and then distribute back to the original coordinate space. In this way, relation reasoning can be performed in early stages of a CNN model. Specifically, rather than relying solely on convolutions in the coordinate space to implicitly model and communicate information among different regions, we propose to construct a where global reasoning can be performed directly, as shown in Figure~ _ref_ (c) . Within this interaction space, a set of regions that share similar semantics are represented by a single feature, instead of a set of scattered coordinate-specific features from the input. Reasoning the relations of multiple different regions is thus simplified to modeling those between the corresponding features in the interaction space, as shown on the top of Figure~ _ref_ (c) . We thus build a graph connecting these features within the interaction space and perform relation reasoning over the graph. After the reasoning, the updated information is then projected back to the original coordinate space for down-streaming tasks. Accordingly, we devise a () to efficiently implement the coordinate-interaction space mapping process by weighted global pooling and weighted broadcasting, as well as the relation reasoning by graph convolution~ _cite_, which is differentiable and also end-to-end trainable. Different from the recently proposed Non-local Neural Networks (NL-Nets) ~ _cite_ and Double Attention Networks~ _cite_ which only focus on delivering information and rely on convolution layers for reasoning, our proposed model is able to directly reason on relations over regions. Similarly, Squeeze-and-Extension Networks (SE-Nets) ~ _cite_ only focus on incorporating image-level features via global average pooling, leading to an interaction graph containing only one node. It is not designed for regional reasoning as our proposed method. Extensive experiments show that inserting our \oursunitshort can consistently boost performance of state-of-the-art CNN architectures on diverse tasks including image classification, semantic segmentation and video action recognition. \noindent Our contributions are summarized below: \noindent