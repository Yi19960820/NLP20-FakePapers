The design of effective local image descriptors has been instrumental for the application of computer vision methods in several problems involving the matching of local image patches, such as wide baseline stereo~ _cite_, structure from motion~ _cite_, image classification~ _cite_, just to name a few. Over the last decades, numerous hand-crafted~ _cite_ and automatically learned~ _cite_ local image descriptors have been proposed and used in the applications above. Despite their conceptual differences, these two types of local descriptors are formed based on similar goals: descriptors extracted from local image patches of the same N-D location of a scene must be unique (compared with descriptors from different N-D locations) and robust to brightness and geometric deformations. Given the difficulty in guaranteeing such goals for hand-crafted local descriptors~ _cite_, the field has gradually focused more on the automatic learning of such local descriptors, where an objective function that achieves the goals above is used in an optimisation procedure. In particular, the most common objective function minimises the distance between the descriptors from the same N-D location (\ie, same class) extracted under varying imaging conditions and different viewpoints and, at the same time, maximises that distance between patches from different N-D locations (or different classes) ~ _cite_ . The more recently proposed approaches~ _cite_ based on deep ConvNets~ _cite_ optimise slightly new objective functions that have the same goal as mentioned above. Specifically, Zagoruyko and Komodakis~ _cite_ and Han \etal~ _cite_ minimise a pairwise similarity loss of local image patches using a siamese network~ _cite_ (see Fig.~ _ref_-(b)), where the patches can belong to the same or different classes (a class is for example a specific N-D location) . Dosovitskiy \etal _cite_ minimise a multi-class classification loss (Fig.~ _ref_-(c)), where the model outputs the classification of a single input patch into one of the many descriptor classes (estimated in an unsupervised manner) . Moreover, Masci \etal~ _cite_ propose a siamese network trained with a pairwise loss that minimises the distance (in the embedded space) between patches of the same class and maximises the distance between patches of different classes (Fig.~ _ref_-(b)) . Even though these methods show substantial gains compared to the previous state of the art in public benchmark datasets~ _cite_, we believe that the loss functions and network structures being explored for this task can be improved. For instance, the triplet network~ _cite_ (see Fig.~ _ref_-(d)) has been shown to improve the siamese network on several classification problems, and the training of the siamese and triplet networks can involve loss functions based on global classification results, which has the potential to generalise better. In this paper, we propose the use of the triplet network~ _cite_ (Fig.~ _ref_-(d)) and a new global loss function to train local image descriptor learning models that can be applied to the siamese and triplet networks (Fig.~ _ref_-(b), (d)) . The global loss to produce a feature embedding minimises the variance of the distance between descriptors (in the embedded space) belonging to the same and different classes, minimises the mean distance between descriptors belonging to the same class and maximises the mean distance between descriptors belonging to different classes (Fig.~ _ref_-(b), (d)) . For the case of pairwise similarity in siamese networks, this global loss minimises the variances of the pairwise similarity between descriptors belonging to the same and different classes, maximises the mean similarity between descriptors belonging to the same class and minimises the mean similarity between descriptors belonging to different classes (Fig.~ _ref_-(b)) . We first extend the siamese network~ _cite_ to a triplet network, trained with a triplet loss~ _cite_ and regularised by the proposed global loss (embedding) . Then we take the siamese network~ _cite_ and train it exclusively with the global loss (pairwise similarity) . Finally, we take the central-surround siamese network~ _cite_, which is the current state-of-the-art model for the problem of local image descriptor learning, and train it with the global loss (pairwise similarity) . We show on the public benchmark UBC dataset~ _cite_ that: N) the triplet network shows better classification results than the siamese network~ _cite_ ; N) the combination of the triplet and the global loss functions improves the results produced by the triplet loss from item (N) above, resulting in the best embedding result in the field for the UBC dataset; and N) the global loss function used to train the central-surround siamese network~ _cite_ produces the best classification result on the UBC dataset.