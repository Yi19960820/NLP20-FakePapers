In digital pathology, histological tissue samples undergo fixation and embedding, sectioning and staining, and are finally digitized via whole-slide scanners. Each individual processing step presents a potential source of variance. In addition to such inherent variation, different staining protocols typically exist between different institutions. While trained human observers can handle most of the resulting variability, algorithms typically require a unified representation of the data to run reliably. Essentially, the challenge in any normalization task is to transform the distribution of color values from an image acquired using an arbitrary staining protocol into a defined reference space, modeled by a different distribution. Chronologically, normalization algorithms applied in histopathology advanced from color matrix projections _cite_ to deconvolutional approaches _cite_, while many modern methods incorporate contextual information _cite_ to improve the normalization result. This trend is motivated by the amount of internal structures found in histological images, such as cell nuclei or blood-vessels, which may have similar color ranges under varying conditions and thus need to be normalized based on their context rather than individual pixel intensities. Particularly, the method ``StaNoSa'' _cite_, uses an autoencoder to provide features that steer a histogram-matching, which introduces the tissue context. In this work, we advance the idea by incorporating the entire normalization process into a deep neural network, where all algorithmic parameters are optimized via stochastic gradient descent. This requires several changes to the normalization setting, which we discuss in Sec.~ _ref_ . We evaluate the approach using an extensive dataset dedicated to the normalization problem, which is described in Sec.~ _ref_ . The dataset and an implementation of our approach are available at .