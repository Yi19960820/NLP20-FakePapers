Person re-identification, the aim of which is to match the same individual across multiple cameras, has attracted widespread attention in recent years due to its wide applications in video surveillance. It is the foundation of threat detection, behavioral understanding and other applications. Despite the considerable efforts of computer vision researchers, however, it is still an unsolved problem due to the dramatic variations caused by light, viewpoint and pose changes _cite_ . Figure _inline_eq_ shows some typical examples from two cameras. There are two crucial components, i.e. feature representations and distance metric in person re-identification systems. In these two components, feature representation is more fundamental because it is the foundation of distance learning. The features used in person re-identification range from the color histogram _cite_, spatial cooccurrence representation model _cite_, attributes model _cite_ to combination of multiple features _cite_ . These handcrafted features can hardly be optimal in practice because of the different viewing conditions that prevail _cite_ . Given a particular feature representation, a distance function is learned to construct a similarity measure _cite_ with good similarity constraints . Although the effectiveness of the distance function has been demonstrated, it heavily relies on the quality of the features selected, and such selection requires deep domain knowledge and expertise _cite_ . In this paper, we present a scalable distance driven feature leaning framework via the convolutional network to learn representations for the person re-identification problem. Unlike the traditional deep feature learning methods aimed at minimizing the classification error, in our framework, features are learned to maximize the relative distance. More specifically, we train the network through a set of triplets. Each triplet contains three images, i.e. a query image, one matched reference (an image of the same person as that in the query image) and one mismatched reference. The network produces features with which the _inline_eq_ distance between the matched pair and the mismatched pair should be as large as possible for each triplet. This encourages the distances between matched pairs to take smaller values than those between the mismatched pairs. Figure _inline_eq_ illustrates the overall principles. As discussed in _cite_, the triplet-based model is a natural model for the person re-identification problem for two main reasons. First, the intra-class and inter-class variation can vary significantly for different classes, and it may thus be inappropriate to require the distance between a matched pair or mismatched pair to fall within an absolute range. Second, person re-identification training images are relatively scarce, and the triplet-based training model can generate more constraints for distance learning, thereby helping to alleviate the over-fitting problem. Similar to traditional neural networks, our triplet-based model also uses gradient descent algorithms in solving the parameters. Owing to limitations in memory size, it is impossible to load all the triplets for a given labeled image set into the memory to calculate the gradient. A practical means is to train the network iteratively in mini-batches, that is, in each iteration, a subset of the triplets are generated and the network parameters are then updated with the gradient derived from that batch. However, as we will see in the later sections, randomly generating the triplets at each iteration is inefficient as only a small number of distance constraints are imposed on the images within the triplets. Therefore we propose a more efficient triplet generation scheme. In each iteration, we randomly select a small number of classes (persons) from the dataset and generate the triplets using only those images, which guarantees that only a small number of images are selected in each iteration and rich distance constraints are imposed. In our proposed triplet generation scheme, one image can occur in several triplets in each iteration with a high degree of probability, and we thus design an extended network propagation algorithm to avoid recalculating the gradients of the same images. Our triplet generation scheme and the extended network propagation algorithm render the overall computational load of our model dependent mainly on the number of the training images, not on the number of triplets. Our approach also enables us to use the existing deep learning implementations to solve our model parameters with only slight modifications. In summary, we make two contributions to the literature: N) A scalable deep feature learning method for person re-identification via maximum relative distance. N) An effective learning algorithm for which the training cost mainly depends on the number of images rather than the number of triplets. The remainder of this paper is organized as follows. In section two, we review the related work on person re-identification problems. In section three, we present our formulation and network architecture. In section four, we derive the algorithms for solving the model parameters using gradient descent methods for a small triplet set. In section five, we show how to train the network in batch mode with an efficient triplet generation scheme, and in section six, we present our experimental results. Section seven concludes our work.