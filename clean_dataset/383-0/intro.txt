Human pose estimation from images has been studies for decades. Due to the dependencies among joint points, it can be considered a structured-output task. In general, human pose estimation approaches can be divided by two types: N) prediction-based methods; N) optimization-based methods. The first type of approach views pose estimation as a regression or detection problem~ _cite_ . The goal is to learn the mapping from the input space (image features) to the target space (ND or ND joint points), or to learn classifiers to detect specific body parts in the image. This type of method is straightforward and usually fast in the evaluation stage. Toshev \etal~ _cite_ trained a cascaded network to refine the ND joint locations in an image stage by stage. However, this approach does not explicitly consider the structured constraints of human pose. Followup work _cite_ learned the pairwise relationship between ND joint positions, and incorporated them into the joint predictions. Limitations of prediction-based methods include: the manually-designed constraints might not be able to fully capture the dependencies among the body joints; poor scalability to ND joint estimation when the search space needs to be discretized; prediction of only a single pose when multiple poses might be valid due to partial self-occlusion. Instead of estimating the target directly, the second type of approach learns a score function, which takes both an image and a pose as inputs, and produces a high score for correct image-pose pairs and low scores for unmatched image-pose pairs. Given an input image _inline_eq_, the estimated pose _inline_eq_ is the pose that maximizes the score function, i.e., where _inline_eq_ is the pose space. If the score function can be properly normalized, then it can be interpreted as a probability distribution, either a conditional distribution of poses given the image, or a joint distribution over both images and joints. One popular model is pictorial structures~ _cite_, where the dependencies between joints are represented by edges in a probabilistic graphical model~ _cite_ . As an alternative to generative models, structured-output SVM~ _cite_ is a discriminative method for learning a score function, which ensures a large margin between the score values for correct input pairs and for incorrect input pairs _cite_ . As the score function takes both image and pose as input, there are several ways to fuse the image and pose information together. For example, the features can be extracted jointly according to the image and poses, e.g., the image features extracted around the input joint positions could be viewed as the joint feature representation of image and pose _cite_ . Alternatively, features from the image and pose can be extracted separately and concatenated, and the score function trained to fuse them together _cite_ . However, with these methods, the features are hand-crafted, and performance depends largely on the quality of the features. On the other hand, deep neural networks have been shown to be good at extracting informative high-level features _cite_ . In this paper, we propose a unified framework for maximum-margin structured learning with deep neural network for human pose estimation. Our unified framework jointly learns the image and pose feature representations and the score function. In particular, our network first extracts separate feature embeddings from the image input and from the ND pose input. The score function is then the dot-product between the image and pose embeddings. The score function and feature embeddings are trained using a maximum-margin criteria, resulting in a discriminative joint-embedding of image and ND pose. The dot-product score function is efficient to compute, and allows for fast inference over a large set of candidate poses. In addition, our proposed framework is quite general and can be applied to a wide range of structured-output tasks.