Human action recognition has become an active research area in recent years, as it plays a significant role in video understanding. In general, human action can be recognized from multiple modalities _cite_, such as appearance, depth, optical flows, and body skeletons~ _cite_ . Among these modalities, usually convey significant information that is complementary to others. However, the modeling of dynamic skeletons has received relatively less attention than that of appearance and optical flows. In this work, we systematically study this modality, with an aim to develop a principled and effective method to model dynamic skeletons and leverage them for action recognition. The dynamic skeleton modality can be naturally represented by a time series of human joint locations, in the form of ND or ND coordinates. Human actions can then be recognized by analyzing the motion patterns thereof. Earlier methods of using skeletons for action recognition simply employ the joint coordinates at individual time steps to form feature vectors, and apply temporal analysis thereon~ _cite_ . The capability of these methods is limited as they do not explicitly exploit the spatial relationships among the joints, which are crucial for understanding human actions. Recently, new methods that attempt to leverage the natural connections between joints have been developed~ _cite_ . These methods show encouraging improvement, which suggests the significance of the connectivity. Yet, most existing methods rely on hand-crafted parts or rules to analyze the spatial patterns. As a result, the models devised for a specific application are difficult to be generalized to others. To move beyond such limitations, we need a new method that can automatically capture the patterns embedded in the of the joints as well as their . This is the strength of deep neural networks. However, as mentioned, the skeletons are in the form of graphs instead of a ND or ND grids, which makes it difficult to use proven models like convolutional networks. Recently,, which generalize to graphs of arbitrary structures, have received increasing attention and successfully been adopted in a number of applications, such as image classification~ _cite_, document classification~ _cite_, and semi-supervised learning~ _cite_ . However, much of the prior work along this line assumes a fixed graph as input. The application of to model dynamic graphs over large-scale datasets, e.g. ~human skeleton sequences, is yet to be explored. In this paper, we propose to design a generic representation of skeleton sequences for action recognition by extending graph neural networks to a spatial-temporal graph model, called . As illustrated in Figure~ _ref_ this model is formulated on top of a sequence of skeleton graphs, where each node corresponds to a joint of the human body. There are two types of edges, namely the that conform to the natural connectivity of joints and the that connect the same joints across consecutive time steps. Multiple layers of spatial temporal graph convolution are constructed thereon, which allow information to be integrated along both the spatial and the temporal dimension. The hierarchical nature of eliminates the need of hand-crafted part assignment or traversal rules. This not only leads to greater expressive power and thus higher performance (as shown in our experiments), but also makes it easy to generalize to different contexts. Upon the generic GCN formulation, we also study new strategies to design graph convolution kernels, with inspirations from image models. The major contributions of this work lie in three aspects: N) We propose, a generic graph-based formulation for modeling dynamic skeletons, which is the first that applies graph-based neural networks for this task. N) We propose several principles in designing convolution kernels in ST-GCN to meet the specific demands in skeleton modeling. N) On two large scale datasets for skeleton-based action recognition, the proposed model achieves superior performance as compared to previous methods using hand-crafted parts or traversal rules, with considerably less effort in manual design. The code and models of ST-GCN are made publicly available .