In N, Google DeepMind successfully used convolutional neural networks with deep reinforcement learning to teach a computer to play classic score-based Atari games _cite_ . We propose to study a complementary problem-that of teaching a computer to play modern video games purely through imitation learning; i.e. pure behavioral mimicry of human actions viewed through gameplay screenshots. The imitation learning framework provides several advantages over its deep-Q sibling, not the least of which is the fact that we no longer depend on a carefully crafted loss function or an a priori notion of ``game score.'' The gameplay data now also consists of a reliable ground truth that we assume represents close-to-optimal behavior, which should add further robustness at training time. \indent The goal of these studies is not to push performance past that of a deep-Q network; while deep-Q methods have already surpassed human performance for some gaming tasks _cite_, our model performance at test-time is intrinsically limited by the human-generated dataset that our networks train on, as we provide our model with no additional reinforcement signal. However, we will show that our methods provide reasonable performance at a significantly lower cost in terms of hardware and time, and can be implemented with minimal fine-tuning at inference. The same model can also in principle be applied to various games without much additional tuning, and this portability is attractive from an implementation perspective. We thus present our results without any intent of dethroning deep-Q learning in terms of performance, but rather to demonstrate that a significantly more lightweight approach using CNNs can yield reasonable results, which can be of great interest when using these methods in practice. \indent More specifically, we propose training a deep convolutional network on the task of playing Super Smash Bros., a classic game for the Nintendo N gaming system. We use as input data gameplay frames (_inline_eq_ NxNpx images) and as ground truth keyboard input generated from a human player (who will be one of the researchers) . Super Smash Bros was chosen not only for its name recognition within the gaming community, but also because it is more complex (with ND camera angles, random zooms, etc.) when compared to the ND state-spaces already thoroughly explored by the Atari experiments in _cite_ . We show that given a moderately sized labeled data set, a supervised approach will be able to produce a model that can play this complex game stably within human reaction time at the level of a competent human player. However, we also recognize that such a method might not be appropriate for all cases; for comparison purposes, we will also train the same model on a Mario Tennis dataset to investigate what parts of the model are portable cross-game and what limitations such models might face in the wild. \indent Crucial to the success of our model is its ability to reason temporally about the dataset and leverage the many rich correlations along the time axis within video game datasets. Our work is thus also relevant to CNN applications in the realm of video and temporal analysis.