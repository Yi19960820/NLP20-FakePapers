Primates excel at view-invariant object recognition~ _cite_ . This is a computationally demanding task, as an individual object can lead to an infinite number of very different projections onto the retinal photoreceptors while it varies under different N-D and N-D transformations. It is believed that the primate visual system solves the task through hierarchical processing along the ventral stream of the visual cortex~ _cite_ . This stream ends in the inferotemporal cortex (IT), where object representations are robust, invariant, and linearly-separable~ _cite_ . Although there are extensive within-and between-area feedback connections in the visual system, neurophysiological~ _cite_, behavioral~ _cite_, and computational~ _cite_ studies suggest that the first feed-forward flow of information (_inline_eq_ ms post-stimulus presentation) might be sufficient for object recognition~ _cite_ and even invariant object recognition~ _cite_ . Motivated by this feed-forward information flow and the hierarchical organization of the visual cortical areas, many computational models have been developed over the last decades to mimic the performance of the primate ventral visual pathway in object recognition. Early models were only comprised of a few layers~ _cite_, while the new generation, called ``deep convolutional neural networks" (DCNNs) contain many layers (N and above) . DCNNs are large neural networks with millions of free parameters that are optimized through an extensive training phase using millions of labeled images~ _cite_ . They have shown impressive performances in difficult object and scene categorization tasks with hundreds of categories~ _cite_ . Yet the view-point variations were not carefully controlled in these studies. This is an important limitation: in the past, it has been shown that models performing well on apparently challenging image databases may fail to reach human-level performance when objects are varied in size, position, and most importantly N-D transformations~ _cite_ . DCNNs are position invariant by construction, thanks to weight sharing. However, for other transformations such as scale, rotation in depth, rotation in plane, and N-D transformations, there is no built-in invariance mechanism. Instead, these invariances are acquired through learning. Although the features extracted by DCNNs are significantly more powerful than their hand-designed counterparts like SIFT and HOG~ _cite_, they may have difficulties to tackle N-D transformations. To date, only a handful of studies have assessed the performance of DCNNs and their constituent layers in invariant object recognition _cite_ . In this study we systematically compared humans and DCNNs at view-invariant object recognition, using exactly the same images. The advantages of our work with respect to previous studies are: (N) we used a larger object database, divided into five categories; (N) most importantly, we controlled and varied the magnitude of the variations in size, position, in-depth and in-plane rotations; (N) we benchmarked eight state-of-the-art DCNNs, the HMAX model~ _cite_ (an early biologically inspired shallow model), and a very simple shallow model that classifies directly from the pixel values ("Pixel") ; (N) in our psychophysical experiments, the images were presented briefly and with backward masking, presumably blocking feedback; (N) we performed extensive comparisons between different layers of DCNNs and studied how invariance evolves through the layers; (N) we compared models and humans in terms of performance, error distributions, and representational geometry; and (N) to measure the influence of the background on the invariant object recognition problem our dataset included both segmented and unsegmented images. This approach led to new findings: (N) Deeper was usually better and more human-like, but only in the presence of large variations; (N) Some DCNNs reached human performance even with large variations; (N) Some DCNNs had error distributions which were indiscernible from those of humans; (N) Some DCNNs used representations that were more consistent with human responses, and these were not necessarily the top performers.