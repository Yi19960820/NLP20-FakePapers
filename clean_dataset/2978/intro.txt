Background estimation and foreground segmentation is a fundamental step in several computer vision applications, such as salient motion detection _cite_, video surveillance _cite_, visual object tracking _cite_ and moving objects detection _cite_ . The goal of background modeling is to efficiently and accurately extract a model which describes the scene in the absence of any foreground objects. Background modeling becomes challenging in the presence of dynamic backgrounds, sudden illumination variations, and camera jitter which is mainly induced by the sensor. A number of techniques have been proposed in the literature that mostly address relatively simple scenarios for scene background modeling _cite_, because complex background modeling is a challenging task itself specifically in handling real-time environments. To solve the problem of background subtraction, Stauffer et al. _cite_ and Elgammal et al. _cite_ presented methods based on statistical background modeling. It starts from an unreliable background model which identify and correct initial errors during the background updating stage by the analysis of the extracted foreground objects from the video sequences. Other methods proposed over the past few years also solved background initialization as an optimal labeling problem _cite_ . These methods compute label for each image region, provide the number of the best bootstrap sequence frame such that the region contains background scene. Taking into account spatio-temporal information, the best frame is selected by minimizing a cost function. The background information contained in the selected frames for each region is then combined to generate the background model. The background model initialization methods based on missing data reconstruction have also been proposed _cite_ . These methods work where missing data are due to foreground objects that occlude the bootstrap sequence. Thus, robust matrix and tensor completion algorithms _cite_ as well as inpainting methods _cite_ have shown to be suitable for background initialization. More recently, deep neural networks are introduced for image inpainting _cite_ . In particular, Chao Yang et al. _cite_ used a trained CNN (Context Encoder _cite_) with combined reconstruction loss and adversarial loss _cite_ to directly estimate missing image regions. Then a joint optimization framework updates the estimated inpainted region with fine texture details. This is done by hallucinating the missing image regions via modeling two kinds of constraints, the global context based and the local texture based, with convolutional neural networks. This framework is able to estimate missing image structure, and is very fast to evaluate. Although the results are encouraging but it is unable to handle random region inpainting task with fine details. In this paper we propose to predict missing image structure using inpainting method, for the purpose of scene background initialization. We name our method as Deep Context Prediction (DCP), because it has the ability to predict context of a missing region via deep neural networks. Few visual results of the proposed DCP algorithm are shown in Figure _ref_ . Given an image, fast moving foreground objects are removed using motion information leaving behind missing image regions (see Figure _ref_ Step (N)) . We train a convolutional neural network to estimate the missing pixel values via inpainting method. The CNN model consists of an encoder capturing the context of the whole image into a latent feature representation and a decoder which uses this representation to produce the missing content of the image. The model is closely related to auto-encoders _cite_, as it shares a similar architecture of encoder-decoder. Our contributions in the proposed method are summarized as follows: The proposed DCP algorithm is based on context prediction, therefore it can predict homogeneous or blurry contexts more accurately compared to other background initialization algorithms. In case of background motion, DCP can still estimate background by calculating motion masks via optical flow, as our target is to eliminate foreground moving objects only. DCP is also not effected by intermittent object motion because of the same reason mentioned previously. In challenging weather conditions (rain, snow, fog) dense optical flow can identify foreground moving objects, so targeting only those objects to remove and inpaint them with background pixels makes DCP a good background estimator. For the case of difficult light conditions DCP can estimate background accurately because of homogeneity in the context of scenes with low illumination.