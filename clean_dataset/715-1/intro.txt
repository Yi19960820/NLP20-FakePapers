A visual system possesses color constancy if it perceives colors almost independently of the prevailing illumination for a wide range of conditions. In digital cameras, the so-called automatic white balance aims at reaching this property. Color constancy is a desirable property in many computer vision and graphics applications where the intrinsic color of the object is needed--for accurate classification, regression, segmentation, and feature extraction~ _cite_ as well as for accurate scene rendering. Methods aiming at achieving color constancy fall into two groups. The first estimate illumination properties of the observed scene which is followed by image color correction called chromatic adaption _cite_ _cite_, _cite_, _cite_ . The second group, operates on an illumination invariant representations without explicitly estimating the scene illumination. The invariant features are designed or learned to depend only on reflectance characteristics or spatial structure _cite_ . We propose a novel method for estimating scene illumination color that uses a structured-output regression on the output of a single fully-connected layer from a deep net. Image color is then corrected on the basis of the estimated illumination parameters. The deep net extract visual information that has been shown to facilitate color constancy _cite_ as well as other computer vision task _cite_ . The structured-output regression models the cross-channel correlations, which is the main contribution of our work. In the literature _cite_, single-output regressor, \ie support vector regression, has been employed to learn the relationship between observation variables and each color dimension of the target variables independently. We show experimentally that the proposed framework achieves competitive performance comparable with several state-of-the-art methods on two popular color constancy benchmarks.