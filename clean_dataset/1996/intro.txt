Video sharing websites measure user engagement through click rates and viewership. To make a novel video attractive for the audience, its video link is often presented as a thumbnail of either a single representative frame or a slideshow of several keyframes. In this work, we explore the problem of automatically generating diverse, representative and attractive keyframe-based summaries for videos. Summarization-based techniques can be broadly divided into three categories: N) keyframe-based, N) skimming-based and N) story-based. In keyframe-based summarization, the video is summarized using a small number of keyframes selected based on some criterion, such as low-level features, like pixel data, motion features, optical flow and frame differences~ _cite_, or higher-level information, like objects and faces~ _cite_ . For this class of algorithms, clustering techniques like k-means are popular: clustering or grouping is performed based on raw RGB pixels, or a combination of low and high level features~ _cite_ . The frames closest to the cluster centers are chosen to be part of the summary. Skimming-based summarization is used to produce longer video summaries. The video is divided into smaller shots using shot boundary detection algorithms and a series of shots are selected to form the summary video. Subshot selection is based on motion activity~ _cite_ and other high level features, such as person and landmark descriptors~ _cite_ . Finally, in storyboard-based summarization, algorithms take into account relationships between the different subshots~ _cite_ . This enables long egocentric videos to be summarized to gain an understanding of the underlying events. {\bf Contributions.} This work focuses on generating compact keyframe-based summarization, with the main contributions are as follows: [-N]