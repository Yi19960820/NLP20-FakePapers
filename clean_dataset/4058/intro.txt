Object classification is a difficult problem due to the translation, rotation and scale variability of objects within the images as well as external variabilities such as noise and illumination. Hand-engineered features such as SIFT~ _cite_ and HOG~ _cite_ modeled the geometric properties of the objects to achieve decent classification accuracy. However, these features have been recently replaced by trained networks~ _cite_, ~ _cite_, ~ _cite_, especially, Convolutional Neural Networks (CNNs) ~ _cite_ that have achieved state-of-the-art accuracy by learning invariant and discriminative class-specific image representations. Despite the success of CNNs, design and optimal configuration of these networks is not well understood which makes it difficult to develop these networks. Mallat~ _cite_, ~ _cite_, ~ _cite_, ~ _cite_ has shown that ScatterNets incorporate geometric knowledge of images to produce discriminative and invariant (translation and rotation) representations which can give performance comparable to that of trained networks.~The invariants at the first layer of the network are obtained by filtering the image with multi-scale and multi-directional complex Morlet wavelets followed by a point-wise nonlinearity and local smoothing. The high frequencies lost due to smoothing are recovered at the later layers using cascaded wavelet transformations, justifying the need for a multilayer network. A log transformation may be applied to de-correlate the multiplicative low-frequency components from the concatenated invariants obtained at all layers~ _cite_ . Next, orthogonal least squares (OLS) selects the subset of object class-specific dimensions across the training data, similar to that of the fully connected layers in CNNs~ _cite_ .The presence of outliers in the extracted features or unwanted features extracted from the background clutter, noise, and illumination can hinder feature selection due to their effect on the least squares parameter estimates. Hence, it is important to introduce approximate symmetry in the extracted features to suppress the effect of these outliers. We propose an improved computationally efficient ScatterNet that extracts relatively symmetric translation invariant representations from a multi-resolution image using the dual-tree complex wavelet transform (DTCWT) ~ _cite_ and the proposed parametric log transformation layer. Here, we only introduce translation invariance, as the orientation of an object in the image plane is often well-known as a strong prior (e.g. side-view images) . The OLS layer next selects a subset of object specific components without undesired bias from outliers due to the introduced symmetry. The selected features are finally used by a Gaussian-kernel support vector machine (G-SVM) to perform object classification on CIFAR-N and CIFAR-N datasets. The contributions of the paper are as follows: The proposed network improves on Mallat's ScatterNet on classification accuracy and computational efficiency on two datasets. Multiple experiments on different training dataset sizes are performed to highlight the advantages of the proposed network against supervised and unsupervised methods. The paper is divided into the following sections. Section N briefly presents our proposed DTCWT scattering network with parametric log transformation. Section N presents the experimental results while Section N draws conclusions.