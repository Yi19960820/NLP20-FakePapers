advancements in ND graphics technology have witnessed extensive application of ND shapes in many areas, such as VR/AR, digital design, electronic entertainment and so on. As a result, a lot more ND shapes are generated for multiple usages, which makes it possible, as well as crucial, to develop effective ND shape recognition methods. Current approaches for ND shape recognition can be generally classified into two categories: ND model-based methods and view-based ones. ND model-based methods like _cite_, _cite_, _cite_, _cite_, _cite_, _cite_, _cite_ extract high-level descriptors directly from the raw representation of ND shapes. By contrast, view-based methods like _cite_, _cite_, _cite_, _cite_, _cite_ aim to extract features from ND images of a ND shape. The final shape descriptor is constructed from these view features. Moreover, with the great success of deep learning techniques in visual recognition and classification tasks _cite_, _cite_, _cite_, view-based methods employing Convolutional Neural Network (CNN) have achieved impressive performance and attracted much research attention. Central to most existing view-based methods is the aggregation of features extracted from multiple images to form a compact and discriminative shape feature. Among these methods, two popular feature fusion paradigms of visual features _cite_, _cite_ have achieved state-of-the-art performance on various ND shape dataset. MVCNN _cite_ adopts max-pooling operation to fuse multi-view features extracted by VGG-M _cite_ . On the other hand, _cite_ presents a novel concatenation technique with the multi-view images. However, certain images with low discriminative ability can cause a negative effect on shape features. Furthermore, the adverse influence is even more severe under real scenes with background clutter and object occlusion, which poses challenges to the application of ND shape recognition approaches. The above issue motivated us to study how the quality of different views affects the recognition results. The experiment shown in Fig. _ref_ demonstrates the influence of view quality on shape recognition. We heuristically classify the views of a ND shape into two categories: poor views and good views, through setting a threshold on the average activation values of feature maps extracted by CNN. More details about the experiment can be found in Section~ _ref_ . The results show that using _inline_eq_ good views achieves even better performance than _inline_eq_ uniformly sampled views, suggesting that different views have significantly different influence on multi-view ND shape representation. The N views lead to not only highly effective shape representation but also low computational cost, compared to computing all N rendered view features. In a real ND scene, background clutter and object occlusion could intensify the influence of different views. Although a generic network like MVCNN may be able to learn to discriminate input views based on their quality in a data-driven fashion, we find that the performance of max pooling operation (CNN + MAX) can be adversely affected by object occlusion and background clutter, which is shown in Fig. _ref_ . It indicates that this popular maximum aggregation operation on multi-view ND shape recognition is sensitive to local noise in images, because the value of the noise may be the local maximum. Instead of using maximum aggregation, we try to design a view-quality-aware network utilizing the deep understanding of CNN. Our work aims to achieve view selection in a data-driven fashion, with an end-to-end trainable model producing view-quality-aware shape representations directly. The model is able to discern the view quality and aggregating information from only discriminative and relevant views. We propose an end-to-end ND shape recognition model, named View Discerning Network, to assess the quality of views and aggregate their features based on the evaluation scores. Specifically, a Score Generation Unit is introduced to the standard CNN to evaluate the quality of each projected image with score vectors. These score vectors are then used to weigh the image features and their summation serves as the representation of the shape. The weighted features are further refined by CNN. The network is trained with supervisions targeting to both shape classification, based on Softmax loss, and shape class guided feature embedding, through minimizing a Contrastive loss. With these supervision signals, views with high quality become dominant among others, since they are assigned with higher scores. In contrast, non-informative views will be deprecated. In designing the Score Generation Unit, we develop two structures to focus on different aspects of image features. The first structure is called Channel-wise Score Unit. A channel corresponds to a filter of the CNN. And each filter produces a feature map for the image. For every channel, Channel-wise Score Unit generates a certain score which is applied to the feature map. Consequently, this structure emphasizes the difference of feature maps extracted by different filters. The second structure, named Part-wise Score Unit, concentrates on the difference of local region of the image. It measures each part of the feature map based on the regional information, yielding a score map with the same size of the feature map. And the feature maps from the same image all share the same score map. The advantage of our proposed method lies in three aspects. First, the learned ND shape representation via View Discerning Networks exhibits more discrimination on various ND shape dataset. Second, the quality of different views can be efficiently captured, making the aggregated representation robust to background clutter and object occlusion. Thirdly, the view discerning network is trained in an end-to-end manner and with weak supervision of only object category information, thus easy to implement. The contributions of this paper include: