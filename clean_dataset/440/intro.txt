Deep learning has been the driving force behind the recent improvements in fundamental computer vision tasks, including image classification, image segmentation, object detection and tracking, etc.~ _cite_ . These deep models, however, require training on high quality, large-scale datasets, and building these datasets is typically very costly. In particular, overhead, satellite images are specifically difficult and expensive to label because of humans' unfamiliarity with aerial perspectives~ _cite_ . One effective way to reduce the amount of training data needed is to perform pre-training on an existing, previously annotated dataset, such as ImageNet~ _cite_, and transfer the learned weights to the domain of interest _cite_ . However, the success of this approach diminishes if the underlying distributions and/or compositions of the pre-training and target datasets are not sufficiently similar. Such a problem is exceptionally pronounced in the satellite imagery space, as the entire frame of reference and perspective of an aerial image is altered compared to a natural image. This has the unfortunate effect of rendering natural image datasets, such as ImageNet, less useful as pre-training mechanisms for downstream computer vision tasks in the satellite domain~ _cite_ . Because direct annotation is expensive, researchers have considered many creative ways to provide supervision without explicit labels. These include unsupervised~ _cite_, label-free _cite_, and weakly supervised learning methods~ _cite_ . A particularly effective strategy is to leverage co-occurrence statistics in a dataset, e.g., predict the next frame in a video, a missing word in a sentence _cite_, encourage a model to learn similar representations in the nearby satellite images _cite_, or predict relationships between entities such as images and text co-occurring together. For example, leveraging co-occurring images and hashtags, build a very large scale image recognition dataset consisting of more than N billion Instagram images across N weakly-supervised labels obtained from textual hashtags and their WordNet _cite_ synsets. After pre-training on this extremely large dataset, they report _inline_eq_ top-N accuracy on the downstream ImageNet classification task, equating to a _inline_eq_ improvement over the same model trained from scratch on ImageNet. Inspired by their work, we construct a new multimodal dataset by pairing geo-referenced Wikipedia articles with satellite images corresponding to the article's location. To the best of our knowledge, this is the first time that Wikipedia has been used in conjunction with satellite images, and with N million potential article-image entries (if we were to collect all the images), our approach yields the . Additionally, as shown in Fig.~ _ref_, our approach is the first to provide comprehensive coverage of the . By treating an article as an information rich label, we obtain highly detailed physical and qualitative context for each image. For example, the article of Kampala contains excerpts such as `` Kampala was named the Nth fastest growing city on the planet, with an annual population growth rate of N percent by City Mayors. Kampala has been ranked the best city to live in East Africa, '' highlighting the amount of information contained in Wikipedia articles. Additionally, demographic, environmental, and social information is often readily available in structured form in many Wikipedia articles. Another exciting dimension that can be utilized to understand satellite images is the accessibility of Wikipedia articles over time, as using alterations in article content and distribution over time for a region could be helpful in detecting changes and predicting economic or population growth, etc. We believe that the scale, coverage, and richness of this novel combination of crowdsourced annotations and satellite images will enable new advances in computer vision and a wide range of new applications. In this paper, we demonstrate the effectiveness of this approach for pre-training deep models for satellite image classification, as in~ _cite_ . We label satellite images with curated summarization tags extracted from the article via an efficient, automated process. For simplicity, we focus on a subset of N images from the African continent, an area where ground labels are particularly scarce~ _cite_ . We then train a CNN architecture to predict these tags from their images. This network is then evaluated on a downstream hand-labeled dataset, as in _cite_, where we prove that it attains more than _inline_eq_ higher accuracy compared to networks trained from scratch. We believe this novel combination of visual and textual information will enable new applications for research in the social sciences, economics, sustainability, etc., via machine learning, computer vision, and natural language processing. In particular, it will complement existing data sources from surveys and open data portals such as Open Street Maps (OSM), which typically lack global coverage and provide more coarse information.