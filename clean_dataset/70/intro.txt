In this work, we propose a method to detect fashion apparels a person in an image is wearing or holding. The types of fashion apparels include hat, bag, skirt, etc. Fashion apparel spotting has gained considerable research traction in the past couple of years. A major reason is due to a variety of applications that a reliable fashion item spotter can enable. For instance, spotted fashion items can be used to retrieve similar or identical fashion items from an online inventory. Unlike most prior works on fashion apparel spotting which address the task as a specialization of the semantic segmentation to the fashion domain, we address the problem as an object detection task where the detection results are given in the form of bounding boxes. Detection-based spotters are more suitable as (a) bounding boxes suffice to construct queries for the subsequent visual search, (b) it is generally faster and have lower memory footprint than semantic segmentation, (c) large scale pixel-accurate training data is extremely hard to obtain, while it is much easier to get training data as bounding boxes, and (d) detection is done at instance-level while semantic segmentation does not differentiate multiple instances belonging to the same class. To the best of our knowledge, our work is the first detection-based (as opposed to segmentation-based) fashion item spotting method. Although any existing object detection methods can be possibly applied, the fashion apparel detection task poses its own challenges such as (a) deformation of clothing is large, (b) some fashion items classes are extremely similar to each other in appearance (e.g., skirt and bottom of short dress), (c) the definition of fashion item classes can be ambiguous (e.g., pants and tights), and (d) some fashion items are very small (e.g., belt, jewelry) . In this work, we address some of these challenges by incorporating state-of-the-art object detectors with various domain specific priors such as pose, object shape and size. The state-of-the-art object detector we employ in this work is R-CNN~ _cite_, which combines object proposals with a Convolutional Neural Network~ _cite_ . The R-CNN starts by generating a set of object proposals in the form of bounding boxes. Then image patches are extracted from the generated bounding boxes and resized to a fixed size. The Convolutional Neural Network pretrained on a large image database for the image classification task is used to extract features from each image patch. SVM classifiers are then applied to each image patch to determine if the patch belongs to a particular class. The R-CNN is suitable for our task as it can detect objects with various aspect ratios and scales without running a scanning-window search, reducing the computational complexity as well as false positives. It is evident that there are rich priors that can be exploited in the fashion domain. For instance, handbag is more likely to appear around the wrist or hand of the person holding them, while shoes typically occur near feet. The size of items are typically proportional to the size of a person. Belts are generally elongated. One of our contributions is to integrate these domain-specific priors with the object proposal based detection method. These priors are learned automatically from the training data. We evaluate the detection performance of our algorithm on the previously introduced Fashionista dataset~ _cite_ using a newly created set of bounding box annotations. We convert the segmentation results of state-of-the-art fashion item spotter into bounding box results and compare with the results of the proposed method. The experiments demonstrate that our detection-based approach outperforms the state-of-the art segmentation-based approaches in mean Average Precision criteria. The rest of the paper is organized as follows. Section~ _ref_ summarizes related work in fashion item localization. Our proposed method is detailed in Section~ _ref_ where we start with object proposal, followed by classification of these proposals using a combination of generative and discriminative approaches. Section~ _ref_ validates our approach on the popular Fashionista Dataset~ _cite_ by providing both qualitative and quantitative evaluations. Finally, Section~ _ref_ contains closing remarks.