Video summarization aims to select key frames/shots among videos to summarize the main storyline and has been widely investigated for facilitating video understanding~ _cite_ . As shown in Figure~ _ref_, this task can be classified into two types: a) generic video summarization, which only takes the visual features of the video contents as the input and b) query-conditioned video summarization which conditions summarization on user queries. The generic video summarization task has been addressed at three different levels: shot-level~ _cite_, frame-level~ _cite_, and object-level~ _cite_ video summarization by selecting key shots/frames/objects in the videos. However, one main issue with generic video summarization is the fact that it does not take user preferences into account, since different users may have different preferences towards the video content, and a single evaluation metric is not robust enough for all video summaries~ _cite_ . Recently, another research direction, query-conditioned video summarization~ _cite_, has been explored, which takes advantage of different user queries in form of texts to learn more user-oriented summaries. It generates user-oriented summaries that have effective correlations between summaries and query, and capture the overall essence of the video. Several approaches to query-conditioned video summarization have been proposed. Sharghi et al.~ _cite_ first extend a sequential DPP (seqDPP) ~ _cite_ to extract key shots. Afterwards, they develop a more comprehensive dataset for this task, and propose a memory network~ _cite_ parameterized seqDPP model. However, there is still room to learn a better summarizer due to the limitation of the memory to jointly encode video and query. To address the above issue we develop a query-conditioned three-player generative adversarial network architecture. We encode the query and the video sequence to learn a joint representation combining visual and text information, and take this query-conditioned representation as the input to the generative adversarial network. A three-player structure is applied during joint training, in order to achieve superior regularization. The contribution in our work can be summarized as follows: first, we propose a query-conditioned three-player adversarial network, which jointly encodes query and visual information and learns in an adversarial manner. Second, we introduce a three-player structure for the adversarial training. The discriminator regularizes the model via the three-player loss, which facilitates the generator to generate more related and meaningful video summaries. Two supervised losses are applied to ensure a more compact summary. One loss regularizes the length and the other aligns prediction and ground truth. Experimental results on a public dataset~ _cite_ demonstrate the superiority of our proposed approach against the state-of-the-art method.