In the United Kingdom, the care quality commission recently reported that--over the preceding N months--a total of N, N chest X-rays (CXRs) were not formally reviewed by a radiologist or clinician at Queen Alexandra Hospital alone. Furthermore, three patients with lung cancer suffered significant harm because their CXRs had not been properly assessed _cite_ . The Queen Alexandra Hospital is probably not the only hospital having problems with providing expert readings for every CXR. populations and expected to drive an increase in demand for CXR readings. In computer vision, deep learning has already shown its power for image classification with superhuman accuracy _cite_ . In addition, the medical image processing field is vividly exploring deep learning. However, one major problem in the medical domain is the availability of large datasets with reliable ground-truth annotation. Two larger X-ray datasets have recently become available: the CXR dataset from Open-i _cite_ and from the National Institutes of Health (NIH) Clinical Center _cite_ . Figure~ _ref_ illustrates four selected examples from ChestX-rayN. Due to its size, the ChestX-rayN consisting of N, N frontal CXR images from N, N unique patients attracted considerable attention in the deep learning community. Triggered by the work of Wang et al. _cite_ using convolution neural networks (CNNs) from the computer vision domain, several research groups have begun to address the application of CNNs for CXR classification. In the work of Yao et al. _cite_, they presented a combination of a CNN and a recurrent neural network to exploit label dependencies. As a CNN backbone, they used a DenseNet _cite_ model which was adapted and trained entirely on X-ray data. Li et al. _cite_ presented a framework for pathology classification and localization using CNNs. More recently, Rajpurkar et al. _cite_ proposed transfer-learning with fine tuning, using a DenseNet-N _cite_ the AUC results on ChestX-rayN for multi-label classification even higher. comparison of approaches remains difficult. Most reported results were obtained with differing experimental setups. This includes (among others) the employed network architecture, loss function and data augmentation. In addition, differing dataset splits were used and only Li et al. _cite_ reported N-fold cross-validated results. In contrast to these results, our experiments (Sec.~ _ref_) demonstrate that performance of a network depends significantly on the selected split. o provide better insights into the effects of distinct design decisions for deep learning, we perform a systematic evaluation using a N-fold re-sampling scheme. We empirically analyze three major topics: Prior work on ChestX-rayN has been limited to the analysis of image data. In clinical practice however, radiologists employ a broad range of additional features during the diagnosis. To leverage the complete information of the dataset (i.e. age, gender, and view position), we propose in Section~ _ref_ a novel architecture integrating this information in addition to the learned image representation.