task of human pose estimation is to determine the precise pixel locations of body keypoints from a single input image _cite_ . Closely-related tasks include ND human pose estimation _cite_ and human pose estimation in videos _cite_ . Human pose estimation is very important for many high-level computer vision tasks, including action and activity recognition _cite_, semantic content retrieval _cite_, human-computer interaction, motion capture _cite_, and animation. Estimating human poses from still images is a challenging task. An effective human pose estimation system must be able to handle large pose variations, changes in clothing and lighting conditions, severe body deformations, heavy body occlusions _cite_ . A key question for addressing these problems is how to extract strong low and mid-level appearance features capturing discriminative as well as relevant contextual information and how to model complex part relationships allowing for effective yet efficient pose inference. Traditional methods for pose estimation are mostly based on Pictorial Structure (PS) models _cite_, which models the spatial relations of rigid body parts using a tree model. A major drawback of such models is the need to hand-design the structure of the model in order to capture important problem-specific dependencies amongst the different output variables and at the same time allow for tractable inference. With Convolutional Neural Networks (ConvNets) and many assistive methods such as batch normalization _cite_, resnet _cite_, and inception design _cite_, human pose estimation has recently achieved significant progress. Even though deep neural networks are capable of fitting large training data through extensive training, the network often needs to be constructed deeper and wider to gain enough representation power _cite_ . As the network becomes more complex, the learning and training processing become more sophisticated and challenging _cite_, especially for those applications with complicated loss functions. Human pose estimation using deep neural networks requires us to map the input images with large variations into multiple body keypoints which must satisfy a set of geometric constraints and interdependence imposed by the human body model. This is a very challenging nonlinear manifold learning process in a very high dimensional feature space. We believe that the deep neural network, which is inherently an algebraic computation system, is not the most efficient way to capture highly sophisticated human knowledge, for example those highly coupled geometric characteristics and interdependence between keypoints in human poses. In this work, we propose to explore how external knowledge can be effectively represented and injected into the deep neural networks to guide its training process using learned projections for more accurate and robust human pose estimation. Specifically, as illustrated in Fig. _ref_, we use inception-resnet module and the stacked hourglass structure to construct a fractal network to regress human pose images into heatmaps with no explicit graphical modeling. We encode external knowledge with visual features which characterize the constraints of human body models and evaluate the fitness of intermediate network output. We then inject these external features into the neural network using a projection matrix learned using an auxiliary cost function. The guidance from the external knowledge is only used during the training process, and is turned off during network inference for human pose estimation. The benefit of external knowledge is to guide the training of the neural network. Its effect is implicitly imposed on the tuning of the parameters, instead of explicit feature representation of the network. The injected features for pairs of limbs impose a strong prior during the training, preventing human part keypoint from connecting to noises, e.g., keypoint from other people in the background that is not cropped out for the target person. The major contributions of this work are summarized as follows: (N) We develop a new framework to represent and project human knowledge to guide the training of deep neural networks for human pose estimation. This external knowledge project framework is generic and can be extended to other learning and training applications and deep neural network design. (N) We propose an efficient network structure, called {\it fractal networks}, for human pose estimation to capture the multi-scale interdependence between body joints in the pose model. This fractal network uses an inception-resnet module as the building block. The rest of the paper is organized as follows. In section _ref_, we provide a brief review of recent works on human pose estimation. Section _ref_ introduces the concept of knowledge guided learning, the structure of fractal network, and the design of inception-resnet module. Section _ref_ presents our experimental results. Section _ref_ concludes our paper.