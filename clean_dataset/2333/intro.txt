Images with rain streaks are often captured by outdoor surveillance equipments, which may significantly degrade the performance of some existing computer vision systems and may also result in a pool visual experience for some multimedia applications. Automatic rain streaks removal has thus become a crucial research task in the field of computer vision and multimedia, and has been successfully applied in the fields of driverless technology~ _cite_ and content based image editing~ _cite_ . The research on visual de-raining can be traced back to the last decade. Most of the early research focused on the removal of rain streaks in video sequences captured with static cameras~ _cite_ . They mostly attempted to solve the problem by exploiting the temporal correlation in the luminance domain between successive frames~ _cite_ . Due to the lack of temporal information, de-raining on single image is more ill-posed, however, it has received widespread research attention due to its greater practicality and challenge~ _cite_ . Traditional methods on single image de-raining explore certain prior information on physical characteristics of rain streaks and model it as a signal separation problem~ _cite_, or directly regard it as an image filtering problem and solve by resorting to nonlocal mean smoothing~ _cite_ . However, since these models are based on handcrafted low-level feature and fixed a priori rain streaks assumptions, they can only cope with rain drops of specific shapes, scales and density, and can easily lead to the destruction of image details which are similar to rain streaks. In recent years, due to the powerful feature representation and end-to-end data inference capabilities, deep convolutional neural networks have been widely applied to single image de-raining and have achieved significant performance improvement. These methods generally model the problem as a pixel-wise image regression process which directly learns to map an input rainy image to its clean version or a negative residual map in an end-to-end mode through a series of convolution, pooling, and non-linear operations, etc. Although considerable progress has been made in comparison with traditional methods, existing deep models still suffer from several limitations. Firstly, most of the deep CNN based models emulate the experience of low-level image processing such as image denoising, super-resolution and filtering, design shallow neural network structure, and maintain a constant feature map resolution during network propagation. As the size of the network receptive field is limited, the pixel value inference of each spatial location only relies on small local surrounding regions, it is usually arduous to remove longer rain streaks~ (e.g. third row of Fig.~ _ref_) . Moreover, due to the ignorance of long-distance spatial context modeling, these models often have difficulty in accurately filling raindrop-removed image content while detecting heavy rain streaks, resulting in an often overly blurred result, especially on texture-rich edges~ (e.g. first row in Fig.~ _ref_) . Although various deep CNN based solutions have been proposed, existing efforts either focus on the entrance of the networks by decomposing the input image into high and low frequency information~ _cite_ or design cascaded learning schemes to decompose the task of rain removal into multi-stages~ _cite_ . A contextualized dilated network is proposed in~ _cite_ to aggregate context information from three scales of receptive filed for more effective rain streak feature learning. All of these methods use convolutional neural network as an encapsulated end-to-end mapping module without deepening into the rationality and superiority of neural network design towards more effective rain streaks removal. Inspired by the adaptive nonlocal means filter~ _cite_ for efficient single-image rain streaks removal, we proposed to incorporate non-local operation~ _cite_ to the design of our end-to-end de-raining network framework. The non-local operation computes the feature response at a spatial position as a weighted sum of the features at a specific range of positions in the considered feature maps~ _cite_ . Specifically, we propose a non-locally enhanced encoder-decoder network framework for single-image de-raining. The core architecture of our trainable de-raining engine is a concatenation of an encoder network and a corresponding decoder network. It is designed to be a symmetrical structure and both the encoder and the decoder network are composed of three cascaded non-locally enhanced dense blocks (abbr.~NEDB) . Each NEDB is designed as a residual learning module which contains a non-local feature map weighting followed by four densely connected convolution layers for hierarchical feature encoding and another convolution layer for residual inference. Moreover, we introduce the pooling striding mechanism in our encoder network to learn increasingly abstract feature representation, which results in a decrease in resolution with the enlargement of receptive filed. We further incorporate pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling in our decoder, which helps to preserve the structure and details in the resulted image. In summary, this paper has the following contributions: