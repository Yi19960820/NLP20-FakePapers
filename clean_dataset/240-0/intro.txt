Image classification based on visual content is a very challenging task, mainly because there is usually large amount of intra-class variability, arising from illumination and viewpoint variations, occlusion and corruption~ _cite_ . Numerous efforts have been made to counter the intra-class variability by manually designing low-level features for classification tasks. Representative examples are Gabor features and LBP~ _cite_ for texture and face classification, and SIFT~ _cite_ and HOG~ _cite_ features for object recognition. Although the hand-crafted low-level features achieve great success for some controlled scenarios, designing effective features for new data and tasks usually requires new domain knowledge since most hand-crafted features cannot be simply adopted to new conditions. Learning features from data itself instead of manually designing features is considered a plausible way to overcome the limitation of low-level features~ _cite_, and successful examples of such methods are dictionary learning and deep learning. The idea of deep learning is to discover multiple levels of representation, with the hope that higher level features represent more abstract semantics of the data. Such abstract representations learned from a deep network are expected to provide more invariance to intra-class variability, if we train the deep model using a large amount of training samples~ _cite_ . One key ingredient for this success is the use of convolutional architectures. A convolutional neural network (CNN) architecture consists of multiple trainable stages stacked on top of each other, followed by a supervised classifier. In practice, many computer vision applications are faced with the problem of small training sets, and transfer learning can be a powerful tool to enable training the target network in such cases. The usual approach is to replace and retrain the classifier on top of the CNN on the target dataset, and also fine-tune the weights of the pretrained network by continuing the backpropagation. However, the effectiveness of feature transfer is declined when the base and target tasks become less similar~ _cite_ . Besides, when the target dataset is small, complex models like CNNs, tend to overfit the data easily~ _cite_ . It could be even more complicated in classification tasks such as face recognition, which the intra-class variability is often greater than the inter-class variability due to pose, expression and illumination changes and occlusion. In contrast, the recent variations of dictionary learning (DL) methods have demonstrated great success in image classification tasks on both small and large intra-class variation datasets. The last few years have witnessed fast development on DL methods under sparse representation theory, accordding to which, signals can be well-approximated by linear combination of a few columns of some appropriate basis or dictionary~ _cite_ . The dictionary, which should faithfully and discriminatively represent the encoded signal, plays an important role in the success of sparse representation and it has been shown that learned dictionaries significantly outperform pre-defined ones such as Wavelets~ _cite_ . Although conventional DL methods perform well for different classification and recognition tasks~ _cite_, their performance dramatically deteriorates when the training data are contaminated heavily because of occlusion, lighting/viewpoint variations or corruption. In the recent years, low-rank (LR) matrix recovery, which efficiently removes noise from corrupted observations, has been successfully applied to a variety of computer vision applications, such as subspace clustering~ _cite_, background subtraction~ _cite_ and image classification~ _cite_ . Accordingly, some DL methods have been proposed by integrating rank minimization into sparse representation framework and achieved impressive results, especially when large noise exists~ _cite_, ~ _cite_ . Moreover, in many areas of computer vision, data are characterized by high dimensional feature vectors; however, dealing with high-dimensional data is challenging for many tasks such as DL. High-dimensional data are not only inefficient and computationally intensive, but the sheer number of dimensions often masks the discriminative signal embedded in the data~ _cite_ . As a solution, a dimensionality reduction (DR) technique is usually performed first on the training samples, and the dimensionality reduced data are then used as the input of DL. However, recent studies reveal that the pre-learned projection matrices neither fully promote the underlying sparse structure of data~ _cite_, nor preserve the best features for DL~ _cite_ . Intuitively, the DR and DL processes should be jointly conducted for a more effective classification. Only a few works have discussed the idea of jointly learning the projection of training samples and dictionary, and all reported more competitive performance than conventional DL methods. Despite the successes, most of the existing joint DR-DL methods cannot handle noisy (occluded/corrupted) and large intra-class observations. On the other hand, low-rank DL methods can cope well with noisy data, but cannot select the best features on top of which dictionaries can be better learned, due to separated DR process. In this paper, we explore the DL, LR and DR spaces simultaneously and propose an object classification method for noisy and large intra-class variation datasets, which have small-sized training set and may have high-dimensional feature vectors. To the best of our knowledge, this is the first proposed method that can handle all these issues simultaneously. To this end, we propose a novel framework called joint projection and low-rank dictionary learning using dual graph constraints (JP-LRDL) . The basic idea of JP-LRDL is illustrated in Figure~ _ref_ . The algorithm learns a discriminative structured dictionary in the reduced space, whose atoms have correspondence to the class labels and a graph constraint is imposed on the coding vectors to further enhance class discrimination. The coefficient graph makes the coding coefficients within the same class to be similar and the coefficients among different classes to be dissimilar. JP-LRDL specially introduces low-rank and incoherence promoting constraints on sub-dictionaries to make them more compact and robust to variations and encourage them to be as independent as possible, respectively. Simultaneously, we consider optimizing the input feature space by jointly learning a feature projection matrix. In particular, another graph is built on training data to explore intrinsic geometric structure of data. The projection graph enables us to preserve the desirable relationship among training samples and penalize the unfavorable relationships simultaneously. This joint framework empowers our algorithm with several important advantages: (N) Ability to handle large intra-class variation observations, (N) Promoting the discriminative ability of the learned projection and dictionary, that enables us to deal with small-sized datasets, (N) Learning in the reduced dimensions with lower computational complexity, and (N) Maintaining both global and local structure of data. Extensive experimental results validate the effectiveness of our method and its applicability to image classification task, especially for noisy observations. The remainder of the paper is organized as follows. Section~ _ref_ briefly reviews some related work. Section~ _ref_ presents the proposed JP-LRDL method. The optimization algorithms are described in Section~ _ref_ . We discuss the time complexity and convergence analysis in Section~ _ref_ . The classification scheme is then explained in Section~ _ref_ . Section~ _ref_ shows experimental results and we draw conclusions in Section~ _ref_ .