The human visual system can easily identify perceptually salient edges in an image. Endowing machine vision systems with similar capabilities is of interest as edges are useful for diverse tasks such as optical flow~ _cite_, object detection~ _cite_, and object proposals~ _cite_ . However, edge detection has proven challenging. Early approaches~ _cite_ relied on low-level cues such as brightness and color gradients. Reasoning about texture~ _cite_ markedly improved results, nevertheless, accuracy still substantially lagged human performance. The introduction of the BSDS dataset~ _cite_, composed of human annotated region boundaries, laid the foundations for a fundamental shift in edge detection. Rather than rely on complex hand-designed features, Doll \'ar et al.~ _cite_ proposed a data-driven, supervised approach for learning to detect edges. Modern edge detectors have built on this idea and substantially pushed the state-of-the-art forward using more sophisticated learning paradigms _cite_ . However, existing data-driven methods require strong supervision for training. Specifically, in datasets such as BSDS~ _cite_, human annotators use their knowledge of scene structure and object presence to mark semantically meaningful edges. Moreover, recent edge detectors use Image \-Net pre-training~ _cite_ . In this paper, we explore whether this is necessary: We propose to train edge detectors using motion in place of human supervision. Motion edges are a subset of image edges, see Figure~ _ref_ . Therefore motion edges can be used to harvest positive training samples. On the other hand, locations away from motion edges may also contain image edges. Fortunately, as edges are sparse, simply sampling such locations at random can provide good negative training data with few false negatives. Thus, assuming accurate motion estimates, we can potentially harvest unlimited training data for edge detection. While it would be tempting to assume access to accurate motion estimates, this is arguably an unreasonably strong requirement. Indeed, optical flow and edge detection are tightly coupled. Recently, Revaud et al.~proposed EpicFlow~ _cite_: given an accurate edge map~ _cite_ and semi-dense matches between frames~ _cite_, EpicFlow generates a dense edge-respecting interpolation of the matches. The result is a state-of-the-art optical flow estimate. This motivates our approach. We begin with only semi-dense matches between frames~ _cite_ and a rudimentary knowledge of edges (simple image gradients) . We then repeatedly alternate between computing flow based on the matches and most recent edge maps and retraining an edge detector based on signal obtained from the flow fields. Specifically, at each iteration, we first estimate dense flow fields by interpolating the matching results using the edge maps obtained from the previous iteration. Given a large corpus of videos, we next harvest highly confident motion edges as positives and randomly sample negatives, and use this data to train an improved edge detector. The process is iterated leading to increasingly accurate flow and edges. An overview of our method is shown in Figure~ _ref_ . We perform experiments with the Structured Edge (SE) ~ _cite_ and Holistic Edge (HE) ~ _cite_ detectors. SE is based on structured forests, HE on deep networks; SE is faster, HE more accurate. Both detectors achieve state-of-the-art results. The main result of our paper is that both methods, trained using our unsupervised scheme, approach the level of performance of fully supervised training. Finally, we demonstrate that our approach can serve as a novel unsupervised pre-training scheme for deep networks~ _cite_ . Specifically, we show that when fine-tuning a network for object detection~ _cite_, starting with the weights learned for edge detection improves performance over starting with a network with randomly initialized weights. While the gains are modest, we believe this is a promising direction for future exploration.