In the image space, the information observed by the dynamical behavior of the object of interest or by the motion of the camera itself is a decisive interpretation for representing natural phenomena. Dense motion, in particular optical flow estimation between a consecutive image pair is the most low-level characterization of such information, which is supposed to estimate a dense field corresponding to the displacement of each pixel. It has become one of the most active fields of computer vision because such characterizations can be extremely embedded into a large number of other higher-level computer vision fields and application domains. Indeed, one can be interested in tracking~ _cite_, ND reconstruction~ _cite_, segmentation, as well as the general virtual reality, augmented reality and post-production~ _cite_ . A typical pipeline of optical flow estimation has been lied on solving a brightness energy with the assistance of patch detection, matching, constrained optimization and interpolation. For many state-of-the-art approaches--even the precision has reached a reasonable level--the related applications are still limited by the difficult photometric effects and low performance in runtime. In the recent years, the deep (CNNs) grows rapidly, which makes a step forward to provide hidden features and end-to-end knowledge representation for many precentral issues e.g. motion and texture style etc . Such knowledge representation is able to improve the robustness and yields a rapid fashion in the typical optical flow pipeline. Camera-shake blur is a common photometric effect in the real-world footage, which is often caused by the fast camera motion under a low light condition. Such effect may lead to an invariant blur information for each of the pixel, and may bring extra difficulties into typical optical flow estimation because the basic brightness constancy~ _cite_ is violated. However, the blur from a daily video footage (N FPS) can be directionally characterized ~ _cite_ . This observation enables an extra prior to enhance the camera-shake deblurring~ _cite_ and further recover precise optical flow from a blurry images. Such directional prior needs a strict pre-knowledge on the motion direction of the camera which can be obtained by an external sensor~ _cite_ . In this paper, we study the issue of recovering accuracy optical flow from frames of a real-world video footage given a camera-shake blur. The main idea is to learn directional filters, encoded the angle and distance similarity between blur and camera motion. Such filters are further applied to enhance the optical flow estimation. {Our proposed method only relies on the input images, and does not need any other information e.g. ground truth camera motion and blur prior.} In overview, we propose a novel hybrid approach: (N) we conduct a CNN architecture using a learnable directional filtering layer. Our network is able to extract the blur \&latent features from a blurry image, and further recover the blur kernel within an iterative deconvolutional fashion (Sec.~ _ref_) ; (N) we integrate our network into a variational optical flow energy, further optimized within a hybrid coarse-to-fine framework (Sec.~ _ref_) . In the evaluation (Sec.~ _ref_), we quantitatively compare our method to four baselines on the synthetic (GT) sequences. Those baselines include two blur-oriented optical flow approaches and two other publicly available state-of-the-art methods. We also give quality comparison given real-world blurry footages.