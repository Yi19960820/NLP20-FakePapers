visual categorization aims to recognize similar subcategories in the same basic-level category. It is one of the most challenging and significant open problems in multimedia and computer vision areas, which has achieved great progress as well as attracted extensive attention of academia and industry in recent years. The progress incarnates in three aspects: (N) More fine-grained domains have been covered, such as animal species _cite_, plant breeds _cite_, car types _cite_ and aircraft models _cite_ . (N) Methodologies of fine-grained visual categorization have achieved promising performance in recent years _cite_, due to the application of deep neural networks (DNNs) . (N) Some information technology companies, such as Microsoft and Baidu, begin to turn fine-grained visual categorization technologies into their applications . Fine-grained visual categorization lies in the continuum between basic-level visual categorization (e.g. object recognition) and identification of individuals (e.g. face recognition) . Its main challenges can be summarized as the following two aspects: (N) Variances among similar subcategories are subtle and local, because they belong to the same genus. (N) Variances in the same subcategory are large and diverse, due to different poses and views, as well as for animals or plants also because of different living environments and growth periods. For example, as shown in Fig. _ref_, the images of ``Artic Tern'' and ``Caspian Tern'' look similar in global appearance, but the images of ``Salty Backed Gull'' look different in the pose, view and feather color. So it is hard for a person without professional knowledge to recognize them. These subcategories can be distinguished by the subtle and local variances of the discriminative parts. It is crucial for fine-grained visual categorization to localize the object and its discriminative parts. Researchers generally adopt a two-stage categorization pipeline: the first stage is to localize the object or its discriminative parts, and the second is to extract their features to categorize the subcategory. For example, Zhang et al. _cite_ utilize R-CNN _cite_ with geometric constraints to detect object and its parts first, and then extract the features of the object and its parts, finally train one-versus-all linear SVMs for categorization. However, not all the parts are beneficial and indispensable for fine-grained categorization. The conclusive distinctions among subcategories generally locate at a few specific parts, such as the red beak or the black tail. So the categorization performance depends on the number of part detectors and whether the detected parts are discriminative or not. However, mainstream methods generally set the detector number due to their prior knowledge or the experimental validation, which is highly empirical and limited. For example, when the number of part detectors applied in the experiments increase from eight to fifteen, the performance of fine-grained categorization declines, as reported in _cite_ . Six part detectors are applied by Zhang et al. _cite_ to achieve the best categorization accuracy. He and Peng _cite_ applies two discriminative parts for fine-grained categorization. They are limited in flexibility, and hard to generalize. Therefore, it is significant to automatically learn how many and which parts really make sense to fine-grained visual categorization. When human beings see two images of two different subcategories, human visual attention mechanism plays an important role in focusing on the pivotal distinctions between them. Inspired by this, researchers begin to apply human visual attention mechanism in their works, aiming to find the most discriminative characteristics for categorization. Xiao et al. _cite_ propose a two-level attention model (TL Atten), in which object-level attention selects relevant image proposals to a certain object, and part-level attention selects relevant image proposals to the discriminative parts of the object. Fu et al. _cite_ propose a recurrent attention convolutional neural network (RA-CNN) to recursively learn discriminative region attention and region-based feature representation. These works simulate human visual attention mechanism to find discriminative parts for categorization from visual information. Attention is the behavioral and cognitive process of selectively concentrating on a discrete aspect of information, whether deemed subjective or objective, while ignoring other perceivable information _cite_ . As is known to all, when human beings give the interpretation of the visual data by textual descriptions, they tend to indicate how many and which parts are distinguishing from other subcategories. These words describing the part attributes are regarded as textual attention, which generally appears frequently in the textual descriptions. This is an involuntary transfer from human visual attention to textual attention. In this transfer process, common characteristics of object and background areas are ignored naturally. Textual attention can be obtained by discovering the frequent item sets in the textual descriptions, which point out the discriminative parts of the subcategory. From Fig. _ref_, we can see that the frequent item sets contain ``red break'', which is a discriminative characteristic that distinguishes ``Heermann Gull'' from ``Red Legged Kittiwake''. \par Therefore, how to exactly relate textual attention to visual attention and mine the discriminative parts are pivotal to fine-grained visual categorization. This paper proposes a fine-grained visual-textual representation learning (VTRL) approach, and its main contributions are: Our previous conference paper CVL _cite_ proposes a two-stream model combining vision and language for learning the fine-grained representation. Vision stream learns deep representations from visual information and language stream utilizes textual information to encode salient visual aspects for distinguishing subcategories. The main differences between the proposed VTRL approach and CVL can be summarized as the following three aspects: (N) Our VTRL approach employs textual pattern mining to localize textual attention for exploiting the human visual attention transferred into textual information, which indicates how many and which parts are significant and indispensable for categorization. While CVL directly utilizes the whole textual information, does not mine fine-grained textual attention information. (N) Our VTRL approach employs visual pattern mining based on discovered textual patterns to localize discriminative parts, so that discriminative parts and objects are both exploited to learn multi-grained and multi-level representations for boosting fine-grained categorization. While CVL only exploits the objects, which ignores the complementary and semantic fine-grained clues provided by the discriminative parts. (N) Our VTRL approach employs fine-grained visual-textual pattern mining to discover the discriminative and significant visual-textual pairwise information via jointly modeling vision and text with GANs, which mines the correlation between textual and visual attention. While CVL only combines vision and text, ignoring to exploit their visual and textual attention, as well as their correlation. Compared with state-of-the-art methods on two widely-used fine-grained visual categorization datasets, our VTRL approach achieves the best categorization accuracy. The remainder of this paper is organized as follows: We briefly review the related works in Section _ref_ . In Section _ref_ our proposed VTRL approach is presented in detail. Then Section _ref_ reports the experimental results and analyses. Finally, Section _ref_ concludes this paper.