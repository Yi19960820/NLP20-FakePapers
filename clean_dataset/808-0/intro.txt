We address the problem of generating a high-resolution (HR) image given a low-resolution (LR) image, commonly referred as single image super-resolution (SISR) _cite_, _cite_, _cite_ . SISR is widely used in computer vision applications ranging from security and surveillance imaging to medical imaging where more image details are required on demand. Many SISR methods have been studied in the computer vision community. Early methods include interpolation such as bicubic interpolation and Lanczos resampling _cite_ more powerful methods utilizing statistical image priors _cite_ or internal patch recurrence _cite_ . Currently, learning methods are widely used to model a mapping from LR to HR patches. Neighbor embedding _cite_ methods interpolate the patch subspace. Sparse coding _cite_ methods use a learned compact dictionary based on sparse signal representation. Lately, random forest _cite_ and convolutional neural network (CNN) _cite_ have also been used with large improvements in accuracy. Among them, Dong et al. _cite_ has demonstrated that a CNN can be used to learn a mapping from LR to HR in an end-to-end manner. Their method, termed SRCNN, does not require any engineered features that are typically necessary in other methods _cite_ and shows the state-of-the-art performance. While SRCNN successfully introduced a deep learning technique into the super-resolution (SR) problem, we find its limitations in three aspects: first, it relies on the context of small image regions; second, training converges too slowly; third, the network only works for a single scale. In this work, we propose a new method to practically resolve the issues. Context We utilize contextual information spread over very large image regions. For a large scale factor, it is often the case that information contained in a small patch is not sufficient for detail recovery (ill-posed) . Our very deep network using large receptive field takes a large image context into account. Convergence We suggest a way to speed-up the training: residual-learning CNN and extremely high learning rates. As LR image and HR image share the same information to a large extent, explicitly modelling the residual image, which is the difference between HR and LR images, is advantageous. We propose a network structure for efficient learning when input and output are highly correlated. Moreover, our initial learning rate is _inline_eq_ times higher than that of SRCNN _cite_ . This is enabled by residual-learning and gradient clipping. Scale Factor We propose a single-model SR approach. Scales are typically user-specified and can be arbitrary including fractions. For example, one might need smooth zoom-in in an image viewer or resizing to a specific dimension. Training and storing many scale-dependent models in preparation for all possible scenarios is impractical. We find a single convolutional network is sufficient for multi-scale-factor super-resolution. Contribution In summary, in this work, we propose a highly accurate SR method based on a very deep convolutional network. Very deep networks converge too slowly if small learning rates are used. Boosting convergence rate with high learning rates lead to exploding gradients and we resolve the issue with residual-learning and gradient clipping. In addition, we extend our work to cope with multi-scale SR problem in a single network. Our method is relatively accurate and fast in comparison to state-of-the-art methods as illustrated in Figure _ref_ .