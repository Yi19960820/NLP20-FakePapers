Gesture recognition can be seen as a way for computers to understand human body language. Thus, improving state-of-the-art algorithms for gesture recognition facilitates human-computer communication beyond primitive text user interfaces or GUIs (graphical user interfaces) . With rapidly improving comprehension of human gestures we can start building NUIs (natural user interfaces) for controlling computers or robots. With the availability of such technologies, conventional input devices, such as a keyboard or mouse, could be replaced in situations in which they are inconvenient in future. Other applications of gesture recognition include sign language recognition, socially assistive robotics and game technology. In this paper, we focus on the one-shot learning gesture recognition problem, in particular the . The dataset was released jointly with a competition, where the goal was to develop a system capable of learning to recognize new categories of gestures from a single training example of each gesture. The large dataset of hand and arm gestures was pre-recorded using an infrared sensor, Kinect _inline_eq_, providing both RGB and depth images . The purpose of this work is to describe methods developed during the ChaLearn Gesture Challenge by the Turtle Tamers team (authors of this paper) . We finished in N _inline_eq_ place in round _inline_eq_ and were invited to present our solution at the International Conference on Pattern Recognition N, Tsukuba, Japan. The code has been made publicly available in the MLOSS repository. Since the goal of the challenge was to provide solid baseline methods for this dataset, our methods were specifically tailored for this particular competition and dataset. Hence, they lack a certain generality, and we discuss and suggest changes for more general settings later. The rest of this work is organised as follows. Related work is summarized in Section~ _ref_ . In Section~ _ref_ we describe the dataset and the problem in detail. In Section~ _ref_ we focus on the preprocessing needed to overcome some of the problems in the dataset. Section~ _ref_ covers feature representation, using Histogram of Oriented Gradients and Histogram of Optical Flow, as well as a method used to compare similarities between these representations. In Section~ _ref_ we describe the actual algorithms, and in Section~ _ref_ we briefly describe algorithms of other participants and compare their results with ours, as well as with other published works. In Section~ _ref_ we summarize our paper and suggest an area for future work.