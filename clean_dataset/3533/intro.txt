Image segmentation is a challenging task in computer vision that can identify the visual elements in an image. These elements can be used as the building blocks for any image understanding method. Traditionally, these image segments are optimized to be semantic (e.g. be an object, part of an object, or part of a scene) and visually coherent; This means that nearby pixels in each segment must have similar intensity _cite_ . Semantic image segmentation has been proposed in several articles _cite_ . All of these methods are limited to a narrow scope of semantics. They can only find the segments belong to of objects (e.g. N categories in PASCAL VOC dataset) . In this paper a method is proposed that can find semantic segments. Recently there has been a remarkable progress in computer vision through Deep Neural Networks. More specifically, with Convolutional Neural Networks (CNNs) end-to-end object recognition modules have been created _cite_ outperforming all of the previous recognition systems. Moreover, _cite_ showed that these features are so powerful that can be used for a variety of tasks in computer vision. Given an image as input we can apply a fully-convolutional neural network to obtain a feature vector per each receptive-field in the image _cite_ . Since these features carry semantical information about the input image, they can be used to find image segments that are semantically coherent. In this paper, we show how these segments can be extracted from such CNN features. CNN features are very high-dimensional (namely, N) . Traditional segmentation approaches that are mainly based on clustering techniques _cite_ are not feasible. Since we want each segments corresponds to a meaningful visual element, large number of cluster centers are essential. That makes the segmentation process even more complex. To overcome such computational complexities, binary encoding of CNN features is proposed instead. A CNN feature is converted to a short binary code: each bit pattern represents a cluster center in the original CNN feature space. For example, a N-bit binary code can generate _inline_eq_ clusters. Each bit corresponds to a visual attribute. Nearby pixels should have similar binary patterns unless they undergo a large semantical change. This is a perfect property to be used for semantic segmentation. Iterative-Quantization (ITQ) _cite_ is employed to learn these binary codes. An Interesting property of the ITQ is that it generates bits in a simple way and the transformation is linear. This is a perfect setting to be embedded in the CNN networks as a new layer. Once the binary map of the CNN features is available, a low-level superpixel extraction method is applied on the whole image and then the superpixels with the similar binary patterns (under Hamming distance) are merged together. Major contributions in this work can be summarized as; a semantic segmentation is proposed which can be used in a general setting, unlike the all previous methods that are limited to specific categories. a compact representation of high-dimensional CNN features is introduced in the form of binary codes, to preserve semantic information, thus it can be used for semantic segmentation. Hence, we present a binary encoding layer in our network, which can be updated using back-propagation. This new layer is able to be attached to any other deep-net for encoding purposes. The primarily version of this paper has been published in~ _cite_ .