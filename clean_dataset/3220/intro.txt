A human brain can verify kinship from photos by analyzing the disriminative patterns of facial parts. This feature is a strong evidence that how brain fascinatingly complex it is. Recently, an immense number of methods have been proposed to achieve kinship verification by computers, since learning-based deep models have shown impressive powers to extract these latent patterns automatically from faces~ _cite_ . In particular, these methods outperform the performance achieved by humans for various identification problem~ _cite_ . Ultimately, the outputs of the models can be used for the identification of missing people, child/parent search as well as tracking some statistics for recommendation services. However, looking the problem in reverse, more intuitively, guessing possible child faces by analyzing their parent photos, is not quite motivated as the original problem in literature (i.e., recognition and verification) . To the best of our knowledge, there is also a limited interest to tackle the problem~ _cite_, even if there are several promising methods to synthesize human faces from large-data collections based on generative deep models~ _cite_ . In general, the objective of this problem (i.e., synthesizing kinship face) is that for the given input of a parent photo (either mother or father), a method synthesizes the most probable faces of a child by exploiting latent facial features exhibited on the parents' faces. However, the robustness of the models, especially for deep models, strongly depends on the number of training samples and the diversity of the datasets. Moreover, currently available datasets for kinship verification are quite small and models should be regularized based on this limitation so as to achieve perceptually satisfying results. In this paper, we propose a fully convolutional network (FCN) which transforms a parent face in a latent space with the responses of encoder layers and iteratively decodes these responses to reconstruct a possible kinship face. For this purpose, we present three novel contributions to the standard FCN for kinship face synthesis: N) We use a pre-trained network for the encoder layers which is optimized for face recognition on a large-scale dataset. Eventually, this allows us to extract more robust hidden features even if limited numbers of faces are modeled for face synthesis. N) Although use of the encoder layers provides several advantages such as sparsity for person identification, decoder layers can easily overfit to the training data due to the large dimensionality of the hidden features. At the end, it hardens the problem to generalize an optimum solution for diverse face scenarios. Hence, we leverage adversarial loss with large-scale unsupervised data to mitigate the overfitting with its generalization capability. N) Lastly, we employ cycle-domain transformation~ _cite_ (i.e., transforming from parent-to-child as well as child-to-parent) which leads to more stable results. The paper is organized as follows. First, we review the literature on face synthesis and kinship verification, since these steps are two major basis of our problem. Later, the details of the proposed method are presented for kinship synthesis. Lastly, experimental results are reported and we explain the final remarks of the paper.