Advanced techniques about ND video _cite_, N panorama video _cite_, light field _cite_, etc., have received more and more attentions and have widely researched due to their practically applied values. However, the information carrier of these techniques mainly refers to image, thus Internet congestion may occur, because of explosive growth image data among social media and other new media. With this trend of rapidly increasing, the main source of Internet congestion will be caused by image/video transmission _cite_, so different kinds of images, especially natural image, should be extremely compressed to alleviate this problem. Image compression aims at reducing the amounts of data to benefit image storage and transmission. Still image compression has been developed from early image compression standards such as JPEG and JPEGN to Google's WebP and BPG, etc. In the earlier times, a lot of works _cite_ mainly put their emphasis on post-processing to reduce coding artifacts so as to improve coding efficiency, whose priority exists in that it doesn't need change any part of existing coding standard. Lately, several works _cite_ employ convolutional neural network (CNN) to remove image blurring and quantization artifacts caused by image compression. Among these works, a very special work _cite_ is an effective compression framework based on two collaborative convolutional neural networks, where one network is used to compactly represent image and the other one works as post-processing to reduce coding distortion. This method has good performances at the case of very low bit-rate coding, but it doesn't explore how to improve coding efficiency at high bit-rate. Thus, this method's practical application is very limited, because image coding at low bit-rate is required, only when the band-width is very narrow. Meanwhile, this method directly trains collaborative convolutional neural networks without considering quantization's effects on neural network ahead of standard codec during back-propagation, so it's a sub-optimal solution for image compression. Recently, image compression with deep neural networks (DNN) has achieved many great breakthroughs, such as _cite_, among which some methods have exceeded JPEGN and even can compete with BPG. These methods target at resolving the challenging problem: quantization function within objective compression loss is non-differentiable. The pioneering work _cite_ leverages recurrent neural networks to compress image in full-resolution, where the binarization layer with stochastic binarization is used to back-propagate gradients. In _cite_, the quantizer in general nonlinear transform coding framework is replaced by an additive independent identically distributed uniform noise, which can make image compression optimized by gradient descent method. In _cite_, identity smooth function's derivation is used as an approximation of rounding function's derivation in the compressive auto-encoders, but no modification is required during passing gradients from decoder to encoder. Most recently, soft assignment is formed by converting Euclidean distance between vector and each quantization center into probability model via soft-max function _cite_ . After that, soft quantization is defined by soft assignment, and then this smooth relaxation is used as the approximation of the quantized function, so that compression loss of auto-encoder networks in terms of quantization can be optimized by stochastic gradient descent method. Our intuitive idea is to learn projection from re-sampled vector to the quantized vector, so that we can jointly train our RSN network and IDN network together. However, we find it's difficult to learn this projection directly with DNN. Fortunately, the projection can be well intimated by neural network from the above re-sampled vectors to the decoded image. Therefore, we propose an image re-sampling compression method (IRSC) by learning virtual codec network (VCN) to supervise re-sampling network (RSN) to resolve the non-differentiable problem of quantization function within compression loss. For simplicity, we give a diagram of deep neural networks based compression framework (DNNC) for one dimension signal, as shown in Fig. _ref_ . Our IRSC method can not only be used for DNNC framework, but it also can be applied to standard-compliant image compression framework (SCIC) . Firstly, an input image is measured by RSN network to get re-sampled vectors. Secondly, these vectors are directly quantized in the re-sampling feature space for DNNC, or transformation coefficients of these vectors are quantized to further improve coding efficiency for SCIC after discrete cosine transform (DCT) . At the encoder, the quantized vectors or transformation coefficients are losslessly compressed by arithmetic coding. At the decoder, the decoded vectors are utilized to restore input image by image decoder network (IDN) . Both of SCIC and DNNC frameworks are built on auto-encoder architecture, whose encoder is the RSN network and whose decoder is the IDN network. The encoder is used to condense input's dimensionality inside the networks. Meanwhile, quantization reduces dimensionality in some dimensional space, no matter whether re-sampled vectors is processed by DCT transform. The decoder of auto-encoder architecture reproduces the input image from these quantized vectors. The difference between SCIC and DNNC mainly comes from whether classical transformation such as DCT transform is explicitly applied to reduce statistical correlation of re-sampled vectors. Obviously, the main difference between our SCIC and _cite_ is that our VCN network bridges the huge gaps of gradient back-propagation between RSN and IDN caused by quantization function's non-differentiability. Another difference lies in that our IRSC method is not restricted to image compression at very low bit-rate. Because our VCN network could well back-propagate gradient from decoder to encoder, our method could conduct full-resolution image re-sampling. The third important difference is that our IRSC method can be applied into DNNC framework. Although our IRSC as well as _cite_ can process non-differentiability of quantization function for image compression, our IRSC method's application is not restricted to the application of DNN-based image compression. The rest of this paper is arranged as follows. Firstly, we review traditional post-processing methods and neural network-based artifact removal techniques, as well as image compression methods with DNN in Section N. Then, we introduce the proposed method in Section N, which is followed by experimental results in the Section N. At last, we give a conclusion in the Section N.