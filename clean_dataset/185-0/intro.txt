Groups are emotional entities are a rich source of varied manifestations of affect. Automatic Group-level Emotion Analysis (GEA) in images is an important problem as it has a wide variety of applications. In e-learning applications, group-level affective computing can be used to adjust the presentation style of a computerized tutor when a learner is bored, interested, frustrated, or pleased. In terms of social monitoring, for example, a car can monitor the emotion of all occupants and engage in additional safety measures, such as alerting other vehicles if it detects the driver to be angry. With regard to management of images, dividing images into albums based on facial emtion is a good solution to searching, browsing and managing images in multi-media systems _cite_ . It also has pratical mearning in key-frame detection and event detection _cite_ . Deep learning based approaches, particularly those using CNNs, have been very successful at image-related tasks in recent years, due to their ability to extract good representations from data. Judging a person's emotion can sometimes be difficult even for humans, due to subtle differences in expressions between the more nuanced emotions (such as sadness and fear) . As a result, finely-tuned and optimized extracted features from images are of great importance in order for a classifier to make good predictions. This paper demonstrates the efficacy of the proposed recurrent random deep ensembles on Group level emotion recognition sub-challenge based on HAPPEI database. The task is to infer the happiness intensity of the group as a whole on a scale from N to N from a bottom-up prespective. First CNN ensembles are introduced to extract several efficiently representative features of each face. Then feature aggrengation is conducted on each face using a Long Short Term Memory (LSTM) . The proposed method will selectively memorize (or forget) the components of features which are important (or less important) . Then face-level estimation is conducted using the trained SVR on the compact feature representation of each face. Various group emotion models are explored, including mean encoding and weighted fusion framework based on top-down features, such as sizes of faces and the distances between them. Note that the proposed method caters to aggregating information from multiple sources including different number of faces in one image. Our best result exhibits a RMSE of N on the validation set of HAPPEI dataset, which compares favorably to the RMSE of N of the baseline. The rest of the paper is organized as follows. Section N describes related previous work. Section N describes in detail the proposed recurrent random deep ensembles for extracting facial features. Section N discusses the experiments and evaluates the results, and section N concludes the paper.