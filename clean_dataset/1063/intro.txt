With the development of the Internet and widespread use of mobile devices with digit cameras, there are massive images in the world and many of them contain texts. The text in natural image carries high level semantics and can provide valuable cues about the content of the image. Thus, if texts in these images can be detected and recognized by computers, they can play significant roles for various vision-based applications, such as spam detection, products search, recommendation, intelligent transportation, robot navigation and target geo-location. Consequently, scene text detection and recognition has become a hot research topic in computer vision and pattern recognition in recent years. Although traditional Optical Character Recognition (OCR) has been investigated for a few decades and great advances have been made for scanned document images _cite_, the detection and recognition of text in both natural scene and born-digital images, so called robust reading, remains an open problem _cite_ . Unlike the texts in scanned document images which are well-formatted and captured under a well-controlled environment, texts in scene images are largely variable in appearance and layout, drawn from various color, font and style, suffering from uneven illumination, occlusions, orientations, distortion, noise, low resolution and complex backgrounds (Fig. N) . Therefore, scene text recognition remains a big challenge. Many efforts have been devoted to the difficult problem of scene text recognition. The methods so far can be roughly categorized into three groups: explicit segmentation methods, implicit segmentation methods and holistic methods. (N) Explicit segmentation methods _cite_ usually involve two steps: character segmentation and word recognition. It attempts to segment the input text image at the character boundaries to generate a sequence of primitive segments with each segments being a character or part of a character, applies a character classifier to candidate characters and combine contextual information to get the recognition result. Although this approach has performed well in handwritten text recognition, the performance in scene text recognition is severely confined by the difficulty of character segmentation. However, explicit segmentation methods have good interpretation since they can locate the position and label of each character. (N) Implicit segmentation methods _cite_ regard text recognition as a sequence labeling, which avoids the difficult character segmentation problem by simply slicing the text image into frames of equal length and labeling the sliced frames. Hidden Markov Model (HMM) and Recurrent Neural networks (RNNs) are typical examples for this case. In particular, the combination of convolutional neural network (CNN) and RNN based network obtained the state-of-the-art results on several challenging benchmarks. However, RNN-based methods have two demerits: (a) The training burden is heavy when the input sequence is very long or the number of output classes is large; (b) The training process is tricky due to the gradient vanishing/exploding etc. (N) Holistic methods _cite_ recognize words or text lines as a whole without character modeling. Though this is feasible for English word recognition and has reported superior performance, its reliance on a pre-defined lexicon makes it unable to recognize a novel word, And also, holistic methods are not applicable to the case that fixed lexicon is not possible, e.g., for Chinese text line recognition. Despite the big progress in recent years, the current scene text recognition methods are insufficient in both accuracy and interpretation compared to human reading. Modern cognitive psychology research points out that reading consists of a series of saccades (whereby the eyes jump from one location to another and during which the vision is suppressed so that no new information is acquired) and fixations (during which the eyes remain relatively stable an process the information in the perceptual span) _cite_, Therefore, if we simplify the perceptual span as a window, the process of reading can be formulated by a sliding window which outputs the meaningful recognition results only when its center is at the fixation point. Based on the above, we propose a simple and efficient scene text recognition method inspired by human cognition mechanisms, in which a sliding window and a character classifier based on deep neural network are used to imitate the mechanisms of saccades and fixations, respectively. Our method has several distinctive advantages: N) It simultaneously detects and recognizes characters and can be trained on weakly labeled data; N) It achieves competitive performance on both English and Chinese scene text recognition; N) The recognition process is highly parallel and enables fast recognition. We evaluate our method on a number of challenging scene text datasets. Experimental results show that our method yields superior or comparable performance compared to the state of the art. The rest of the paper is organized as follow. Section N reviews related works. Section N details the proposed method. Experimental results are given in Section N and conclusion is drawn in Section N.