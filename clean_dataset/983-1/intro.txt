Face detection is an essential step for many subsequent face-related applications, such as face alignment~ _cite_ face recognition~ _cite_ and face verification~ _cite_, \etc. It has been well developed over the past few decades. Following the pioneering work of Viola-Jones face detector~ _cite_, most of early works focused on crafting effective features manually and training powerful classifiers. But these hand-crafted features are indiscriminative and each component is isolated, making the face detection pipeline sub-optimal. Recently, object detection borrows ImageNet~ _cite_ pre-trained models as the backbone from image classification and have acquired significant improvements. For the task of image classification only needs semantics to recognize the category, feature maps own more semantic information and less detailed information with going deeper in CNN, However, both of semantics and details are in demand for face detectors to detect faces in different locations with various scales and charicteristics. Consequently FPN~ _cite_ presents a divide and conquer principle that different scales of objects are collected and distributed to different feature layers, with a top-down architecture attached to maintain both the high spatial resolution and semantic information. We observe that FPN obtains semantic enrichment at lower-level layers by adding deformation of higher-level feature maps to lower-level feature maps, which may cause too much semantics from higher-level feature maps damages details in lower-level feature maps. As can be seen in~ _cite_, semantics represents the more semantic meaningful patterns whose receptive filed is larger, while details represent basic visual patterns whose receptive filed is smaller. Intuitively, they will make conflicts when fusing semantics and details in an addition manner. So, the key of feature fusion is to prevent conflicts among different feature maps and loss of information in the process of transformation. To obtain semantic enrichment at lower-level layers and meantime prevent details from being covered by too much semantics, we propose a novel feature pyramidal structure to fuse higher-level feature maps and lower-level feature maps in a spatial and channel-wise attention manner. More specially, we apply semantic information of higher-level feature maps as contextual cues to element-wisely multiply lower-level feature maps. We further avoid loss of semantic information by applying transposed convolution (also called deconvolution~ _cite_) to transform feature maps. Secondly, most works divide the task of detection into the classification task and the regression task, both of which handle pre-set anchors. When anchors match objects not well, the objects would be ignored with a waste of detection supervision information, making optimization sub-optimal. So anchor assign strategy decides the ceiling of performance of anchor-based face detection. In this paper, to complement anchor assign strategy and best utilize detection supervision information, we introduce an efficient segmentation branch like~ _cite_ . The segmentation branch is trained with bounding-box segmentation ground-truth in a hierarchical manner. The segmentation branch can help networks learn more discriminative features from object regions, which has been proved helpful in~ _cite_, in a self-supervised manner. We employ the segmentation in the training phase to apply attention mechanism--a dynamic feature extractor that combines contextual fixations over times, as CNN features are naturally spatial, channel-wise and multi-layer~ _cite_, and there will be no extra parameters in the inference time. We conduct extensive experiments on WIDER FACE~ _cite_ benchmarks to validate the efficacy of our proposed structure. As a summary, the main contributions of this paper include the following: