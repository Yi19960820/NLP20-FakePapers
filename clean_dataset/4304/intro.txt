Face alignment refers to the process of fitting a shape model on a face image, i.e. precisely localizing keypoints that correspond, for instance, to eye or lip corners, nose tip or eyebrow locations. It serves as an input to many human-computer interaction systems, such as face reenactment _cite_ or expression recognition _cite_ . Most recent approaches for face alignment consist in applying a number of updates, starting from a mean shape. For each of these updates, a regressor is trained to map shape-indexed features to a displacement in either the space of a parametric face model (parametric regression), or directly in the space of the feature point locations (explicit regression) . Then, given a face image, the shape is successively refined by applying the sequence of updates predicted by the learned regressors, in a cascaded way. On the one hand recent approaches such as _cite_, _cite_, and _cite_ advocate that the use of a parametric shape brings more stability to the alignment. Also, it allows to drastically reduce the dimensionality of the regression problem. On the other hand, approaches such as _cite_ and _cite_ show that, given enough training data, explicit regression allows to capture fine-grained shape deformations, especially in the latter stages on the cascade. In our work, we propose to combine the best of those two worlds, by first applying updates in the space of a constrained, parametric model. Then, in the latter stages, fine-grained deformations can be captured by means of explicit regression layers (Figure _ref_) . Each individual cascade stage usually consist in (a) a dimensionality reduction step, and (b) a regression step. For instance, authors in _cite_, _cite_ and _cite_ use PCA to perform (a) . In order to achieve (b), Xiong et al. _cite_ use least-square error minimization. Asthana et al. in _cite_ propose an incremental least-squares formulation. Martinez et al. in _cite_ use _inline_eq_-norm regularization to induce robustness to poor initializations. These approaches offer the advantage of being very fast, especially when applying regression upon learned local features _cite_ . However, performing (a) and (b) sequentially can lead to suboptimal solutions. Furthermore, those method generally use linear regressions to predict the updates. Hence the low number of parameters (which is constrained by the PCA output space dimension, in the case of SDM _cite_) may hinder their ability to capture the variability of larger datasets, such as the one in _cite_ . Moreover, deep learning techniques have recently started to show their capabilities for face alignment. In the work of Sun et al. _cite_, convolutional neural networks (CNNs) are used to extract suitable image representation. Then fully-connected layers are used to perform (a) and (b) in an end-to-end fashion. Zhang et al. _cite_ use a cascade of deep autoencoders. Zhang et al. _cite_ design a deep learning pipeline to learn both (a) and (b) in a single pass. However, their approach require the use of large collections of images labelled with auxiliary attributes to help learn the image representations. Authors in _cite_ also do not use cascaded regression, as the evaluation of several deep networks, and especially fully-connected layers, is prohibitively expensive in terms of computational load _cite_, _cite_ . Thus, one can wonder what could be an ideal candidate regressor in the frame of a cascaded regression pipeline to perform face alignment. Firstly, it shall be differentiable in order to learn (a) and (b) (and possibly the image representations) in an end-to-end fashion. Secondly, it shall be evaluated very fast in order to keep the runtime low when stacking several cascade layers. Thirdly, it has to embrace a good amount of parameters in order to scale well on larger databases, while at the same time it shall not overfit when trained on smaller corpses of examples. Recently, Kontschieder et al. _cite_ introduced the deep neural forest (NF) framework for training differentiable decision trees. In this work, we propose to adapt the NF framework to achieve real-time processing. We call this method greedy neural forest (GNF) and wrap the deep GNF regressors inside a semi-parametric cascade. We demonstrate that the proposed cascaded semi-parametric deep GNF (CSP-dGNF) achieves high accuracies as well as very low runtime, while scaling very well to larger and more complex databases. To sum it up, the contributions of this paper are the following: