Single image dehazing refers to the restoration of an image from its degraded observation under hazy conditions. To combat adversary conditions such as haze, physical modeling of the image degradation process has been extensively studied in the literature (e.g. _cite_, _cite_, _cite_) . It is known that the process of light passing through a scattering medium such as atmosphere is characterized by the attenuation along the path of transportation. To make mathematical modeling tractable, it is often assumed that the fraction of light deflected and the distance traveled observe a linear relation. Such simplified assumption has led to the popular image formation model connecting observed hazy image with scene radiance (unknown target) and transmission map _cite_ . Based on such formation model, the problem of single image dehazing boils down to estimating the transmission map; and for this reason, many previous works on single image dehazing have focused on a model-based (e.g., uncorrelation principle _cite_, dark channel prior _cite_) or learning-based (e.g., dehazenet _cite_, multi-scale CNN _cite_) approach toward transmission map estimation. We challenge this conventional wisdom by highlighting a few weaknesses of transmission-map-first approach. First, since the image formation model is based on simplified assumptions, it only represents an of the true in-scattering term in a full radiative transport equation _cite_ . The validity of this approximation becomes questionable in more realistic acquisition scenarios such as heavy haze and night environment. Therefore, the effectiveness of using a transmission map to recover scene radiance might deteriorate as hazy condition varies. Second, the transmission-map-first approach suffers from the potential-i.e., any error in the estimated transmission map could have catastrophic impact on the recovered scene radiance. Surprisingly, this issue of error propagation has not been addressed in the open literature to the best of our knowledge. In previous works (e.g., _cite_, _cite_), only a small positive constant is added to the denominator for improving numeral stabilities of solution algorithms. Third, with the estimation of transmission map involved as an intermediate step, it becomes difficult to conduct end-to-end optimization especially from the point of view. In this paper we advocate a deep learning-based approach toward single image dehazing without estimating transmission map at all (as shown in Fig. _ref_) and capable of end-to-end perceptual optimization. Our direct approach is motivated by a flurry of most recent advances in the field of deep learning including deep residue networks _cite_, _cite_, _cite_ and generative adversarial networks (GAN) _cite_, _cite_, _cite_ . The main contributions of this work are summarized by the three components as shown in Figure~ _ref_ . _inline_eq_ . Inspired by the analogy between denoising and dehazing, we propose to directly learn a nonlinear mapping from the space of degraded images to that of haze-free ones via deep residual network _cite_ . Since our approach does not rely on estimating transmission maps as an intermediate step, it can work with a variety of hazy conditions (both heavy and light) no matter whether the image formation model holds or not. Moreover, by feeding the output of the network as the input, we can obtain a extension of deep residual learning; in other words, haze-free images can be viewed as the fixed-point _cite_ of our generative network. _inline_eq_ . As mentioned above, it is often difficult to address the issue of perceptual quality in transmission-map-first approaches. In this work, we propose to leverage the success of generative adversarial networks (GAN) from image synthesis _cite_ and super-resolution _cite_ to single image dehazing. Based on our discriminative network, we propose to optimize the perceptual quality of dehazed images by introducing an loss function. Adaptive weights in our loss function are conceived to facilitate perceptual optimization of GAN-based dehazing when hazy condition varies. _inline_eq_ . In view of the tendency of producing various artifacts in dehazed images (e.g., color shifting _cite_ and halo-like _cite_), we propose to remove the unpleasant artifacts by a novel application of guided filtering _cite_ . More specifically, the hazy image will serve as a guidance for correcting the recursively-learned residue image. The effectiveness of such guided filtering based post-processing on suppressing various artifacts has been verified especially around large scene depth discontinuities. When compared with previous approaches, our Perceptually Optimized GAN (POGAN) can be trained in an end-to-end fashion because it bypasses the unnecessary step of transmission map estimation. By explicitly addressing the issue of perceptual quality, our POGAN can be optimized for both indoor and outdoor scenes and under a variety of haze conditions (heavy vs. light) . We have conducted extensive experimental studies with respect to both synthetic and real-world images. In our study, we have compared both subjective and objective visual quality of dehazed images and found that our POGAN often performs favorably against other state-of-the-art approaches especially in terms of subjective evaluation. Restored images by this work are often the most faithful reproduction of original images with respect to color vividness and fine structural details.