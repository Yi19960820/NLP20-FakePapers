Ischemic stroke is the most common cerebrovascular disease and one of the most frequent causes of death and disability worldwide. A patient with ischemic stroke can benefit most from the earliest possible definitive diagnosis, and imaging plays an essential role in the assessment of patients . Due to its excellent soft tissue contrast, the magnetic resonance imaging (MRI) has become the modality of choice for clinical evaluation of ischemic stroke lesions. For a quantitative analysis of stroke lesion in MRI images, the expert manual segmentation is still a common approach and has been employed to compute the size, shape and volume of the stroke lesions. However, it is a tedious and time consuming task and is non-reproducible. Therefore, the development of fully automated and accurate stroke lesion segmentation method has become an active research field, but it is not easy task . Conventionally, the lesion segmentation is treated as an abnormality detection problem, where a healthy atlas is established, and the lesions are detected according to the differences in tissue appearance . The brain appearance, however, differs from patient to patient, and the lesion may also cause deformation in brain structure. Moreover, the MRI acquired from different machines may also introduce different levels of noise and deformation of brain tissue appearance, leading to incorrect detection and segmentation. Therefore, many machine-learning methods have been proposed, where the features are learnt from massive training data, and high segmentation accuracy can be achieved. For instance, random forest based methods were used in the literature, which presents good performance in brain tumor segmentation by using hand-crafted features. Note that the performance of the random-forests-based methods heavily rely on the manually annotated features. To achieve better performance, it is preferable to make the machine find the features from the data by itself. The deep learning is a machine-learning approach that uses layered hierarchical, graphical networks to extract features from data at progressively higher levels of abstraction . In recent years, the deep-learning-based methods have been widely used in object classification and semantic image segmentation thanks to its recent breakthrough in convolutional neural network (CNN) . The deep learning methods are originally used for image classification for daily images, such as flowers, persons, etc., and have achieved _inline_eq_ top-N error in the classification of N objects in Imagenet Large Scale Visual Recognition Challenge (ILSVRC) N. When applied to biomedical image classification and segmentation, the deep learning methods suffers from the lack of data. For instance, the ILSVRC N dataset contains _inline_eq_ images, while the brain tumor segmentation (BraTS) challenge N has only N patients in the training dataset and N patients in the testing dataset . In the sub-acute stroke lesion segmentation task of the ischemic stroke lesion segmentation (ISLES) N challenge, the dataset is much smaller, with N patients in the training dataset and N patients in the testing dataset . The insufficient data limits its ability to learn features from the training data, and may also lead to over-fitting on the training data. Despite of this, many deep-learning-based methods have been proposed for brain tumor and ischemic stroke segmentation, and presents good performance. Note that the CNN is originally developed for image classification, one of the most popular methods is to convert the image segmentation task to a pixel-by-pixel classification, and dedicated loss functions have been designed to overcome the huge class imbalance between the normal tissues and the lesion tissues . Such approaches, however, are generally memory and computation consuming, as the surrounding area of each pixel should be included to provide contextual information in classifying each pixel. Inspired by the pioneering work of Long et al. where a fully convolutional network (FCN) was proposed by replacing the fully-connected layers as convolutional layers, Kamnitsas, et al proposed a ND-Convolution-based FCN, known as DeepMedic, which won the ISLES N and BraTS N challenges . In ISLES N dataset, it is able to detect sub-acute ischemic stroke lesion of N out of N patients, and achieves a Dice coefficient of N on the test dataset . In BraTS N challenge, it achieves a Dice coefficient of N in segmenting the tumor tissues . The promising results in ISLES and BraTS shows the great potential of deep learning in the brain tissue segmentation tasks. However, the MRI images provided in the challenge datasets are acquired for scientific usage with a high resolution of _inline_eq_ mm per voxel. In clinical image, the image slices are usually much thicker, typically _inline_eq_ mm, and the data cannot be preprocessed with methods such as brain extraction, cerebrospinal fluid removal, standardization. Therefore, the DeepMedic developed for BraTS and ISLES datasets cannot be applied directly in clinical data. Recently, clinical diffusion weighted image (DWI) data has been applied to lesion segmentation of acute ischemic stroke base on deep learning technique and presents a very promising results, where a network which combines two Deconvolution Network (DeconvNet) is developed and trained on a clinical dataset of N acute ischemic stroke patients. A multi-scale CNN is further developed to remove potential false positives. The mean dice coefficient, mean number of false positives and the mean number of false negatives achieved in are N, N and N, respectively. While the former two are reasonable, the latter is relatively too large. In clinical diagnosis, the false negatives (FNs) are more fatal compared to false positives (FPs) due to the fact that the FPs can be possibly filtered by doctors while the FNs, which are sometimes too subtle to be noticed, will lead to severe misdiagnosis accident when the misclassified lesion is the only lesion in the brain. This motivates us to study how to further reduce the FNs to develop a practical deep-learning based stroke lesion segmentation method for clinical diagnosis usage. In stroke diagnosis, only DWI is not sufficient for the diagnosis of ischemic stroke due to the TN shine-through effects and chemical shift artifact. Therefore, more acquisition parameters, such as Apparent Diffusion Coefficient (ADC) and TN-weighted images (TNWI), should be included in the diagnosis . In this paper, we will show that the lesions can be preciously detected by using DWI, ADC and TNWI in the diagnosis. In the clinical work, we catch sight of acute and subacute strokes frequently coexist in the brain tissues, making them difficult to be clearly separated in segmentation. Moreover, subacute stroke lesions also have its clinical significance, and are usually required to be evaluated in clinical diagnosis. Therefore, we propose to segment both acute and subacute ischemic stroke lesions to provide useful reference for clinicians. For improving the performance of a CNN, it is natural to use more convolution layers, such that more features can be extracted. However, the performance will become worse if we stack too many convolution layers, as the initial convolution layers cannot be trained due to the gradient vanishing problem. Recently, a so-called residual network (ResNet) is proposed to make the network much deeper. Instead of simply stack more convolution layers, many skip connections are added between layers of the network. Such structure allows the gradient to pass backward through the skip connections, and all the convolution layers are able to be updated to extract features since the first training epoch. In this paper, we propose a residual-structured fully convolutional network (Res-FCN) for brain ischemic lesion segmentation. Specifically, we collected the clinical data of N ischemic stroke patients from Nankai University affiliated Tianjin Huanhu Hospital, where N of them are used for training, and N of them for testing. By using multi-modal MRI images, i.e., DWI, ADC and TNWI, the proposed Res-FCN is able to achieve a mean number of false negatives of N per patient. The result achieved in our work sheds a light on the use of automated segmentation in clinical diagnosis.