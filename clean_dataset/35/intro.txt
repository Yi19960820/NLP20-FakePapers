A new and vast array of research in the field of human activity recognition has been brought about with the recent technological advancements in wearable cameras. Majority of the human activity recognition techniques till now were concentrated on videos captured from a third person view. Developing techniques for the automatic analysis of ego-centric videos has immense application potential ranging from assistance during surgical procedure, law and order, assisting elderly citizens, video summarization, etc. But most of the existing research deal with activities carried out by the camera wearer, not interactions and reactions of others to the observer (person wearing the camera) . The interaction recognition problem is different and difficult compared to the action recognition problem. This is because egocentric video captures a huge variety of objects, activities, and situations, and sometimes the person interacting with the observer can move out of the field of view as the person approaches the observer. Presence of ego-motion adds more complexity to the problem as it can interfere with the analysis of motion taking place in the scene. The applications of a method capable of automatically understanding interactions from egocentric view include surveillance, social interaction for robots, human machine interaction, etc. Regardless of the recent advancements in deep learning techniques for addressing problems such as object recognition, caption generation, action recognition, etc., it has never been applied in the problem of first person interaction recognition. All the existing methods use hand-crafted features or processing stages for recognizing interactions in first person videos. End-to-end deep learning techniques require no prior information regarding the data and it is capable of achieving high degree of generalization compared to hand-crafted features based approaches. As a result, we propose to follow a deep learning approach for addressing the problem under study. To the best of our knowledge, this is the first time a deep learning based method is proposed for solving first person interaction recognition problem. Our contributions can be summarized as follows: The remaining of the paper is organized as follows. A brief idea about the relevant state of the art techniques is provided in section _ref_ . The proposed deep neural network architecture for addressing the concerned problem is discussed in section _ref_ . Section _ref_ discusses the experimental results obtained as part of the performance evaluation and the document is concluded in section _ref_ .