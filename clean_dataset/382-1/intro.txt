Traditionally, most learning approaches have been treating representation-learning/feature-selection and clustering separately. However recent studies have outperformed traditional methods by learning optimal representations for clustering. In most of these works a deep auto-encoder is first trained to reduce a reconstruction loss. Next, the encoder parameters and clustering parameters (e.g. the K-means centroids) are jointly optimized in order to improve the overall clustering accuracy. However, we observed that in most cases the improvement of the clustering phase over the pre-training phase amounts no more than _inline_eq_ percents of accuracy. Therefore, reaching a high level of accuracy in the pre-raining phase is of crucial importance. Moreover, a reconstruction loss is not an optimal choice for clustering, due to the natural trade-off between reconstruction and clustering. A reconstruction aims to reproduce every detail in the original data, while clustering aims to reduce all possible variations into several templates. In this paper we propose a novel unified framework for learning a clustering oriented representation. We suggest the optimization of an auto-encoder in the pre-training phase, with respect to a discriminative loss function which encourage a clustering oriented representation. The discriminative loss is the weighted sum of all pairwise similarities among data-points in the batch. Minimization of this loss implies making data-points' representation as dissimilar as possible. Under the assumption of a balanced dataset, the majority of the pairs are indeed dissimilar and only a small fraction of them are similar (i.e., only the within cluster pairs) . Accordingly, the utilization of this loss is justified. The proposed optimization scheme enables the utilization of relatively small networks whom can be trained very fast. For the clustering phase we propose a joint optimization scheme that maintain the pairwise discrimination loss while it optimizes the clustering objective. We apply the proposed algorithm to several datasets (MNIST, COIL-N, COIL-N), and demonstrate its superiority both in terms of accuracy and speed of convergence. To summarize, the contributions of this paper are twofold: (N) the major contribution of this paper is a novel optimization scheme for the auto-encoder pre-training phase, that encourages a discriminative latent space which fits with the clustering objective and reaches higher accuracy prior to the clustering phase, and (N) a novel clustering scheme in which the discrimination of the latent space is strengthened while searching for the optimal centroids.