It is currently not possible to accurately estimate joint loads on the sporting field as the process to estimate these forces and moments generally requires high-fidelity multidimensional force plate inputs and complex biomechanical modeling procedures, traditionally available only in biomechanics laboratories. The sports biomechanist must instead trade the ecological validity of field-based data capture and manage the limitations of the artificial laboratory environment to accurately model internal and external musculoskeletal loads . \par One of the most devastating sport injuries is the rupture of the anterior cruciate ligament (ACL) which can be a season or career-ending event for the professional athlete . Most ACL incidents in team sports such as basketball and hockey are non-contact events (N to N~ \%), with more than N~ \% reportedly occurring during sidestepping or single-leg landing maneuvers . These statistics highlight that the ACL injury mechanism should be generally regarded as an excessive load-related event, resulting specifically from an individual's neuromuscular strategy and associated motion, which by definition is preventable. Alongside technique factors, studies have identified increased knee joint moments (KJM), specifically high external knee abduction moments during unplanned sidestepping tasks, as a strong indicator of ACL injury risk, and as such, real time accurate estimates of ground reaction forces and moments (GRF/M) and knee joint loads could be used as an early warning system to prevent on-field non-contact knee trauma. \par The orthodox approach to calculating joint loads requires directly recording forces applied to the athlete by either (N) modifying the laboratory environment to better mimic the specific sport requirements, or (N) instrumenting the athlete directly with force transducers or other surrogate wearable sensors to estimate these forces. In soccer, Jones \etal brought the field into the laboratory by mounting turf on the surface of the force plate. Conversely, Yanai \etal employed the reverse approach by embedding force plates directly into the baseball pitching mound. Alternatively, two main types of wearable sensor technologies have also been used to estimate GRF/M, first, in-shoe pressure sensors, and more recently, body mounted inertial sensors . Unfortunately, the accuracy of these methods is restricted to simple gait motion (\eg walking), whereby they estimate only a single force component (primarily vertical _inline_eq_), or the sensor itself (location or added mass) adversely affects performance . The current generation of wearable sensors are limited by low-fidelity, low resolution, or uni-dimensional data analysis (\eg velocity) based on gross assumptions of linear regression, which overfit to a simple movement pattern or participant cohort, however, researchers have reported success deriving kinematics from these devices for movement classification . To improve on these methods, a number of research teams have sought to leverage computer vision and data science techniques, and while initial results appear promising, to date they lack validation to ground truth data, or relevance to specific sporting related tasks . For example, Fluit \etal and Yang \etal derive GRF/M from motion capture. However, the former requires the complexity of a full body musculoskeletal model, while the latter again predicts only _inline_eq_ . These examples of data science and machine learning solutions have relied on basic neural networks and small sample sizes, which means perhaps the biggest untapped opportunity for biomechanics research and practical application is to approach these problems by building on the success of more recent deep learning techniques, which are better suited to exploit large amounts of historical biomechanical data . \par In the biomechanics laboratory, retro-reflective motion capture is considered the gold standard in marker-based motion analysis, utilizing high-speed video cameras (up to _inline_eq_) with built-in strobes of infrared (IR) light to illuminate small spherical retro-reflective passive markers attached to the body . Often captured concurrently with the motion data are analog outputs from force plates providing synchronized GRF/M. The three orthogonal force and moment components recorded are: horizontal (shear) forces _inline_eq_ and _inline_eq_, the vertical force _inline_eq_, and the three rotation moments _inline_eq_, _inline_eq_ and _inline_eq_ about the corresponding force axes. Force plates can be affected by a variety of systematic errors and installation must be carried out in such a manner as to minimize vibration, and with regard to the frequency and absolute force magnitude of the captured movement. This means that mounting the plate flush with a concrete floor pad during laboratory construction produces optimal force recordings. However, this makes the force plate difficult to move or install in outdoor sporting environments, and errors can also be propagated from failures in maintenance, calibration, and operation . \par Motion and force plate data are conventionally used as inputs to derive the corresponding joint forces and moments via inverse dynamics analysis . Over the past twenty years at The University of Western Australia (UWA), upper and lower body biomechanical models have been developed in the scripting language BodyBuilder (Oxford Metrics, Oxford, UK), with the aim of providing repeatable kinematic and kinetic data outputs (\eg KJM) between the three on campus biomechanics laboratories and external research partners . This paper aims to leverage this legacy UWA data collection by using non-linear data science techniques to accurately predict KJM directly from motion capture alone. \par Deep learning is a branch of machine learning based on the neural network model of the human brain and which uses a number of hidden internal layers . Enabled by recent increases in computing power, the technique has gained popularity as a powerful new tool in computer vision and natural language processing, and one potentially well-suited to the ND time-based data structures found in biomechanics . Caffe (Convolutional Architecture for Fast Feature Embedding), maintained by Berkeley AI Research (BAIR), is one of a growing number of open-source deep learning frameworks, alongside others including TensorFlow and Torch . Caffe originated from the ImageNet Large Scale Visual Recognition Challenge (N), is optimized for both CPU and GPU operation, and allows models to be constructed from a library of modules, including convolution (convolutional neural network, CNN) and pooling layers, which facilitates a variety of deep learning approaches . Training a deep learning model from scratch can require a large number of data samples, processing power and time. Fine-tuning (transfer learning) is a technique commonly employed to take an existing related model and only re-train certain higher level components, thus needing relatively less data, time and computational resources. Pre-trained models such as AlexNet, CaffeNet and GoogLeNet are selected according to their relevance to the higher-level data-set. CaffeNet, for example, was trained on N ImageNet images and N, N object classes . \par Contrary to the traditionally isolated data capture methods in the sport sciences, what made this investigation possible was access to the UWA data archive. Using this pooled historical data, the aim of the study was to accurately predict extension/flexion, abduction/adduction and internal/external rotation KJM from marker-based motion capture. Although this would negate the requirement for embedded force plates and the inverse dynamics modeling process, it is still tied to the laboratory. However, if successful this work would provide the necessary information to facilitate the next phase of the project, which is to drive multivariate regression models (not just classification) from low-fidelity wearable sensor input, trained from high-fidelity laboratory data, for eventual outdoor use. It was hypothesized that by mimicking the physics behind inverse dynamics the strongest correlations would be achieved via the double-cascade technique from CaffeNet models which had been pre-trained in the relationship between marker-based motion capture and GRF/M.