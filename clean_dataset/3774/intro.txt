Depth and Ego motion estimation from images is an important problem in computer vision which finds application in several fields such as augmented reality _cite_ _cite_, ND construction _cite_, self-driving cars _cite_, medical imaging _cite_ etc. Recent advances in deep learning have helped in achieving new benchmarks in this field which is getting better and better with time. The initial deep models _cite_ _cite_ used supervised mode of learning that required explicit availability of ground truth depth which is not always possible. This is partially remedied by using semi-supervised methods which either use sparse ground truth obtained from sensors like LIDAR _cite_ or make use of synthetically generated data as ground truth _cite_ . Compared to these methods, the unsupervised methods are becoming more popular with time as no explicit ground truth information is required for the learning process. In these cases, the geometric constraints between a pair of images either in temporal _cite_ _cite_ or spatial domain _cite_ or both _cite_ are exploited to estimate the depth and pose information. Continuing this trend, we restrict our focus of discussion only to unsupervised deep network models from here onwards in the rest of this paper. Some of the most recent and best results in this category are reported by methods such as, VidNDepth _cite_, UnDeepVO _cite_, DeepFeat-VO _cite_ and UnDEMoN _cite_ . VidNDepth _cite_ uses inferred ND world geometry and enforces consistency of estimated point clouds and pose information across consecutive frames. Since they rely on temporal consistency (monocular sequence of images), the absolute scale information is lost. This is remedied in UnDeepVO _cite_ where authors enforce both spatial and temporal consistencies between images as well as between ND point clouds. UnDEMoN _cite_ further improves the performance of UnDeepVO _cite_ by predicting disparity instead of depth and using different penalty function for training. DeepFeat-VO _cite_ attempts to further improve the results by including deep feature-based warping losses into the training process. These deep features are obtained from a depth model pre-trained on a different dataset. In spite of these advancements, the depth and pose estimation results are still not close to what is obtained from stereo methods _cite_ which use left-right image pair as input to the network. There is still enough scope for improving the accuracies of unsupervised methods. Most of the unsupervised methods try to minimize the reconstruction losses either in temporal domain (forward-backward images) _cite_ _cite_ or in spatial domain (left-right images) _cite_ or in both _cite_ during the training process. Bi-linear interpolation is one of the commonly used method for image reconstruction which is widely used in the view synthesis literature _cite_ _cite_ . Bi-linear interpolation uses a quadratic regression model to estimate color intensity of a target pixel by using only four neighboring pixels of the source image. The use of only four neighborhood points limits the ability of the regression model to deal with large motions in the scene. This is remedied by using a large search space (more than four points) to estimate the target pixel as suggested in _cite_ . This, however, may not give good interpolation for far-away objects. Furthermore, the accuracy of reconstruction can be improved by using higher order regression model at the cost of higher computational cost. This provides us the necessary motivation to use a deep network model for image reconstruction required for disparity estimation. This deep network provides higher order regression which is expected to perform better a quadratic regressor used in bi-linear sampler. In addition, it solves the problem of search space required for interpolation as it takes the whole image as the input. The use of deep network based image sampler instead of using the standard bi-linear sampler commonly used in other methods provides the basis for the work presented in this paper. In this paper, we suggest several improvements to the UnDEMoN architecture _cite_ with the aim to produce superior depth and pose estimation results. The proposed model makes use of a deep network for reconstructing right image given the left image and the corresponding disparity. This is labeled as deep image sampler network (DISNet) which is used along with a bi-linear sampler (BIS) to provide superior image reconstruction abilities required for depth and pose estimation. While the DISNet provides higher order regression and larger input search space for interpolation, the bi-linear sampler provides the necessary geometry constraints to reduce the solution space of this ill-posed problem. A simplified overview of the proposed framework is shown in Figure _ref_ . As one can observe, the disparity estimation network (DispNet) uses the image reconstruction error obtained from both DISNet and BIS together for training. In addition to this, we use a thinner deep model (with lesser number of hidden layers) compared to the previous UnDeMoN model. The total number of parameters in the proposed inference model is about one-fourth (only N \%) of the original UnDEMoN model _cite_, making it one of the lightest depth or disparity estimation model in the literature. The resulting model provides superior depth and pose estimation which outperforms all existing state-of-the-art methods. For instance, the proposed model provides N \%, N \%, N \% and N \% improvement over UnDEMoN _cite_, VidNDepth _cite_, DeepFeat-VO _cite_ and UnDeepVO _cite_ respectively. The proposed model is named "UnDEMoN N to indicate improvement over the previously existing UnDEMoN model _cite_ . In short, the following two main contributions are made in this paper: (N) The proposed model makes use of a deep network based image sampling model for depth and pose estimation which is a novel contribution in this field. (N) The proposed model uses very less number of trainable parameters for achieving superior performance making it one of the most computationally efficient deep model for depth and pose estimation. our model. Finally, a rigorous analysis of the network performance is carried out on KITTI dataset and is compared with all existing state-of-the-art methods. To the best of our knowledge, the results presented in this paper are the best reported so far and hence forms a new benchmark in this field. The rest of this paper is organized as follows. An overview of related work is provided in the next section. The proposed model is described in Section _ref_ . The experimental results are analysed and compared in Section _ref_ . Finally, the conclusion and future scope of improvement is provided in Section _ref_ .