In the past few months, tremendous progress has been made in the field of semantic segmentation _cite_ . Deep convolutional neural networks (CNNs) _cite_ that play as rich hierarchical feature extractors are a key to these methods. These networks are trained on large-scale datasets _cite_ as classifiers, and transferred to the semantic segmentation tasks based on the annotated segmentation masks as supervision. But pixel-level mask annotations are time-consuming, frustrating, and in the end commercially expensive to obtain. According to the annotation report of the large-scale Microsoft COCO dataset _cite_, the workload of labeling segmentation masks is more than N times heavier than that of spotting object locations. Further, the crowdsourcing annotators need to be specially trained for the tedious and difficult task of labeling per-pixel masks. These facts limit the amount of available segmentation mask annotations, and thus hinder the performance of CNNs that in general desire large-scale data for training. On the contrary, bounding box annotations are more economical than masks. There have already existed a large number of available box-level annotations in datasets like PASCAL VOC N _cite_ and ImageNet _cite_ . Though these box-level annotations are less precise than pixel-level masks, their amount may help improve training deep networks for semantic segmentation. In addition, current leading approaches have not fully utilized the detailed pixel-level annotations. For example, in the Convolutional Feature Masking (CFM) method _cite_, the fine-resolution masks are used to generate very low-resolution (\eg, _inline_eq_) masks on the feature maps. In the Fully Convolutional Network (FCN) method _cite_, the network predictions are regressed to the ground-truth masks using a large stride (\eg, N pixels) . These methods yield competitive results without explicitly harnessing the finer masks. If we consider the box-level annotations as very coarse masks, can we still retain comparably good results without using the segmentation masks? In this work, we investigate bounding box annotations as an alternative or extra source of supervision to train convolutional networks for semantic segmentation . We resort to unsupervised region proposal methods _cite_ to generate candidate segmentation masks. The convolutional network is trained under the supervision of these approximate masks. The updated network in turn improves the estimated masks used for training. This process is iterated. Although the masks are coarse at the beginning, they are gradually improved and then provide useful information for network training. Fig.~ _ref_ illustrates our training algorithm. We extensively evaluate our method, called ``BoxSup'', on the PASCAL segmentation benchmarks _cite_ . Our box-supervised (\ie, using bounding box annotations) method shows a graceful degradation compared with its mask-supervised (\ie, using mask annotations) counterpart. As such, our method waives the requirement of pixel-level masks for training. Further, our semi-supervised variant in which N/N mask annotations are replaced with bounding box annotations yields comparable accuracy with the fully mask-supervised counterpart. This suggests that we may save expensive labeling effort by using bounding box annotations dominantly. Moreover, our method makes it possible to harness the large number of available box annotations to improve the mask-supervised results. Using the limited provided mask annotations and extra large-scale bounding box annotations, our method achieves state-of-the-art results on both PASCAL VOC N and PASCAL-CONTEXT _cite_ benchmarks. Why can a large amount of bounding boxes help improve convolutional networks? Our error analysis reveals that a BoxSup model trained with a large set of boxes effectively increases the object accuracy (the accuracy in the middle of an object), and its improvement on object boundaries is secondary. Though a box is too coarse to contain detailed segmentation information, it provides an instance for learning to distinguish object categories. The large-scale object instances improve the feature quality of the learned convolutional networks, and thus impact the overall performance for semantic segmentation.