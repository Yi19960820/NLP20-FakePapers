The analysis of CT slices extracted at the third lumbar vertebra (LN) has garnered significant clinical interest in the past few years, in particular in regards to computing a sarcopenia measure _cite_ . Sarcopenia refers to loss of muscle mass and is computed as the total area of the skeletal muscle mass divided by the square of the patient's height. Sarcopenia is particularly relevant in oncology where severe muscle loss in adult patients is typically found to be associated with poor outcome _cite_ . LN is taken as a standard landmark by a majority of medical researchers for sarcopenia measurement _cite_, as muscle and adipose fat areas at LN and LN have been found to be most linearly correlated to their whole-body counterparts _cite_ . The main motivation for automating the whole process of computing a sarcopenia measure is to provide it as prognostic information to clinicians in cancer populations alongside the CT images. Extracting measurement directly from CT images is convenient as CT is frequently obtained as part of cancer staging and disease assessment. The current work-flow for computing a sarcopenia measurement is as follows: manual extraction of the LN slice; this involves scrolling through the ND image slice by slice until the LN slice is found. Semi-automated segmentation software (e.g. Slice-O-Matic or ImageJ) that involves manual refinement is then used to segment the skeletal muscle and adipose fat tissue. This process takes N to N minutes per image, and it becomes time-consuming to run on large datasets. In this paper we solely address the problem of automatic slice detection, as skeletal muscle segmentation has already been addressed in the literature using fully-convolutional networks _cite_ . Slice detection in _cite_ is formulated as a regression problem, where a VGG architecture with a single output fully-connected layer is used to predict the slice location. The main advantage of the approach is that it operates on ND images instead of ND; it does so by converting the ND CT images to ND via Maximal Intensity Projection (MIP) . This involves projecting the maximal intensity pixel value along the perpendicular direction of the frontal plane. The MIP image representation still contains enough information for locating the LN vertebra. This greatly reduces the dimensionality of the problem and allows feeding into the CNN images that have more context, as opposed to a ND volume where input size is limited by memory capacity. As vertebrae are similar in appearance, context is an important feature in discriminating between them. A dense layer with a single output is attached to the last convolutional layer output of a pre-trained VGG network. The weights are then fine-tuned. The method only trains on image crops of fixed size ([N, N, N]) . However, there are a few drawbacks: (N) In order to detect the LN slice, a sliding window approach is adopted; this means that convolutions from overlapping image areas are being repeatedly recomputed as the window slides over the whole image, and this increases prediction time; (N) the method has no probabilistic output as it only outputs a single number that indicates the predicted slice location; (N) only image crops that contain the LN vertebra are used for training, while image crops that do not contain it are excluded. With this approach, a special elimination process is used during test time that relies on the assumption that image crops that do not contain the target vertebra will produce random outputs. (N) and (N) could potentially be solved by adding another output to the network that serves as an indicator whether the LN slice is present or absent. This would allow training on negative examples and produce a probabilistic output; however, the sliding window approach is still computationally inefficient. In this paper, we propose an efficient method to detect the LN slice (or potentially any other slice) based on fully-convolutional networks (FCNN) that output full-resolution confidence maps either in ND or ND. This is motivated by previous works _cite_ that use FCNN to predict confidence maps for landmark localisation. In summary, we make the following contributions: (N) an efficient method to automatically detect the LN slice (or potentially any other slice) without using a sliding window approach; this is due to the use of a fully-convolutional network formulation for confidence map prediction; (N) we propose a novel variant architecture based on a simple modification of the UNet _cite_ architecture that produces ND confidence map output instead of the standard ND output, which is suited for our particular use case; (N) we compile a large annotated dataset of \numImages images obtained from multiple public sources; and (N) the dataset and code for reproducing our method will be publicly available online at _url_ .