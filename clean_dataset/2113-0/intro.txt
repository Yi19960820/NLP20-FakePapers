Recently deep neural networks (DNNs) have attained impressive performance in many fields such as image classification _cite_, semantic segmentation _cite_, and image compression _cite_ . The performance of these deep networks has begun to exceed human performance in many tasks. Human top-N classification error rate on the large scale ImageNet dataset has been reported to be N \% _cite_, whereas a state-of-the-art neural network _cite_ achieves a top-N error rate of N \%. Most existing works assume that the input images are of good quality. However in many practical scenarios, images may be distorted. Image distortions can arise during acquisition or transmission. In acquisition, the image sensor can exhibit noise in low light conditions. Motion blur can occur if the camera is moving. In transmission, packet-loss could cause missing regions of the image, or missing frequencies, depending on how the image is encoded. As machine learning has begun to see popularity as a cloud-based service, these issues have become more relevant. It has been shown that neural network performance decreases under image quality distortions _cite_ . The degradation is particularly evident for additive noise or blur distortions. Given that networks equal or exceed human performance on undistorted images, it is interesting to ask: do networks still achieve equal or greater performance as compared to humans on distorted images? If human and DNN performance are similar on distorted images, then distorted images may be inherently difficult to recognize. Conversely, if it is shown that humans exceed DNN performance on distorted images, then there is some representational capacity present in the human visual system that is lacking in DNNs. To answer this question we perform classification experiments with N human subjects. We ask the subjects to classify images that are distorted with varied levels of additive Gaussian noise and Gaussian blur. We find that human subjects are able to more accurately classify images under blur and noise distortions compared with DNNs (Figure~ _ref_) . Furthermore, we find that at high distortion levels the correlation in the errors between deep networks and human subjects is relatively low. This could indicate that the internal models of the DNNs are quite different from the human visual system. These results could be used to guide future research into more robust learning systems. It may be useful to take motivation from the human visual system to achieve good performance on distorted images. Comparing the performance of machine learning systems with human subjects has attracted interest because it may give insights on how machine learning systems can be improved. Borji and Itti _cite_ compare human classification accuracy and the accuracy of several machine learning algorithms on several datasets. The study considers images as well as line drawings and jumbled images. The study, however, does not test distorted images, and does not include deep learning algorithms. Fleuret \etal _cite_ test human and computer performance on a range of synthetic classification tasks. The tasks are binary classification experiments on synthetic images where the difference between the two classes is determined by the spatial arrangement of the constituent parts. Even though these tasks are simple, machine performance is still well below human performance. Stabinger \etal _cite_ test modern deep networks on these same classification tasks, but find that the networks can still not achieve human accuracy. While these tests are interesting, the experiments do not represent real data that is likely to occur in most applications. Parikh _cite_ tested human and computer performance on jumbled images. Jumbled images are constructed by splitting the image into patches and randomly permuting the patches. Global information is lost with jumbling and only local information can be used for classification. The jumbled image can be thought as a distortion of the original image, but it is not a distortion that occurs naturally due to data acquisition or transmission. The aforementioned studies reach similar conclusions that machine learning algorithms still lack the classification capability of human subjects. However, in the past several years, developments in deep learning have closed this gap and even surpassed human performance. More recent experiments _cite_ show that human classification accuracy on the large scale ImageNet dataset is less than that of state-of-the-art DNNs (e.g. _cite_) . Given that DNN performance now can match or exceed human performance, we can begin to examine more difficult problems. Humans have the capacity to recognize severely distorted images. For example, Torralba \etal _cite_ show that human subjects can accurately recognize low resolution images. Similarly, Bachmann _cite_ show that human subjects can recognize low resolution faces. Chen \etal _cite_ show the effect of noise on a face recognition task. Performance is impaired, but subjects are still able to perform the task with reasonable accuracy. Given that humans can recognize to some degree under quality distortions, it is interesting if DNNs can show the same ability. However, it has recently been shown that deep networks do not achieve good performance on distorted images _cite_ . Noise and blur were shown to affect the DNNs the most compared with other distortions. It is not surprising that deep networks trained on clean images perform poorly on distorted images. DNNs are optimized using the statistics of a collection of images, and when the statistics in the testing stage are very different, the model cannot generalize well. Most efforts to add robustness involve fine-tuning DNNs on distorted images. Vasiljevic \etal _cite_ show that fine-tuning yields improvements for blurred images. Similarly, Zhou \etal _cite_ show that this approach also works for images distorted with noise. However, Dodge and Karam _cite_ show that models fine-tuned on one type of distortion do not easily generalize to other types of distortions. They show how a gating network can be used to determine the distortion type and level of an input, and pass the data to an appropriately trained network. Finally, the dirty pixel approach _cite_ shows that fine-tuning with an additional pre-processing module can yield a DNN more robust to blur and noise. Is fine-tuning the best we can do? We can expect some dropoff in performance when distortions are added because information is lost. But, is the dropoff mostly due to the loss of information? Or are there some inherent properties of existing DNNs that make it difficult to recognize signal from noise? It may be difficult to analytically answer these questions. Nevertheless, we can experimentally compare DNNs with another visual recognition system, namely the human visual system, and see whether a similar dropoff in performance can be observed. To this aim, we perform experiments to gauge the performance of human subjects on a classification task under quality distortions. By comparing these results with the results from DNNs, we can perhaps gain insight into how to build deep networks that are more robust to distortions.