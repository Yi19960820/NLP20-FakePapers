crossing classification and detection are important tasks for mobility autonomy. Even though, there are few data available on where crosswalks are in the world. The automatic annotation of crosswalks' locations worldwide can be very useful for online maps, GPS applications and many others. In addition, the availability of zebra crossing locations on these applications can be of great use to people with disabilities, to road management, and to autonomous vehicles. However, automatically annotating this kind of data is a challenging task. They are often aging (painting fading away), occluded by vehicle and pedestrians, darkened by strong shadows, and many other factors. A common approach to tackle these problems is using the camera on the phones to help the visually impaired people. Ivanchenko et al. _cite_ developed a prototype of a cell phone application that determines if any crosswalk is visible and aligns the user to it. Their system requires some thresholds to be tuned, which may decrease performance delivered off-the-shelf. Another approach is a camera mounted on a car, usually aiming driver assistance systems. Haselhoff and Kummert _cite_ presented a strategy based on the detection of line segments. As discussed by the authors, their method is constrained to crosswalks perpendicular to the driving direction. Both perspectives (from a person _cite_ or a car _cite_) present a known limitation: there is a maximum distance in which crosswalks can be detected. Moreover, these images are quite different from those used in the work hereby proposed, i.e., satellite imagery. Nonetheless, Ahmetovic et al. _cite_ presented a method combining both perspectives. Their algorithm searches for zebra crossings in satellite images. Subsequently, the candidates are validated against Google Street View images. One of the limitations is that the precision of the satellite detection step alone, as the one proposed in this work, is _inline_eq_ lower than the combined algorithm. In addition, their system takes Nms to process a single image. Banich _cite_ presented a neural-network-based model, in which the author used N features of stripelets, i.e., pair of lines. The author states that the proposed model cannot deal with crosswalks affected by shadows and can only detect white crosswalks. The aforementioned methods _cite_ were evaluated on manually annotated datasets that were usually local (i.e., within a single city or a country) and small (from N to less than N crosswalks) . Another approach that has been increasingly investigated is the use of aerial imagery, specially satellite imagery. Herumurti et al. _cite_ employed a circle mask template matching and SURF method to detect zebra crossing on aerial images. Their method was validated on a single region in Japan and the method that detects most crosswalks took N seconds to detect N crosswalks. Ghilardi et al. _cite_ presented a model to classify crosswalks in order to help the visually impaired. Their model is based on an SVM classifier fed with manually annotated crosswalk regions. As most of the other related works, the dataset used in their work is local and small (N small patches, and N of crosswalks) . Koester et al. _cite_ proposed an SVM based on HOG and LBPH features to detect zebra crossings in aerial imagery. Although very interesting, their dataset (not publicly available) was gathered manually from satellite photos, therefore it is relatively small (N zebra crossings and _inline_eq_ negative samples) and local. In addition, their method shows a low generalization capability, because a model trained in one region shows low recall when evaluated in another (known as cross-based protocol), e.g., the recall goes from N \% to N \%. In this letter, we present a system able to automatically acquire and annotate zebra crossings satellite imagery, and train deep-learning-based models for crosswalk classification in large scale. The proposed system can be used to automatically annotate crosswalks worldwide, helping systems used by the visually impaired, autonomous driving technologies, and others. This system is the result of a comprehensive study. This study assesses the quality of the available data, the most suitable model and its performance in several imagery levels (city, country, continent and global) . In fact, this study is performed on real-world satellite imagery (almost N, N images) acquired and annotated automatically. Given the noisy nature of the data, results are also compared with human annotated data. The proposed system is able to train models that achieve N \% on a global scale.