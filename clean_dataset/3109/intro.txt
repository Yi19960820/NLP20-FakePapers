The quest to answer the deepest open questions about the cosmos has pushed astronomers and cosmologists to sample larger and larger volumes of the Universe. Current and next-generation of surveys, such as GAIA, the Dark Energy Survey (DES), LSST and the SKA will usher in an era of exascale astronomy requiring new machine learning and statistical inference tools. The LSST, for example, will image the night sky with such depth and frequency that upwards of a million transient alerts are expected every night with at least one million Type Ia supernova (SNIa) candidates detected over a decade of operations . This will swamp existing follow-up capabilities, pushing us into the era of photometric transient identification trained on small spectroscopic subsets . Such techniques will always lead to a small set of misidentifications and the danger is that the resulting contamination, unless dealt with in a sophisticated way, will lead to biased results. However, long before one reaches the final scientific analysis, the data deluge create challenges in the analysis pipeline. For example, difference images are created by subtracting a reference image from the most recent image of a given part of the sky. In the ideal case this will leave a pure noise image unless a real transient such as a supernova, asteroid or variable star exists in the image. In reality there are inevitable artefacts that occur because of instrumental effects: diffraction spikes, CCD saturation and bleeding, registration errors and the like. We thus need to disentangle the potential objects of interest from the artefacts. Historically this sorting and classification into real objects and artefacts has been done by astronomers scanning the images as soon as possible after the images have been taken. In the case of the SDSS supernova survey, this typically led to hundreds or thousands of images being scanned each night; a tedious job. Recently it has been shown that this hand scanning can be done effectively by crowdsourcing ; the public correctly identified _inline_eq_ of the spectroscopically-confirmed supernovae. However, using humans to do this classification makes it very difficult to quantify the biases that arise from the subtly different algorithms and internal decision trees in each human scanner's brain. In addition, the effective decision tree changes with time depending on the mood and tiredness of the hand-scanner which obviously cannot be characterised systematically. This human bias was partially dealt with in the SDSS supernova survey by injecting fake SNe into the pipeline yielding an average detection efficiency for each scanner, but it is clearly a fundamental limitation of human hand scanning which is even worse for crowd-sourced classifications. Apart from these biases hand scanning will not be an option for LSST due to the millions of images that will need to be scanned each night. Replacing humans with machine learning for this transient-artefact classification therefore represents an important frontier in achieving the goals of future transient surveys. Existing work includes the pioneering work of the SNfactory where features included the position, shape and FWHM of the main object, as well as distance to the nearest object in the reference image. Also of interest are the work done by the Palomar Transient Factory (PTF), where the focus falls on distinguishing between transients and variable stars and the discovery of variability in time-domain imaging surveys where classifiers output probabilistic statements about the degree to which newly observed sources are astrophysically relevant sources of variable brightness. Recently have presented a new Random Forest implementation for artefact/transient classification in the DES SN pipeline. Their feature set consisted of N features, most of which were based on analogs from and . Some of their new features were among the most important features for their classification-including flux and PSF based parameters that were obtained from their implementation of SExtractor . In contrast, we use SDSS data and derive our features from principal component analysis of the Sloan {\it g}, {\it r} and {\it i} difference images. We compare a number of different potential machine-learning algorithms such as k-nearest neighbours, artificial neural network (SkyNet--), naive Bayes and Support Vector Machine (SVM) and show that it is possible to achieve human-levels of classification completeness/recall with limited degradation in purity. In section _ref_ we describe the SDSS data used; the testing and performance measures in section _ref_ and the feature extraction and machine learning algorithms we employed are described in sections _ref_ and _ref_ . Our results are discussed in section _ref_ .