The advent of convolutional neural networks (ConvNets) for classification, regression, and prediction tasks, currently most commonly referred to as deep learning, has brought substantial improvements to many well studied problems in computer vision, and more recently, medical image computing. This field is dominated by diagnostic imaging tasks where N) all image data are archived, N) learning targets, in particular annotations of any kind, exist traditionally~ _cite_ or can be approximated~ _cite_, and N) comparably simple augmentation strategies, such as rigid and non-rigid displacements~ _cite_, ease the limited data problem. Unfortunately, the situation is more complicated in interventional imaging, particularly in ND fluoroscopy-guided procedures. First, while many X-ray images are acquired for procedural guidance, only very few radiographs that document the procedural outcome are archived suggesting a severe lack of meaningful data. Second, learning targets are not well established or defined; and third, there is great variability in the data, \eg due to different surgical tools present in the images, which challenges meaningful augmentation. Consequently, substantial amounts of clinical data must be collected and annotated to enable machine learning for fluoroscopy-guided procedures. Despite clear opportunities, in particular for prediction tasks, very little work has considered learning in this context~ _cite_ . A promising approach to tackling the above challenges is fluoroscopy generation from diagnostic ND CT, most commonly referred to as digitally reconstructed radiographs (DRRs) ~ _cite_ . Rendering DRRs from CT provides fluoroscopy in known geometry, but more importantly: Annotation and augmentation can be performed on the ND CT substantially reducing the workload and promoting valid image characteristics, respectively. However, machine learning models trained on DRRs do not generalize to clinical data since traditional DRR generation, \eg as in~ _cite_, does not accurately model X-ray image formation. To overcome this limitation we propose DeepDRR, an easy-to-use framework for realistic DRR generation from CT volumes targeted at the machine learning community. On the example of view independent anatomical landmark detection in pelvic trauma surgery~ _cite_, we demonstrate that training on DeepDRRs enables direct application of the learned model to clinical data without the need for re-training or domain adaptation.