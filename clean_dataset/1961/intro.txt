Image super-resolution (SR) aims to estimate a high-resolution (HR) image from low-resolution (LR) observations. In essence, due to the information loss in the image degradation process, SR is an ill-posed problem. The earliest works, image interpolation, estimate the HR image based on local statistics of the LR image. Typical methods include bilinear, bicubic and new edge directed interpolation that predict the HR pixels by utilizing the spatial relationship between LR and HR pixels. Later on, many successive works _cite_ regard the image SR as a Maximum-a-posteriori estimation and propose to impose various priors to constrain the inverse estimation of image SR. In these methods, priors and constraints are typically achieved in a heuristic way. Thus, it is insufficient to represent the diversified patterns of natural images. Learning based methods obtain a mapping between LR and HR images based on a large training set with dynamic learned prior knowledge. Sparse representation based methods such as _cite_ learn the map by building an LR and HR patch mapping dictionary. Neighbor embedding (NE) methods linearly combine the HR neighbors to infer the HR image. Timofte et al. _cite_ proposed an adjusted anchored neighborhood regression method for image SR. Li et al. _cite_ proposed a neighbor preserving based method which specially utilizes HR reference patches only in reconstructing the high frequency region of LR images. Recently, deep-learning based methods _cite_ are proposed. SRCNN is the first method _cite_ that utilizes a three-layer convolutional network for image SR. In _cite_, the sparse prior is incorporated into the network. Then, the residual learning _cite_ and sub-band recovery with edge guidance _cite_ networks are constructed to recover HF signal and offer state-of-the-art performance. Despite impressive results achieved by the learning-based methods, some HF information has still been lost because of the ill-posed nature of the image SR and the problem that mean squared error leads to _cite_ . As a result, a few methods have recently been proposed, which additionally compensate for HF information loss with online retrieved HR references. Yue et al. _cite_ directly utilized the references to enhance the SR result by patch matching and patch blending. Li et al. _cite_ used the retrieved HR image patches to learn more accurate sparse distribution. Liu et al. _cite_ utilized a group-structured sparse representation to further use the nonlocal dependency information of HR references. However, in these methods there are still several important issues not being fully considered. For example, their fusion methods do not effectively extract external HF information for compensation, which may even bring artifacts. Besides, they did not make full use of the internal redundancy to benefit the recovery of HF information. To address the aforementioned issues, we propose a unified deep network that additionally utilizes online retrieved data to facilitate image SR. Our work can efficiently extract an HF map from multiple HR references that are retrieved based on the intermediately inferred SR image. Contributions of this paper are as follows: N) It is the first work that efficiently extracts high-frequency information from the HR reference and successfully compensate for the HF information loss of the SR result with the deep framework. N) We show the proposed method is capable to model internal and external images jointly, achieving a more accurate and robust fusion of internal and external information for HF information recovery. N) Compared with both previous deep learning-based methods and online compensation SR methods, our approach has offered new state-of-the-art performance. The rest of the article is organized as follows. Sec. _ref_ illustrates our DHN network. Details of utilizing the EHF map for compensation are introduced in Sec. _ref_ . Experimental results are shown in Sec. _ref_ and concluding remarks are given in Sec. _ref_ .