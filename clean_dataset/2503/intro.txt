People's physical appearance plays a big role in our day-to-day interactions: it affects our first impression of others, it has an effect on whom we are attracted to, whom we find trustworthy, etc. Physical attribute prediction also has many different uses in social media, dating, recommender systems, and surveillance. Recognizing physical attributes in people is a rather easy task for humans, because by seeing different people and observing the changes in their appearance over time, our brains have been gradually trained to perform this task. Giving computers the ability to perform this task requires that exact same training. Our aim in this paper is to train models to perform this prediction using face images and Neural Networks. Machine learning is a broad area of study, and it offers many approaches for solving a problem. The advantage of deep learning over traditional machine learning algorithms is that there is no need for hand crafted features, the Deep Neural Network itself will perform feature extraction and feature engineering. Neural Networks have helped us perform some machine learning tasks much better than we ever could, but that is not all. Convolutional Neural Networks (CNNs), a specialized version of Deep Neural Networks, have revolutionized both machine learning and computer vision. They have shown great promise in tasks such as object recognition, object detection and object classification. It was with the appearance of AlexNet _cite_ and its success in the ImageNet competition _cite_ that gave rise to the popularity of Deep Neural Networks. AlexNet won the ImageNet challenge in N. After that Deep Neural Networks started to get wider, deeper and more complex. To investigate the effect of network depth on accuracy, VGG was released by Karen Simonyan et al. _cite_ . Rasmus Rothe et al. _cite_ finetuned VGG for apparent age estimation and won ChaLearn LAP competition in N. After the success of VGG, deeper network architectures such as Inception _cite_ and ResNet _cite_ were developed . In this paper, we tackle the task of physical attribute prediction from face images. We created our own dataset containing N, N images, details for which is given in table _ref_ . We also train N models to predict the attributes in the famous CelebA dataset. Physical attribute prediction from face images is a difficult task because of the non-standard ways these photographs were taken in, difference in light conditions, angle of the pictures, distance to the camera and background noise. Our models were trained to predict body type, ethnicity, gender, height and weight on our own dataset and to predict the attributes provided in CelebA. Our contributions in this paper are: The rest of the paper is organized as follows: Section _ref_ reviews some of the related work done in recent years. Section _ref_ introduces our dataset (FIRW) and CelebA. In Section _ref_ we present details of FIRW, the CelebA data set, network architectures and training details. Section _ref_ shows the results of our experiments. Finally, Section _ref_ concludes the paper.