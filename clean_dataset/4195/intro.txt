Quantification of left ventricle (LV) from cardiac imaging is among the most clinically important and most frequently demanded tasks for identification and diagnosis of cardiac disease~ _cite_, yet still a challenging task due to the high variability of cardiac structure across subjects and the complicated global/regional temporal dynamics. Full quantification, i.e., to simultaneously quantify all LV indices including two areas, six regional wall thicknesses (RWT), three LV dimension, and one phase (as shown in Fig.~ _ref_), providing more detailed information for comprehensive cardiac function assessment, is even more challenging since the uncertain relatedness intra and inter each type of indices may hinder the learning procedure from better convergence and generalization. In this work, we propose a newly-designed deep multitask learning network FullLVNet for full quantification of LV respecting both intra-and inter-task relatedness. In clinical practice, obtaining reliable quantification is subjected to measuring on segmented myocardium, which is usually obtained by manually contouring the borders of myocardium~ _cite_ or manual correction of contours~ _cite_ generated by LV segmentation algorithms~ _cite_ . However, manually contouring is time-consuming, of high inter-observer variability, and typically limited to the end diastolic (ED) and end systolic (ES) frames, which makes it insufficient for dynamic function analysis. LV segmentation algorithms, despite the recent advances, is still a difficult problem due to the lack of edge information and presence of shape variability. Most existing segmentation methods for cardiac MR images~ _cite_ requires strong prior information and user interaction to obtain reliable results, which may prevent them from efficient clinical application. In recent years, direct methods without segmentation have grown in popularity in cardiac volumes estimation~ _cite_ . Although these methods obtained effective performance by leveraging state-of-art machine learning techniques, they suffer from the following limitations. N) Lack of powerful task-aware representation. The vulnerable hand-crafted or task-unaware features are not capable of capturing sufficient task-relevant cardiac structures. N) Lack of temporal modeling. Independently handling each frame without assistance from neighbors can not guarantee the consistency and accuracy. N) Not end-to-end learning. The separately learned representation and regression models cannot be optimal for each other. N) Not full quantification. Only cardiac volume alone is not sufficient for comprehensive global, regional and dynamic function assessment. In this paper, we propose a newly-designed multitask learning network (FullLVNet), which is constituted by a specially tailored deep CNN for expressive feature embedding; two followed parallel RNN modules for temporal dynamic modeling; and four linear models for the final estimation. During the final estimation, FullLVNet is capable of improving the generalization by N) modeling intra-task relatedness through group lasso regularization within each regression task; and N) modeling inter-task relatedness with three phase-guided constraints that penalize violation of the temporal behavior of LV indices. After being trained with a two-step strategy, FullLVNet is capable of delivering accurate results for all the considered indices of cardiac LV.