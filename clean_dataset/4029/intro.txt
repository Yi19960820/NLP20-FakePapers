Acoustic sensors (Sonar) are typical choices for Autonomous Underwater Vehicles, as this kind of device can sense in any kind of water environment, including turbid and low light conditions. The robust interpretation of Sonar data is still a challenge. Recently there have been efforts to apply Deep Neural Networks to Sonar data, with great success. But in general, designing and tuning neural networks require large efforts from developers, as well as large amounts of training data. If such datasets are not available, a neural network cannot be used. A related concept to neural networks is transfer learning (TL), where the feature vectors learned by a Convolutional Neural Network (CNN) is used to solve a different problem, usually object detection and/or recognition. Reports _cite_ have been made that feature vectors obtained from a CNN trained on the ImageNet dataset _cite_ can be used to classify completely different images, showcasing that a CNN does indeed learn generic features that can be used for other tasks. But these kind of results are only possible due to the existence of the ImageNet dataset. There are related open research questions, such as, can similar results be obtained in much smaller datasets? How does the size of the training set influence classification accuracy? While the underwater robotics community does not possess a dataset in the scale of ImageNet _cite_, we do have a small dataset of N images captured with an ARIS Explorer N Forward-Looking Sonar. These images contain N different kinds of objects (mostly marine debris) plus a background class. We propose the use of this dataset to evaluate some of the limits of CNNs in sonar images. In this paper we evaluate three separate problems with respect to their limits: The main contribution of this work is the experimental evaluation of the effect of transfer learning, object size and training set sizes on recognition accuracy in sonar images. We believe our key results are: that CNN can produce high accuracy classifiers that are invariant to object size, specific recommendations for training with small datasets, either by using regularization or by transfer learning.