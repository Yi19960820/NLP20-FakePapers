Though quite challenging, recovering the ND full-body human pose from a monocular RGB image sequence has recently attracted a lot of research interests due to its huge potentials on high-level applications, which includes human-computer interaction~ _cite_, surveillance~ _cite_, video browsing/indexing~ _cite_ and virtual reality~ _cite_ . Besides the challenges shared with ND image pose estimation (e.g., large variation in human appearance, arbitrary camera viewpoints and obstructed visibilities due to external entities and self-occlusions), ND articulated pose recovery from monocular imagery is much more difficult since ND pose is inherently ambiguous from a geometric perspective~ _cite_, as shown in Fig.~ _ref_ . To resolve all these issues, a preferable way is to investigate how to simultaneously enforce ND spatial relationship, ND geometry constraint and temporal consistency within one single model. Recently, notable successes have been achieved for ND pose estimation based on ND part models coupled with ND deformation priors, \eg, _cite_, and the deep learning techniques, \eg, _cite_ . However, these methods have not explored the ND pose geometry that is crucial for ND pose estimation. There has been some limited attempts on combining the image-based ND part detectors, ND geometric pose priors and temporal models for generating ND poses _cite_ . They mainly follow two kinds of pipelines: the first _cite_ resorts to the model-based ND pose reconstruction by using external ND pose gallery, while the second pipeline _cite_ focuses on elaborately designing human body kinematic constraints with the model training. These separate techniques and prior knowledge make their models very sophisticated. Hence, validating the effectiveness of their each component is also not straightforward. In contrast to all these mentioned methods, we introduce a completely data-driven approach that learns to integrate the ND spatial relationship, ND geometry and temporal smoothness for the network training in a fully differential way. We propose a novel Recurrent ND Pose Sequence Machine (RPSM) for estimating ND human poses from a sequence of images. Inspired by the pose machine _cite_ and convolutional pose machine _cite_ architectures for ND pose estimation, our RPSM proposes a multi-stage training to capture long-range dependencies among multiple body-parts for ND pose prediction, and further enforce the temporal consistency between the predictions of sequential frames. Specifically, the proposed RPSM recursively refines the predicted ND pose sequences by sensing what already achieved in the previous stages, i.e., ND pose representations and previously predicted ND poses. At each stage, our RPSM is composed by a ND pose module, a feature adaption module, and a ND pose recurrent module. These three modules are constructed by the integration of the advanced convolutional and recurrent neural networks to fully exploit spatial and temporal constraints, which makes our RPSM with multi-stages a differentiable architecture that can be trained in an end-to-end way. As illustrated in Fig.~ _ref_, our RPSM enables to gradually refine the ND pose prediction for each frame with multiple sequential stages, contributing to seamlessly learning the image-dependent constraint between multiple body parts and sequence-dependent context from the previous frames. Specifically, at each stage, the ND pose module takes each frame and ND feature maps produced in previous stages as inputs and progressively updates the ND pose representations. Then a feature adaption module is injected to transform learned pose representations from ND to ND domain. The ND pose recurrent module, constructed by a Long-Short Term Memory (LSTM) layer, can thus regress the ND pose estimation by combining the three lines of information, \ie the transformed ND pose representations, ND joint prediction from the previous stage and the memorized states from past frames. Intuitively, the ND pose representations are conditioned on the monocular image which captures the spatial appearance and context information. The ND joint prediction implicitly encodes the ND geometry structural information by aggregating multi-stage computation. Then temporal contextual dependency is captured by the hidden states of LSTM units, which effectively improves robustness of the ND pose estimations over time. The main contribution of this work is three-fold. i) We propose a novel RPSM model that learns to recurrently integrate rich spatial and temporal long-range dependencies using a multi-stage sequential refinement, instead of relying on specifically manually defined body smoothness or kinematic constraints. ii) Casting the recurrent network models to sequentially incorporate ND pose geometry structural information is innovative in literature, which may also inspire other ND vision tasks. iii) Extensive evaluations on the public challenging N dataset _cite_ and HumanEva-I dataset _cite_ show that our approach outperforms existing methods of ND human pose estimation by large margins.