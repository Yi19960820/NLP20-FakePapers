Image classification~ _cite_ and object detection~ _cite_ have been improved significantly by development of deep convolutional networks~ _cite_ . However, object detection is still more challenging than image classification as it aims at both localizing and classifying objects. Accurate localization of objects in each image requires both well-processed ``candidate'' object locations and ``selected refined'' boxes with precise locations. Looking at the object detection problem as an extractive image summarization and representation task, the set of all predicted bounding boxes per image should be as informative and non-repetitive as possible. The Region-based Convolutional Network methods such as Fast and Faster R-CNN~ _cite_ proposed an efficient approach for object proposal classification and localization with a multi-task loss function during training. The training process in such methods contains a fine-tuning stage, which jointly optimizes a softmax classifier and a bounding-box regressor. Such a bounding box regressor tries to minimize the distance between the candidate object proposals with their corresponding ground-truth boxes for each category of objects. However, it does not consider relation ``between'' boxes in terms of location and context while learning a representation model. In this paper, we propose a new loss layer added to the other two softmax classifier and bounding-box regressor layers (all included in the multi-task loss for training the deep model) which formulates the discriminative contextual information as well as mutual relation between boxes into a Determinantal Point Process (DPP) ~ _cite_ loss function. This DPP loss finds a subset of diverse bounding boxes using the outputs of the other two loss functions (namely, the probability of each proposal to belong to each object category as well as the location information of the proposals) and will reinforce them in finding more accurate object instances in the end, as illustrated in Figure~ _ref_ . We employ our DPP loss to maximize the likelihood of an accurate selection given the pool of overlapping background and non-background boxes over multiple categories. Inference in state-of-the-art detection methods~ _cite_ is generally based on Non-Maximum Suppression (NMS), which considers only the overlap between candidate boxes per class label and ignores their semantic relationship. We propose a DPP inference scheme to select a set of non-repetitive high-quality boxes per image taking into account spatial layout, category-level analogy between proposals, as well as their quality score obtained from deep trained model. We call our proposed model as ``Learning Detection with Diverse Proposals Network--LDDP-Net''. Our proposed loss function for representation enhancement and more accurate inference can be applied on any deep network architecture for object detection. In our experiments below we focus on the Faster R-CNN model to show the significant performance improvement added by our DPP model. We demonstrate the effect of our proposed DPP loss layer in accurate object localization during training as well as inference on the benchmark detection data sets PASCAL VOC and MS COCO based on average precision and average recall detection metrics. To sum up, we make following contributions in this work: LDDP Code is available at _url_ .