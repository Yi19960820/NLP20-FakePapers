Action recognition and description~ _cite_ of videos are fundamental tasks and challenges for computer vision. And they have received significant amount of attention in the research community. With the rapid development of deep Convolution Neural Network (CNN) ~ _cite_ and Recurrent Neural Network (RNN) ~ _cite_ recently, lots of state-of-art methods ~ _cite_ adopt them to extract features of different single frames. Nevertheless, when we attempt to extend image classification tasks to action recognition tasks, the key problem is how to obtain temporal information in videos. Current methods can be mainly categorized into two classes. One is to incorporate tracking using either trajectory-based approaches or attention models, the other is to adopt N-d convolution. In this paper, we proposed a novel multi-level and deep supervised method using attention model, which is robust to either intra-class variance or inter-class similarity. We also proposed a soft supervised regularization term to enhance performance in our model. Our main contribution are three folds. The paper is organized as follows: In Section N, we introduce current approaches to obtain temporal information in videos. Then, we describe our model in detail in Section N. After that, we show our experiments and evaluation in Section N and N respectively. Finally, we present our conclusion and potential future work in Section N.