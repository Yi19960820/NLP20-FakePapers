Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in the tasks of image recognition and object detection. CNNs are organized in successive computational layers alternating between convolution and pooling (sub-sampling) . Compared to other types of deep neural networks, CNNs are relatively easy to train with back-propagation mainly because they have a very sparse connectivity in each layer _cite_ . In a convolutional layer, linear filters are used for convolution. The main parameters of CNNs are the parameters (i.e., weights) of the filters. To reduce the number of parameters, a parameter sharing strategy is adopted. Although parameter sharing reduces the capacity of the networks, it improves its generalization ability (Sec. N, _cite_) . The computational layers can be enhanced by replacing the linear filter with a non-linear function: shallow MultiLayer Perceptron (MLP) _cite_ . The CNN with shallow MLP is called NiN _cite_ . With enough hidden units, MLP can represent arbitrary complex but smooth functions and hence can improve the separability of the extracted features. So NiN is able to give lower recognition error than classical CNN. As a filter in CNNs, a shallow MLP convolves across the input channels. Because the filter itself is also a network, the resulting CNN is called Network in Network (NiN) . But the MLP in NiN does not employ sparse connectivity. Instead, MLP is a fully connected network. So many parameters of MLP have to be computed and stored. This limits the performance of NiN. To breakthrough the limitation, in this paper we propose to modify the fully connected MLP to a locally connected one. This is accomplished by leveraging a kernel (a.k.a., filter) on each layer (or some layers) of the MLP. That is, the size of the kernel is smaller than that of the input. Because the convolution operation is conducted in the embedded MLP of the convolution neural networks, we call the proposed method Convolution in Convolution (CiC) . In summary, the contributions of the paper and the merits of the proposed CiC are as follows. The rest of the paper is organized as follows. We review related work in Section II. The proposed method is presented in Section III. Subsequently, experimental results are provided in Section IV. We then conclude in Section V based on these experimental results.