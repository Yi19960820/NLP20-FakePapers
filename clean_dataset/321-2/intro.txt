\secvspace Object detectors have become significantly more accurate (\eg, _cite_) and gained important new capabilities. One of the most exciting is the ability to predict a foreground segmentation mask for each detected object (\eg, _cite_), a task called . In practice, typical instance segmentation systems are restricted to a narrow slice of the vast visual world that includes only around N object categories. A principle reason for this limitation is that state-of-the-art instance segmentation algorithms require and such supervision may be limited and expensive to collect for new categories _cite_ . By comparison, bounding box annotations are more abundant and less expensive _cite_ . This fact raises a question: Is it possible to train high-quality instance segmentation models without complete instance segmentation annotations for all categories? With this motivation, our paper introduces a new instance segmentation task and proposes a novel transfer learning method to address it. We formulate the partially supervised instance segmentation task as follows: (N) given a set of categories of interest, a small has instance mask annotations, while the other categories have only bounding box annotations; (N) the instance segmentation algorithm should utilize this data to fit a model that can segment instances of object categories in the set of interest. Since the training data is a mixture of strongly annotated examples (those with masks) and weakly annotated examples (those with only boxes), we refer to the task as . The main benefit of partially supervised \vs weakly-supervised training (\cf _cite_) is it allows us to build a large-scale instance segmentation model by exploiting both types of existing datasets: those with bounding box annotations over a large number of classes, such as Visual Genome _cite_, and those with instance mask annotations over a small number of classes, such as COCO _cite_ . As we will show, this enables us to scale state-of-the-art instance segmentation methods to thousands of categories, a capability that is critical for their deployment in real world uses. To address partially supervised instance segmentation, we propose a novel approach built on Mask R-CNN _cite_ . Mask R-CNN is well-suited to our task because it decomposes the instance segmentation problem into the subtasks of bounding box object detection and mask prediction. These subtasks are handled by dedicated network `heads' that are trained jointly. The intuition behind our approach is that once trained, the parameters of the bounding box head encode an embedding of each object category that enables the transfer of visual information for that category to the partially supervised mask head. We materialize this intuition by designing a parameterized that is trained to predict a category's instance segmentation parameters as a function of its bounding box detection parameters. The weight transfer function can be trained end-to-end in Mask R-CNN using classes with mask annotations as supervision. At inference time, the weight transfer function is used to predict the instance segmentation parameters for category, thus enabling the model to segment all object categories, including those without mask annotations at training time. We explore our approach in two settings. First, we use the COCO dataset _cite_ to simulate the partially supervised instance segmentation task as a means of establishing quantitative results on a dataset with high-quality annotations and evaluation metrics. Specifically, we split the full set of COCO categories into a subset with mask annotations and a complementary subset for which the system has access to only bounding box annotations. Because the COCO dataset involves only a small number (N) of semantically well-separated classes, quantitative evaluation is precise and reliable. Experimental results show that our method improves results over a strong baseline with up to a N \% relative increase in mask AP on categories without training masks. In our second setting, we train a instance segmentation model on N categories using the Visual Genome (VG) dataset _cite_ . VG contains bounding box annotations for a large number of object categories, however quantitative evaluation is challenging as many categories are semantically overlapping (\eg, near synonyms) and the annotations are not exhaustive, making precision and recall difficult to measure. Moreover, VG is not annotated with instance masks. Instead, we use VG to provide output of a large-scale instance segmentation model. Output of our model is illustrated in Figure _ref_ and _ref_ .