Face verification/recognition has been developing rapidly in recent years, which facilitates a wide range of intelligent applications such as surveillance video analysis, mobile authentication, etc. Since these frequently-used applications generate a huge amount of data that requires to be transmitted or stored, a highly efficient facial image compression is broadly required as illustrated in Fig. _ref_ . Basically, facial image compression can be regarded as a special application of general image compression technology. While evolution of general image/video compression techniques has been focused on continuously improving Rate Distortion performance, viz. reducing the compressed bit rate under the same distortion between the reconstructed pixels and original pixels or reducing the distortion under the same bit rate. The apparent question is how to define the distortion metric, especially for specific application scenario such as face recognition in surveillance. Usually we can classify the distortion into three levels of distortion metrics: Pixel Fidelity, Perceptual Fidelity, and Semantic Fidelity, according to different levels of human cognition on image/video signals. The most common metric is Pixel Fidelity, which measures the pixel level difference between the original image and compressed image, e.g., MSE (Mean Square Error) has been widely adopted in many existed image and video coding techniques and standards (e.g., MPEG-N, H.N, HEVC, etc.) . It can be easily integrated into image/video hybrid compression framework as an in-loop metric for rate-distortion optimized compression. However, it's obvious that pixel fidelity metric cannot fully reflect human perceptual viewing experience _cite_ . Therefore, many researchers have developed Perceptual Fidelity metrics to investigate objective metrics measuring human subjective viewing experience _cite_ . With the development of aforementioned intelligent applications, image/video signals will be captured and processed for semantic analysis. Consequently, there will be increasingly more requirements on research for Semantic Fidelity metric to study the semantic difference (e.g., difference of verification accuracy) between the original image and compressed image. There are few research work on this area _cite_ and usually are task-specific. The aforementioned various distortion metrics provide a criteria to measure the quality of reconstructed content. However, the ultimate target of image quality assessment is not only to measure the quality of images with different level of distortion, but also to apply these metrics to optimize image compression schemes. While it's a contradictory that most complicated quality metrics with high performance are not able to be integrated easily into an image compression loop. Some research works tried to do this by adjusting image compression parameters (e.g., Quantization parameters) heuristically according to embedded quality metrics _cite_, but they are still not fully automatic-optimized end-to-end image encoder with integration of complicated distortion metrics. In this paper, we are trying to solve this problem by developing a Learning based Facial Image Compression (LFIC) framework, to make it feasible to automatically optimize coding parameters according to gradient feedback from the integrated hybrid facial image distortion metric calculation module. Different from traditional hybrid coding framework with prediction, transform, quantization and entropy coding modules, we separate these different modules inside or outside the end-to-end loop according to their derivable property. We demonstrated the efficiency of this framework with the simplest prediction, quantization and entropy coding module. We propose a new module called Regionally Adaptive Pooling (RAP) inside the end-to-end loop to improve the ability to configure compression performance. RAP has advantages of being able to control bit allocation according to distortion metrics' feedback under a given bit budget. Face verification accuracy is adopted as one semantic distortion metric to be integrated into LFIC framework. Although we adopt the simplest prediction, quantization and entropy coding module, the LFIC framework has shown great improvement over traditional codec like JPEGN, WebP and neural network-based codecs, and also demonstrates much better performance compared with existing specific facial image compression schemes. The visualization as illustrated in Fig. _ref_ shows that more focus is on the distinguishable regions (e.g., eye, nose) according to face verification metric. Also, it demonstrates that our LFIC framework can automatically capture the information in critical areas based on semantic distortion metric. In general, our contributions are four-folds: N) a Learning based Facial Image Compression framework; N) a novel pooling strategy called RAP; N) a successful exploration to apply Generative Adversarial Network (GAN) as metric to compression directly; N) a starting exploration for semantic based image compression.