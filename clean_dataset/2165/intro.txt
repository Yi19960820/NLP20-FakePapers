In video to depth, the task is to estimate depth from a video sequence. The problem has traditionally been approached using Structure from Motion (SfM), which takes a collection of images as input, and jointly optimizes over ND structure and camera motion . The resulting camera parameter estimates can be used as input to Multi-View Stereo in order to build a more complete ND representation such as surface meshes and depth maps ~ . In parallel, deep learning has been highly successful in a number of ND reconstruction tasks. In particular, given ground truth depth, a network can learn to predict depth from a single image, stereo images, or collections of frames . One advantage of deep networks is that they can use single-image cues such as texture gradients and shading as shown by their strong performance on depth estimation from a single image~ . Furthermore, differentiable network modules can be composed so that entire pipelines (i.e. feature extraction, feature matching, regularization) can be learned directly from training data. On the other hand, as recent work has shown, it is often hard to train generic network layers to directly utilize multiview geometry (e.g. \@ using interframe correspondence to recover depth), and it is often advantageous to embed knowledge of multiview geometry through specially designed layers or losses . In this work, we continue the direction set forth by recent works~ that combine the representation ability of neural networks with the geometric principles underlying image formation. We propose DeepVND, a composition of classical geometrical algorithms which we turn into differentiable network modules and combine into an end-to-end trainable architecture. DeepVND interleaves two stages: camera motion estimation and depth estimation (Figure _ref_) . The motion module takes depth as input, and outputs an incremental update to camera motion. The depth module takes camera motion as input, and performs stereo reconstruction to predict depth. At test time, DeepVND acts as block coordinate descent, alternating between updating depth and camera motion. To estimate camera motion we introduce Flow-SEN, a new motion estimation architecture, which outputs an incremental update to camera motion. Flow-SEN takes depth as input, and estimates dense ND correspondence between pairs of frames. We unroll a single iteration of Perspective-n-Point (PnP) performing Gauss-Newton updates over SEN perturbations to minimize geometric reprojection error. The new estimate of camera motion can then be fed back into Flow-SEN, which re-estimates correspondence for a finer grain pose update. Our Depth Module builds upon prior work~ and formulates multiview-stereo (MVS) reconstruction as a single feed-forward network. Like classical MVS, we leverage geometry to build a cost volume over video frames, but use trainable network for both feature extraction and matching. Our work shares similarities with prior works~ that also combine deep learning and multiview geometry, but is novel and unique in that it essentially ``differentializes'' a classical SfM pipeline that alternates between stereopsis, dense ND feature matching, and PnP. As a comparison, DeMon~ and DeepTAM~ differentialize stereopsis and feature matching, but not PnP because they use a generic network to predict camera motion. Another comparison is with BA-Net~, whose classical analogue is performing bundle adjustment from scratch to optimize feature alignment over camera motion and the coefficients of a limited set of depth maps (depth basis) . In other words, BA-Net performs one joint nonlinear optimization over all variables, whereas we decompose the joint optimization into more tractable subproblems and do block coordinate descent. Our decomposition is more expressive in terms of reconstruction since we can optimize directly over per-pixel depth and are not constrained by a depth basis, which can potentially limit the accuracy of the final depth. In our experiments, we demonstrate the effectiveness of DeepVND across a variety of datasets and tasks, and outperform strong methods such as DeepTAM, DeMoN, BANet, and MVSNet . As we show, alternating depth and motion estimation quickly converges to good solutions. On all datasets we outperform all existing single-view and multi-view approaches. We also show superior cross-dataset generalizability, and can outperform existing methods even when training on entirely different datasets.