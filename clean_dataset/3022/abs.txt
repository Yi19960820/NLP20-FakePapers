{Human actions in video sequences are three-dimensional~ (ND) spatio-temporal signals characterizing both the visual appearance and motion dynamics of the involved humans and objects. Inspired by the success of convolutional neural networks~ (CNN) for image classification, recent attempts have been made to learn ND CNNs for recognizing human actions in videos. However, partly due to the high complexity of training ND convolution kernels and the need for large quantities of training videos, only limited success has been reported. This has triggered us to investigate in this paper a new deep architecture which can handle ND signals more effectively. Specifically, we propose ~ (_inline_eq_) that factorize the original ND convolution kernel learning as a sequential process of learning ND spatial kernels in the lower layers (called spatial convolutional layers), followed by learning ND temporal kernels in the upper layers (called temporal convolutional layers) . We introduce a novel transformation and permutation operator to make factorization in _inline_eq_ possible. Moreover, to address the issue of sequence alignment, we propose an effective training and inference strategy based on sampling multiple video clips from a given action video sequence. We have tested _inline_eq_ on two commonly used benchmark datasets (and) . Without using auxiliary training videos to boost the performance, _inline_eq_ outperforms existing CNN based methods and achieves comparable performance with a recent method that benefits from using auxiliary training videos.}