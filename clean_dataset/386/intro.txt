Recognizing correctly actions in untrimmed videos is an important but challenging problem in computer vision. The core difficulties are occlusions, viewpoint, lighting condition and so on _cite_ . Recently, cost-effective and easy-to-use depth cameras, e.g. Microsoft Kinect _inline_eq_ sensor or Intel RealSense, have integrated the real-time skeleton tracking algorithms _cite_, providing ND structural information of human motion. This data source is robust to illumination changes, also invariant to camera viewpoints. Thus, exploiting skeletal data for ND action recognition becomes a very effective research direction. Previous works on Skeleton-based Action Recognition (SAR) can be divided into two main groups: SAR using hand-crafted features and SAR with deep learning networks. The first group _cite_ uses hand-crafted local features and probabilistic graphical models such as Hidden Markov Model (HMM) _cite_, Conditional Random Field (CRF) _cite_, or Fourier Temporal Pyramid (FTP) _cite_ to classify actions. Almost all of these approaches are data-dependent and require a lot of feature engineering. The second group _cite_ considers SAR as a time-series problem and proposes the use of Recurrent Neural Networks with Long-Short Term Memory units (RNN-LSTMs) _cite_ to model the contextual information of the skeletons. Although RNN-LSTMs are able to model the long-term temporal of motion and have advanced the state-of-the-art, this approach just considers skeleton sequences as a kind of the low-level feature, by feeding raw skeletons directly into the network input. The huge number of input features makes RNNs become very complex and may easily lead to overfitting. Moreover, many RNN-LSTMs act as a classifier and can not extract high-level features _cite_ for recognition tasks. \hspace* {N} We believe that an effective representation of motion is the key factor influencing the performance of a SAR model. Different from previous studies, this paper introduces a novel representation based on skeletal data for ND action recognition with D-CNNs. To best represent the characteristics of ND actions, we exploit body poses (P ose F eatures-PF s) and their motions (M otion F eatures-MF s) for building a new representation called SPMF (S keleton P ose-M otion F eature) . Each SPMF contains important characteristics related to the spatial structure and temporal dynamics of skeletons. A new deep framework based on the Inception Residual networks (Inception-ResNets _cite_) is then proposed for learning and classifying actions, as shown in Figure~ _ref_ . Generally speaking, four hypotheses motivate our exploration of using D-CNNs for SAR are: (N) human actions can be correctly represented via the movement of skeletons; (N) the spatial-temporal dynamics of skeletons can be transformed into a ND image structure--a representation that can be effectively learned by learning methods as D-CNNs; (N) compared to RGB and depth modalities, skeletons are high-level information while with much less complexity than RGB-D sequences, making action learning model much simpler and faster; (N) a well-designed and deeper CNN can improve learning accuracy. Our experimental results on two benchmark datasets confirmed these statements. \hspace* {N} The main contributions of this paper can be summarized as follows: First, we investigate and propose a novel skeleton-based representation, namely SPMF, for ND action recognition. Second, we design and optimize new D-CNNs based on Inception-ResNet for learning motion features from SPMF in an end-to-end learning framework. To the best of our knowledge, this is the first time a very deep network as Inception-ResNet is exploited for SAR. Last, the proposed method set a new state-of-the-art on the MSR ActionND and the NTU-RGB + D datasets. In the next section, we introduce the SPMF representation and the proposed deep learning networks. Experiments and their results are provided in Section~ _ref_ . Section~ _ref_ concludes the paper and discusses the future work.