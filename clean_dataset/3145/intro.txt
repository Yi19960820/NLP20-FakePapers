Deep neural networks have been used successfully to learn meaningful representations on a variety of tasks~ . By adding more hidden units or layers, we can learn more complicated relationships between sensory data and desired outputs. However, increasing the model complexity incurs an enormous solution space. Thus, regularization techniques have been normally combined with deep neural networks to obtain acceptable solutions. Previous regularization techniques involve designing efficient training schemes [\ie, dropout~, DropConnect~, and Batch Normalization~] and well-structured networks [\ie, Network In Network~, and Inception~] . Even with these cutting-edge techniques, deep neural networks are still prone to performance degradation when certain small perturbations are injected to samples. The perturbations, which are barely perceptible to humans but make neural networks easily less confident, are called adversarial examples ~ . This phenomenon occurs due to fewer training examples than parameters and the inner products of high-dimensional vectors~ . In the case of fully connected layers, activation grows by _inline_eq_ in the worst-case, when _inline_eq_ components of an inner product are changed by _inline_eq_ . As shown in Fig.~ _ref_ (a), decision boundaries constructed by deep networks are wiggly and sensitive to adversarial perturbations. In~ _cite_ in particular, adversarial training was proposed to minimize classification loss both on given samples and adversarial examples. This type of training helps neural networks to increase the confident scores of corrupted samples and generalize across different clean examples. However, the gradients of a discriminative objective function may vanish when the gradients of both the original and adversarial examples are aggregated. To resolve this issue, we present a new network called manifold regularized networks (MRnet), which regularizes deep neural networks based on the concept of manifold learning. Manifold learning refers to methodologies based on the manifold hypothesis in which nearest samples in a high-dimensional input space are also nearest pairs on a manifold of much lower dimensionality. As traditional manifold learning [\ie, ISOMAP~, Locally Linear Embedding~, and t-SNE~] are well-formulated to find transformation preserving geodesic distances in high-dimensional space, they demonstrate limited performance in practice because of insufficient nearest training samples (Fig.~ _ref_ (b)) . There have been many attempts~ to unify deep learning and manifold learning. These studies have common limitations inherited from those of the original manifold learning. In this paper, we incorporate an explicit penalty term to conserve neighborhood relationships into deep neural networks. With the penalty term, we can preserve neighborhood relationships, which is a objective of manifold learning. Here, we address common limitations of deep networks and manifold learning. We generate adversarial examples which are close enough training samples, and then make neural networks insensitive to adversarial perturbations by embedding the adversarial's near to original samples. Similar to popular deep learning techniques, the manifold penalty can be applied easily to gradient-based optimization. We demonstrate that our method can not only improve classification performances but also find appropriate manifold representations for three benchmark datasets. Especially, the low-dimensional embedding results show effective representations than alternatives.