Estimating the full ND pose of a human from a single RGB image is one of the most challenging problems in computer vision. It involves tackling two inherently ambiguous tasks. First, the ND location of the human joints, or landmarks, must be found in the image, a problem plagued with ambiguities due to the large variations in visual appearance caused by different camera viewpoints, external and self occlusions or changes in clothing, body shape or illumination. Next, lifting the coordinates of the ND landmarks into ND from a single image is still an ill-posed problem--the space of possible ND poses consistent with the ND landmark locations of a human, is infinite. Finding the correct ND pose that matches the image requires injecting additional information usually in the form of ND geometric pose priors and temporal or structural constraints. We propose a new joint approach to ND landmark detection and full ND pose estimation from a single RGB image that takes advantage of reasoning jointly about the estimation of ND and ND landmark locations to improve both tasks. We propose a novel CNN architecture that learns to combine the image appearance based predictions provided by style ND landmark detectors~ _cite_, with the geometric ND skeletal information encoded in a novel pretrained model of ND human pose. Information captured by the ND human pose model is embedded in the CNN architecture as an additional layer that lifts ND landmark coordinates into ND while imposing that they lie on the space of physically plausible poses. The advantage of integrating the output proposed by the ND landmark location predictors--based purely on image appearance--with the ND pose predicted by a probabilistic model, is that the ND landmark location estimates are improved by guaranteeing that they satisfy the anatomical ND constraints encapsulated in the human ND pose model. In this way, both tasks clearly benefit from each other. A further advantage of our approach is that the ND and ND training data sources may be completely independent. The deep architecture only needs that images are annotated with ND poses, not ND poses. The human pose model is trained independently and exclusively from ND mocap data. This decoupling between ND and ND training data presents a huge advantage since we can augment the training sets completely independently. For instance we can take advantage of extra ND pose annotations without the need for ND ground truth or extend the ND training data to further mocap datasets without the need for synchronized ND images. In this work, we show how to integrate a prelearned ND human pose model directly within a novel CNN architecture (illustrated in figure~ _ref_) for joint ND landmark and ND human pose estimation. In contrast to preexisting methods, we do not take a pipeline approach that takes ND landmarks as given. Instead, we show how such a model can be used as part of the CNN architecture itself, and how the architecture can learn to use physically plausible ND reconstructions in its search for better ND landmark locations. Our method achieves state-of-the-art results on the N dataset both in terms of ND and ND errors.