The importance of small obstacle discovery for on-road autonomous driving cannot be overstated. Small obstacles such as bricks, stones and rocks pose a veritable hazard to driving, especially to the state estimation modules that are a core constituent of such systems. Some times these obstacles can take the shape of stray dogs and cats that are entailed protection. Many a time these objects are too low on the road and go unnoticed on depth and point cloud maps obtained from state of the art range sensors such as ND LIDAR. The problem slowly seems to be generating interest in the robotic and vision community _cite_, not without a reason. For one, even the best of range sensors such as ND LIDAR can find segmenting obstacles of height N-Ncms from a distance of Nm or more rather challenging. The problem is more pronounced with low cost low baseline stereo rigs, wherein the disparity profile can hardly be used to discern such obstacles from the background when they are at a depth of Nm or more. Introspection reveals that the problem is difficult to solve purely based on appearance cues even with the best of the state of the art deep convolutional networks since gradients in the image can be caused equally due to changes in appearance such as markings and zebra crossings on the road as much as it could be due to obstacle edges. This problem aggravates in case the obstacles are small. Hence, an apt combination of both appearance and depth or disparity evidences is more likely to perform the task better. Recent efforts~ _cite_ on multi modal fusion also suggests likewise. Most of the previous works~ _cite_ in small obstacle detection are based on low level image and depth profile analysis, which are prone to errors due to noise in depth computation (especially while using a stereo rig) . The challenge in naive application of recently successful deep learning architectures is the limited availability of annotated data. In this paper, we propose a novel deep learning architecture called MergeNet which can be trained using as low as N images to obtain state of the art results. We pose the problem of obstacle detection as that of segmenting the road scene into multiple classes. The proposed model consists of three key networks, namely the stripe-net, the context-net and the refiner-net. Stripe-net is a fully convolutional encoder-decoder model which is trained with column-wise strips of RGBD input (each training image is divided into a set of non overlapping vertical strips and fed to the network individually) . The key idea behind Stripe-net is twofold: (a) learning discriminative features at a low-level by only attending to the vertical pathway of a road scene and (b) sharing parameters across the stripes to ensure lower model complexity and in turn reducing susceptibility to overfit even on small datasets. Context-net is also a fully convolutional encoder-decoder, but is trained on the full image. The role of this network is to incorporate global features which typically span a width higher than the stripe-width used in the previous network. Global coherence and important contextual cues are more suitably learnt using this network. Finally, the refiner-net is used for aggregating both the low and high level features and making the final prediction. Figure~ _ref_ illustrates a motivating example, showing the results at different stages of the proposed architecture. Formally, we make the following contributions: The rest of the paper is organized as follows: Section~ _ref_ lists the related work. The proposed architecture is detailed in Section~ _ref_ . The experiments and results are presented in Section~ _ref_ and Section~ _ref_ . The final section comprises of conclusions and future work.