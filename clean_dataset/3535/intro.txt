Generative models of human identity and appearance have broad applicability to behavioral science and technology. For example, psychologists and neuroscientists can use them to create experimental stimuli, varying the degree of similarity between a target face and a lineup of other faces to test an observer's face recognition abilities. Computer vision researchers can use them to create face-detection and face-recognition technologies for applications in security and social media. And artists can use them to create engaging animated characters in video games. Any generative model of human identity and appearance can be cleaved into two parts: (N) a so-called latent ``face space'', the underlying multidimensional psychological space of perceived features and properties that specifies which faces are similar to which other faces, and (N) a renderer that converts a point in the face space to an image. The success of a generative model of human identity and appearance, then, depends on the quality of both the face space and the renderer. One way to create a high-quality generative model of human identity and appearance is to learn the model directly from a corpus of portraits, using machine learning methods such as deep neural networks to construct a latent face space and renderer that reflect the training data. With an adequately large and diverse data set that contains variation relevant to human identity and appearance, such an approach holds considerable promise in achieving the goal of creating generative models with smoothly navigable and interpretable face spaces that render into photorealistic portraits representative of human diversity. The plan of the paper is as follows. We begin by presenting a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Next we train a deep neural network (specifically, a variational autoencoder with an autoregressive decoder) on these images. We then perform a visual Turing test for assessing the quality of such models for use with humans, and show that our best model nearly passes the test. Next, we show that samples from the model can be enlarged and drastically improved while preserving identity. Lastly, we demonstrate an initial application of our model to quickly extracting information from human mental representations, yielding expertless ``police sketching'', reducing by tenfold the number of human judgments required in comparison to previous methods .