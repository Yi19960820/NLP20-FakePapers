{C} {onvolutional} Neural Networks (CNNs) are learning machines that are extensively used by top performing methods in image classification _cite_ . By the introduction of Fully Convolutional Neural Networks (FCNNs) _cite_, these structures have also proven to constitute the state of the art in pixel-wise classification tasks such as semantic image segmentation and salient object detection. A typical FCNN relies on a pre-trained CNN that is used for image classification and fine-tunes the CNN's parameters for segmentation task, often adding or replacing some layers. These pre-trained CNNs usually contain a very large number of parameters, e.g. N million for VGG-N _cite_ . Such large networks require a lot of memory, which makes them challenging to deploy on limited memory devices such as mobile phones. There have been some efforts to reduce memory requirement of a CNN via pruning _cite_ or quantizing _cite_ the weights of the network, however these approaches are post-processing operations on large networks trained on millions of images. For some segmentation tasks such as salient object detection, one might question the need for using such a high capacity network in the first place. It can be argued that such a network might be an overkill for salient object detection and one can achieve reasonable performance by using a much smaller network. Moreover, object recognition CNNs have greatly reduced resolutions in their final layer activations due to pooling or strided convolution operations throughout the network. In order to atone for this resolution loss, segmentation networks either introduces additional connections to make use of the localization power of low-middle layers _cite_, or adds a deconvolutional network on top of the CNN _cite_ with unpooling layers. Both approaches results into an even more increase in the number of parameters used in the segmentation network. In this paper, we propose a way to overcome two problems of FCNNs mentioned above: requirement of a big pre-trained network and resolution loss because of pooling layers. To this end, we utilize a memory-efficient deep segmentation network without any pooling layers. We achieve this by encoding input images via gridized superpixels _cite_ . This allows us to use low resolution images that accurately encode object edges. By using these images, we show that it is possible to train a memory-efficient FCNN with a reasonable depth, no pooling layers, yet with large receptive field and comparable performance with state of the art, see Fig. _ref_ . The contributions of our work are listed as follows: The rest of the paper is organized as follows. In Section _ref_, the related work is discussed, in Section _ref_, the proposed method is described, in _ref_, the experimental results are analyzed. Finally, Section _ref_ concludes the paper and suggests topics for future research.