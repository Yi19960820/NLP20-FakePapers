The aim of computer-assisted surgery (CAS) is to provide the surgeon with the right type of assistance at the right moment. For many applications in CAS, such as providing the position of a tumor, specifying the most probable tool required next by the surgeon or determining the remaining duration of surgery, analyzing the surgical workflow is a prerequisite. comprises methods for perceiving and understanding surgical processes in the operating room, generally via data collected from sensors or from human input _cite_ . Since laparoscopic surgeries are performed using an endoscopic camera, a video stream is always available during surgery, making it the obvious choice as input sensor data for workflow analysis. Several methods in the state-of-the-art for video-based surgical workflow analysis utilize convolutional neural networks (CNNs) for interpreting the video stream _cite_ . Deep Neural Networks, such as CNNs, have a high number of parameters that have to be determined during training, which requires a large amount of annotated data. For many tasks in surgical workflow analysis, expert knowledge is often required for labeling data, making it difficult to obtain a sufficient amount of annotations. Motivated by the fact that data without annotations is often readily available, multiple methods for pretraining CNNs using unlabeled data for solving surgical workflow related tasks have been recently proposed _cite_ . These methods generally exploit information inherent in the unlabeled data to solve an auxiliary task related to the actual problem. Recently crowdsourcing based approaches have been used to successfully create annotations for simple surgical workflow related tasks in laparoscopy, such as tool segmentation _cite_, locating point correspondences _cite_ and for assessing skills _cite_ . More complex tasks, such as surgical phase segmentation, require more task-specific background knowledge, which generally only domain experts, such as surgeons, possess. Often these experts have limited resources for labeling such data, making it difficult to acquire large, annotated data sets. A system that could instead actively ask for expert labels only on certain examples, e.g. examples with a high uncertainty, would reduce the total annotation effort and make collecting large, annotated datasets for surgical workflow analysis more feasible. Such a system is called an system _cite_ . During active learning, an initial model is trained using a small amount of labeled data, the . An then determines through a metric, such as uncertainty, which data points should be labeled next. A new model is then trained on the extended training data _cite_ . Recently, new methods for estimating uncertainties on the predictions of deep neural networks, such as (DBN), have been developed _cite_ . Seeing that such estimates can be used for active learning has motivated Gal et al. _cite_ to formulate acquisition functions based on DBNs. In this paper, we investigate if an active learning system based on DBNs can successfully guide the annotation process for image-and video-based surgical workflow related tasks and thereby reduce the number of required labels. For this, we first modify the framework proposed in Gal et al. _cite_ for laparoscopic instrument presence detection and phase segmentation. Namely, our main contributions are the following: To the best of our knowledge, we are the first to apply DBN-based active learning to annotate data related to surgical workflow. Furthermore, as far as we are aware, this is the first work that utilizes DBN-based active learning for video annotation.