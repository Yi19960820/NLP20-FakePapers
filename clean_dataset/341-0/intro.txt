widespread availability of cameras has led to an enormous and ever-growing collection of unedited and unstructured videos generated by users around the world _cite_ . A popular domain corresponds to sports videos taken at public events and professional/amateur matches. These types of user-generated sports videos (UGSVs) are often lengthy with several uninteresting parts, and thus many of them are stored and are never reviewed. A convenient way to review, transfer, and share the video via channels, such as social network services, includes generating summaries of a UGSV that only shows the interesting parts or highlights. Automatic video summarization is a challenging problem that involves extracting semantics from video. Traditional user-generated video summarization methods target general videos in which contents are not limited to a specific domain. This is mainly because of the difficulty in extracting semantics from an unstructured video _cite_ . As opposed to extracting semantics, these methods use low-level visual features and attempt to reduce visual redundancy using clustering-based approaches _cite_ . More recent user-generated video summarization methods use deep neural network-based features to extract higher-level semantics _cite_ . With respect to sports video and especially with respect to professional sports in broadcast TV programs, there exist a number of summarization methods that leverage editing conventions to extract high-level semantics by exploiting a knowledge of the specific sport _cite_ . For example, broadcast sports video contains slow-motion replays _cite_, narration and superimposed text _cite_, and specific camera work _cite_ . This type of video editing constitutes the basis for heuristic rules that aid in the determination of highlights (or certain interesting moments of a game such as a free kick in soccer or a pitch in baseball) . Additionally, broadcast video is often edited by following the structure of the sport (i.e., ``downs'' in American football), and this constitutes another cue for summarization _cite_ . UGSV lies in in-between general user-generated video and broadcast sports video. Given a specific sport, domain knowledge can be used to generate a UGSV summary. However, UGSV does not typically follow any editing convention or structure, and thus a different type of cues is required to grab the semantics. This paper describes a novel method for UGSV summarization. Our observation with respect to semantics extraction is that a game in most sports consists of a succession of players' actions, and thus the actions can be one of the most important cues to determine if a certain part of video is interesting or not. For example, a definitive smash in tennis is more likely to be enjoyed by tennis viewers than a repetitive ball exchange. Also, a feint in boxing might not be interesting by itself, but viewers would surely enjoy it if it is followed by an uppercut that knocks out the opponent. Based on this observation, the proposed method uses players' actions to model the highlights of a sports game (Fig.~ _ref_) . Inspired by recent methods for action recognition in video, the proposed method uses a two-stream architecture that extracts two types of action features for action representation. One type involves players' body joint positions estimated in ND or ND (obtainable from depth maps) . Body joint-based features provide a precise representation of actions. The other type involves holistic features that can be obtained with deep convolutional neural networks (CNNs) designed to extract spatio-temporal features from video. Holistic features help to capture actions in their context. Subsequently, long short-term memory (LSTM) is used to model the temporal dependencies of the extracted features for highlight classification. In our summaries, a highlight may contain one or more actions performed by the players. Several types of body joint-based and holistic features are comparatively evaluated for UGSV summarization. We consider the case of Kendo (Japanese fencing) as an example of a sport to evaluate the proposed method. This work is an extension of our previous work in _cite_ . The main contributions of this work are as follows: