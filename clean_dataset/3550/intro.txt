Person re-identification (ReID) is an important task in wide area video surveillance. The key challenge is the large appearance variations, usually caused by the significant changes in human body poses, illumination and views. As person ReID commonly uses the Cumulative Matching Characteristic curve~ _cite_ for performance evaluation which follows rank-criteria, recently deep learning approaches~ _cite_ usually treat the person ReID as a ranking task and apply a triplet loss to address the problem. The main purpose of the triplet loss is to obtain a correct order for each probe image and distinguish identities in the projected space. However, in person ReID the categories (\ie person identities) in the testing set are unseen and have no overlap with the training categories. As shown in Fig.~ _ref_ (a), a model learned (\eg typically by a triplet loss) in the training set is specific to the training identities, and performs well in distinguishing these identities. When it is applied on the unseen testing identities, the trained model struggles to be a good performer, showing a weaker generalization capability from training to testing. The underlying reason is that the model trained by a triplet loss would still cause a relatively large intra-class variation, which was also observed in~ _cite_ . It is noted that reducing intra-class variations and enlarging inter-class variations can decrease the generalization error of trained models~ _cite_ . We argue that the performance of the triplet loss on the testing set can be improved by further reducing the intra-class variations and enlarging the inter-class variations. A desired output is shown in Fig.~ _ref_ (b) . In this paper, we introduce a quadruplet ranking loss, which is modified based on the triplet loss and capable of achieving a smaller intra-class variation and a larger inter-class variation with significant performance on the testing set. Our designed loss simultaneously considers the following two aspects in one quadruplet: N) obtaining correct orders for pairs w.r.t the same probe image (\eg _inline_eq_ in Fig.~ _ref_) ; and N) pushing away negative pairs from positive pairs w.r.t different probe images (\eg _inline_eq_ in Fig.~ _ref_) . The first aspect shares the same idea with the triplet loss and is to keep the correct orders of each probe image in the training set, while the second aspect focuses on further reducing the intra-class variations and enlarging the inter-class variations. The balance of these two aspects is controlled implicitly by two margins. It is worth mentioning that, the second aspect is not necessary for a good result on the training set, but we argue it's helpful to enhance the generalization ability of the trained models on the testing set. Experiments in Section~ _ref_ demonstrate that this design can produce larger inter-class variations and smaller intra-class variations, and thus lead to a better performance on the testing set. In addition to a triplet loss, some deep learning methods~ _cite_ address the person ReID problem from the classification aspect and adopt a binary classification loss to train their models. To justify the proposed loss, we present a theoretical analysis of the relationships of three different losses: our quadruplet loss, the triplet loss and the commonly used binary classification loss. To the best of our knowledge, this is the first detailed study of such relationships in a unified view for person ReID. Meanwhile, we propose a quadruplet deep network based on our quadruplet loss. In the proposed network, the input sample is a quadruplet. In practice, even for a small dataset, it can produce an overwhelming number of quadruplet samples. Selecting suitable samples for training a deep net is a big challenge. We introduce a margin-based online hard negative mining to select hard samples to train the model. Our algorithm adaptively sets the margin threshold according to the trained model, and uses this margin threshold to automatically select hard samples. In summary, our contributions are four-fold: N) a quadruplet loss, with strong and weak push strategies; N) a quadruplet deep network with a margin-based online hard negative mining strategy; N) a theoretical and insightful analysis of loss relationships, putting different losses in a unified view; N) significant performance on representative datasets (\eg CUHKN, CUHKN and VIPeR), being superior to most of the state-of-the-art methods.