segmentation is one of the fundamental tasks in computer vision and image processing whose objective is to recover the intrinsic subspaces, their numbers as well as dimensions from a collection of observed samples embedding in an ambient high dimensional space, and then assign each sample to the correct subspace. To implement this task, the core issue will become to cluster these samples into groups based on their underlying subspace memberships. Numerous methods have been devoted to the task of subspace clustering (SC) in recent decades, including the iterative clustering frameworks _cite_, statistical methods _cite_, algebraic approaches _cite_, spectral clustering based frameworks _cite_, and they have been successfully adapted to various practical applications such as motion segmentation, handwritten image clustering as well as face clustering. \par Among the above mentioned methods, spectral clustering based framework becomes much more appealing due to its simplicity, in which only a suitable affinity matrix will be critically constructed to reflect the pairwise relationships among the observed samples _cite_ . Exploiting the property of linear subspace, self-expressiveness or autoregressive model can provide an effective way of building an affinity matrix for SC. It suggests that any a sample can be represented by the linear combinations of some other ones if they are lying in the subspace _cite_ . It follows that the overall latent self-representation coefficients with respect to a set of samples will capture their structured relationships so as to construct an affinity matrix. In this spirit, spectral clustering based SC becomes to compute the self-representation coefficients via solving a linear inverse problem, where a regularization can be imposed on coefficients to obtain the informative and stable solutions. Elhamifar and Vidal developed a sparse subspace clustering (SSC) framework by involving a sparsity-inducing norm for regularization _cite_, which significantly improves the clustering performances in many applications than other approaches _cite_ . Following this baseline framework, many subsequent researches equipped with various regularizations are gradually developed for SC _cite_, including _inline_eq_ norm _cite_, _inline_eq_ norm _cite_, Frobenius norm _cite_, nuclear norm _cite_, the combinations _cite_ and some structure inducing variants _cite_, . \par According to the previous introduction, the above spectral clustering based frameworks for SC will rely on two separate phases. In the first phase, given a set of high dimensional observations, an affinity matrix will be constructed from the solution of a regularized linear inverse problem. Then we carry out the standard spectral clustering algorithm to obtain the clustering labels for these samples. However, such paradigm generally suffers from the following deficiencies. Firstly, determining the clustering labels or memberships based on the resulted representations will be fundamentally sub-optimal due to ignoring their underlying dependencies _cite_ . In other words, the membership will essentially influence the discrimination of the representations, which is not taken into account in the aforementioned frameworks. Secondly, the intrinsic subspace structure enabling clustering will be generally violated in the high dimensional observation domain due to some realistic contaminations _cite_ . As a consequence, the observed samples will be generally entangled and biased from their intrinsic subspaces which aggravates the difficulties and computational complexities for clustering in that domain. \par To address the first problem, Li and Vidal presented a unified framework for learning the affinity matrix and clustering labels simultaneously to capture their dependencies _cite_, and they recently extend this framework to the task of subspace completion and clustering to address the problem of missing entries in observed samples _cite_ . However, they still perform SC in the primary domain without further involving the discriminative strategies to disentangle the high dimensional observations. Considering the issue of high dimensionality, a common strategy in many SC frameworks is firstly to project the samples onto a low dimensional subspace with an off-the-shelf dimensionality reduction (DR) method,, principal component analysis (PCA) _cite_ and random projection _cite_ and then carry out the clustering algorithm in this subspace _cite_ _cite_ . Although this architecture has been widely exploited in practical situations, these DL algorithms do not concern the subspace structures among samples, which will result in a sacrificed clustering accuracy in general. To address this issue, Patel proposed a latent space sparse subspace clustering (LSNC) algorithm for simultaneously DR and SC in a united framework _cite_, which is further extended to a kernelized nonlinear framework (NLSNC) _cite_ . In their frameworks, the linear DR operator can preserve the subspace structure by considering the self-representations, but they still ignore the subspace memberships during computing the DR operator and representations. It follows that samples in the resulted latent space do not exhibit more separability to improve the clustering accuracy remarkably. To find a more discriminative latent space, Qiu and Sapiro learned a discriminative low rank transformation (LRT) by involving the estimated labels, which can encourage a maximally separated structure for inter-class subspaces and reduce the variation within the intra-class subspaces _cite_ . In their research, they combined LRT with a robust SSC deriving from local linear embedding (LLE) _cite_ for SC, which achieves significant improvements on face clustering and classification than other algorithms. However, their framework still suffers from many deficiencies, such as less robustness to outlying labels, getting stuck in trivial or pathological solutions,, which will increase the potential risk of performance collapsing. In this paper, we will propose a novel framework for subspace clustering in a discriminative feature subspace to address the above problems. The main contributions are summarized as following. The experimental results on three typical benchmarks for the applications of motion segmentation, digital handwritten clustering, face clustering all demonstrate the effectiveness of our proposed framework. In particular, the superiority of our framework is validated by sharply improving the clustering accuracy by a large margin, compared with the other state-of-the-art subspace clustering approaches. \par The rest paper is organised as follows. In Sec. _ref_, we make a detailed review of related works to highlight our motivations. Sec. _ref_ proposes our framework in detail and we derive the optimization scheme in Sec. _ref_ . Extensive experiments are conducted in Sec. _ref_ to demonstrate its effectiveness and superiorities and Sec. _ref_ concludes this paper.