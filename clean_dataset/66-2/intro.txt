Nasopharyngeal carcinoma (NPC), which has an unknown and complicated etiology, is a kind of malignant tumor. The distinctive geographic distribution of NPC makes some regions such as Southeast Asia, South China, the Arctic and the Middle East/North Africa have extremely higher incidence than other regions _cite_ . Patients with early detection and diagnosis of NPC will have a greater N-year survival rate with N \% for stage and N \% for stage, while the median survival of patients at advanced stage is only N years _cite_ . Therefore, timely and effective treatments play a crucial role in reducing the mortality of NPC. Radiotherapy, which highly depends on medical images such as the Magnetic Resonance Images (MRI) to get accurate delineation of the gross tumor volume (GTV) to separate normal adjacent tissues from lesion regions to reduce radiation-associated toxicity _cite_, is the mainstay of treatment for NPC. However, clinicians need to manually mark the boundary of NPC slice by slice before developing radiotherapy plans currently, which is time-consuming and labor-intensive. Additionally, the quality of manual segmentation highly depends on the experience of clinicians, which influences treatment effect. Therefore, an automatic and accurate segmentation approach is urgently needed to alleviate the workload of clinicians and improve the efficacy of treatment presently. Recently, according to the type of features used, methods of NPC segmentation can be divided into two categories, one is based on traditional handcrafted features, and the other one is based on deep features obtained from deep neural network (DNN) . In traditional methods, besides relatively simple manual features of medical images, such as intensity _cite_, texture _cite_ and shape _cite_, some traditional knowledge-based methods such as support vector machine (SVM) _cite_, semi-supervised fuzzy c-means _cite_, dictionary learning _cite_ are also implemented to generate NPC boundary. Huang et al. _cite_ proposed a three-step NPC segmentation method in MRI. In this method, an adaptive algorithm and a distance regularized level set were applied to obtain the region of NPC and the contour, then a novel HMRF-EM framework based on the maximum entropy is presented to further refine segmentation results. Wang et al. _cite_ introduced a joint dictionary learning methods, which obtains simultaneously multiple dictionaries of CT, MRI and corresponding label, to achieve NPC segmentation. Frameworks based on handcrafted features and traditional knowledge-based methods have been successfully implemented in the aforementioned papers to complete NPC segmentation. Nevertheless, the complex anatomical structure of NPC and the similarity of intensities between nearby tissues make it difficult to be accurately segmented only with the help of manual features. Meanwhile, the high diversity of shapes and sizes makes this task more challenging _cite_ . Therefore, inspired by the success of deep learning technology, some methods _cite_ based on DNN were proposed to get more accurate segmentation in recent years. Ma et al. _cite_ developed an image-patch-based convolutional neural network (CNN), integrating two CNN-based classification networks into a Siamese-like sub-network, to combine CT and TN-weighted (TN) images to complete NPC segmentation. Ma et al. _cite_ proposed a method combining CNN and graph cut. According to this framework, the initial segmentation was firstly generated through integrating results obtained from three CNN-based networks focusing on axial, sagittal and coronal view. Then, a ND graph-cut-based method was utilized to further refine it. Previous deep-learning-based researches have established some excellent frameworks for NPC segmentation. Nevertheless, there remain the following deficiencies. In this paper, we develop a multi-modality MRI fusion network (MMFNet), which is a novel framework to effectively captain interdependencies of multi-source features from ND medical images, to improve NPC segmentation by fusing multi-modality MRI (TN, CETN and TN) . In the MMFNet, the backbone, which contains several encoders and one single decoder, can be used to well learn both modality-specific and fused features used implicitly for NPC segmentation in each modality of MRI. We propose a fusion block to fuse modality-specific features. It can be divided into a ND Convolutional Block Attention Module (ND-CBAM), which is an attention module for ND medical images and recalibrates multi-source features to highlight informative features and the regions of interest (ROIs), and a residual fusion block (RFBlock), which fuses re-weighted features to keep balance between them and high-level features from decoder. Additionally, a training strategy named self-transfer is used to effectively initialize encoders, which can stimulate different encoders to make full mining of modality-specific features. By the MMFNet, we combine multiple MRI to realize accurate segmentation of NPC. We implement extensive experiments and comparisons with the related methods to demonstrate its effectiveness and advantages. The main contributions of this paper can be summarized as followed: The remaining paper is organized as followed. In section _ref_, related works will be reviewed. Section _ref_ will introduce our proposed framework. Experimental results and analysis will be reported in section _ref_ . Then in section _ref_ we will set some ablation experiments to further discuss proposed method. Finally, a conclusion will be made in section _ref_ .