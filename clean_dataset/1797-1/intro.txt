\vsp A safe and robust autonomous driving system relies on accurate perception of the environment. To be more specific, an autonomous vehicle needs to accurately detect cars, pedestrians, cyclists, road signs, and other objects in real-time in order to make the right control decisions that ensure safety. Moreover, to be economical and widely deployable, this object detector must operate on embedded processors that dissipate far less power than powerful GPUs used for benchmarking in typical computer vision experiments. Object detection is a crucial task for autonomous driving. Different autonomous vehicle solutions may have different combinations of perception sensors, but image based object detection is almost irreplaceable. Image sensors are cheap compared with others such as LIDAR. Image data (including video) are much more abundant than, for example, LIDAR cloud points, and are much easier to collect and annotate. Recent progress in deep learning shows a promising trend that with more and more data that cover all kinds of long-tail scenarios, we can always design more powerful neural networks with more parameters to digest the data and become more accurate and robust. While recent research has been primarily focused on improving accuracy, for actual deployment in an autonomous vehicle, there are other issues of image object detection that are equally critical. For autonomous driving some basic requirements for image object detectors include the following: a) Accuracy. More specifically, the detector ideally should achieve _inline_eq_ recall with high precision on objects of interest. b) Speed. The detector should have real-time or faster inference speed to reduce the latency of the vehicle control loop. c) Small model size. As discussed in~ _cite_, smaller model size brings benefits of more efficient distributed training, less communication overhead to export new models to clients through wireless update, less energy consumption and more feasible embedded system deployment. d) Energy efficiency. Desktop and rack systems may have the luxury of burning NW of power for neural network computation, but embedded processors targeting automotive market must fit within a much smaller power and energy envelope. While precise figures vary, the new Xavier processor from Nvidia, for example, is targeting a NW thermal design point. Processors targeting mobile applications have an even smaller power budget and must fit in the NW--NW range. Without addressing the problems of a) accuracy, b) speed, c) small model size, and d) energy efficiency, we won't be able to truly leverage the power of deep neural networks for autonomous driving. In this paper, we address the above issues by presenting SqueezeDet, a fully convolutional neural network for object detection. The detection pipeline of SqueezeDet is inspired by~ _cite_: first, we use stacked convolution filters to extract a high dimensional, low resolution feature map for the input image. Then, we use ConvDet, a convolutional layer to take the feature map as input and compute a large amount of object bounding boxes and predict their categories. Finally, we filter these bounding boxes to obtain final detections. The ``backbone'' convolutional neural net (CNN) architecture of our network is SqueezeNet~ _cite_, which achieves AlexNet level imageNet accuracy with a model size of _inline_eq_ MB that can be further compressed to _inline_eq_ MB. After strengthening the SqueezeNet model with additional layers followed by ConvDet, the total model size is still less than _inline_eq_ MB. The inference speed of our model can reach _inline_eq_ FPS with input image resolution of NxN. Benefiting from the small model size and activation size, SqueezeDet has a much smaller memory footprint and requires fewer DRAM accesses, thus it consumes only _inline_eq_ J of energy per image on a TITAN X GPU, which is about NX less than a Faster R-CNN model described in~ _cite_ . SqueezeDet is also very accurate. One of our trained SqueezeDet models achieved the best average precision in all three difficulty levels of cyclist detection in the KITTI object detection challenge~ _cite_ . The rest of the paper is organized as follows. We first review related work in section~ _ref_ . Then, we introduce our detection pipeline, the ConvDet layer, the training protocol and network design of SqueezeDet in section~ _ref_ . In section~ _ref_, we report our experiments on the KITTI dataset, and discuss accuracy, speed, parameter size of our model. Due to limited page length, we put energy efficiency discussion in the supplementary material to this paper. We conclude the paper in section~ _ref_ .