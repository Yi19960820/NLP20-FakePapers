Ever since the introduction of generative adversarial networks (GANs) _cite_, they have become one of the most widely used deep generative models to synthetically generate complicated real-world data. The core of the training of GANs is a min-max game in which two neural networks (generator and discriminator) compete with each other: the generator tries to trick the discriminator/classifier into classifying its generated synthetic/fake data as true. Various applications have benefited from the utilization of GANs, e.g., video prediction, object generation, photo super resolution~ (see _cite_ and the references therein) . Despite the interest that GANs have drawn, the task of training GANs remains a challenging problem, both from a theoretical and a practical standpoint. {{Specifically, GAN training suffers from the following major problems: _inline_eq_ mode-collapse: the generator collapses with results in a poor generalization, i.e., producing limited varieties of samples, _inline_eq_ lack of equilibrium: the min-max game may not have any equilibrium, and _inline_eq_ instability: even when the equilibrium exists, model parameters may oscillate, destabilize and never converge to an equilibrium.}} These failure modes result in generation of poor quality data. It was shown in~ _cite_ that the real data lies in a submanifold, and the generated data and real data lying in disjoint manifolds is one of the reasons for the aforementioned problems in the training of GANs. Motivated from this insight, this paper takes some initial steps towards designing GAN architectures which can exploit the unique geometry of the real data (especially the manifold information) to overcome the aforementioned problems. The basic idea is simple yet powerful: in addition to the gradient information provided by the discriminator, we want the generator to exploit other geometric information present in the real data, such as the manifold information. Taking advantage of this additional information, we will have more stable gradients while training our generator. Specifically, we propose a novel method for incorporating geometry and regularizing the GAN training by adding an additional regularization term (referred to as manifold regularizer) with generator updates. The proposed manifold regularizer forces the generator to respect the unique geometry of the real data manifold. We theoretically prove that the addition of this regularization term in any class of GANs (including DCGAN and Wasserstein GAN) leads to improved performance in terms of generalization, equilibrium, and stability. In practice, the manifold regularized GANs (MR-GANs) are simple to implement, and results in better performance compared to their unregularized counterparts. In the literature, not much theory exists that explains the unstable behaviour of GAN training except for _cite_ that stands out as one of the most successful work. The authors provided important insights into mode collapse and instability in GAN training. They showed that these issues arise when the supports of the generated distribution and the true distribution are disjoint. The authors in~ _cite_, on the other hand, explored questions relating to the sample complexity and expressiveness of the GAN architecture and their relation to the existence of an equilibrium. Given that an equilibrium exists, the convergence of GAN with update procedure using gradient descent was studied in~ _cite_ . From a practical perspective, various architectures and training objectives have been proposed to address GAN training challenges~ _cite_ . Several optimization heuristics and architectures have also been proposed to address challenges such as mode collapse~ _cite_ . Methods for regularizing the discriminator for better stability were devised in~ _cite_ . The authors in~ _cite_ presented a stabilizing regularizer that is based on a gradient norm, where the gradient is calculated with respect to the data samples. On the other hand, the authors of _cite_ designed regularizers based on the norm of a gradient calculated with respect to the parameters. The authors in _cite_ applied a Jacobian regularizer to the discriminator of a feature-matching GAN to improve the performance of GAN-based semi-supervised learning. In contrast to regularizing the discriminator, this paper proposes to regularize the generator for improving GAN training. Finally, the authors in~ _cite_ proposed replacing the original GAN loss with a different loss function matching the statistical mean and radius of the spheres approximating the geometry of the real data and generated data. However, characterizing the geometric information of the data only by the mean and radius of loses a significant amount of geometrical information. The construction in~ _cite_ was purely heuristic and did not have any theoretical backing. On the contrary, we cirectly exploit the undistorted manifold information for regularizing the training of the generator rather than treating it as a loss function and theoretically prove that the proposed approach yields improved performance in terms of generalization, existence of equilibrium, and stability. The main contributions of the paper are summarized as follows: