The recent successes of deep learning are partially attributed to supervised training of networks with large numbers of parameters using large datasets. In computer vision, supervised training of convolutional networks with very large labeled datasets provide state-of-the-art solutions in many applications such as object recognition, image captioning and question answering. While it has been shown that convolutional networks have low generalization error, their generalization capability does not extend to samples which are not adequately represented by the training data. A potential source of mismatch between the training data distribution and new samples is appearance. To a human, the images shown in Figure~ _ref_ (top row) unambiguously represent the digits "N", "N" and "N" whereas a convolutional network trained on the original MNIST dataset has a low probability of producing the correct answer for the modified digit images. The reason that a human has an easy time at this task is not because he has previously been exposed to the particular representations of the digits shown in Figure~ _ref_, but because he is able to adapt to novel appearances of learned concepts. Invariances to a predetermined set of transformations such as translation, rotation, contrast and noise can be taught to the network via methods such as tangent prop~ _cite_ and data augmentation~ _cite_ ; however, these methods can not adapt to new appearances such as those shown in Figure~ _ref_ . Similarly, domain adaptation~ _cite_ offers a solution only if a sufficient number of images in the target domain are available. We propose a novel neighborhood similarity layer (NSL) and show that when used in a convolutional network it can greatly increase its generalization accuracy to novel appearances without requiring domain adaptation. The NSL is motivated by the Gestalt principle of grouping with respect to similarity. More specifically, NSL computes normalized inner products of feature vectors of the previous layer between a central pixel which acts as a frame of reference and the spatial neighborhood of that pixel. NSL is a parameter-free layer, which if used after the early convolutional layers in a network, can be seen as inducing appearance invariance. We show that the inclusion of the NSL results in good generalization accuracy for classification and semantic labeling, without using domain adaptation, when the source and target domains differ. Remarkably, the accuracy of the network with NSL trained on MNIST~ _cite_ and tested on SVHN~ _cite_, without any domain adaptation, surpasses state-of-the-art domain adaptation results. Cross-domain appearance invariance without domain adaptation is a step towards reasoning about novel representations of learned concepts. We also show that these results can be further improved when NSL is used in conjunction with domain adaptation. Finally, we demonstrate in the context of cell detection, that NSL can improve accuracy by introducing contrast invariance when the source and target domains are the same.