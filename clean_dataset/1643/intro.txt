With the growing deployment of surveillance video cameras, the surveillance applications have received increasing attention from the research community. Different from other problems such as face and vehicle detection _cite_, crowd counting, or estimating the head count, from video frames, has been proved to be a critical functionality in various traffic and public security scenarios _cite_, and applications in zoology _cite_ and neural science _cite_ further extend the usability and importance of the problem. Multiple challenges exist to produce accurate and efficient crowd counting results. Heavy occlusion, lightning and camera perspective changes are the common issues. Moreover, as shown in Figure _ref_, head counts vary dramatically in different scenarios; area of the head ranges from hundreds of pixels to only a few pixels, and the crowd is often unevenly distributed due to camera perspective or physical barriers. Recent approaches provide rough head count estimates based on multi-scale and context-aware cues _cite_ ; a universal normalization or scaling mechanism is often used for different density domains. Practically, this can be suboptimal and leads to inaccuracy especially when the scenario is highly dynamic. Better adaption to different density domains is a first-order question for current crowd counting algorithms. In this paper, we propose a deep learning pipeline to automatically infer the crowd density level given a single input image, and our framework adaptively chooses a counter network that is explicitly trained for the target density domain. Different counter networks and the density level estimator are associated in a spatial gating unit for end-to-end crowd counting. With this ground, our framework addresses the density adaption problem and produces more satisfactory results. The idea of constructing representation from multiple levels has been taken in several previous works, e.g., the Switch-CNN _cite_ . Compared to these approaches using different network structures as regressors and classifier, our subnetworks employ the similar design and are easy to train. To evaluate our proposed framework, we report the evaluations on the recent ShanghaiTech _cite_ and the UCF \_CC \_N crowd counting dataset _cite_, and we compare with several recent approaches including MCNN _cite_ and CP-CNN _cite_ . Notably, we achieve a significant N MAE improvements over the state-of-the-art Shang et al. _cite_ on UCF \_CC \_N, and N MAE gains over CP-CNN _cite_ on ShanghaiTech Part B. Meanwhile, a N FPS processing speed is obtained on an Nvidia Titan X GPU (Maxwell) . A number of studies on crowd counting have been demonstrated to solve the real world problem _cite_ . They can be summarized into three categories depending on the methodology: detection-based, regression-based and density-based, which will be briefly reviewed below. \noindent Detection-based crowd counting is straightforward and utilizes off-the-shelf detectors _cite_ to detect and count target objects in images or videos. However, for crowded scenarios, objects are highly occluded and many objects are too small to detect. All these make the counting inaccurate. \noindent Regression-based crowd counting . Regression-based approaches such as _cite_ are proposed to bypass the occlusion problem that can be critical for detection-based methods. Specifically, a mapping between image features and the head count is recovered, and the system benefits from better feature extraction and count number regression algorithms _cite_ . Moreover, _cite_ leverage spatial or depth information and use segmentation methods to filter the background region and regress count numbers only on foreground segments. These type of methods are sensitive to different crowd density levels and heavily depend on a normalization strategy that is universally good. \noindent Density-based crowd counting. _cite_ use continuous density maps instead of discrete count numbers as the optimization objective and learn a mapping between the image feature and the density map. Specifically, _cite_ presents a data-driven method to count in unseen scenarios. _cite_ proposes a multi-column network to directly generate the density map from input images. _cite_ introduces the boosting process which yield a significant improvement both in accuracy and runtime. To address perspective-free problem, _cite_ feeds a pyramid of input patches into their own designed network. _cite_ improves over _cite_ and uses a switch layer to exploit the variation of the crowd density. _cite_ jointly estimates the density map and count number with FCN and LSTM layers. _cite_ uses global and local context to generate high quality density map. The insufficiency of these type of methods is that the mapping between density and image may lead to deviation and the actual count can often be inaccurate. In this paper, our framework leverages both continuous density map and discrete head count annotations in training; a density-level domain adaption network is used to explicitly recognize the domain allocation of each image patch. Different from previous works, we do not focus on pursuing a better density estimation but count directly. It totally drops the local details and is hard to learn. Instead, we propose a count map, which to some extent preserves the local details and can be calculated analytically. Besides, if we only use a single network to predict count map, the result will be dominated by the patch with high-density crowds. Therefore, we classify each patch into low-or high-density. This step has two advantages: i) counting number of patches with low-density crowds becomes more accurate; ii) the classifier becomes easier to train.