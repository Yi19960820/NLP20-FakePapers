tumor grade is a strong prognostic marker for the survival of breast cancer patients _cite_ . It is assessed by examination of hematoxylin and eosin (H \&E) stained tissue sections using bright-field microscopy~ _cite_ . Histopathological grading of breast cancer combines information from three morphological features: (N) nuclear pleomorphism, (N) tubule formation and (N) mitotic count, and can take a value within the N-N range, where N corresponds to the worst patient prognosis. In this study, we focus our attention on the mitosis count component, as it can be used as a reliable and independent prognostic marker _cite_ . Mitosis is a crucial phase in the cell cycle where a replicated set of chromosomes is split into two individual cell nuclei. These chromosomes can be recognized in H \&E stained sections as mitotic figures (see Fig. _ref_) . For breast cancer grading, the counting of mitotic figures is performed by first identifying a region of with a high number of mitotic figures at low microscope magnification (hotspot) and subsequently counting all mitotic figures in this region at high magnification. The recent introduction of whole-slide scanners in anatomic pathology enables pathologists to make their diagnoses on digitized slides _cite_, so-called whole-slide images (WSIs), and promotes the development of novel image analysis tools for automated and reproducible mitosis counting. Publicly available training datasets for mitosis detection _cite_ have important limitations in terms of (N) size, (N) tissue representativity, and (N) reference standard agreement. In these datasets, the total number of annotated mitotic figures is currently limited to objects, far away from standard datasets used to train modern computer vision systems _cite_ . In addition, mitotic figures were annotated in certain manually selected tumor regions only, often excluding tissue areas with image artifacts (common in WSIs) . Furthermore, exhaustive manual annotations are known to suffer from disagreement among observers and limited recall _cite_ . We propose a method to improve the annotation process based on the automatic analysis of immunohistochemical stained slides. Phosphohistone-HN (PHHN) is an antibody that identifies cells undergoing mitosis _cite_ . Mitotic figures appear in PHHN immunohistochemically stained slides (abbreviated as PHHN stained slides) as high contrast objects that are easier to detect than in H \&E _cite_, illustrated in Fig. _ref_ . We propose to H \&E slides and them with PHHN to obtain both H \&E and PHHN WSIs from the exact same tissue section _cite_ . By automatically analyzing mitotic activity in PHHN and registering it to H \&E, we generated training data for mitosis detection in H \&E WSIs in a scalable manner, i.e. independent from the manual annotation procedure. Although the process of H \&E tissue staining follows a standard protocol, the appearance of the stained slides is not identical among pathology laboratories and varies across time even within the same center (see Fig. _ref_) . This variance typically causes mitosis detection algorithms to underperform on images originating from pathology laboratories different than the one that provided the training data _cite_ . Several solutions have been proposed to tackle this lack of generalization. First, building multicenter training datasets that contain sufficient stain variability. Following this approach, the Tumor Proliferation Assessment Challenge (TUPAC) resulted in numerous successful mitosis detection algorithms. Top-performing methods in the challenge are based on convolutional neural networks (CNNs) ~ _cite_ . This is in line with the trend observed in recent years, which has seen CNNs as the top-performing approach in image analysis, both in computer vision and medical imaging _cite_, and corroborates the fact that CNNs have become the standard methodology for automatic mitosis detection. However, multicenter datasets cannot cover all the variability encountered in clinical practice, and are expensive to collect. Second, stain standardization techniques _cite_ have been widely used by many of these successful mitosis detection methods to reduce stain variability. However, they require preprocessing all training and testing WSIs and do not reduce the generalization error of trained models. Third, data augmentation strategies have been used to simulate stain variability during the model training. These techniques typically involve RGB transformations such as brightness and contrast enhancements, and color hue perturbations _cite_ . We argue that designing specific data augmentation strategies for H \&E stained tissue images is the most promising approach to reduce the generalization error of these networks, avoiding the elevated costs of assembling a multicenter cohort, and effectively enforcing stain invariance into the trained models. We propose an augmentation strategy tailored to H \&E WSIs that modifies the hematoxylin and eosin color channels directly, as opposed to RGB, and it is able to generate a broad range of realistic H \&E stain variations from images originating in a single center. We call this technique . Automatic mitosis detection algorithms rely on techniques such as the use of high capacity CNNs and multi-network ensembling to achieve state of the art performance _cite_ . These are simple yet effective mechanisms to improve performance, reduce generalization error and diminish the sensitivity of the model to the detection threshold. However, due to their computationally expensive nature, it is unfeasible to use them for dense prediction in gigapixel WSIs. We propose to exploit the technique of _cite_ to reduce the size of the trained ensemble to that of a single network, maintaining similar levels of performance and increasing processing speed drastically. Our contributions can be summarized as follows: The paper is organized as follows. Sec. _ref_ reports the datasets used to train and validate our method. Sec. _ref_ and Sec. _ref_ describe the methodology in depth. All details regarding CNN architectures, training protocols and hyper-parameter tuning are explained in Sec. _ref_ . Experimental results are listed in Sec. _ref_, followed by Sec. _ref_ where the discussion and final conclusion are stated.