Deep convolutional neural networks (CNNs) have gained tremendous attention recently due to their great success in boosting the performance of image classification _cite_, object detection _cite_, action recognition _cite_ and many other visual computing tasks _cite_ . In the context of scene classification, although a series of state-of-the-art results on popular benchmark datasets (MIT Indoor N _cite_, SUNN _cite_) have been achieved, CNN features are still used in a rudimentary manner. For example, recent work in _cite_ simply trains the classical Alex's net _cite_ on a scene-centric dataset (``Places") and directly extracts holistic CNN features from entire images. The architecture of CNNs suggests that they might not be best suited for classifying images, including scene images, where local features follow a complex distribution. The reason is that spatial aggregation performed by pooling layers in a CNN is too simple, and does not retain much information about local feature distributions. When critical inference happens in the fully connected layers near the top of the CNN, aggregated features fed into these layers are in fact global features that neglect local feature distributions. It has been shown in _cite_ that in addition to the entire image, it is consistently better to extract CNN features from multiscale local patches arranged in regular grids. In order to build a discriminative representation based on deep CNN features for scene image classification, we need to address two technical issues: (N) Objects within scene images could exhibit dramatically different appearances, shapes, and aspect ratios. To detect diverse local objects, one could in theory add many perturbations to the input image by warping and cropping at various aspect ratios, locations, and scales, and then feed all of them to the CNN. This is, however, not feasible in practice; (N) To distinguish one scene category from another, it is much desired to harvest discriminative and representative category-specific objects and object parts. For example, to tell a ``city street" from a ``highway", one needs to identify objects that can only belong to a ``city street" but not a ``highway" scene. Pandey and Lazebnik~ _cite_ adopt the standard DPM to adaptively infer potential object parts. It is however unclear how to initialize the parts and how to efficiently learn them using CNN features. In this paper, we present a novel pipeline built upon deep CNN features for harvesting discriminative visual objects and parts for scene classification. We first use a region proposal technique to generate a set of high-quality patches potentially containing objects _cite_ . We apply a pre-trained CNN to extract generic deep features from these patches. Then, for each scene category, we train a one-class SVM on all the patches generated from the images for this class as a discriminative classifier~ _cite_, which heavily prunes outliers and other non-representative patches. The remaining patches correspond to the objects and parts that frequently occur in the images for this scene category. To further harvest the most discriminative patches, we apply a non-parametric weakly supervised learning model to screen these remaining patches according to their discriminative power across different scene categories. Instead of directly using the chosen category-specific objects and parts, we further perform discriminative clustering to aggregate similar objects and parts into groups. Each resulting group is called a ``Meta Object" . Finally, a scene image representation is obtained by pooling the feature response maps of all the learned meta objects at multiple spatial scales to retain more information about their local spatial distribution. Locally aggregated CNN features are more discriminative than those global features fed into the fully connected layers in a single CNN. There exists much recent work advocating the concept of middle-level objects and object parts for efficient scene image classification _cite_ . Among them, the methods proposed in _cite_ are most relevant. Nonetheless, there exist major differences between our method and theirs. First, we use multiscale object proposals instead of grid-based sampling with multiple patch sizes, thus we can intrinsically obtain better discriminative object candidates. Second, we aggregate our meta objects through deep CNN features while previous methods primarily rely on low-level features (i.e., HOG) . As demonstrated through experiments, deep features are more semantically meaningful when used for characterizing middle-level objects. Last but not the least, there exist significantly different components along individual pipelines. For instance, we adopt unsupervised learning to prune outliers while Juneja {\em et al.} ~ _cite_ train a large number of exemplar-SVMs, which is more computationally intensive. Furthermore, our discriminative clustering component also plays an important role in aggregating meta objects. In summary, this paper has the following contributions: (N) We propose a novel pipeline for scene classification that is built on top of deep CNN features. The advantages of this pipeline are orthogonal to any category independent region proposal methods _cite_ and middle-level parts learning algorithms _cite_ . (N) We propose a simple yet efficient method that integrates unsupervised and weakly supervised learning for harvesting discriminative and representative category-specific patches, which we further aggregate into a compact set of groups, called meta objects, via discriminative clustering. (N) Instead of global fine-tuning, we locally fine-tune the CNN using the meta objects discovered from the target dataset. We have confirmed through experiments that the scene image representation obtained using this pipeline is capable of delivering state-of-the-art performance on two popular scene benchmark datasets, MIT Indoor N~ _cite_ and SunN~ _cite_ .