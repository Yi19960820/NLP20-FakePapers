Biometrics technology is used in a wide variety of security applications. The aim of such systems is to recognize a person based on physiological traits (e.g fingerprint, iris) or behavioral traits (e.g. voice, handwritten signature) _cite_ . The handwritten signature is a particularly important type of biometric trait, mostly due to its widespread use to verify a person's identity in legal, financial and administrative areas. One of the reasons for its extensive use is that the process to collect handwritten signatures is non-invasive, and people are familiar with their use in daily life _cite_ . Research in signature verification is divided between online (dynamic) and offline (static) scenarios. In the online case, the signature is captured using a special input device (such as a tablet), and the dynamic information of the signature process is captured (pen's position, inclination, among others) . In this work, we focus on the Offline (static) signature verification problem, where the signature is acquired after the writing process is completed, by scanning the document containing the signature. In this case, the signature is represented as a digital image. Most of the research effort in this area has been devoted to obtaining a good feature representation for signatures, that is, designing good feature extractors. To this end, researchers have used insights from graphology, computer vision, signal processing, among other areas _cite_ . As with several problems in computer vision, it is often hard to design good feature extractors, and the choice of which feature descriptors to use is problem-dependent. Ideally, the features should reflect the process used to generate the data-for instance, neuromotor models of the hand movement. Although this approach has been explored in the context of online signature verification _cite_, there is not a widely accepted ``best'' way to model the problem, specially for Offline (static) signature verification, where the dynamic information of the signature generation process is not available. In spite of the advancements in the field, systems proposed in the literature still struggle to distinguish genuine signatures and skilled forgeries. These are forgeries made by a person with access to a user's signature, that practices imitating it (see Figure _ref_) . Experimental results show somewhat large error rates when testing on public datasets (such as GPDS _cite_), even when the number of samples for training is around N-N (results are worse with N-N samples per user, which is a common scenario in banks and other institutions) . In this work we propose using feature learning (also called representation learning) for the problem of Offline Signature Verification, in order to obtain better feature representations. Our hypothesis is that, in the absence of a good model of the data generation process, it is better to learn the features from data, rather than using hand-crafted features that have no resemblance to how the signatures are created, which is the case for the best performing systems proposed in the literature. For example, recent Offline Signature Verification systems are based on texture descriptors, such as Local Binary Patterns _cite_, interest-point-matching such as SURF _cite_, among others. We base our research on recent successful applications of purely supervised learning models for computer vision (such as image recognition _cite_) . In particular, we use Deep Convolutional Neural Networks (CNN) trained with a supervised criterion, in order to learn good representations for the signature verification problem. This type of architecture is interesting for our problem, since it scales better than fully connected models for larger input sizes, having a smaller number of trainable parameters. This is a desirable property for the problem at hand, since we cannot rescale signature images too much without risking losing the details that enable discriminating between skilled forgeries and genuine signatures. The most common formulation of the signature verification problem is called Writer-Dependent classification. In this formulation, one classifier is built for each user in the system. Using a supervised feature learning approach directly in this case is not practical, since the number of samples per user is very small (usually around N-N samples) . Instead, we propose a two-phase approach: a Writer-Independent feature learning phase followed by Writer-Dependent classification. The feature learning phase uses a surrogate classification task for learning feature representations, where we train a CNN to discriminate between signatures from users not enrolled in the system. We then use this CNN as a feature extractor and train a Writer-dependent classifier for each user. Note that in this formulation, adding a new user to the system requires training only a Writer-Dependent classifier. We tested this method using two datasets: the GPDS-N corpus (_cite_) and the Brazilian PUC-PR dataset _cite_ . The first is the largest publicly available corpus for offline signature verification, while the second is a smaller dataset that has been used for several studies in the area. Our main contributions are the following: We propose a two-stage framework for offline signature verification, where we learn features in a Writer-Independent way, and build Writer-Dependent classifiers. Our results show that we do have enough data in signature datasets to learn relevant features for the task, and the proposed method achieves state-of-the-art performance. We also investigate how the features learned in one dataset transfer to another dataset, and the impact in performance of the number of samples available for WD training.