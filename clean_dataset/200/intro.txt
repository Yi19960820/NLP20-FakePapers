Denoising is an active topic in image processing since it is a key step in many practical applications, such as image and video capturing. It aims to generate a clean image _inline_eq_ from a given noisy image _inline_eq_ which follows an image degradation model _inline_eq_ . For the widely used additive Gaussian noise (AWGN) model, the _inline_eq_ {th} observed pixel is where _inline_eq_ is i.i.d Gaussian noise with zero mean and variance _inline_eq_ . AWGN has been used to model the signal-independent thermal noise and other system imperfections. Degradation due to low light shot noise is signal dependent and has often been modeled using Poisson noise where _inline_eq_ is a Poisson random variable with mean _inline_eq_ . However, this noise approaches a Gaussian distribution for average light conditions as _inline_eq_, for large enough _inline_eq_ . Hence, the noise due to capturing by an imaging device is better modeled as a Poisson noise with AWGN, referred to as Poisson-Gaussian noise, such that which has been verified by experimental results _cite_ . Recently, the state of art denoising accuracy is achieved by deep neural networks _cite_ _cite_, which construct a mapping between the noisy image and clean image. Unforunately, most of existing denoising networks cannot be executed in real-time due to their large network size. In addition, it is relatively difficult to set the hyperparameters when learning a very deep network, such as the weight initialization, the learning rate, and the weight decay rate. With inappropriate parameters, the training might fall into local minimum or not converge at all. In this paper, we propose a Denoising Residual Network (DN-ResNet) which is more efficient and accurate than prior art. DN-ResNet consists of residual blocks (ResBlock) which are gradually inserted into the network stage by stage during the training. This training strategy not only allows the resulting DN-ResNet to converge faster, but also allows it to be more computationally efficient than prior art denoising networks. Even better perceptive quality have been observed by using the proposed edge-aware loss function instead of the conventional mean square error (MSE) . In addition, we introduce the depthwise separable ResBlock (DS-ResBlock) into DN-ResNet to construct the depthwise separable ResNet (DS-DN-ResNet) . DS-DN-ResNet is generated by the proposed incremental evolution from DN-ResNet, where the ResBlocks in DN-ResNet are replaced by DS-ResBlocks stage by stage. As a result, we may obtain a N times complexity reduction for DN-ResNet, with less than N dB PSNR loss. To our knowledge, DN-ResNet is the first unified deep CNN trained for the problem of blind denoising of images corrupted by multiple type of noises. By cascading only N ResBlocks, DN-ResNet and DS-DN-ResNet achieve the state of art performance on all three denoising problems, Gaussian, Poisson, and Poisson-Gaussian, for both cases of non-blind denoising (known noise level for noisy input) and blind denoising (unknown noise level for noisy input) . The speed is also much faster than prior art denoising networks. Moreover, we show that DN-ResNet works well for compressed image restoration. This implies that DN-ResNet can be generalized to other applications. As summary, our contributions are three folds: N. We show that ResNet is effective for image denoising, and using edge-aware loss function significantly improves the perceptive quality. The resulting DN-ResNet achieves the state of art accuracy, and is N times less complicate than existing networks; N. We introduce the depthwise separable ResBlock (DS-ResBlock) to construct DS-DN-ResNet. The incrementally evolved DS-DN-ResNet is N times faster than DN-ResNet, without significant accuracy loss; N. We show that the proposed DN-ResNet works well for all types of noises, even without knowing the noise level. It can be generalized to other image enhancement task such as compressed image restoration;