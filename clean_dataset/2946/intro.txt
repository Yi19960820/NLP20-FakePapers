The inclusion of rich semantic information within a dense map enables a much greater range of functionality than geometry alone. For instance, in domestic robotics, a simple fetching task requires knowledge of both what something is, as well as where it is located. As a specific example, thanks to sharing of the same spatial and semantic understanding between user and robot, we may issue commands such as 'fetch the coffee mug from the nearest table on your right'. Similarly, the ability to query semantic information within a map is useful for humans directly, providing a database for answering spoken queries about the semantics of a previously made map; `How many chairs do we have in the conference room? What is the distance between the lectern and its nearest chair?' In this work, we combine the geometric information from a state-of-the-art SLAM system ElasticFusion _cite_ with recent advances in semantic segmentation using Convolutional Neural Networks (CNNs) . Our approach is to use the SLAM system to provide correspondences from the ND frame into a globally consistent ND map. This allows the CNN's semantic predictions from multiple viewpoints to be probabilistically fused into a dense semantically annotated map, as shown in Figure~ _ref_ . ElasticFusion is particularly suitable for fusing semantic labels because its surfel-based surface representation is automatically deformed to remain consistent after the small and large loop closures which would frequently occur during typical interactive use by an agent (whether human or robot) . As the surface representation is deformed and corrected, individual surfels remain persistently associated with real-world entities and this enables long-term fusion of per-frame semantic predictions over wide changes in viewpoint. The geometry of the map itself also provides useful information which can be used to efficiently regularise the final predictions. Our pipeline is designed to work online, and although we have not focused on performance, the efficiency of each component leads to a real-time capable (_inline_eq_ Hz) interactive system. The resulting map could also be used as a basis for more expensive offline processing to further improve both the geometry and the semantics; however that has not been explored in the current work. We evaluate the accuracy of our system on the NYUvN dataset, and show that by using information from the unlabelled raw video footage we can improve upon baseline approaches performing segmentation using only a single frame. This suggests the inclusion of SLAM not only provides an immediately useful semantic ND map, but it suggests that many state-of-the art ND single frame semantic segmentation approaches may be boosted in performance when linked with SLAM. The NYUvN dataset was not taken with full room reconstruction in mind, and often does not provide significant variations in viewpoints for a given scene. To explore the benefits of SemanticFusion within a more thorough reconstruction, we developed a small dataset of a reconstructed office room, annotated with the NYUvN semantic classes. Within this dataset we witness a more significant improvement in segmentation accuracy over single frame ND segmentation. This indicates that the system is particularly well suited to longer duration scans with wide viewpoint variation aiding to disambiguate the single-view ND semantics.