With the development of Convolutional Neural Network (CNN) _cite_, great improvements have been achieved on object detection _cite_, due to the availability of large scale datasets with accurate boundingbox-level annotations _cite_ . However, collecting such accurate annotations can be very labor-intensive and time-consuming, whereas achieving only image-level annotations (\ie, image tags) is much easier, as these annotations are often available at the Internet (\eg, image search queries _cite_) . In this paper, we aim at the Weakly Supervised Object Detection (WSOD) problem, \ie, only image tags are available during training to indicate whether an object exists in an image. Most of previous methods follow the Multiple Instance Learning (MIL) pipeline for WSOD _cite_ . They treat images as bags and image regions generated by object proposal methods _cite_ as instances to train instance classifiers (object detectors) under the MIL constraints _cite_ . Meanwhile, recent efforts tend to combine MIL and CNN by either using CNN as an off-the-shelf feature extractor _cite_ or training an end-to-end MIL network _cite_ . Here we are also along the MIL line for WSOD, and train an end-to-end network. Though many promising results have been achieved in WSOD, they are still far from comparable to fully supervised ones _cite_ . Weakly supervised object detection only requires supervision at image category level. Bilen and Vedaldi _cite_ presents an end-to-end deep network for WSOD, in which final image classification score is the weighted sum of proposal scores, that is, each proposal contributes a percentage to the final image classification. The deep network can correctly classify image even only ``see'' a part of object, and as a result, the top ranking proposal may fail to meet the standard object detection requirement (IoU _inline_eq_ N between ground truths and predicted boxes) . As shown in Fig.~ _ref_ ~ (left), the top-ranking proposal A is too small. Meanwhile, proposals B, C, and D have similar detection scores. This shows that the WSOD network is not discriminative enough to correctly localize object. This is a core problem of end-to-end deep network based WSOD. To address this problem, we put forward two improvements in this paper: N) Instead of estimating instance weights through weighted sum pooling, we propose to add some blocks in the network for learning more discriminative instance classifiers by explicitly assigning binary instance labels; N) We propose to refine instance classifier online using spatial relation. Our motivation is that, though some detectors only capture objects partially, proposals having high spatial overlaps with detected parts may cover the whole object, or at least contain larger portion of the object. In _cite_, Bilen and Vedaldi propose a spatial regulariser via forcing features of highest scoring region and its adjacent regions to be the same, which significantly improves WSOD performance. Nevertheless, forcing spatially overlapped proposals to have the same features seems too rigorous. Rather than taking the rigorous constraint, we think the features of spatially overlapped proposals are in the same manifold. Then these overlapped proposals could share similar label information. As shown in Fig.~ _ref_ ~ (right), we except the label information of A can propagate to B and C which has large overlap with A, and then the label information of B and C can propagate to D to correctly localize object. To implement this idea, we design some instance classifiers in the network of _cite_ . The labels of instance could be refined by their spatially overlapped instances. We name this new network structure Multiple Instance Detection Network (MIDN) with instance classifier. In practice, there are two important issues. N) How to initialize instance labels, since there is no instance-level supervision in this task. N) How to train the network with instance classifier efficiently. A natural way for classifier refinement is the alternative strategy, that is, alternatively relabelling instance and training instance classifier, while this procedure is very time-consuming, especially considering training deep networks with a huge number of Stochastic Gradient Descent (SGD) iterations. To overcome these difficulties, we propose a novel Online Instance Classifier Refinement (OICR) algorithm to train the network online. Our method has multiple output streams for different stages: the first is the MIDN to train a basic instance classifier and others refine the classifier. To refine instance classifier online, after the forward process of SGD, we can obtain a set of proposal scores. According to these scores, for each stage, we can label the top-scoring proposal along with its spatially overlapped proposals to the image label. Then these proposal labels can be used as the supervision to train instance classifier in the next stage. Though the top-scoring proposal may only contain a part of an object, its adjacent proposals will cover larger portion of the object. Thus the instance classifier can be refined. After implementing the refinement procedure multiple times, the detector can discover the whole object instead of parts gradually, as shown in Fig.~ _ref_ . But in the beginning of training, all classifiers are almost non-trained, which will result in very noisy supervision of refined classifiers, and then the training will deviate from correct solutions a lot. To solve this problem, we design a weighted loss further by assigning different weights to different proposals in different training iterations. Using this strategy, all classifier refinement procedures can thus be integrated into a single network and trained end-to-end. It can improve the performance benefiting from the classifier refinement procedure. Meanwhile, the multi-stage strategy and online refinement algorithm is very computational efficient in both training and testing. Moreover, performance can be improved by sharing representations among different training stages. We elaborately conduct many experiments on the challenging PASCAL VOC dataset to confirm the effectiveness of our method. Our method achieves _inline_eq_ mAP and _inline_eq_ CorLoc on VOC N that outperforms previous best performed methods by a large margin. In summary, the main contributions of our work are listed as follows.