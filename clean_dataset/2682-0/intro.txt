N million new cases of skin cancer are diagnosed in the United States alone, each year. Melanoma is the advanced form of skin cancer and the global incidence of melanoma was estimated to be over N, N cases in N, with almost N, N deaths. Although the mortality rate is significant, early detection improves the survival rate to over N \% _cite_ _cite_ . Computer-aided-diagnostic systems that enable automatic and accurate skin lesion detection, segmentation and classification are thus essential. Recently, many studies attempted to address this challenge, for example: _cite_ proposed a deep learning framework consisting of two fully convolutional residual networks, to simultaneously segment and classify skin lesions; _cite_ introduced a deformable model using a newly defined speed function and stopping criterion for skin lesion segmentation; and _cite_ used a deep learning approach called fully convolutional residual network (FCRN) with more than N layers for both segmentation and classification. In this study we propose a CNN-based skin lesion segmentation framework, called SkinNet. The proposed CNN architecture is a modified version of the U-Net _cite_ . The latter has demonstrated state-of-the-art performance in various medical image segmentation tasks in recent years. The U-net architecture basically consists of a contracting path (encoder), which downsamples an image into a set of high-level features, followed by a symmetric expanding path (decoder), which uses the feature information to build a pixel-wise segmentation mask. SkinNet employs dilated convolutions _cite_ in the lowest layer of the encoder-branch in the U-Net, to provide a more global context for the features extracted from the image. Additionally, we replace the conventional convolution layers in both the encoder and decoder branches of U-Net, with dense convolution blocks, to better incorporate multi-scale image information. Section _ref_ describes the proposed method, dataset and experimental setup and the results are summarized in Section _ref_ .