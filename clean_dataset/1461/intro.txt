ND shape classification _cite_ is an important yet challenging task arising in recent years. Larger repositories of ND models _cite_ such as google sketchup and Yobi ND have been built for many applications. They include ND printing, game design, mechanical manufacture, medical analysis, and so on. To handle the increasing size of repositories, an accurate ND shape classification system is in demand. Quite a few hand-craft features _cite_, _cite_, _cite_ were proposed to solve the ND shape classification problem before. Interesting properties of a ND model are explored from different representations such as views _cite_, _cite_, _cite_, volumetric data _cite_, _cite_, _cite_, and mesh models _cite_, _cite_, _cite_, _cite_ . However, these features are not discriminative enough to overcome large intra-class variation and strong inter-class similarity. In recent years, solutions based on the convolutional neural network (CNN) _cite_, _cite_ have been developed for numerous computer vision applications with significantly better performances. As evidenced by recent publications _cite_, _cite_, _cite_, the CNN solutions also outperform traditional methods relying on hand-craft features in the ND shape classification problem. A CNN method classifies ND shapes using either view-based _cite_, _cite_ or volume-based input data _cite_, _cite_, _cite_ . A view-based CNN classifies ND shapes by analyzing multiple rendered views while a volume-based CNN conducts classification directly in the ND representation. Currently, the classification performance of the view-based CNN is better than that of the volume-based CNN since the resolution of the volumetric input data has to be much lower than that of the view-based input data due to higher memory and computational requirements of the volumetric input. On the other hand, since volume-based methods preserve the ND structural information, it is expected to have a greater potential in the long run. In this work, we target at shrinking the performance gap between volume-based CNN methods and view-based CNN methods, and call the resulting solution the ``Volumetric CNN" or VCNN in short. Furthermore, we attempt to conduct fundamental research on network design and understanding in the following two aspects. To illustrate the second point above, we show two confusion sets in Fig. _ref_ . It will be argued that the filter weights that connect the last fully connected (FC) layer and the output layer carry very valuable information. It points to the centroid of feature vectors of shapes in the same class, and is therefore called the "shape anchor vector" (SAV) for the class. Two shape classes are confusing if the angle of their SAVs is small and at least one of them has a large inter-class variance (or diversity) . The rest of this paper is organized as follows. Related work is reviewed in Sec. _ref_ . The proposed VCNN system is presented in Sec. _ref_ . Experimental results are given to demonstrate the superior performance of the VCNN method in Sec. _ref_ . Finally, concluding remarks are given in Sec. _ref_ .