Standard image classification is a fundamental problem in computer vision--assigning category labels to images. It can serve as a building block for many different computer vision tasks including object detection, visual segmentation, and scene parsing. Recent progress in deep learning~ _cite_ significantly improved classification performance on large scale image datasets~ _cite_ . Approaches typically assume image labels to be semantically independent and adapt either a multi-class or binary classifier to label images. In recent work~ _cite_, deep learning methods that take advantage of label relations have been proposed to improve image classification performance. However, in realistic settings, these label relationships could form a complicated graph structure. Take Figure~ _ref_ as an example. Various levels of interpretation could be formed to represent such an image. This image of a baseball scene could be described as an image at coarse level, or with a more concrete concept such as, or with even more fine-grained labels such as and objects such as,, . Models that incorporate semantic label relationships could be utilized to generate better classification results. The desiderata for these models include the ability to model label-label relations such as positive or negative correlation, respect multiple concept layers obtainable from sources such as WordNet, and to handle partially observed label data--given a subset of accurate labels for this image, infer the remaining missing labels. The contribution of this paper is in developing a structured inference neural network that permits modeling complex relations between labels, ranging from hierarchical to within-layer dependencies. We do this by defining a network in which a node is activated if its corresponding label is present in an image. We introduce stacked layers among these label nodes. These encode layer-wise connectivity among label classification scores, representing dependency from top-level coarse labels to bottom-level fine-grained labels. Activations are propagated bidirectionally and asynchronously on the label relation graph, passing information about the labels within or across concept layers to refine the labeling for the entire image. We have evaluated our method on three image classification datasets (AWA dataset~ _cite_, NUS-WIDE dataset~ _cite_ and SUNN dataset~ _cite_) . Experimental results show a consistent and significant performance gain with our structured label relation model compared with baseline and related methods.