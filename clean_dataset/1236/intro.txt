Signature verification systems aim to verify the identity of individuals by recognizing their handwritten signature. They rely on recognizing a specific, well-learned gesture, in order to identify a person. This is in contrast with systems based on the possession of an object (e.g. key, smartcard) or the knowledge of something (e.g. password), and also differ from other biometric systems, such as fingerprint, since the signature remains the most socially and legally accepted means for identification _cite_ . In offline (static) signature verification, the signature is acquired after the writing process is completed, by scanning a document containing the signature, and representing it as a digital image _cite_ . Therefore, the dynamic information about the signature generation process is lost (e.g. position and velocity of the pen over time), which makes the problem very challenging. Defining discriminative feature extractors for offline signatures is a hard task. The question ``What characterizes a signature'' is a difficult concept to implement as a feature descriptor, as illustrated in Figure _ref_ . This can be observed in the literature, where most of the research efforts on this field have been devoted to finding a good representation for signatures, that is, designing feature extractors tailored for signature verification, as well as using feature extractors created for other purposes _cite_ . Recent work uses texture features, such as Local Binary Patterns (LBP) _cite_, _cite_ and Gray-Level Co-occurrence Matrix (GLCM) _cite_ ; directional-based features such as Histogram of Oriented Gradients (HOG) _cite_ and Directional-PDF _cite_, _cite_ ; feature extractors specifically designed for signatures, such as the estimation of strokes by fitting Bezier curves _cite_ ; among others. No feature extractor has emerged as particularly suitable for signature verification, and most recent work uses a combination of many such techniques. The difficulty of finding a good representation for signatures reflects on the classification performance of signature verification systems, in particular to distinguish genuine signatures and skilled forgeries-forgeries that are made targeting a particular individual. When we consider experiments conducted on large public datasets, such as GPDS _cite_, the best reported results achieve Equal Error Rates around N \%, even when the number of samples for training is around N-N, with worse results using fewer samples per user. To address both the issue of obtaining a good feature representation for signatures, as well as improving classification performance, we propose a framework for learning the representations directly from the signature images, using convolutional neural networks. In particular, we propose a novel formulation of the problem, that incorporates knowledge of skilled forgeries from a subset of users, using a multi-task learning strategy. The hypothesis is that the model can learn visual cues present in the signature images, that are discriminative between genuine signatures and forgeries in general (i.e. not specific to a particular individual) . We then evaluate if this feature representation generalizes for other users, for whom we do not have skilled forgeries available. Our main contributions are as follows: N) we present formulations to learn features for offline signature verification in a Writer-Independent format. We introduce a novel formulation that uses skilled forgeries from a subset of users to guide the feature learning process, using a multi-task framework to jointly optimize the model to discriminate between users (addressing random forgeries), and to discriminate between genuine signatures and skilled forgeries; N) we propose a strict experimental protocol, in which all design decisions are made using a validation set composed of a separate set of users. Generalization performance is estimated in a disjoint set of users, from whom we do not use any forgeries for training; N) we present a visual analysis of the learned representations, which shows that genuine signatures and skilled forgeries get better separated in different parts of the feature space; N) lastly, we are making two trained models available for the research community, so that other researchers can use them as specialized feature extractors for the task. Experiments were conducted on four datasets, including the largest publicly available signature verification dataset (GPDS), achieving a large performance improvement in the state-of-the-art, reducing Equal Error Rates from N \% to N \% in GPDS-N. We used the features learned on this dataset to train classifiers for users in the MCYT, CEDAR and Brazilian PUC-PR datasets, also surpassing the state-of-the-art performance, and showing that the learned feature space not only generalizes to other users in the GPDS set, but also to other datasets. Preliminary results, using only genuine signatures for learning the features, were published as two conference papers. In _cite_, we introduced the formulation to learn features from genuine signatures from a development dataset, using them to train Writer-Dependent classifiers to another set of users. In _cite_, we analyzed the learned feature space and optimized the CNN architecture, obtaining state-of-the-art results on GPDS. The present work includes this formulation of the problem for completeness, with additional experiments on two other datasets (MCYT and CEDAR), a clearer explanation of the method and the experimental protocol, as well as the novel formulation that leverages knowledge of skilled forgeries for feature learning. The remaining of this paper is organized as follows: Section _ref_ reviews the related work on signature verification and on feature learning techniques. Section _ref_ details the formulation and methodology to learn features for offline signature verification, and section _ref_ describes our experimental protocol. Section _ref_ presents and discusses the results of our experiments. Lastly, section _ref_ concludes the paper.