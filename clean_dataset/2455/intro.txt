convolutional neural networks (CNNs) achieve state-of-the-art performance for a wide variety of tasks in computer vision, such as image classification and segmentation _cite_ . Recent studies have also shown that representations extracted from these networks can shed light on new tasks through transfer learning _cite_ . The superior performance of CNNs for large training datasets has led to their ubiquity in many industrial applications and to their emerging applications in science and medicine. Thus, CNNs are widely employed in many data-driven platforms such as cellphones, smart watches and robots. While the huge number of weights and convolutional filters in deep CNNs is key factor in their success, it makes them hard or impossible to interpret in general and especially for scientific and medical applications _cite_ . Compressing CNNs or reducing the number of weights, while keeping prediction performance, thus facilitates interpretation, and understanding in science and medicine. Moreover, compression benefits the use of CNNs in platforms with limited memory and computational power. In this paper, interpretability is defined as the ability to explain or to present the decisions made by the model in understandable terms to a human _cite_, say a biologist or a radiologist. Interpretability is typically studied from one of two perspectives. The first is algorithmic interpretablity and transparency of the learning mechanism. The other is post-hoc interpretability and explanation of the learned model using tools such as visualization. The first perspective attempts to answer the question that how the model learns and works, while the second perspective describes the predictions without explaining the learning mechanism. From the perspective of post-hoc interpretability, a CNN with fewer filters is easier to visualize and explain to human users, because CNNs are often visualized using graphical explanation of their filters _cite_ . Thus to make more interpretable CNNs, a compression scheme should reduce the number of filters while keeping the model accurate (predictively) . We call such schemes "structural compression". In this paper, we argue that structurally compressed networks with fewer numbers of filters are easier to be investigated or interpreted by humans for possible domain knowledge gain. The problem of compressing deep CNNs have been widely studied in literature, even though interpretability is not a motivating factor in majority of these studies. In the classical approach to compression of CNNs, individual weights, and not filters, are pruned and quantized _cite_ . We call these classical compression schemes "weight compression". Optimal brain damage _cite_, optimal brain surgeon _cite_, Deep Compression _cite_, binary neural networks _cite_ and most recently SqueezeNet _cite_ are some examples. On the other hand, some studies have investigated pruning filters instead of weights, however, the interpretability of pruned networks has not been studied in details _cite_ . These studies are focused on high compression rates and low memory usage. In this paper, our goal is not to achieve state-of-the-art compression ratio or memory usage rates, but we aim to investigate the interpretability of a compressed network. However, to compare our compression ratio and computational cost to a baseline method, we chose the structural compression in _cite_ . He et al. _cite_ and Li et al. _cite_ have studied structural compression based on removing filters and introduced importance indices based on average of incoming or outgoing weights to a filter. Pruning activations or feature-maps to achieve faster CNNs has been also studied in _cite_ . Pruning activations can be viewed as removing filters in specific locations of the input, however, those filters almost always remain in other locations. Thus it rarely results in any compression of filters. On the other hand, pruning filters from the structure is equal to removing them for all the possible locations and avoiding to store them. Additionally, because of the simplified structure, filter-pruned networks are more interpretable compared to activation-pruned ones, therefore more applicable in scientific and medical domains. Pruning a fully-trained neural network has a number of advantages over training the network from scratch with fewer filters. A difficulty in training a network from scratch is not knowing which architecture or how many filters to start with. While several hyper-parameter optimization techniques _cite_ exist, the huge numbers of possible architectures and filters would lead to a high computational cost in a combinatorial manner as in other model selection problems _cite_ . Pruning provides a systematic approach to find the minimum number of filters in each layer required for accurate training. Furthermore, recent results suggest that for large-scale CNNs, the accuracy of the pruned network is slightly higher compared to a network trained from scratch (_cite_ for VGG and ResNet, _cite_ for AlexNet) . For small-scale CNNs, it is possible to train a network from scratch that achieves the same accuracy as the pruned network even though the aforementioned computational cost is not trivial in this case. Additionally, in the majority of transfer learning applications based on well-trained CNNs, pruning algorithms achieve higher accuracies compared to training from scratch given the same architecture and number of filters _cite_ . For example, _cite_ showed that a pruned AlexNet gains N \% more classification accuracy in bird species categorization compared to training the network from scratch. Our main contributions in this paper are two folds. First, we introduce a greedy structural compression scheme to prune filters in CNNs. A filter importance index is defined to be the classification accuracy reduction (CAR) (similarly for regression or RAR) of the network after pruning that filter. This is similar in spirit to the regression variable importance measures in _cite_ . We then iteratively prune filters in a greedy fashion based on the CAR importance index. Although achieving state of the art compression ratio is not the main goal in this paper, we show that our CAR structural compression scheme achieve higher classification accuracy in a hold-out test set compared to the baseline structural compression methods. CAR compressed AlexNet without retraining can achieve a compression ratio of N (for layer N) to N (for layer N) while having a close-to-original classification accuracy (N \% top-N classification accuracy compared to original N \%) . This is N \% (for layer N) to N \% (for layer N) higher than the compression ratio from the benchmark method. If we fine-tune or retrain the CAR-compressed network, the compression ratio can be as high as N (for layer N) when maintaining the same N \% classification accuracy. We take advantage of weight pruning, quantization and coding by combining our method with Deep Compression _cite_ and report considerably improved compression ratio. For AlexNet, we reduce the size of individual convolutional layers by factor of N (for layer N) to N (for layer N), while achieving close to original classification accuracy (or N \% compared to N \%) through retraining the network. Our second contribution is bridging the compression and interpretation for CNNs. We demonstrate the ability of our CAR algorithm to remove functionally redundant filters such as color filters making the compressed CNNs more accessible to human interpreters without much classification accuracy loss. To our knowledge, such a connection between compression and functionality has not been reported previously. Furthermore, we introduce a variant of our CAR index that quantifies the importance of each image class to each CNN filter. This variant of our CAR importance index has been presented in _cite_, and is included in the Section N of this paper to establish the usefulness of the CAR index. Through this metric, a meaningful interpretation of each filter can be learned from the most and the least important class labels. This new interpretation of a filter is consistent with the visualized pattern selectivity of that filter. The rest of the paper is organized as follows. In section N, we introduce our CAR compression algorithm. The performance of the compression for the state-of-the-art CNNs in handwritten digit image and naturalistic image classification tasks is investigated in section N In section N, we connect compression to the interpretation of CNNs by visualizing functionality of pruned and kept filters in a CNN. In section N, a class-based interpretation of CNN filters using a variant of our CAR importance index is presented. The paper is concluded in section N.