Classification of very high resolution (VHR) image data remains a hard and time-consuming task. Major difficulties include the scarcity of available data, and the challenge of semantically interpreting the backscatter signal. Linked to those difficulties, there are no large-scale, image databases for Remote Sensing image analysis and knowledge discovery. Furthermore, while optical image classification has seen a breakthrough with the advent of methods that require Big Data, SAR-based systems have so far not experienced the same progress, likely because of not enough data with associated training labels is available. In this work we try to tackle the lack of training data, by introducing a large-scale image database. Precisely, our dataset contains more than _inline_eq_ image instances and respective labels, chosen from _inline_eq_ distinct semantic classes. Using this data, we perform a set of experiments to understand the impact of dataset size on classification accuracy. In this context, we also investigate the possibility to further expand the dataset with synthetic SAR images generated with the help of () . These are powerful generative models that have been shown to produce high-quality synthetic images in other fields, thereby reducing (or even compeltely avoiding) the annotation effort. Our main contributions in this work can be summarized as follow: