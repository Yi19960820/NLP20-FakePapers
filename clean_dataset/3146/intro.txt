This paper studies the task of person re-identification (re-ID) . Given a probe (person of interest) and a gallery, we aim to find in the gallery all the images containing the same person with the probe. We focus on the identification problem, a retrieval task in which each probe has at least one ground truth in the gallery _cite_ . A number of factors affect the re-ID accuracy, such as detection/tracking errors, variations in illumination, pose, viewpoint, . A critical influencing factor on re-ID accuracy is the misalignment of pedestrians, which can be attributed to two causes. First, pedestrians naturally take on various poses as shown in Fig. _ref_ . Pose variations imply that the position of the body parts within the bounding box is not predictable. For example, it is possible that one's hands reach above the head, or that one is riding a bicycle instead of being upright. The second cause of misalignment is detection error. As illustrated in the second row of Fig. _ref_, detection errors may lead to severe vertical misalignment. When pedestrians are poorly aligned, the re-ID accuracy can be compromised. For example, a common practise in re-ID is to partition the bounding box into horizontal stripes _cite_ . This method works under the assumption of slight vertical misalignment. But when vertical misalignment does happen as in the cases in Row N of Fig. _ref_, one's head will be matched to the background of a misaligned image. So horizontal stripes may be less effective when severe misalignment happens. In another example, under various pedestrian poses, the background may be incorrectly weighted by the feature extractors and thus affect the following matching accuracy. To our knowledge, two previous works _cite_ from the same group explicitly consider the misalignment problem. In both works, the pictorial structure (PS) is used, which shares a similar motivation and construction process with PoseBox, and the retrieval process mainly relies on matching the normalized body parts. While the idea of constructing normalized poses is similar, our work locates body joints using a state-of-the-art CNN based pose estimator, and the components of PoseBox are different from PS as evidenced by large-scale evaluations. Another difference of our work is the matching procedure. While _cite_ do not discuss the pose estimation errors which prevalently exist in real-world datasets, we show that these errors make rigid feature learning/matching with only the PoseBox yield inferior results to the original image, and that the three-stream PoseBox fusion network effectively alleviates this problem. Considering the above-mentioned problems and the limit of previous methods, this paper proposes the pose invariant embedding (PIE) as a robust visual descriptor. Two steps are involved. First, we construct a PoseBox for each pedestrian bounding box. PoseBox depicts a pedestrian with standarized upright stance. Carefully designed with the help of pose estimators _cite_, PoseBox aims to produce well-aligned pedestrian images so that the learned feature can find the same person under intensive pose changes. Trained alone using a standard CNN architecture _cite_, we show that PoseBox yields very decent re-ID accuracy. Second, to reduce the impact of information loss and pose estimation errors (Fig. _ref_) during PoseBox construction, we build a PoseBox fusion (PBF) CNN model with three streams as input: the PoseBox, the original image, and the pose estimation confidence. PBF achieves a globally optimized tradeoff between the original image and the PoseBox. PIE is thus defined as the FC activations of the PBF network. On several benchmark datasets, we show that the joint training procedure yields competitive re-ID accuracy to the state of the art. To summarize, this paper has three contributions.