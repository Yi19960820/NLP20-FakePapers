Deep learning has been widely applied to medical image recognition since its great success in natural image recognition, and has achieved state-of-the-art performance in various areas such as anatomical structure identification, lesion detection and classification _cite_ . Unlike general object classification, medical images often have intrinsic characteristics that can be exploited to facilitate neural network learning for improved results. For example, medical recognition tasks on images acquired from computed tomography (CT) or magnetic resonance imaging (MRI) generally favor a ND convolutional neural network (CNN) over a ND CNN, due to the additional spatial information in three dimensions _cite_ . Another example of neural networks that exploit medical intrinsic information is the BrainNetCNN, where special edge-to-edge, edge-to-node and node-to-graph convolutional filters are designed to leverage topological locality of brain networks for the prediction of neurodevelopmental outcomes _cite_ . In this paper, we propose a novel method that leverages disease progression learning for medical image recognition. Concretely, given any medical recognition problem that is associated with a disease progression, we use long short-term memory (LSTM) to model the disease progression, for example, to predict survival time based on brain tumor images (e.g. short-term survival, medium-term survival and long-term survival) _cite_, or a disease staging problem. As illustrated in Figure _ref_ (a, b, c), the disease staging problem commonly exists across multiple modalities, including but not limited to classifying breast histopathological images into normal, benign, in-situ or invasive _cite_ ; MRI images of white matter into mild, moderate or severe based on age-related changes _cite_ ; and retinal fundus images into no-diabetic-retinopathy (NDR), simple-diabetic-retinopathy (SDR), pre-proliferative-diabetic-retinopathy (PPDR) or proliferative-diabetic-retinopathy (PDR) _cite_ . Rather than considering each different stage as an independent class as done in most previous research, we hypothesize that there is a stage difference memory driven by the disease progression that should also be represented in the neural network. By leveraging this memory information from the stage sequence, more robust and optimal results could be possible. LSTM is a widely-used network that is powerful for sequential data learning, as it has memory units that efficiently remember previous steps _cite_ . There are previous publications using LSTM for medical data, but mostly based on diagnostic text reports _cite_, ND image stacks _cite_, or clinical measurements/admissions _cite_, among which, some also use the concept of disease progression modeling _cite_ . However, all previous work either do not clearly define stage classes for a disease progression, or still consider each stage as an independent class and the sequence learning only occurs within each individual stage class. I.e., there is no explicit learning of the stage sequence itself, other than learning of temporal sequence (e.g. a series of clinical events), or spatial sequence (e.g. ND MRI/CT images) . To the best of our knowledge, we are the first to use LSTM for the learning of stage sequence along the disease progression for medical image recognition, with each stage represented by feature vectors that are extracted from a well-established vision model (e.g. GoogleNet or ResNet) . Auxiliary outputs from the vision model are also adopted in order to capture stage features that may not be continuous along the disease progression. Our proposed method is evaluated on a diabetic retinopathy dataset, where it shows a performance increase of around N _inline_eq_ in disease staging accuracy, compared to the baseline method that is similar but without disease progression learning.