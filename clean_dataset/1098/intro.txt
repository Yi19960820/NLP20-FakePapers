\noindent Consider the images in Fig.~ _ref_ . The image on the left was correctly classified as a flute by a deep convolutional neural network~ \citep [] {HeNa} . This is quite a remarkable feat for such a complicated image. After the network was trained on millions of photographs, this and many other images were accurately categorized into one thousand natural object categories, surpassing, for the first time, the accuracy of a human observer on the ImageNet classification challenge. Now, consider the image in the middle. On its face, it is quite simple compared to the image on the left. It is just a binary image containing two curves. Further, it has a rather distinguishing property, at least to the human eye: both curves are the same. The relation between the two items in this simple scene is rather intuitive and immediately obvious to a human observer. Yet, the CNN failed to learn this relation even after seeing millions of training examples. Why is it that a CNN can accurately detect the flute while struggling to recognize the simple relation depicted in the middle panel of Fig.~ _ref_ ? That such task is extremely difficult for contemporary computer vision algorithms like CNNs, is known . However, these results, which often relied on a single architecture, were not entirely conclusive: does the inability of CNNs to solve various visual-relation problems reflect a poor choice of network hyperparameters or rather a systematic failure of the entire class of models? To our knowledge, there has been no systematic exploration of the limits of contemporary machine learning algorithms on relational reasoning problems. \newline \indent In this study, we will probe the limits of CNNs on visual-relation tasks. In Experiment N, we perform a systematic performance analysis of CNN architectures on each of the twenty-three synthetic visual reasoning test (SVRT) problems, which reveals a dichotomy of visual-relation tasks: hard same-different problems vs. easy spatial-relation problems. In Experiment N, we describe a novel, controlled, visual-relation challenge which convincingly shows that CNNs solve same-different tasks via rote memorization. With these experiments, we hope to motivate the computer vision community to reconsider existing visual question answering challenges and turn to cognitive science and neuroscience for inspiration in the design of visual reasoning architectures.