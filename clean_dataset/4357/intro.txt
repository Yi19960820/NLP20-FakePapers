Visual tracking is one of the most fundamental problems in computer vision, and has a long list of applications such as robotics, human-machine interaction, intelligent vehicle, surveillance and so forth. Despite great advances in recent years, visual tracking remains challenging due to many factor including occlusion, scale variation, etc. Recently, Siamese network has drawn great attention in the tracking community owing to its balanced accuracy and speed. By formulating object tracking as a matching problem, Siamese trackers~ _cite_ aim to learn {\it offline} a generic similarity function from a large set of videos. Among these methods, the work of~ _cite_ proposes a one-stage Siamese-RPN for tracking by introducing the regional proposal network (RPN), originally used for object detection~ _cite_, into Siamese network. With the proposal extraction by RPN, this approach simultaneously performs classification and localization from multiple scales, achieving excellent performance. Besides, the use of RPN avoids applying the time-consuming pyramid for target scale estimation~ _cite_, resulting in a super real-time solution. Despite having achieved promising result, Siamese-RPN may drift to the background especially in presence of similar semantic distractors (see Fig.~ _ref_) . We identify two reasons accounting for this. First, the distribution of training samples is imbalanced: (N) positive samples are far less than negative samples, leading to ineffective training of the Siamese network; and (N) most negative samples are easy negatives (non-similar non-semantic background) that contribute {\it little} useful information in learning a discriminative classifier~ _cite_ . As a consequence, the classifier is dominated by the easily classified background samples, and degrades when encountering difficult similar semantic distractors. Second, low-level spatial features are not fully explored. In Siamese-RPN (and other Siamese trackers), only features of the last layer, which contain more semantic information, are explored to distinguish target/background. In tracking, nevertheless, background distractors and the target may belong to the same category, and/or have similar semantic features~ _cite_ . In such case, the high-level semantic features are less discriminative in distinguishing target/background. In addition to the issues above, the one-stage Siamese-RPN applies a single regressor for target localization using pre-defined anchor boxes. These boxes are expected to work well when having a high overlap with the target. However, for {\it model-free} visual tracking, no prior information regarding the target object is known, and it is hard to estimate how the scale of target changes. Using pre-defined coarse anchor boxes in a single step regression is insufficient for accurate localization~ _cite_ (see again Fig.~ _ref_) . The class imbalance problem is addressed in two-stage object detector (\eg, Faster R-CNN~ _cite_) . The first proposal stage rapidly filters out most background samples, and then the second classification stage adopts sampling heuristics such as a fixed foreground-to-background ratio to maintain a manageable balance between foreground and background. In addition, two steps of regressions achieve accurate localization even for objects with extreme shapes. Motivated by the two-stage detector, we propose a multi-stage tracking framework by cascading a sequence of RPNs to solve the class imbalance problem, and meanwhile fully explore features across layers for robust visual tracking. As the {\bf first contribution}, we present a novel multi-stage tracking framework, the Siamese Cascaded RPN (C-RPN), to solve the problem of class imbalance by performing hard negative sampling~ _cite_ . C-RPN consists of a sequence of RPNs cascaded from the high-level to the low-level layers in the Siamese network. In each stage (level), an RPN performs classification and localization, and outputs the classification scores and the regression offsets for the anchor boxes in this stage. The easy negative anchors are then filtered out, and the rest, treated as hard examples, are utilized as training samples for the RPN of the next stage. Through such process, C-RPN performs stage by stage hard negative sampling. As a result, the distributions of training samples are sequentially more balanced, and the classifiers of RPNs are sequentially more discriminative in distinguishing more difficult distractors (see Fig.~ _ref_) . {\bf Another benefit} of C-RPN is the more accurate target localization compared to the one-stage SiamRPN~ _cite_ . Instead of using the pre-defined coarse anchor boxes in a single regression step, C-RPN consists of multiple steps of regressions due to multiple RPNs. In each stage, the anchor boxes (including {\it locations} and {\it sizes}) are adjusted by the regressor, which provides better initialization for the regressor of next stage. As a consequence, C-RPN progressively refines the target bounding box, leading to better localization as shown in Fig.~ _ref_ . Leverage features from different layers in the neural networks has been proven to be beneficial for improving model discriminability~ _cite_ . To fully explore both the high-level semantic and the low-level spatial features for visual tracking, we make the {\bf second contribution} by designating a novel feature transfer block (FTB) . Instead of separately using features from a single layer in one RPN, FTB enables us to fuse the high-level features into low-level RPN, which further improves its discriminative power to deal with complex background, resulting in better performance of C-RPN. Fig.~ _ref_ illustrates the framework of C-RPN. Last but not least, the {\bf third contribution} is to implement a tracker based on the proposed C-RPN. In extensive experiments on six benchmarks, including OTB-N~ _cite_, OTB-N~ _cite_, VOT-N~ _cite_, VOT-N~ _cite_, LaSOT~ _cite_ and TrackingNet~ _cite_, our C-RPN consistently achieves the state-of-the-art results and runs in real-time.