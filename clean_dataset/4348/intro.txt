Learning a good representation from complex data distribution can be resolved by deep directed generative models. Among them, Generative Adversarial Network (GAN) _cite_ is proposed to generate complicated data space by sampling from a simple pre-defined latent space. Specifically, a generator is modeled to map the latent samples to real data, and a discriminator is applied to differentiate real samples from generated ones. However, the original GAN only learns the forward mapping from a entangled latent space to data space. Given the complicated data, it lacks the inverse inference network to map the data back to the interpretable latent space. Efforts have been put on learning the bidirectional mapping in an adversarial way. InfoGAN _cite_ is proposed to address the problem of uninformative latent space of GAN, by disentangling the latent variables, and maximizing the mutual information between a subset of the variables and the observations. InfoGAN is able to learn a representation with semantic meaning in a fully unsupervised way. However, faithful reconstruction cannot be achieved by InfoGAN. Another model named Adversarial Autoencoder (AAE) _cite_ performs variational inference by matching the aggregated posterior distribution with the prior distribution using an adversarial loss. The autoencoder-like structure guarantees a good reconstruction performance, but the generation using the sampled latent variables is not faithful enough. BiGAN _cite_ and ALI _cite_ both propose an encoder (inference network) and decoder (generative network), and seek to match the joint distributions of latent variables and data from the two networks. However, the objective functions do not constraint on the relationship between the latent variables and the observations, which results in an unsatisfied reconstruction performance. ALICE _cite_ resolves this non-identifiability issues by additionally optimizing the conditional entropy. But it does not learn a disentangled latent space for semantic interpretation and knowledge discovery. Bi-directional mapping is also addressed in some applications like image domain transformation or image semantic editing. In BiCycleGAN _cite_, the authors differentiated two models cVAE-GAN and cLR-GAN and explained the hybrid model in an intuitive way (regarding to real or fake sampling) . It does not encode interpretable information into the latent vector, but directly concatenates the vector with the images from another domain. crVAE _cite_ could only demonstrate the semantic meaning of latent vector from visual inspection. IAN _cite_ proposed a hybridization of VAE and GAN to solve the semantic photo editing problem by improving the representation capability of latent space without increasing its dimensionality. The decoder of VAE is used as generator of GAN, and hidden layer outputs of discriminator are used to quantify reconstruction loss, which was showed to improve the reconstruction quality. However no cycle consistency was enforced and the latent space was not disentangled. DTN _cite_ applied a similar structure for image domain transfer, while the latent space is not constrained to a regularized distribution, thus random generation tasks were not performed. In this paper, we seek to learn a generic interpretable representation and bidirectional network which is capable of reconstruction, generation and clustering at the same time. A model supporting all these capabilities is important for data analysis and transmission. Reconstruction ability will help data compression while transmitting. Clustering and generation ability will benefit the natural analysis of complicated data without human prior knowledge. we first perform a theoretical analysis of two types of structures, which are x-Rep-x and Rep-x-Rep. We identify their advantages and disadvantages respectively by studying the loss functions they try to minimize, and relate it to the mutual information and conditional entropy in the information theory _cite_ . Then we propose a novel model involving the concept of cycle consistency _cite_ to combine those two structures, which is able to achieve a better overall performance in terms of unsupervised classification accuracy, data reconstruction and generation by learning a useful generic disentangled latent space. Finally, we show and analyze the effectiveness of this new model on the image datasets like MNIST, FashionMNIST, CelebA and SVHN.