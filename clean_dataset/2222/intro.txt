Salient object detection aims at identifying visually interesting object regions that are consistent with human perception. It is essential in many computer vision tasks including object-aware image retargeting _cite_ interactive image segmentation _cite_ and so on. Most of the traditional saliency detection methods are based on low-level hand-crafted features such as color and texture descriptors, or they compute variants of appearance uniqueness and region compactness based on statistical priors, e.g. center prior _cite_ and boundary prior _cite_ . These methods report acceptable results on relatively simple datasets, but their saliency maps deteriorate when the input images become cluttered and complicated. Recently, deep learning has achieved great success in high-level computer vision tasks, and many deep learning based saliency detection methods _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ have been proposed to learn competent high-level feature representations for salient objects, which achieve state-of-the-art performance and outperform unsupervised saliency detection methods. These methods are either built on semantic segmentation _cite_ (to leverage high-level semantic cues) or they learn saliency features by exploiting different datasets _cite_ . The basic priors (center prior, boundary prior and etc.) used in unsupervised saliency detection methods are summarized and described with human knowledge. They are more universal and applicable to general cases. Even though the performance has been outperformed by deep learning based methods, there still exit scenarios where unsupervised methods outperform deep learning based methods, see Fig.~ _ref_ for examples. This naturally raises a question that whether the data-driven deep learning based saliency detection methods have sufficiently exploited the statistics of saliency. In this paper, we investigate the problem that ``Could unsupervised saliency and deep saliency benefit each other to achieve even better performance?'' A positive answer will provide deeper insight to understand the nature of salient object detection. To this end, we propose to bridge the deep supervised saliency with unsupervised saliency by integrating deep and unsupervised saliency in a unified framework for salient object detection. Our method takes results of unsupervised saliency (RBD _cite_) and normalized color images as inputs, and directly learns an end-to-end mapping between inputs and the corresponding saliency maps. Then multi-scale saliency fusion is performed to get a spatially consistent saliency map.