The ability to train a system that detects objects in cluttered scenes by only naming the objects in the training images, without specifying their number or their bounding boxes, is understood to be of major importance. Then it becomes possible to annotate very large datasets or to automatically collect them from the web. Most current methods to train object detection systems assume strong supervision _cite_ . Providing both the bounding boxes and their labels as annotations for each object, still renders such methods more powerful than their weakly supervised counterparts. Although the availability of larger sets of training data is advantageous for the training of convolutional neural networks (CNNs), weak supervision as a means of producing those has only been embraced to a limited degree. The proposed weak supervision methods have come in some different flavours. One of the most common approaches _cite_ consists of the following steps. The first step generates object proposals. The second stage extracts features from the proposals. And the final stage applies multiple instance learning (MIL) to the features and finds the box labels from the weak bag (image) labels. This approach can thus be improved by enhancing any of its setps. For instance, it would be advantageous if the first stage were to produce more reliable-and therefore fewer-object proposals. It is the aforementioned approach that our weak supervision algorithm also follows. To improve the detection performance, object proposal generation, feature extraction, and MIL are trained in a cascaded manner, in an end-to-end way. We propose two architectures. The first is a two stage network. The first stage extracts class specific object proposals using a fully convolutional network followed by a global average (max) pooling layer. The second stage extracts features from the object proposals by a ROI pooling layer and performs MIL. Given the importance of getting better object proposals we added a middle stage to the previous architecture in our three stage network. This middle stage performs a class specific segmentation using the input images and the extracted objectness of the first stage. This results in more reliable object proposals and a better detection. The proposed architecture improves both initial object proposal extraction and final object detection. In the forward sense, less noisy proposals indeed lead to improved object detection, due to the non-convexity of the cost function. In the reverse, backward sense, due the weight sharing between the first layers of both stages, training the MIL on the extracted proposals will improve the performance of feature extraction in the first convolutional layers and as a result will produce more reliable proposals. Next, we review related works in section N and discuss our proposed method in section N. In section N we explain the details of our experiments, incl. the dataset and complete set of experiments and results.