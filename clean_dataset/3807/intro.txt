Tremendous effort has focused on the tasks of object instance detection and pose estimation in images and videos. In this paper we consider the pose estimation in a single RGB-D image, as shown in Fig.~ _ref_ . Given the extra depth channel, it becomes feasible to extract the full ND pose (ND rotation and ND translation) of object instances present in the scene. Pose estimation has important applications in many areas, such as robotics _cite_, medical imaging _cite_, and augmented reality _cite_ . Recently, Brachmann \etal _cite_ achieved state-of-the-art results by adapting analysis-by-synthesis approach for pose estimation in RGB-D images. They use a random forest _cite_ to obtain pixelwise dense predictions. Building upon the system of _cite_, we propose a novel method to learn to compare in the analysis-by-synthesis framework. We use a convolutional neural network (CNN) inside a probabilistic context to achieve this. Analysis-by-synthesis has been a successful approach for many tasks in computer vision, such as object recognition _cite_, scene parsing _cite_, pose estimation and tracking _cite_ . A forward synthesis model generates images from possible geometric interpretations of the world, and then selects the interpretation that best agrees with the measured visual evidence. In particular for pose estimation, the idea is to compare the observation with the output of a forward process, such as a rendered image of the object of interest in a particular pose. When attempting pose estimation in RGB-D images, comparing for analysis-by-synthesis is nontrivial due to occlusion or complicated sensor noise. There are for example areas with no depth measurements in Kinect or poor IR-reflectance. The paper is organized as follows. Section~ _ref_ provides an overview of related work. Our proposed approach is described in Sec.~ _ref_ . In Sec.~ _ref_ we present evaluation of our method compared to the state-of-the-art on two datasets. We conclude the paper in Sec.~ _ref_ .