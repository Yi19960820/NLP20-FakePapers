Scene text contains rich and high-level semantic information which is crucial for scene understanding. Recognizing text in the wild usually involves two steps, text detection and text recognition. In this paper, we focus on text recognition which directly convert cropped text region images into text strings. Since the development of deep learning, scene text recognition has become a hot topic in computer vision. Although OCR has been quite successful, it mainly aims at neat document. Due to the complexity of natural scenes, scene text recognition is still challenging. Fig.N shows some quite difficult examples. The current mainstream scene text recognition method is to treat it as sequence recognition which usually employs RNN to capture contextual information. We call this approach context-level modelling. Although some texts in natural images do have explicit semantic information, such as English words, many scene texts just are simple concatenation of characters without explicit contextual relationship, such as Fig.N (c) . At this point, just use context-level modelling usually does not handle decently. In this paper, we present a novel and effective framework called Double Supervised Network with Attention Mechanism (DSAN) for lexicon-free scene text recognition. Different from existing methods, DSAN treats semantic information in text from two perspectives. It contains two supervision branches to tackle explicit and inexplicit semantic information respectively. Specifically, beyond context-level modelling branch which aims at capturing explicit semantic information, one supervision enhancement branch is applied to handle inexplicit semantic information at character level. These two branches have mutually reinforcing effects and they are jointly trained together. In addition, one text attention module is integrated in the entire framework which can make the model to adaptively focus on the most important areas. We conduct experiments on three benchmarks and the results demonstrate the effectiveness of the proposed method.