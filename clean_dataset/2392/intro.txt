An ongoing research interest in the area of scene understanding and robotic perception is the minimization of viewpoints necessary to reconstruct the ND geometry of an object. Particularly, the maturation of mobile robots capable of interacting and navigating unfamiliar environments, and the recent availability of low-cost depth sensors puts emphasis on methods for reconstructing ND geometry of objects in a robot's field-of-view. The proposed approach employs a deep convolutional neural network (CNN) to learn generic geometric features and makes use of these to carry out object completion by means of a single depth map. An auto-encoder is used to learn a compressed representation of object geometries in order to achieve high-resolution reconstruction while drastically reducing the number of parameters in the final layers of the network. The auto-encoder is separately trained on uniformly spaced sub-regions of voxelizations and is stacked on the end of the CNN for fine-tuning. This allows the CNN to, in effect, regress on a compressed representation of geometric feature voxelizations while still producing high resolution reconstructions. Early works in the area of ND reconstruction proposed sparse methods involving a minimum of two views, which attempt to explicitly calculate the depth of a set of points in a set of images. The N-point algorithm _cite_ by Longuet-Higgins in N followed by Hartley's normalized adaptation in N make use of the epipolar constraint between a minimum of N points to determine corresponding depths. The two-view case was generalized by Weng, Liu and Huang _cite_ as well as Spetsakis and Aloimonos _cite_ to support an arbitrary number of views with the introduction of the \lq trifocal tensor \rq, which captures the trilinear relationship of points between more than two views. Most recently in N, Wu et al. trained a convolutional deep belief network on depth maps and volumetric representations of objects to learn generic shape representations concurrently with object classifications _cite_ . As part of this work, the ModelNet data set was created, which is used throughout this project.