When any scene is presented to the human visual system, it rapidly summarizes it through eye fixation on salient regions of the scene. Visual attention, or more particularly selective visual attention is the main reason behind this phenomenon. For more than a decade, researchers are trying to develop computational models of selective attention as it’s modeling has numerous important applications across different fields like computer vision, robotics etc. _cite_ _cite_ . Many methods of saliency detection have been reported in existing literature and they can be broadly categorized into two groups: low level or bottom-up methods and learning based methods. Low level methods generally seek inspirations from biological processes. Most of the models from this category follow a general pipeline which was first proposed by the seminal work of Itti et al. _cite_ . The authors extracted low level features such as color, orientation, texture etc., from images, computed feature specific saliency maps and finally integrated these to produce master saliency map. ‘Center-surround difference operator is usually employed to construct feature-specific saliency maps. Gao et al. _cite_ also compared center and surround features, using KL-Divergence in order to measure distinctness of a specific pixel and subsequently its saliency. Bruce and Tsotsos _cite_ conjectured salient regions contain maximum ‘self-information’ relative to their surroundings. Seo and Milanfar _cite_ proposed a local ‘self-resemblance’ mechanism based saliency model. Among more recent bottom-up approaches, Murray et al. _cite_ modeled saliency from a color space perspective. Holzbach and Cheng _cite_ proposed a method which predicts saliency via calculating dissimilarity between multiple sampling templates. Goferman et al. _cite_ also exploited mainly low level features for saliency detection; however their model also incorporates face detector for high level feature detection. Recently, machine learning based approaches have gained popularity because in addition to the low level features, these models also take high level contextual and semantic features into account. As high level features play an important role in driving visual attention, learning based models generally performs better. Judd et al. _cite_ trained a SVM (support vector machine) classifier based model directly from human eye tracking data by utilizing hand crafted low, mid and high level features. Vig et al. _cite_ also projected a similar SVM based algorithm but instead of using hand-tuned features their model learns the ‘optimal saliency features’ automatically from the human eye fixation data. Kavak et al. _cite_ proposed a multiple kernel based learning approach to saliency detection. In this paper, we propose an end to end convolutional neural network based model, WEPSAM, for accurate saliency detection. It is a well-known fact that convolutional neural networks (CNN) are very powerful learning systems. From semantic segmentation to object recognition, CNN based models have achieved state of the art performances in a wide range of computer vision tasks. However one major drawback associated with convolutional nets is that their performance critically depends on the size of the dataset. Often large scale datasets, required for proper training of convolutional nets, are not available. To tackle this problem, we introduce a ‘weak data’ driven pre-training paradigm which proves to be a simple but effective solution. The main objective of our work is not to endorse any particular CNN architecture, but rather to present a new training scheme which can help us to train a CNN much faster (compared to a randomly initialized network) for tasks such asIt saliency prediction where ground truth data is scarce. The primary contributions of our paper are as follows: