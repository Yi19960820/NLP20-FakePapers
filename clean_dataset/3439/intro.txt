In this paper, we investigate an interesting and nontrivial problem in computer vision, object skeleton extraction from natural images (Fig.~ _ref_) . Here, the concept of ``object'' means a standalone thing with a well-defined boundary and center~ _cite_, such as an animal, a human, and a plane, as opposed to amorphous background stuff, such as sky, grass, and mountain. Skeleton, also called, is a useful structure-based object descriptor. Extracting object skeletons directly from natural images is of broad interests to many real applications including object recognition/detection~ _cite_, text recognition~ _cite_, road detection and blood vessel detection~ _cite_ . Skeleton extraction from pre-segmented images~ _cite_ used to be a hot topic, which has been well studied and successfully applied to shape-based object matching and recognition~ _cite_ . However, such methods have severe limitations when being applied to natural images, as segmentation from natural images is still an unsolved problem. Skeleton extraction from natural images is a much more challenging problem. The main difficulties stem from three aspects: (N) Complexity of natural scenes: Natural scenes can be very cluttered. Amorphous background elements, such as fences, bricks and even the shadows of objects, exhibit somewhat self-symmetry, and thus are prone to cause distractions. (N) Diversity of objects: Objects in natural images may exhibit entirely different colors, textures, shapes and sizes. (N) Specificity of skeletons: local skeleton segments have a variety of patterns, such as straight lines, T-junctions and Y-junctions. In addition, a local skeleton segment naturally associates with a certain scale, determined by the thickness of its corresponding object part. However, it is unknown in natural images. We term this problem as unknown-scale problem in skeleton extraction. A number of works have been proposed to study this problem in the past decade. Broadly speaking, they can be categorized into two groups: (N) Traditional image processing methods~ _cite_, which compute skeletons from a gradient intensity map according to some geometric constraints between edges and skeletons. Due to the lack of object prior, these methods can not handle the images with complex scenes; (N) Recent learning based methods~ _cite_, which learn a per-pixel classification or segment-linking model based on elaborately hand-designed features computed at multi-scales for skeleton extraction. Limited by the ability of traditional learning models and hand-designed features, these methods fail to extract the skeletons of objects with complex structures and cluttered interior textures. In addition, such per-pixel/segment models are usually quite time consuming for prediction. Consequently, there still remains obvious gap between these skeleton extraction methods and human perception, in both performance and speed. Skeleton extraction has its unique aspect by looking into both local and global image context, which requires much more powerful models in both multi-scale feature learning and classifier learning, since the visual complexity increases exponentially with the size of the context field. To tackle the obstacles mentioned above, we develop a holistically-nested network with multiple scale-associated side outputs for skeleton extraction. The holistically-nested network~ _cite_ is a deep fully convolutional network (FCN) ~ _cite_, which enables holistic image training and prediction for per-pixel tasks. Here, we connect a scale-associated side output to each convolutional layer in the holistically-nested network to address the unknown-scale problem in skeleton extraction. Referring to Fig.~ _ref_, imagine that we are using multiple filters with different sizes (such as the convolutional kernels in convolutional networks) to detect a skeleton pixel with a certain scale; then only the filters with the sizes larger than the scale will have responses on it, and others will not. Note that the sequential convolutional layers in a holistically-nested network can be treated as the filters with increasing sizes (the receptive field sizes on the original image of each convolutional layer are increasing from shallow to deep) . So each convolutional layer is only able to capture the features of the skeleton pixels with scales less than its receptive field size. The sequential increasing receptive field sizes provide a principle to quantize the skeleton scale space. With these observations, we propose to impose supervision to each side output, optimizing it towards a scale-associated groundtruth skeleton map. More specifically, each skeleton pixel in it is labeled by a quantized scale value and only the skeleton pixels whose scales are smaller than the receptive filed size of the side output are reserved. Thus, each side output is associated with some certain scales and able to give a certain number of scale-specific skeleton score maps (the score map for one specified quantized scale value) when predicting. The final predicted skeleton map can be obtained by fusing these scale-associated side outputs. A straightforward fusion method is to average them. However, a skeleton pixel with larger scale probably has a stronger response on a deeper side output, and a weaker response on a shallower side output; a skeleton pixel with smaller scale may have strong responses on both of the two side outputs. By considering this phenomenon, for each quantized scale value, we propose to use a scale-specific weight layer to fuse the corresponding scale-specific skeleton score map provided by each side output. In summary, the core contribution of this paper is the proposal of the scale-associated side output layer, which enables both target learning and fusion in a scale-associated way. Therefore, our holistically-nested network is able to localize skeleton pixels with multiple scales. To the best of our knowledge, there are only two datasets related to our task. One is the SYMMAXN dataset~ _cite_, which is converted from the well-known Berkeley Segmentation Benchmark (BSDSN) ~ _cite_ . However, this dataset is used for local reflection symmetry detection. Local reflection symmetry~ _cite_ is a kind of low-level feature of image, regardless of the concept of ``object''. Some samples in this dataset are shown in Fig.~ _ref_ (a) . Note that, a large number of symmetries occur in non-object parts. Generally, object skeleton is a subset of local reflection symmetry. The other one is the WH-SYMMAX dataset~ _cite_, which is converted from the Weizmann Horse dataset~ _cite_ . This dataset is suitable to verify object skeleton extraction methods; however, as shown in Fig.~ _ref_ (b) the limitation is that only one object category, the horse, is contained in it. To evaluate skeleton extraction methods, we construct a new dataset, named SKN . There are N natural images in this dataset, which are selected from the recent published MS COCO dataset~ _cite_ . The objects in these N images belong to a variety of categories, including humans, animals, such as birds, dogs and giraffes, and artificialities, such as planes and hydrants. We apply a skeletonization method~ _cite_ to the provided human-annotated foreground segmentation maps of the selected images to generate the groundtruth skeleton maps. Some samples of the SKN dataset are shown in Fig.~ _ref_ (c) . We evaluate several skeleton extraction methods as well as symmetry detection methods on both SKN and WH-SYMMAX. The experimental results demonstrate that the proposed method significantly outperforms others.