chest X-ray (CXR) has been one of the most common radiological examinations in lung and heart disease diagnosis. Currently, reading CXRs mainly relies on professional knowledge and careful manual observation. Due to the complex pathologies and subtle texture changes of different lung lesion in images, radiologists may make mistakes even when they have experienced long-term clinical training and professional guidance. Therefore, it is of importance to develop the CXR image classification methods to support clinical practitioners. The noticeable progress in deep learning has benefited many trials in medical image analysis, such as lesion segmentation or detection _cite_, diseases classification _cite_, noise induction _cite_, image annotation _cite_, registration _cite_, regression _cite_ and so on. In this paper, we investigate the CXR classification task using deep learning. Several existing works on CXR classification typically employ the for training. For example, Wang \etal _cite_ evaluate four classic CNN architectures, \ie AlexNet _cite_, VGGNet _cite_, GoogLeNet _cite_, ResNet _cite_, to tell the presence of multiple pathologies using a global CXR image. In addition, using the same network, the disease lesion areas are located in a weakly supervised manner. Viewing CXR classification as a multi-label recognition problem, Yao \etal _cite_ explore the correlation among the N pathologic labels with global images in ChestX-rayN _cite_ . Using a variant of DenseNet _cite_ as an image encoder, they adopt the Long-short Term Memory Networks (LSTM) _cite_ to capture the dependencies. Kumar \etal _cite_ investigate that which loss function is more suitable for training CNNs from scratch and present a boosted cascaded CNN for global image classification. The recent effective method consists in CheXNet _cite_ . It fine-tunes a N-layer DenseNet on the global chest X-ray images, which has a modified last fully-connected layer. However, the global learning strategy can be compromised by two problems. On the one hand, as shown in Fig.~ _ref_ (the first row), the lesion area can be very small (red bounding box) and position unpredictable (\eg, ``Atelectasis'') compared with the global image, so using the global image for classification may include a considerable level of noise outside the lesion area. This problem is rather different from generic image classification _cite_ where the object of interest is usually positioned in the image center. Considering this fact, it is beneficial to induce the network to focus on the lesion regions when making predictions. On the other hand, due to the variations of capturing condition, \eg, the posture of the patient and the small size of children body, the CXR images may undergo distortion or misalignment. Fig.~ _ref_ (the second row) presents a misalignment example. The irregular image borders may exist an non-negligible effect on the classification accuracy. Therefore, it is desirable to discover the salient lesion regions and thus alleviate the impact of such misalignment. To address the problems caused by merely relying on the global CXR image, this paper introduces a three-branch attention guided convolutional neural network (AG-CNN) to classify the lung or heart diseases. AG-CNN is featured in two aspects. First, it has a focus on the local lesion regions which are disease specific. Generally, such a strategy is particularly effective for diseases such as "Nodule", which has a small lesion region. In this manner, the impact of the noise in non-disease regions and misalignment can be alleviated. Second, AG-CNN has three branches, \ie a global branch, a local branch and a fusion branch. While the local branch exhibits the attention mechanism, it may lead to information loss in cases where the lesion areas are distributed in the whole images, such as Pneumonia. Therefore, a global branch is needed to compensate for this error. We show that the global and local branches are complementary to each other and, once fused, yield favorable accuracy to the state of the art. The working mechanism of AG-CNN is similar to that of a radiologist. We first learn a global branch that takes the global image as input: a radiologist may first browse the whole CXR image. Then, we discover and crop a local lesion region and train a local branch: a radiologist will concentrate on the local lesion area after the overall browse. Finally, the global and local branches are fused to fine-tune the whole network: a radiologist will comprehensively consider the global and local information before making decisions. Our contributions are summarized as follows.