Deep Learning Approximation (DLA) speeds up the runtime of neural networks, which is especially relevant for pay-per-compute or limited-compute embedded environments. It decouples the task of speeding up neural networks from the task of making them more accurate. It enables tuning off-the-shelf networks for runtime, to complement fine-tuning for accuracy. At deploy time, the dollar cost of a production pipeline using a neural network is directly proportional to the time required to execute a forward pass of the neural network. This is in contrast to training, which generally happens only once and offline. In turn, for large networks time is proportional to the number of floating-point operations (FLOPs) required in a forward pass. For example, in the cloud, instances are paid for by the hour, so a pipeline running a ResNet-N model (_inline_eq_ FLOPs) vs. a ResNet-N model (_inline_eq_ FLOPs) running _inline_eq_ times slower and therefore costs _inline_eq_ x more. This extra dollar cost comes at minimal benefit (_inline_eq_ \% vs _inline_eq_ error on ImageNet) . Running faster models means a higher throughput, which means better hardware utilization, both in cloud and embedded environments. For embedded environments, faster and smaller models mean lower power, cooling, and CPU speed requirements. DLA has several other important properties. For networks used as a black-box or where training data is confidential, re-training or fine-tuning the network is not an option or is extremely challenging. In these cases, DLA is a method for speeding up the network forward pass without needing access to the training data. If you can finetune, finetuning can recover accuracy lost during the DLA process. In DLA, first apply lossless optimizations to reduce FLOP count and runtime, which is always an optimal optimization step. Then, we propose a method for automatically selecting an appropriate approximation to apply to each layer in a network based on a single parameter, which represents whether accuracy or speedup is more important. The approximation methods are all based on singular value decompositions (SVD) applied directly to the weight tensors. On a benchmark set of standard computer vision tasks and neural network architectures, we show between a N and Nx speedup without additional re-training and minimal accuracy loss. In each case, funetuning after applying DLA recovers lost accuracy.