A large bulk of the recent computer vision research has focused on applying artificial neural networks to ND images. More recently, a growing research area focuses on applying neural networks to ND physical scenes. Point clouds or point sets are a common format for representing ND data since some sensors, including laser-based systems, collect scene data directly as point clouds. Voxelization is a straightforward way of applying powerful deep convolutional neural network techniques to point clouds, as is done in VoxNet _cite_ and NDShapeNets _cite_ . Voxelization, however, is not always desirable because point clouds can, in many cases, represent structural information more compactly and more accurately than voxelized alternatives. In contrast to voxelization methods, PointNet _cite_ and others have developed architectures that operate directly on point clouds, including ECC _cite_, Kd-Net _cite_, DGCNN _cite_, and KCNet _cite_ . This research adds to the growing body of knowledge about learning on point sets. This paper describes a neural network layer (Ursa layer) that accepts a point cloud as input and efficiently yields a single feature vector, which is both agnostic to the ordering of the points in the point cloud and encodes the dimensional features of every point. This output feature vector is an efficient representation of the entire point cloud-an observation which can be used for classification (or other machine learning tasks) in later portions of the network. The layer's trainable parameters are centroids, and each centroid has the same dimension as a point in the point cloud. For the remainder of this paper, in order to distinguish the centroids from the points in the point cloud, the centroids will be referred to as stars, and the collection of stars in the Ursa layer will be referred to as a constellation. The output of the layer is a feature vector with length equal to the number of constellation stars, which us used in the later layers of the neural network to inform the classification output. Another important characteristic of this approach is that it does not require a preprocessing step-the Ursa layer is trained as part of the overall network structure using backpropagation and gradient descent learning. The Ursa layer is invariant to the ordering of the input points. The Ursa layer is not inherently invariant to shift, scale, or rotation; rather, it relies on demonstrations of those types of variations (possibly through data augmentation) in the input data during training to learn these variations. The output of the Ursa layer is a global shape descriptor of the point cloud that is fed to later layers in the classifier to classify the point cloud. Experiments on this architecture show the classification accuracy is comparable to current point cloud-based classifiers, but with a significantly smaller model size. The experiments tested the Ursa architecture with various distance functions and various numbers of constellation stars using MNIST (ND) data and ModelNetN (ND) data. Experimentally, the best distance measure was dependent on the data set. For both data sets, too few or too many stars generally degraded performance. Performance gains leveled off with N or more stars and, in some cases, more stars led to worse performance.