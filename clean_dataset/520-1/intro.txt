An increasingly large volume of digital video content is becoming available in our daily lives through the internet due to rapid growth of increasingly sophisticated, mobile and low-cost video recorders. These videos are often edited and altered for various purposes using image and video editing tools that have become more readily available. Manipulations or forgeries can be done for nefarious purposes to either hide or duplicate an event or content in the original video. Frame duplication refers to a video manipulation where a copy of a sequence of frames inserted into the same video either replacing previous frames or as additional frames. Figure~ _ref_ provides an example of frame duplication where in the manipulated video the red frame sequence from the original video is inserted between the green and the blue frame sequences. As a real-world example, frame duplication forgery could be done to hide an individual leaving a building in a surveillance video. If such a manipulated video was part of a criminal investigation, without effective forensics tools the investigators could be misled. It is very important to develop robust video forensic techniques, like the one proposed here, to catch videos with increasing sophisticated forgeries. Video forensics techniques~ _cite_ aim to extract and exploit features from videos that can distinguish forgeries from original, authentic videos. Like other areas in information security the sophistication of attacks and forgeries continue to increase for images and videos, requiring a continued improvement in the forensic techniques. Robust detection and localization of duplicated parts of a video can be a very useful forensic tool for those tasked with authenticating large volumes of video content. In recent years, multiple digital video forgery detection approaches have been employed to solve this challenging problem. Wang and Farid~ _cite_ proposed a frame duplication detection algorithm which takes the correlation coefficient as a measure of similarity. However, such an algorithm requires heavy computational load due to a large amount of correlation calculations. Lin {\em et al.} ~ _cite_ proposed to use histogram difference (HD) instead of correlation coefficients as the detection features. The drawback is that the HD features do not show strong robustness against common video operations or attacks. Hu {\em et al.} ~ _cite_ propose to detect duplicated frames using video sub-sequence fingerprints extracted from the DCT coefficients. Yang {\em et al.} ~ _cite_ propose an effective similarity-analysis-based method that is implemented in two stages, where the features are obtained via SVD. Ulutas {\em et al.} propose to use a BoW model~ _cite_ and binary features~ _cite_ for frame duplication detection. Although deep learning solutions, especially those based on convolution neural networks, have demonstrated promising performance in solving many challenging vision problems such as large-scale image recognition~ _cite_, object detection~ _cite_ and visual captioning~ _cite_, no deep learning solutions have been developed for this specific task so far, which motivates us to fill this gap. In this paper, we propose a novel coarse-to-fine deep learning framework, denoted as CNF-DCNN, for frame duplication detection and localization in forged videos. As illustrated in Figure~ _ref_, we first utilize an IND network~ _cite_ to obtain the candidate duplicate sequences at a coarse level; this helps narrow the search faster through longer videos. Next, at a finer-level, we apply a Siamese network composed of two ResNet networks~ _cite_ to further confirm duplication at the frame level to obtain accurate corresponding pairs of duplicated and selected original frames. Finally, the duplicated frame-range can be distinguished from the corresponding selected original frame-range by our inconsistency detector that is designed as a IND network with N-frames as a input video clip. Unlike other methods, we consider the consistency between two consecutive frames from a N-frame video clip in which these two consecutive frames are in center, {\em i.e.}, N-th and N-th frames. This is aimed at capturing the temporal-context for matching a range of frames for duplication. Inspired by Long {\em et al.} ~ _cite_, we design an inconsistency detector based on the IND network to cover three categories, {\em i.e.}, ``none", ``frame drop", and ``shot break", which represent that between N-th and N-th frames there are no manipulations, there are frames removal within one shot, and there exist two shots transit in the N-frame video clips, respectively. Therefore, we are able to use output scores from the learned IND network to formulate a confidence score of inconsistency between any two consecutive frames to distinguish the duplicated frame-range from the selected original frame-range, even in videos with multiple shots. We also propose a heuristic strategy to produce a video-level frame duplication likelihood score. This is built upon the measures like number of possible frames duplicated, minimum distance between duplicated frames and selected frames, and the temporal gap between the duplicated frames and the selected original frames. To summarize, the contributions of this paper are as follows: