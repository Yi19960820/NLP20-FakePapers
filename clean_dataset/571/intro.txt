Semantic segmentation can be considered as a per-pixel classification problem. There are two challenges in this task: N) classification: an object associated to a specific semantic concept should be marked correctly; N) localization: the classification label for a pixel must be aligned to the appropriate coordinates in output score map. A well-designed segmentation model should deal with the two issues simultaneously. However, these two tasks are naturally contradictory. For the classification task, the models are required to be invariant to various transformations like translation and rotation. But for the localization task, models should be transformation-sensitive, i.e., precisely locate every pixel for each semantic category. The conventional semantic segmentation algorithms mainly target for the localization issue, as shown in Figure~ _ref_ B. But this might decrease the classification performance. In this paper, we propose an improved net architecture, called Global Convolutional Network (GCN), to deal with the above two challenges simultaneously. We follow two design principles: N) from the localization view, the model structure should be fully convolutional to retain the localization performance and no fully-connected or global pooling layers should be used as these layers will discard the localization information; N) from the classification view, large kernel size should be adopted in the network architecture to enable densely connections between feature maps and per-pixel classifiers, which enhances the capability to handle different transformations. These two principles lead to our GCN, as in Figure~ _ref_ A. The FCN~ _cite_-like structure is employed as our basic framework and our GCN is used to generate semantic score maps. To make global convolution practical, we adopt symmetric, separable large filters to reduce the model parameters and computation cost. To further improve the localization ability near the object boundaries, we introduce block to model the boundary alignment as a residual structure, shown in Figure~ _ref_ C. Unlike the CRF-like post-process~ _cite_, our boundary refinement block is integrated into the network and trained end-to-end. Our contributions are summarized as follows: N) we propose Global Convolutional Network for semantic segmentation which explicitly address the ``classification'' and ``localization'' problems simultaneously; N) a Boundary Refinement block is introduced which can further improve the localization performance near the object boundaries; N) we achieve state-of-art results on two standard benchmarks, with N on PASCAL VOC N and N on the Cityscapes.