Although large scale classification based on supervised learning has achieved major successes in recent years by deep learning _cite_, the collection and annotation of huge amounts of training data for each class become a bottleneck for many visual recognition tasks. The increasing new categories and few available training examples are forcing us to develop more efficient learning paradigms. Zero-shot learning (ZSL) aims to recognize previously unseen classes without labelled training instances, which has gained growing attention recently _cite_ . For ZSL tasks, some intermediate semantic properties, such as attributes _cite_ or category hierarchies _cite_, are usually revealed and shared for seen and unseen classes, acting as side information by which the unseen classes could be inferred rationally. Explicitly, in ZSL settings, the dataset of seen classes is well labelled with categories and attributes tags, whereas the unseen classes are faced with absence of training instances but presence of their attribute descriptions. The purpose of ZSL for visual recognition is to predict for each novel image which of unseen classes it belongs to. Previous works for ZSL can be broadly divided into two major categories. Some works advised to perform a two-stage probability based method, namely attribute prediction and then classification inference _cite_, while others attempted to decompose the ZSL tasks into two sub-tasks, semantic embedding and similarity measurement, whose performance is excessively reliant on the capability of shared semantic embedding spaces _cite_ . In this paper we present a novel approach for ZSL via generating pseudo feature representations, called GPFR, inspired by humans' behaviors of recognizing a novelty. It is generally known that the process to recognize novel concepts for most of people is abstractively from individuality to generality, and then from generality to individuality. More specifically, assuming the fundamental understandings about what features represent the attributes are obtained from some prepared images, like etc, one can surmise roughly what a zebra looks like if told zebra has above attributes. As illustrated in Fig.~ _ref_, our intuition is to firstly learn some credible feature representations for each attribute by utilizing prepared dataset of seen classes, and then summarize these attribute representations into an combined representation, according to the specified attribute descriptions of each unseen class. Finally, the combined representation can be viewed as a so-called pseudo representation of unseen class image, which will offer valuable guidance for the training of unseen class predictor. In our ZSL framework, leveraging the Convolutional Neural Network (CNN) based image features _cite_, we firstly train a Joint Attribute Feature Extractor (JAFE) in which each fundamental unit is put in charge of the extraction of one attribute feature vector. Regardless of labels of seen classes, we extract all possible feature vectors for every attribute tag by JAFE, then assembled these vectors into a cognitive repository of attributes based on a confidence margin filter. According to the attribute descriptions of unseen classes, a probability based sampling strategy is exploited to select some attribute feature vectors from this cognitive repository to synthesize combined vectors. This strategy allows us access to lots of synthetic feature vectors for a specified unseen class, called pseudo feature representations, which fills the gaps between training domain and test domain and achieves data augmentation in feature level as well for supervised recognition from another perspective. Taking these pseudo feature representations as inputs, a multi-classes predictor for unseen classes can be learned. During test time, a novel image goes through the JAFE to generate its combined feature vector over all attributes, followed by above well-trained predictor to perform the ultimate inference. Results on a synthetic colored MNIST dataset (C-MNIST) demonstrate the effectiveness and extensibility of our GPFR. Furthermore, its performance on several ZSL benchmark datasets show improvements to state-of-the-art results, especially for zero-shot retrieval mAP (\ie mean average precision) . We conclude our contributions as follows. First, we develop a concise GPFR framework for ZSL tasks, which fills the gaps between seen and unseen concepts and achieves compelling results on four challenging ZSL benchmark datasets. Second, our GPFR model realizes inherently the data augmentation in feature level, which can be easily extended to supervised learning scenario.