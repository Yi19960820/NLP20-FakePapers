The image correction problem has been studied for decades. It dates back to the production of Charge-Coupled Devices (CCDs), which convert optical perception to digital signals. Due to the semiconductors used in the CCDs, there is an unknown nonlinearity existed between the scene radiance and the pixel values in the image. This nonlinearity is usually modeled by gamma correction, which has resulted in a series of image correction methods. These methods tend to focus on image pixel balance via different approaches including histogram equalization _cite_, edge preserving filtering _cite_, and CNN encoder-decoder _cite_ . Typically, they function as a preprocessing step for many machine vision tasks, such as optical flow estimation~ _cite_, image decolorization~ _cite_, image deblurring~ _cite_, face stylization~ _cite_ and visual tracking~ _cite_ . Despite the demonstrated success, existing methods have the limitation in correcting images with under/over exposure. An example is shown in Figure~ _ref_, where the state-of-the-art image correction methods fail to recover the missing details in the underexposed regions. This is because the pixel values around these regions are close to N, and the details are diminished within them. Although different image pixel operators have been proposed for image correction, the results are still unsatisfactory, due to the ill-posed nature of the problem. Thus, a question is raised if it is possible to effectively recover the missing details during the image correction process. To answer the aforementioned question, we trace back to the image formation procedure. Today's cameras still require the photographer to carefully choose the exposure duration (_inline_eq_) and rely on the camera response functions (CRFs) to convert a natural scene (_inline_eq_) into an LDR image (_inline_eq_), which can be written as~ _cite_: However, when an inappropriate exposure duration is chosen, the existing CRFs can neither correct the raw data in the CCDs nor the output LDR images. This causes the under/over exposure in the LDR images. Based on this observation, we propose an end-to-end framework, called, for image correction. It contains two CNN networks. The first CNN network reconstructs the missing details in the HDR domain and the second CNN network transfers the details back to the LDR domain. Through the reciprocating HDR transformation process, LDR images are corrected in the intermediate HDR domain. Overall, the contribution in this work can be summarized as follows. We interpret image correction as the Deep Reciprocating HDR Transformation (DRHT) process. An end-to-end DRHT model is therefore proposed to address the image correction problem. To demonstrate the effectiveness of the proposed network, we have conducted extensive evaluations on the proposed network with the state-of-the-art methods, using the standard benchmarks.