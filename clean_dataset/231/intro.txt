Person re-detection is the task of matching pedestrians across different spatial and temporal locations over multiple cameras (see Figure _ref_) . For instance, determining whether the person observed at point A is the same person now visible at point B. Despite the efforts of researchers, it remains an unsolved problem, with the most challenging issue being to adapt to large changes in appearance caused by variations in lighting, and changes in the pose of the subject and the camera. Existing research on person re-detection has mainly focused extracting better features from the input images by developing feature extraction methods that are invariant to changes in condition; developing distance metrics to compare pairs of extracted features; or both. Over the past few years, deep convolutional neural network (DCNN) methods have shown their potential with significant performance improvements in person re-detection. Some researchers _cite_ have considered person re-detection as a multi class recognition problem and classification loss is used to train the network; while others consider it a verification problem _cite_ . For verification, most researchers adopted either a Siamese network or a triplet based network. Siamese architectures take a doublet (pair of images) as input and pull the images of the same person close together in feature space, while features extracted from different people will be kept separate from each other in the feature space. Usually, verification or similarity regression models take a pair of images as input for training purposes, which are then used to extract identifiable features to determine whether the query images (person-of-interest) are of the same person or not. On the contrary, identification or multi class recognition models classify an input image into a large number of identity classes to predict the identity of the input image. Verification and identification models are shown in Figure N and Figure N, respectively. With regards to feature extraction, both approaches are different and have their own strengths and weaknesses. The two approaches also differ in that an identification approach necessitates a closed-world view, while the verification approach allows an open-world view. The identification methods assume that the identities of subjects to be recognized exist in the gallery, and subjects outside this list cannot be identified. By contrast, a verification task considers person re-detection as an open world scenario by using a distance measure and threshold to determine if two images belong to the same person or not. On the other hand, triplet based models takes three images as input: an anchor image, a positive image and a negative image; and the network enforces that the distance between the anchor and positive image should be less than the distance between the anchor and negative image. Essentially, the overall network architecture is a Siamese network with either two or three branches for the pairwise and triplet loss, respectively. However, the triplet loss forces that the distance of intra-class identity to be less than the distance of inter-class identities only in cases where the test images are from the same identity. In a real world scenario, test subjects and their images are totally unseen, thus the triplet based framework suffers from a poor generalization capability. The drawback of the verification model is that it does not consider all the information in the training data. This model considers only doublet (pairwise) or triplet labels of the relationship between a pair of images instead of other images in the dataset _cite_ . An identification model overcomes this by extracting non-linear features directly from the input image to learn the person ID (identification) during training, and the loss function is used in the final layer makes full use of the re-ID labels. However, when used outside of training, to overcome the closed-world nature of the training approach, identification methods extract features from the last fully connected layer and compare these, however there is no guarantee that features from the same subject will lie close to one another in the feature space. As can be seen from the above, the two approaches have contrasting strengths where an identification approach will increase inter-class variations and a verification approach will minimise the intra-class variations. Motivated by the above observations, we propose to introduce a new loss function for person re-detection which we term the quartet loss function. This loss function enforces that the distance between the matched image pair is less than the distance between the mismatched image pair with respect to the same probe image, while simultaneously enforcing that the distance between positive pairs is less than the distance between negative pairs with respect to different probe images, resulting in better generalization and better performance. The proposed approach also combines elements of the verification and identification models to take full advantage of both approaches to maximize the performance of the person re-detection system. To summarize, our contributions are: The rest of the paper is organized as follows: Section N outlines existing research relating to person re-detection; Section N describes our proposed methodology; Section N presents our experimental setup and results; and Section N concludes the paper.