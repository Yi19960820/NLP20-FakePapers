The basic idea of most Hough Transform-based object detection approaches _cite_ is to model the relationship between local image features and voting points by training a codebook of local appearance. All image features in a test image are extracted and mapped to a number of voting points by using the codebook. All the voting points form a Hough image. The positions of the local maxima in a Hough image are considered to be the locations of object hypotheses. A codebook of local appearance is usually constructed by using a clustering approach. For example, the Implicit Shape Model (ISM) _cite_ employs an agglomerative clustering approach to cluster local image features. The obtained cluster centers form a codebook. A distance threshold is used during the clustering step to determine whether a local feature should merge with a cluster. When the threshold value varies, the derived codebooks and detection results may be significantly different. {The Hough forest approach} _cite_ constructs a codebook (i.e., a tree in a random forest) by using a supervised clustering step that also uses some parameters, such as the depth of a tree and the criteria used to stop the growth of a tree. However, how to choose appropriate values for these parameters remains an open problem. In addition, some popular histogram features, such as Histograms of Oriented Gradient (HOG) _cite_, are extracted from overlapping image blocks. In that case, the redundancy and the multicollinearity of a derived high-dimensional feature set can be very high, and the performance of object detection approaches can be decreased. The above issues, i.e., the difficulty of choosing appropriate values for the parameters used in a clustering step and the negative influence of redundancy and multicollinearity, can be solved by using Partial Least Squares (PLS) _cite_ . PLS is a popular statistical regression technique, which projects feature vectors onto a much lower dimensional latent subspace. Since the latent components yielded by the projection are mutually orthogonal, the multicollinearity of a feature set is eliminated and the redundancy of the feature set is reduced. As for choosing appropriate values for parameters, the value of the only parameter used in PLS, i.e., the number of latent components, can be determined by using a cross-validation procedure. By exploiting these advantages of PLS, we propose a novel Hough Transform-based object detection approach. Instead of constructing a codebook as in _cite_, our approach uses Bridge Partial Least Squares (BPLS) _cite_ to establish linear regression models. The obtained models take context-encoded feature vectors as inputs and generate Hough votes for all possible object locations to yield Hough images. We call these linear regression models as context-encoded Hough Regression Models (HRMs) . The local maxima of Hough images correspond to the estimated object locations. BPLS is an efficient variant of the traditional PLS technique. The traditional PLS technique uses an inefficient iterative procedure in which an eigenvalue decomposition step is implemented repeatedly to extract enough number of latent components. BPLS can simultaneously extract all latent components for feature vectors by using eigenvalue decomposition only once. The iterative procedure in PLS is not required in BPLS. BPLS was originally proposed in the area of chemometrics and used to analyze functional magnetic resonance imaging (fMRI) data. In this paper, we use BPLS to establish HRMs for object detection. Furthermore, we propose a novel multi-scale voting scheme, inspired by the idea of _cite_, to efficiently handle object scale changes. This voting scheme simultaneously casts Hough votes at multiple scales by using only an original image. Therefore, multiple Hough images corresponding to multiple object scales can be obtained simultaneously, while an image pyramid (which is used in _cite_) is not required. Based on this scheme, a principled fusion strategy is proposed to fuse multiple detection hypotheses corresponding to one object to reduce false positives. This strategy reveals and measures the correlation between two hypotheses by evaluating normalized pointwise mutual information (NPMI) _cite_ between them. If two hypotheses at two different scales are considered to be correlated by evaluating NPMI, they are fused to avoid a false positive. The proposed approach is called the HRM approach. The training and test procedures of the HRM approach are shown in Algorithm~ _ref_ and _ref_, respectively. {In the experiments, the HRM approach is also compared with its several variants to evaluate the influences of its components on its performance.} This study extends its earlier version, i.e., the PSCG approach _cite_, mainly by: (N) exploiting a more efficient variant of PLS, i.e., BPLS, to improve the efficiency in computing HRMs; (N) proposing a novel multi-scale voting scheme to efficiently handle object scale changes and reveal the correlations between hypotheses; (N) generalizing the probabilistic framework in the PSCG approach to describe the proposed multi-scale voting scheme; (N) proposing a principled and NPMI-based strategy to fuse hypotheses to reduce false positives. The rest of this paper is organized as follows: Section~ _ref_ summarizes the related work; Section~ _ref_ specifies how to establish HRMs by using PLS and BPLS; the proposed multi-scale voting scheme and probabilistic framework are described in Section~ _ref_ ; the NPMI-based fusion strategy is explained in Section~ _ref_ ; experimental results on popular benchmark datasets are shown in Section~ _ref_ ; conclusions are given in Section~ _ref_ .