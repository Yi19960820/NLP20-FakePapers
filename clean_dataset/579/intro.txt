Neural network models are at the core of modern image recognition methods. Among these models, convolutional neural networks _cite_ (CNN) have been developed to consider both basic and complex patterns in images, and achieved top of the line results in numerous challenges _cite_ . Nonetheless, in the specific case of image recognition, a good model has to efficiently encode local relations within the input features, such as between the Red, Green, and Blue (R, G, B) channels of a single pixel, as well as structural relations, such as those describing edges or shapes composed by groups of pixels. In particular, traditional real-valued CNNs consider pixels as three different and separated values (R, G, B), while a more natural representation is to process a pixel as a single multidimensional entity. More precisely, both internal and global hidden relations are considered at the same level during the training of CNNs. Thereby, and strong of many applications _cite_, quaternion neural networks _cite_ (QNN) have been proposed to encapsulate multidimensional input features. Quaternions are hyper-complex numbers that contain a real and three separate imaginary components, fitting perfectly to three and four dimensional feature vectors, such as for image processing. Indeed, the three components (R, G, B) of a given pixel are embedded in a quaternion, to create and process pixels as entities. With the purpose to solve the above described problem of local and global dependencies, deep quaternion convolutional neural networks _cite_ (QCNN) have been proposed. In the previous works, better image classification results than real-valued CNN are obtained with smaller neural networks in term of number of parameters. The authors claim that such better performances are due to the specific quaternion algebra, alongside with the natural multidimensional representation of a pixel. Nonetheless, and despite promising results, no clear intuitions of QCNN performances in image recognition have been demonstrated yet. Moreover, these studies employ color images for training and validation sub-processes. Therefore, the paper proposes: N) to explore the impact of the Hamilton product (Section _ref_), which is at the heart of the better learning and representation abilities of QNN; N) to show that quaternion-valued neural networks are able to perfectly learn color features dependencies (R, G, B) . Quaternion and real-valued neural networks are therefore compared on a gray-scale to color image task that highlights the capability of a model to learn both internal (i.e. the relations that exist inside a pixel) and external relations of an image. In this extend, a quaternion convolutional encoder-decoder (QCAE) (Section _ref_) and a real-valued convolutional encoder-decoder _cite_ (CAE) are trained to reconstruct a unique gray-scale image from the KODAK PhotoCD dataset (Section _ref_) . During the validation process, an unseen color image is presented to both models, and reconstructed pictures are compared visually and with the peak signal to noise ratio (PSNR) as well as the structural similarity (SSIM) metrics (Section _ref_) . To validate the learning of internal dependencies, these models must reconstruct the color image without prior information about the color space given from the training phase. The experiments show that QCAE succeeds to produce an almost perfect copy of the testing image, while the CAE fails, by reconstructing a slightly worst and black and white version. Such behavior makes quaternion-valued models a better fit to image recognition in heterogeneous conditions. Indeed, quaternion-valued are less harmed by smaller and heterogeneous data, due to their ability to dissociate internal and global dependencies trough the Hamilton product, and convolutional process respectively. Finally, it is worth noticing that these performances are observed with a reduction of the number of neural parameters of four times for QCAE compared to CAE.