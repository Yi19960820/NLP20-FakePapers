Deep convolutional neural networks (CNNs) have greatly pushed the previous limits of various computer vision tasks since the seminal work _cite_ in N. CNN models can naturally integrate hierarchical features and classifiers, which can be trained in an end-to-end manner. Benefiting from that, significant improvements have been witnessed in fundamental computer vision tasks, such as image classification _cite_, object detection _cite_, semantic segmentation _cite_, \etc. One of the main factors that can further boost the CNN performance is multi-task learning (MTL), which is engaged in learning multiple related tasks simultaneously. This is because related tasks can benefit from each other by jointly learning certain shared, or more precisely, mutually related representations _cite_ . The multiple supervision signals originating from different tasks in MTL can be viewed as implicit data augmentation (on labels) or additional regularization (among different tasks) _cite_ . This enables to learn mutually related representations that work well for multiple tasks, thus avoiding overfitting and leading to better generalizability. Most commonly, the CNN structure for MTL is heuristically determined by sharing all convolutional layers, and splitting at fully-connected layers for task-specific losses. However, as different layers learn low-, mid-, and high-level features _cite_, a natural question arises: The study in Misra \etal _cite_ reveals that sharing/splitting at different layers gives different performances. Especially, improper features sharing at some layers may degrade the performance of some, or even all, tasks. In addition, the deep nature of CNNs makes it infeasible to exhaustively test all the possible structures to find the optimal sharing/splitting scheme. In order to tackle this issue, Misra \etal used trainable to weighted-sum the features from different tasks at multiple CNN levels and achieved state-of-the-art performance _cite_ . We consider this problem in another way, \ie, by leveraging all the hierarchical features from different tasks. This is because that the CNN layers trained by different tasks can be treated as different feature descriptors, therefore the features learned from them can be treated as different representations/views of input data. . Specifically, starting with _inline_eq_ single-task networks (from _inline_eq_ tasks), a direct attempt to take advantage of hierarchical features from all the tasks is that: we may concatenate all the task-specific features with the same spatial resolution according to the feature dimension. After that, we expect the CNN to learn a discriminative feature embedding for each task, by receiving these concatenated features as inputs. However, most existing CNNs have carefully designed structures, which only receive features (tensors) with a fixed number of feature channels. By concatenating features, we substantially enlarge the number of channels as _inline_eq_ times if we have _inline_eq_ tasks. This makes it impossible to feed these concatenated features to the following layers of the CNN. This property of the CNN motivates us to conduct on the concatenated features. Its purpose is to learn a discriminative feature embedding, and to reduce the feature dimension such that it can satisfy the input channel requirement of the following layers. Feature transformation is one of the most important approaches to tackle the discriminative dimension reduction problem. It aims to learn a projection matrix that projects the original high-dimensional features into a low-dimensional representation, while keeping as much discriminative information as possible. In this paper, we show that, from the perspective of feature transformation, discriminative dimensionality reduction is closely related to some common operations of modern CNNs. Specifically, the transformation in discriminative dimensionality reduction is in fact equivalent to the . In addition, the constraints on the norm of the transformation weights (\ie, the weights of the _inline_eq_ convolutional layer) and input feature vectors can be represented by and _cite_, respectively. We refer to the combination of these operations as (NDDR) . Therefore, we are able to link the original single-task networks from different tasks by the NDDR layers. Desirably, the proposed network structure can be trained end-to-end in the CNN without any extraordinary operations. It is worth noting that this paper focuses on a general structure for general-purpose MTL. The proposed NDDR layer combines existing CNN components in a novel way, which possesses clear mathematical interpretability as discriminative dimensionality reduction. Moreover, the use of the existing CNN components is desirable to guarantee the extensibility of our method to various state-of-the-art CNN architectures, where the proposed NDDR layer can be used in a ``plug-and-play'' manner. The rest of this paper is organized as follows. First, we describe the NDDR layer and propose a novel NDDR-CNN as well as its variant NDDR-CNN-Shortcut for MTL in Sect. _ref_ . After that, we discuss the related works in Sect. _ref_, where we show that our method can generalize several state-of-the-art methods, which can be treated as our special cases. In Sect. _ref_, the ablation analysis is performed, where the hyperparameters used in our network are suggested. Following that, the experiments are performed on different network structures and different task sets in Sect. _ref_, demonstrating the promising performance and desirable generalizability of our proposed method. We make concluding remarks in Sect. _ref_ .