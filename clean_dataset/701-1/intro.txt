In incremental classification, an agent must sequentially learn to classify training examples, without necessarily having the ability to re-study previously seen examples. While deep neural networks (DNNs) have revolutionized machine perception~, off-the-shelf DNNs cannot incrementally learn classes due to catastrophic forgetting. Catastrophic forgetting is a phenomenon in which a DNN completely fails to learn new data without forgetting much of its previously learned knowledge~ . While methods have been developed to try and mitigate catastrophic forgetting, as shown in _cite_, these methods are not sufficient and perform poorly on larger datasets. In this paper, we propose FearNet, a brain-inspired system for incrementally learning categories that significantly outperforms previous methods. The standard way for dealing with catastrophic forgetting in DNNs is to avoid it altogether by mixing new training examples with old ones and completely re-training the model offline. For large datasets, this may require weeks of time, and it is not a scalable solution. An ideal incremental learning system would be able to assimilate new information without the need to store the entire training dataset. A major application for incremental learning includes real-time operation on-board embedded platforms that have limited computing power, storage, and memory, e.g., smart toys, smartphone applications, and robots. For example, a toy robot may need to learn to recognize objects within its local environment and of interest to its owner. Using cloud computing to overcome these resource limitations may pose privacy risks and may not be scalable to a large number of embedded devices. A better solution is on-device incremental learning, which requires the model to use less storage and computational power. In this paper, we propose an incremental learning framework called FearNet (see Fig.~ _ref_) . FearNet has three brain-inspired sub-systems: N) a recent memory system for quick recall, N) a memory system for long-term storage, and N) a sub-system that determines which memory system to use for a particular example. FearNet mitigates catastrophic forgetting by consolidating recent memories into long-term storage using pseudorehearsal~ . Pseudorehearsal allows the network to revisit previous memories during incremental training without the need to store previous training examples, which is more memory efficient. Problem Formulation: Here, incremental class learning consists of _inline_eq_ study-sessions. At time _inline_eq_, the learner receives a batch of data _inline_eq_, which contains _inline_eq_ labeled training samples, i.e., _inline_eq_, where _inline_eq_ is the input feature vector to be classified and _inline_eq_ is its corresponding label. The number of training samples _inline_eq_ may vary between sessions, and the data inside a study-session is not assumed to be independent and identically distributed (iid) . During a study session, the learner only has access to its current batch, but it may use its own memory to store information from prior study sessions. We refer to the first session as the model's ``base-knowledge, '' which contains exemplars from _inline_eq_ classes. The batches learned in all subsequent sessions contain only one class, i.e., all _inline_eq_ will be identical within those sessions. Novel Contributions: Our contributions include: