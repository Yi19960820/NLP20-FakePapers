A person asked to draw, paint or otherwise recreate a visual scene will naturally do so in a sequential, iterative fashion, reassessing their handiwork after each modification. Rough outlines are gradually replaced by precise forms, lines are sharpened, darkened or erased, shapes are altered, and the final picture emerges. Most approaches to automatic image generation, however, aim to generate entire scenes at once. In the context of generative neural networks, this typically means that all the pixels are conditioned on a single latent distribution~ . As well as precluding the possibility of iterative self-correction, the ``one shot'' approach is fundamentally difficult to scale to large images. The (DRAW) architecture represents a shift towards a more natural form of image construction, in which parts of a scene are created independently from others, and approximate sketches are successively refined. The core of the DRAW architecture is a pair of recurrent neural networks: an network that compresses the real images presented during training, and a that reconstitutes images after receiving codes. The combined system is trained end-to-end with stochastic gradient descent, where the loss function is a variational upper bound on the log-likelihood of the data. It therefore belongs to the family of, a recently emerged hybrid of deep learning and variational inference that has led to significant advances in generative modelling~ . Where DRAW differs from its siblings is that, rather than generating images in a single pass, it iteratively constructs scenes through an accumulation of modifications emitted by the decoder, each of which is observed by the encoder. An obvious correlate of generating images step by step is the ability to selectively attend to parts of the scene while ignoring others. A wealth of results in the past few years suggest that visual structure can be better captured by a sequence of partial glimpses, or foveations, than by a single sweep through the entire image . The main challenge faced by sequential attention models is learning where to look, which can be addressed with reinforcement learning techniques such as policy gradients~ . The attention model in DRAW, however, is fully differentiable, making it possible to train with standard backpropagation. In this sense it resembles the selective read and write operations developed for the Neural Turing Machine~ . The following section defines the DRAW architecture, along with the loss function used for training and the procedure for image generation. Section~ _ref_ presents the selective attention model and shows how it is applied to reading and modifying images. Section~ _ref_ provides experimental results on the MNIST, Street View House Numbers and CIFAR-N datasets, with examples of generated images; and concluding remarks are given in Section~ _ref_ . Lastly, we would like to direct the reader to the video accompanying this paper (_url_) which contains examples of DRAW networks reading and generating images.