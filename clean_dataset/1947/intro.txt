Automatic image aesthetics assessment is challenging. Among the early efforts _cite_, various hand-craft aesthetics features _cite_ have been manually designed to approximate the photographic and psychological aesthetics rules. However, to design effective aesthetics features manually is still a challenging task because even the very experienced photographers use very abstract terms to describe high quality photos. Other approaches leveraged more generic features _cite_ to predict photo aesthetics. However, these generic features may not be suitable for assessing photo aesthetics, as they are designed to capture the general characteristics of the natural images instead of describing the aesthetics of the images. Because of the limitations of these feature-based approaches, many researchers have recently turned to use deep learning strategy to extract effective aesthetics features _cite_ . These deep CNN methods have indeed shown promising results. However, the performance is often compromised by the constraint that the neural network only takes the fixed-size input. To accommodate this requirement, input images will need to be obtained via cropping, warping, or padding. As we can see from Figure _ref_, these additional operations often alter image composition, reduce image resolution, or cause extra image distortion, and thus impair the aesthetics of the original images because of potential loss of fine grained details and holistic image layout. However, such fine-grained details and overall image layout are critical for the task of image quality assessment. He _cite_ and Mai _cite_ tried to address the limitation in fixed-size input by training images in a few different scales to mimic varied input sizes. However, they still learn from transformed images, which may result in substantial loss of fine grained details and undesired distortion of image layout. Driven by this important issue, a question arises: Can we simultaneously learn fine-grained details and the overall layout to address the problems caused by the fixed-size limitation? To resolve this technical issues, we present in this paper a dedicated CNN architecture named A-Lamp. This novel scheme can accept arbitrary images with its native size. Training and testing can be effectively performed by considering both fine-grained details and image layout, thus preserving the information from original images. Learning both fine-grained details and image layout is indeed very challenging. First, the detail information is contained in the original, high resolution images. Training deep networks with large-sized input dimensions requires much longer training time, training dataset, and hardware memory. To enable learning from fine grained details, a multi-patch-based method was proposed in _cite_ . This scheme shows some promising results. However, these randomly picked bag of patches cannot represent the overall image layout. In addition, this random cropping strategy requires a large number of training epochs to cover the desired diversity in training, which lead to low efficiency in learning. Second, how to effectively describe specific image layout and incorporate it into the deep CNN is again very challenging. Existing works related to image layout descriptors are dominantly based on a few simple photography composition principles, such as visual balance, rule of thirds, golden ratio, and so on. However, these general photography principles are inadequate to represent local and global image layout variations. To incorporate global layout into CNN, transformed images via warping and center-cropping have been used to represent the global view _cite_ . However, such transformation often alters the original image composition or causes undesired layout distortion. In this paper, we resolved this challenges by developing an Adaptive Layout-Aware Multi-Patch Convolutional Neural Network (A-Lamp CNN) architecture. The design A-Lamp is inspired jointly by the success of fine-grained detail learning using multi-patch strategy _cite_ and the success of holistic layout representation by attribute graph. However, the proposed scheme can successfully overcome the stringent limitations of the existing schemes. Like DMA-Net in _cite_, our proposed A-Lamp CNN also crops multiple patches from original images to preserve fine-grained details. Comparing to DMA-Net, this scheme has two major innovations. First, instead of cropping patches randomly, we propose an adaptive multi-patch selection strategy. The central idea of adaptive multi-patch selection is to maximize the input information more efficiently. We achieve this goal by dedicatedly selecting the patches that play important role in affecting images' aesthetics. We expect that the proposed strategy shall be able to outperform the random cropping scheme even with substantially less training epochs. Second, unlike the DMA-Net that just focus on the fine-grained details, this A-Lamp CNN incorporates the holistic layout via the construction of attribute graph. We use graph nodes to represent objects and the global scene in the image. Each object (note) is described using object-specific local attributes while the overall scene is represented with global attributes. The combination of both local and global attributes captures the layout of an image effectively. This attribute-graphs based approach is expected to model image layout more accurately and outperform the existing approaches based on warping and center-cropping. These two innovations result improvement in both efficiency and accuracy over DMA-Net. The main contributions of this proposed A-Lamp scheme can be summarized into three-fold: _inline_eq_ We introduce a new neural network architecture to support learning from any image sizes without being limited to small and fixed size of the image input. This shall open a new avenue of deep learning research on arbitrary image size for training. _inline_eq_ We design two novel subnets to support learning at different levels of information extraction: fine-grained image details and holistic image layout. Aggregation strategy is developed to effectively combine hybrid information extracted from individual subnet learning. _inline_eq_ We have also developed an adaptive patch selection strategy to enhance the training efficiency associated with variable size images being used as the input. This aesthetics driven selection strategy can be extended to other image analysis tasks with clearly-defined objectives.