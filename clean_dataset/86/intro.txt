Consider the video of a natural dynamic scene. The video could have been captured either by a static or a dynamic camera. Given several categories comprising of natural scene videos, we would like to assign the correct category for a given video. This dynamic scene classification problem is more challenging for a moving camera than that for a static camera. In the case of images, a lot of significant research has been done to address the problem of scene recognition. Image scene recognition involves classifying an image into one of the several given classes (SUN Database) _cite_ . Convolution Neural Network (CNN) based approaches have recently dominated the task of image scene classification, obtaining very high accuracy and outperforming other previous state-of-the-art approaches by a significant margin. These approaches have worked remarkably well on several other large scale image datasets with upto thousands of categories. These powerful methods focus on finding appropriate spatial feature descriptors for a given image. Hence, they take into consideration only the spatial description of the scene present in the image. In contrast to image scene classification where the class labels are based only on the spatial properties, dynamic scene classification tries to classify videos into different categories whose semantic labels is derived from the activities occurring in the scene. Several examples of dynamic scenes are shown in Figure _ref_ . The dynamic scenes like 'avalanche' is given its class label based on the movement of ice, and not just based on the spatial attributes of the scene. The proposed approach is inspired by the unparalleled success of Convolutional Neural Network (CNN) based approaches for various recognition tasks over the past few years. Krizhevesky et al. mentioned the idea of using very large and deep CNN models to classify videos as well _cite_ . But building new architecture for videos and training it on a very large dataset is a complex procedure. However, two recent works on large scale video classification use CNNs to achieve the task by learning features from hundreds of thousands of videos extracted from Youtube or Facebook _cite_ _cite_ . In _cite_, the proposed architecture was trained on a large collection of sports videos (Sports-NM) for about a month and obtained very good results when tested on UCF-N. A number of CNN implementations pretrained on a large database of images are available which are ready to be used for off-the-shelf image feature extraction. We take forward this idea of classification with off-the-shelf CNN implementation in order to perform dynamic scene classification for videos by using Caffe CNN framework. We utilize several pre-trained models such as AlexNet _cite_, Places and Hybrid Places model _cite_ for the task. The present approach differs from that of _cite_ in the sense that the CNN trained on standard image dataset (ImageNet, Places) is used to classify videos of dynamic scenes. This relieves us from training CNN on a new video dataset. We use very simple yet effective tools for dynamic scene classification and show that even common statistical measures can be employed to capture the temporal variation which can be combined with spatial information for dynamic scene videos. We enhance this framework and adapt it for the problem of dynamic scene classification and obtain very high accuracy. It is worth mentioning that all of the previous dynamic scene classification methods, except Tran et al.'s CND _cite_, relied on using local features and did not exploit very large dataset. The proposed approach explores three different models of CNN pre-trained on ImageNet (ILSVRC N), Places, and Hybrid (combination of both) datasets. The ImageNet database is largely dedicated to object recognition tasks but not dynamic scene classification tasks _cite_ . On the other hand, Places and Hybrid dataset consist fully or partially of scene images, hence we expect them to have more discriminative power for dynamic scene classification task. The primary contribution of the proposed approach are listed below. N. Exploiting pre-trained CNN models and adapting it to the dynamic scene classification task for obtaining high accuracy, N. Using common statistical measures to merge spatial features with their temporal variation to arrive at a novel feature descriptor, N. We perform comparative study on different off-the-shelf CNN models and compare different pooling strategies, N. We design the classification algorithm in such a way that it is highly robust to scene motion as well as camera motion, N. We obtain state-of-the-art result on two dynamic scene datasets-Maryland and YUPenn. The increase in classification accuracy is observed to be very high in the case of Maryland dataset. The rest of the paper is organized as follows. Section N describes the relevant works about dynamic scene classification and the CNN literature in detail. Section N presents a detailed account of the proposed approach. In section N, we present results and comparisons of the experiments carried out with complete quantitative analysis. We conclude the paper in section N with some suggestions for future work.