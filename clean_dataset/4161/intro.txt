The current advances in computer vision and image recognition have seen wide use of convolutional neural networks (CNNs) . In _cite_, it has been shown that the convolutional units of various layers of CNNs are capable of detecting the position of object in the image without any supervision on the location of object. They show that although earlier convolutional layers are capable of capturing only the low-level features in the image, higher layers are able to capture task-specific features. However, the information about the location of these features in the image is lost when fully connected layers are used for classification. Some fully convolutional networks have been proposed recently such as GoogleNet _cite_, and Network in Network _cite_ that aim to reduce the number of network parameters while maintaining performance by avoiding the fully-connected layers. The work of _cite_ introduced the concept of Global Average Pooling layers which act as a structural regularizer and prevent overfitting. However, _cite_ shows that the average pooling layers can be used to retain the localization ability of the final layers of the network. This concept is also used in _cite_ for localization and binary classification of food items. The main disadvantage in using the Global Average Pooling layers lies in the fact that these models require differential connections during training and deployment. Looking into the biology of the human nervous system, we know that this is not the case for connections in the brain. Most connections are pruned and stabilized during the development period of the organism. Therefore, we looked into methods to bridge this gap and came up with an architecture where we do not need to alter the connections of a network. The major motivation of our work comes from the fact that different high level features correspond to different classes and the classification of an image to a particular class depends on certain features being excited more heavily than others. Blocking certain specific features affect the perception of humans to perceive or classify the image to a particular class. Drawing from this idea, we believe the errors in classification with a filter absent would be a useful cue to understand the importance of features captured by that filter. Keeping these in mind, we present a novel architecture that can be used to localize the positions of instances of all classes in an image and then classify each one of those hotspots. Unlike previous methods, the architecture is not as sensitive to the size of the input image and hence has a wider scope of application. The experiments are done on the MNIST dataset and further discussions are presented from the point of view of text extraction from natural images, as a proof of concept, but can be easily extended to other datasets and domains.