Deep neural networks have been widely applied in reinforcement learning (RL) algorithms to achieve human-level control in various challenging domains. More specifically, recent work has found outstanding performances of deep reinforcement learning (DRL) models on Atari N games, by using only raw pixels to make decisions _cite_ . The literature on reinforcement learning is vast. Multiple deep RL algorithms have been developed to incorporate both on-policy RL such as Sarsa _cite_, actor-critic methods _cite_, etc. and off-policy RL such as Q-learning using experience replay memory _cite_ _cite_ . A parallel RL paradigm _cite_ has also been proposed to reduce the heavy reliance of deep RL algorithms on specialized hardware or distributed architectures. However, while a high proportion of RL applications such as Atari N games contain objects with different gain or penalty (for example, enemy ships and fuel vessel are two different objects in the game ``Riverraid''), most of previous algorithms are designed under the assumption that various game objects are treated equally. In this paper, we propose a new Object-sensitive Deep Reinforcement Learning (O-DRL) model that can exploit object characteristics such as presence and positions of game objects in the learning phase. This new model can be adapted to most of existing deep RL frameworks such as DQN _cite_ and ANC _cite_ . Our experiments show that our method outperforms the state-of-the-art methods by N \%-N \% in various Atari games. Moreover, current deep RL models are not explainable, i.e., they cannot produce human understandable explanations. When a deep RL agent comes up with an action, people cannot understand why it picks the action. Therefore, there is a clear need for deep RL agents to dynamically and automatically offer explanations that users can understand and act upon. This capability will make autonomy more trustworthy, useful, and transparent. Incorporating object recognition processing is very important for providing explanations. For example, in the Atari game “Ms. Pacman”, the player controls Pac-Man through a maze, eating beans and avoiding monster enemies. There are also flashing dots known as power pellets that provide Pac-Man with the temporary ability to eat the enemies. By identifying the different objects (Pac-Man itself, beans, power pellets, enemies, walls, etc.), the deep RL agent can gain the potential to explain the actions like human beings. In this paper, we develop a new method called object saliency maps to automatically produce object-level visual explanations that explain why an action was taken. The proposed method can be incorporated with any existing deep RL model to give human understandable explanation of why the model choose a certain action. Our contributions are threefold: First, we propose a method to incorporate object characteristics to the learning process of deep reinforcement learning. ~Second, we propose a method to produce object-level visual explanation for deep RL models. ~ Third, our experiments show improvements over existing methods.