Due to its flexibility and expressiveness, hand gesture can provide an efficient and natural way for human computer interaction (HCI) . Hand gesture recognition has been researched for decades and has great potentials for applications in sign language recognition, remote control and virtual reality etc~ _cite_ . Dynamic hand gesture recognition aims to understand what a hand sequence conveys. It remains a challenging task due to high intra-class variance because the way of performing a gesture differs from person to person. Previous works on dynamic hand gesture recognition usually took RGB images and depth images~ _cite_ as input~ _cite_ . Some of them used multi-modal input including IR images~ _cite_ or audio stream~ _cite_ . Recent progresses on hand pose estimation~ _cite_ have greatly promoted the research on dynamic hand gesture recognition from ND hand skeleton sequences. Smedt et al.~ _cite_ proposed a skeleton-based approach for dynamic hand gesture recognition and demonstrated its superiority over depth-based approaches. In their approach, a temporal pyramid representation was utilized to model temporal information. Shape of connected joints, histogram of hand directions and wrist rotations were used to characterize hand shape and hand movement. However, the amplitude of gesture is not considered in their approach and the temporal pyramid representation may lose some motion information. The most important clues for dynamic hand gesture are articulated movements of fingers and the global movements of the hand. In prior works, some sort of joint angle features~ _cite_ were utilized to describe the hand shape. However, these features are not sufficient enough to characterize the full pose of a hand. In this paper, we propose a motion feature augmented RNN for skeleton-based dynamic hand gesture recognition. We extract the angles of bones from the hand skeleton, which is efficient and concise representation of the finger articulated movements. To describe the global movements of the hand, we extract the global rotation and global translation of the hand. A distance adaptive discretization scheme is given to better model the amplitude of the gestures. The finger motion features and global features are fed into a bidirectional RNN along with the skeleton sequence to predict the class of input gesture. Experiments on the publicly-available skeleton-based DHG-N/N dataset~ _cite_ demonstrate the effectiveness of our proposed method.