Understanding human pose is a long standing requirement with interesting applications (gaming and other applications using Kinect, robotics, understanding pedestrian behavior, etc.) . There has been strong progress over the years particularly using deep learning based pose estimation methods. However, progress is still required for accurate pose estimation in real world settings. One drawback faced is that the pose estimation methods require manual supervision with explicit labeling of the joint positions. This is particularly more for training state of the art deep learning systems. We address this requirement by proposing a method for obtaining automatic coarse human pose estimates. The method provides us with dense blob based pose estimates that suffices for most practical purposes (such as action recognition) . Moreover it is obtained {\it without any manual supervision} . In fig.~ _ref_ we illustrate the dense pixel-wise estimates of body parts that are obtained from our method. We can clearly delineate separate regions such as head, neck, torso, knee area and legs as obtained by our method. The use of dense pixel-wise pose estimation allows our method to be robust to a wide variety of pose variations and problems such as occlusions and missing body parts. Further, these are obtained by using only motion cues for the various parts in videos. The approach in this paper relies on self-supervision or surrogate supervision. Some approaches based on this rely on surrogate tasks such as re-assembling dislocated patches _cite_ or tracking people _cite_ . An interesting recent line of work that is related to this work relies on learning segmentation by using motion flows _cite_ . These surrogate tasks can be used for obtaining visual representations for generic tasks like classification or segmentation. Visual representations obtained through the techniques proposed so far however do not address granular tasks such as human pose estimation. Yet, we as humans can solve the problem easily. The primal cue that enables us in this task is observing the motion of the different body parts. This was evident early on and used by Gunnar Johansson in his seminal early work that analysed human body motion _cite_ . In this work Johansson observed that the relative motion between the body parts can be used for analysing human pose. Inspired by this insight we use the relative grouping of motion flow of humans to obtain the pose supervision required. Our approach uses embarrassingly simple techniques that can be easily obtained in any setting for obtaining automatic supervision. These can always be improved upon. Our aim in using these techniques was to show that even the most basic grouping of human motion flow suffices to obtain the supervision required to be competitive to current state of the art techniques trained using carefully annotated supervised data. Interestingly, with enough data, the deep network learns to generate output parts that are substantially better than the noisy supervision provided as input. The results are evaluated in terms of pose estimate comparisons as well as components of an action recognition method. The end-result is a competitive pose estimation method for free (zero supervision cost) by using easily available video data.