Classical convolutional neural networks (cCNNs) classify objects from static, high quality images exceptionally well. However, in many applications (autonomous driving, robotics), imaging data is rarely derived from photographs taken under excellent lighting conditions, but rather from images with occluded objects, motion distortion, low signal to noise ratios—resulting from poor image quality or low light levels—and frequently streaming over time (video) . cCNNs have been used successfully for image denoising to enhance the quality of single photographs _cite_ ; outperforming traditional computer vision approaches such as block-matching and N-d filtering (BMND) _cite_ . However, these networks rely on standard feedforward architectures and cannot combine information from multiple frames of a video sequence. As such, cCNNs are easily outperformed by humans if even small levels of noise are added to images _cite_ . It is clear that systems that rely on computer vision to navigate the real world should be able to do so in all kind of conditions, from bright mid-day sun, rainy days, or at night. Generally, neuronal latencies increase in visual cortex in response to stimuli with low contrast _cite_ . In a study of inferior temporal cortex, researchers found that the increased response time for low contrast stimuli was dependent on the selectivity of individual neurons---ranging from tens of milliseconds for broadly tuned neurons, to N--N ms for very selective neurons _cite_ . This suggests that despite their broadly-tuned neighbors being active earlier, these selective neurons do not become active until additional information has been integrated by previous stages of the visual system. Furthermore, humans without a viewing duration constraint have trouble identifying occluded images; a task a cCNN such as AlexNet _cite_ does not perform particularly well, either _cite_ . Allowing the human observers more time, or adding recurrent connections to the last layer (fcN) of AlexNet improves performance for both _cite_, indicating how beneficial recurrent connections can be. We hypothesize that when responding to ambiguous stimuli, such as in low contrast conditions or occlusion, the neural circuit permits more time for recurrent processing before selective neurons---presumably important for decision-making---become active. The classical feedforward CNNs were inspired by the primate visual system _cite_ . Yet, this architecture ignores recurrent connections, which are abundant in the primate visual system. We believe that the visual system---especially at low contrast/low SNR values---acts as both a CNN and a recurrent neural network, in which local recurrent connections can integrate information at every layer. To our knowledge, no one has used recurrent convolutional layers to boost classification performance or other computer vision tasks at low SNRs. Others have added recurrent connections in early convolutional layers of CNNs _cite_, which improved performance in ImageNet classification _cite_ and aided in digit clutter analysis _cite_ . Here, we show that cCNN performance using a standard cCNN architecture breaks down in the low-SNR regime, while a recurrent CNN can still classify relatively well. We systematically compare the integration performance of recurrent CNNs (gruCNNs) to a Bayes-optimal temporal integration of cCNNs, and show that integration at early processing stages with recurrent connections is significantly improved.