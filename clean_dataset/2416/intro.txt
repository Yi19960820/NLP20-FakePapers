Gliomas are the most common primary brain tumors that start in the glial cells of the brain in adults. They can be categorized according to their grade: Low-Grade Gliomas (LGG) exhibit benign tendencies and portend a better prognosis for the patient, while High-Grade Gliomas (HGG) are malignant and lead to a worse prognosis~ _cite_ . Medical imaging of brain tumors plays an important role for evaluating the progression of the disease before and after treament. Currently the most widely used imaging modality for brain tumors is Magnetic Resonance Imaging (MRI) with different sequences, such as TN-weighted, contrast enhanced TN-weighted (TNce), TN-weighted and Fluid Attenuation Inversion Recovery (FLAIR) images. These sequences provide complementary information for different subregions of brain tumors~ _cite_ . For example, the tumor region and peritumoral edema can be highlighted in FLAIR and TN images, and the tumor core region without peritumoral edema is more visible in TN and TNce images. Automatic segmentation of brain tumors and substructures from medical images has a potential for accurate and reproducible delineation of the tumors, which can help more efficient and better diagnosis, surgical planning and treatment assessment of brain tumors~ _cite_ . However, accurate automatic segmentation of the brain tumors is a challenging task for several reasons. First, the boundary between brain tumor and normal tissues is often ambiguous due to the smooth intensity gradients, partial volume effects, and bias field artifacts. Second, the brain tumors vary largely across patients in terms of size, shape, and localization. This prohibits the use of strong priors on shape and localization that are commonly used for robust segmentation of many other anatomical structures, such as the heart~ _cite_ and the liver~ _cite_ . In recent years, deep Convolutional Neural Networks (CNNs) have achieved the state-of-the-art performance for multi-modal brain tumor segmentation~ _cite_ . As a type of machine learning approach, they require a set of annotated training images for learning. Compared with traditional machine learning approaches they do not rely on hand-crafted features and can learn features automatically. In~ _cite_, a CNN was proposed to exploit both local and global features for robust brain tumor segmentation. It replaces the final fully connected layer used in traditional CNNs with a convolutional implementation that obtains N fold speed up. This approach employs a two-phase training procedure and a cascade architecture to tackle difficulties related to the imbalance of tumor labels. Despite the better performance than traditional methods, this approach works on individual ND slices without considering ND contextual information. DeepMedic~ _cite_ uses a dual pathway ND CNN with N layers to make use of multi-scale features for brain tumor segmentation. For post-processing, it uses a ND fully connected Conditional Random Field (CRF) ~ _cite_ that helps to remove false positives. DeepMedic achieved better performance than using ND CNNs. However, it works on local image patches and therefore has a relatively low inference efficiency. In~ _cite_, a triple cascaded framework was proposed for brain tumor segmentation. The framework uses three networks to hierarchically segment whole tumor, tumor core and enhancing tumor core sequentially. It uses a network structure with anisotropic convolution to deal with ND images, taking advantage of dilated convolution~ _cite_, residual connection~ _cite_ and multi-scale fusion~ _cite_ . It demonstrated an advantageous trade-off between receptive field, model complexity and memory consumption. This method also fuses the output of CNNs in three orthogonal views for more robust segmentation of brain tumors. In~ _cite_, an ensemble of multiple models and architectures including DeepMedic~ _cite_, ND Fully Convolutional Networks (FCN) ~ _cite_ and U-Net~ _cite_ was used for robust brain tumor segmentation. The ensemble method reduces the influence of the meta-parameters of individual CNN models and the risk of overfitting the configuration to a specific training dataset. However, it requires much more computational resources to train and run a set of models. Training with a large dataset plays an important role for the good performance of deep CNNs. For medical images, collecting a very large training set is usually time-consuming and challenging. Therefore, many works have used data augmentation to partially compensate this problem. Data augmentation applies transformations to the samples in a training set to create new ones, so that a relatively small training set can be enlarged to a larger one. Previous works have used different types of transformations such as flipping, cropping, rotation and scaling training images~ _cite_ . In~ _cite_, a simple and data-agnostic data augmentation routine termed mixup was proposed for training neural networks. Recently, several studies have empirically found that the performance of deep learning-based image recognition methods can be improved by combining predictions of multiple transformed versions of a test image, such as in pulmonary nodule detection~ _cite_ and skin lesion classification~ _cite_ . In~ _cite_, test images were augmented by mirroring for brain tumor segmentation. In~ _cite_, a mathematical formulation was proposed for test-time augmentation, where a distribution of the prediction was estimated by Monte Carlo simulation with prior distributions of parameters in an image acquisition model. That work also proposed a test-time augmentation-based aleatoric uncertainty estimation method that can help to reduce overconfident predictions. The framework in~ _cite_ has been validated with binary segmentation tasks, while its application to multi-class segmentation has yet to be demonstrated. In this paper, we extend the work of~ _cite_ and~ _cite_, and apply test-time augmentation to automatic multi-class brain tumor segmentation. For a given input image, instead of obtaining a single inference, we augment the input image with different transformation parameters to obtain multiple predictions from the input, with the same network and associated trained weights. The multiple predictions help to obtain more robust inference of a given image. We explore the use of different CNNs as the underpinning network structures. Experiments with BraTS N training and validation set showed that an improvement of segmentation accuracy was achieved by test-time augmentation, and our method can provide uncertainty estimation for the segmentation output.