High-order statistics feature learning is one of the most active areas in pattern recognition. Especially, in the past few decades, covariance matrix was proposed as a generic descriptor. As the robustness to rotation, scale change and outlier, region covariance descriptors have achieved promising performance in object detection~ _cite_, texture classification~ _cite_ and tracking ~ _cite_ . When dealing with skeleton-based human action recognition, a large amount of variants are evolved from the covariance theory. For example, to represent human skeleton graph in action recognition, a kernelized version named kernel-matrix-based (KMB) descriptor~ _cite_ is proposed to depict the relationship between skeletal joints. In~ _cite_, Hussein et al. computes the statistical covariance of ND Joints (CovNDJ) as spatio-temporal SPD features to encode the relationship between joint movement meanwhile takes the temporal variation of action sequences into account. The driving forces to this trend are the powerful representation ability and the behind fundamental mathematical theory of Riemannian manifold spanned by symmetric positive definite (SPD) matrices, of which covariance is a special case. For SPD descriptors, two crucial issues should be well solved. The first one is how to learn more discriminative features from SPD matrix space. Several approaches, such as manifold-to-manifold transformation~ _cite_ and locally linear embedding~ _cite_, attempt to seek for the optimal SPD embedding matrices on Riemannian manifold. Inspired by deep learning, more recently, Huang et al.~ _cite_ proposed a Riemannian network to extract high-level features from SPD matrices by designing the bilinear mapping (BiMap) layer and eigenvalue rectification (ReEig) layer. The second one is how to define the metric of SPD matrices. As SPD matrices lie on Riemannian manifold rather than Euclidean space, directly applying the algorithm designed in Euclidean geometry to SPD matrices may lead poor performances. To address this problem, some approximate metrics are proposed under the framework of manifold. Especially, Log-Euclidean metric~ _cite_ flattens Riemannian manifold to tangent space so that numerous conventional methods designed in Euclidean space can be used. However, this process inevitably need to calculate matrix logarithm, which has high computation cost due to the requirement of SVD. Furthermore, the modeling ability of temporal dynamics need to be enhanced to reduce the obscure of a single matrix descriptor (e.g., covariance) for a sequence. Recently recursive learning~ _cite_ and convolutional neural network (CNN) ~ _cite_ have obtained the breakthrough successes, but they only work in Euclidean space, and generalizing them to manifolds should have a constructive value to the SPD descriptor. To this end, several crucial issues need to be solved: In this paper, we propose a novel deep manifold-to-manifold transforming network (DMT-Net) to address all above issues. To implement local convolutional filtering on SPD matrices, we specifically design an SPD layer by constraining those filters to be SPD. Under this constraint, we theoretically prove manifold preservation after convolutional filtering. To enhance the flexibility, we also design a non-linear activation layer with the guarantee of manifold preservation, which only need perform element-wise operation and thus does not require SVD. To model sequence dynamics, we specifically design an manifold-preserved recursive layer to encode sequentially SPD matrices of segmented subclips. In metric computation, we design a diagonalizing layer to convert each SPD map into a positive diagonal matrix, which makes log-Euclidean matric be efficiently calculated and avoids high-computational SVD. All these are integrated together and jointly trained for recognition. To evaluate the effectiveness of the proposed method, we conduct experiments on various datasets of action recognition. The experimental results show that our method outperforms those state-of-the-arts. In summary, our main contributions are four folds: