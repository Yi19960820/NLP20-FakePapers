methods _cite_ are general techniques in machine learning that combine several learners; these techniques include bagging _cite_, boosting _cite_ and stacking _cite_ . Ensemble methods frequently improve predictive performance. We describe a novel approach to ensemble learning that chooses the learners to be used, the way in which these learners should be trained to create predictors (predictive models), and the way in which the predictions of these predictors should be combined according to the {\em features} of a new instance for which a prediction is desired. By {\em jointly} deciding which learners and training sets to be used, we provide a novel method to grow complex predictors; by deciding how to aggregate these predictors we control overfitting. As a result, we obtain substantially improved predictive performance. Our proposed model, ToPs (Trees of Predictors), differs from existing methods in that it constructs and applies {\em different} predictive models to {\em different} subsets of the feature space. Our approach has something in common with tree-based approaches (e.g. Random forest, Tree-bagging, CART, etc.) in that we successively split the feature space. However, while tree-based approaches create successive splits of the feature space in order to maximize {\em homogeneity} of each split {\em with respect to labels}, ToPs creates successive splits of the feature space in order to maximize {\em predictive accuracy} of each split {\em with respect to a constructed predictive model} . To this end, ToPs creates a tree of subsets of the feature space and associates a predictive model to each such subset--i.e., to each node of the tree. To decide whether to split a given node, ToPs uses a feature to create a tentative split, then chooses a learner and a training set to create a predictive model for each set in the split, and searches for the feature, the learner and the training set that maximizes the predictive accuracy (minimizes the prediction error) . ToPs continues this process recursively until no further improvement is possible. A simple toy example, illustrated in Fig. _ref_, may help to illustrate how ToPs works and why it improves on other tree-based methods. We consider a classification problem: making binary predictions of hypertension in a patient population. We assume two features: Diabetic or Non-diabetic and Age Range N-N, N-N, N-N, N +, so that there are N categories of patients. We assume the data is as shown in Fig. _ref_ (a): there are N patients in each category; N patient who is Diabetic and in the Age Range N-N has hypertension, etc. We first consider a simple classification tree. Such a tree first selects a single feature and threshold to split the population into two groups so as to maximize the purity of labels. In this case the best split uses Age Range as the splitting feature and partitions patients into those in the Age Ranges N-N or N-N and those in the Age Ranges N-N or N + . No further splitting improves the purity of labels so we are left with the tree shown in Fig. _ref_ (b) . The resulting predictive model predicts that those in the Age Ranges N-N or N-N will not have hypertension and those in the Age Ranges N-N or N + will have hypertension; this model makes N prediction errors. We now consider an instantiation of ToPs which uses as base learner a linear regression (to produce a probability of hypertension) followed by thresholding at N (Recall that we are treating this as a classification problem.) The best split for this instantiation of ToPs uses Diabetic/Non-diabetic as the splitting feature (leading to the split shown in Fig. _ref_ (c)) but creates different predictive models in the two halves of the split: in the Non-diabetic half of the split, the model predicts that patients in the Age Ranges N-N, N-N and N-N will not have hypertension and that patients in the Age Range N + will have hypertension; in the Diabetic half of the split the model predicts that patients in the Age Ranges N-N and N-N will not have hypertension and that patients in the Age Ranges N-N and N + will have hypertension. (After this split, no further splits using this single base learner improve the prediction accuracy.) This model makes only N errors (less than the number of errors made by the classification tree) . Note that the tree produced by ToPs is completely different from the classification tree, that the predictive models and predictions produced by ToPs are different from those produced by the classification tree, and that the predictions produced by ToPs within a single terminal node are not uniform. In this case, ToPs performs better than the classification tree because it "understands" that the effect of age on the risk of hypertension is different for patients who are Diabetic and for patients who are Non-diabetic. Although this toy example may seem artificial, it exemplifies what happens when we apply ToPs to a real dataset. For example, one of our experiments is survival prediction of patients who are wait-listed for a heart transplant. (For more discussion, see Section _ref_ and _ref_ .) In that setting features _inline_eq_ are patient characteristics and labels _inline_eq_ are survival times. The data set _inline_eq_ consists of records of actual patients; a single data point _inline_eq_ records that a patient with features _inline_eq_ survived for time _inline_eq_ . The construction of our algorithm demonstrates that the {\em best predictor} of survival for males is {\em different} from the {\em best predictor} of survival for females. As a result, predictions of survival for a male and a female with otherwise similar features may be quite different-because the features that influence survival have different importance and interact differently for males and females. Using a gender-specific predictor leads to significant improvement in prediction accuracy. In what follows, Section _ref_ highlights the differences between our method and related machine learning methods. Section _ref_ provides a full description of our method. Section _ref_ derives loss bounds. Section _ref_ compares the performance of our method with that of many other methods on a variety of datasets, demonstrating that our method provides substantial and statistically significant improvement. Section _ref_ details the operation of our algorithm for one of the datasets to further illustrate how why our method works. Section _ref_ concludes. Proofs are in the Appendix (at the end of the manuscript) ; parameters of the experiments and additional figures and discussion can be found in the Supplementary Materials.