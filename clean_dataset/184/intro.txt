Automated land cover mapping based on satellite image analysis and classification is a well-known challenge which is of a great interest for many fields, such as agriculture _cite_ and risk monitoring _cite_ . The recently launched Sentinel-N satellite constellation provides a richer content in spatial, spectral and temporal domains, and produces a huge amount of images to process daily. In this context, Deep Learning (DL) appears as an appealing alternative to traditional classification approaches to deal with such a massive amount of data. A DL architecture is a deep artificial neural network composed of a hierarchical succession of neuron layers performing linear and non-linear processing. Mimicking the human brain behavior, the network tuning (typically millions of parameters) is automatically performed thanks to a supervised training process on large datasets that are generally associated to some ``ground truth'' knowledge. However, the ground truth quality is essential to reach satisfying performances. Some recent works already use deep neural nets to process remotely sensed images. In _cite_, the authors compared different well-established deep architectures (AlexNet, AlexNet-small, VGG) for the classification of SAT-N/SAT-N dataset (from US National Agriculture Imagery Program, NAIP) using Convolutional Neural Networks (CNN) . Pirotti et al.~ _cite_ benchmarked different machine learning methods (including multilayered perceptron) for classification of Sentinel-N images. In _cite_, we proposed a new ND CNN architecture for hyperspectral data pixelwise classification (semantic segmentation) . In _cite_, we adapted the SegNet architecture to achieve semantic segmentation of multimodal airborne imagery. In this paper, we rely on the recent DenseNet~ _cite_ and SegNet~ _cite_ architectures to perform land cover semantic segmentation of large multispectral Sentinel-N images. These architectures are experimentally assessed through two different use cases, namely fine and coarse resolution estimation. We also introduce a new ND DenseNet network in order to jointly process both spatial and spectral dimensions. In addition, we suggest the use of a ``noisy ground truth'' (i.e. outdated and low spatial resolution labels) for both training and testing. The idea is to explore the feasibility of outdated low quality knowledge integration for modern image sensors and analysis methods. Experiments are conducted in a wide region between France, Switzerland and Italy relying on the reference areas of GlobCover (ESA N Global Land Cover Map) annotation and N ESA Sentinel-N images.