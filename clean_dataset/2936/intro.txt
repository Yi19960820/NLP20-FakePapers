Engagement is a significant aspect of human-technology interactions and is defined differently for a variety of applications such as search engines, online gaming platforms, and mobile health applications _cite_ . According to Monkaresi~ \etal~ _cite_, most definitions describe engagement as attentional and emotional involvement in a task. This paper deals with engagement during learning via technology. Investigating engagement is vital for designing intelligent educational interfaces in different learning settings including educational games _cite_, massively open online courses (MOOCs) _cite_, and intelligent tutoring systems (ITSs) _cite_ . For instance, if students feel frustrated and become disengaged (see disengaged samples in Fig.~ _ref_), the system should intervene in order to bring them back to the learning process. However, if students are engaged and enjoying their tasks (see engaged samples in Fig.~ _ref_), they should not be interrupted even if they are making some mistakes _cite_ . In order for the learning system to adapt the learning setting and provide proper responses to students, we first need to automatically measure engagement. This can be done by, for example, using context performance _cite_, facial expression _cite_ and heart rate _cite_ data. Recently, engagement recognition using facial expression data has attracted special attention because of widespread availability of cameras~ _cite_ . This paper aims at quantifying and characterizing engagement using facial expressions extracted from images. In this domain, engagement detection models usually use typical facial features which are designed for general purposes, such as Gabor features _cite_, histogram of oriented gradients _cite_ and facial action units _cite_ . To the best of the authors' knowledge, there is no work in the literature investigating the design of specific and high-level features for engagement. Therefore, providing a rich engagement representation model to distinguish engaged and disengaged samples remains an open problem (Challenge N) . Training such a rich model requires a large amount of data which means extensive effort, time, and expense would be required for collecting and annotating data due to the complexities _cite_ and ambiguities _cite_ of the engagement concept (Challenge N) . To address the aforementioned challenges, we design a deep learning model which includes two essential steps: basic facial expression recognition, and engagement recognition. In the first step, a convolutional neural network (CNN) is trained on the dataset of the Facial Expression Recognition Challenge N (FER-N) to provide a rich facial representation model, achieving state-of-the-art performance. In the next step, the model is applied to initialize our engagement recognition model, designed using a separate CNN, learned on our newly collected dataset in the engagement recognition domain. As a solution to Challenge N, we train a deep learning-based model that provides our representation model specifically for engagement recognition. As a solution to Challenge N, we use the FER-N dataset, which is around eight times larger than our collected dataset, as external data to pre-train our engagement recognition model and compensate for the shortage of engagement data~ . The contributions of this work are threefold: