Active Appearance Models (AAMs) _cite_ have been used successfully in several areas of facial interpretation over the last two decades. Given a new face image, the method aims to “describe” that image by synthesizing a new image similar to it as much as possible. Indeed, AAMs are statistical models of appearance, generated by combining a shape model that represents the facial structure, and a quasi-localized texture model that represents the pattern of pixel intensities, i.e. skin texture, across a facial image patch. However, their capability of generalization is limited by the nature of Principal Component Analysis (PCA) used in both shape and texture models. Besides, since AAMs naively combine the shape and texture features to represent the facial appearance also by using PCA, it can only reveal the linear relationship between these features. There have been numerous improvements and adaptations using, for example, the probabilistic PCA _cite_, nonlinear Deep Boltzmann Machines (DBM) _cite_, etc., to model large and non-linear variations in shapes and textures. Duong et al. _cite_ recently proposed the Deep Appearance Models (DAMs) approach to model face images using a DBM network. Their main ideas are first to learn the shape and the texture models of sample faces separately using the DBM approach. The relationships between these two modalities are then pursued to generate the final appearance model using Restricted Boltzmann Machines (RBM) at the top layer. Given an unseen face, DAMs find the optimal facial shape using the forward compositional algorithm. This algorithm minimizes the non-linear least squares error between the warped and the reconstructed textures from the models. This network architecture enables the non-linear modeling capability to overcome the limitations presented in the original AAMs method. However, there are still some limitations of DAMs in both face modeling and shape fitting. Firstly, the DAMs method still takes into account numerous appearance variations of face images, e.g. facial poses, occlusions, lighting, etc. in their fitting procedure resulting in undesirable fitting performance. Their minimization method using the squared error is good enough for constrained face images rather than for the problem of unconstrained face modeling with occlusions, poses and noise. Secondly, the texture models of DAMs method cannot distinguish between occluded and non-occluded areas since it treats all regions in the same way during model learning phase. DAMs will capture both ``good" and ``bad" regions in the learned models. Thus, it will give undesirable reconstruction texture images (as shown in Fig. _ref_) . To overcome the above modeling and fitting issues, we propose a novel Robust Deep Appearance Models (RDAMs) to learn an additional appearance variation mask that could be used in the fitting procedure to ignore those variations. This mask is modeled by the visible and hidden unit in Robust Boltzmann Machines (RoBM) _cite_ . This proposed model not only learns compact representation for recognition/prediction tasks, but also reconstructs better shape and texture. The contributions of this work can be summarized as follows. Firstly, we propose a new texture modeling approach named Robust Deep Boltzmann Machines described in section _ref_ . It can model ``good" and ``bad" regions separately via a DBM and a binary RBM, respectively. Then, for example, given a face with sunglasses, RDBM can recover a ``clean" face without sunglasses (as shown in Fig. _ref_) . Secondly, the proposed RDAMs approach models shape using a DBM since it has non-linear property and can be setup in deep modeling to give more robust representation for shapes. Thirdly, we propose to use the learned binary RBM to generate a mask for shape model fitting using inverse compositional algorithm described in section _ref_ .