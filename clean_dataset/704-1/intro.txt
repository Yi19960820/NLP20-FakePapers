Precise segmentation of infant brain MRI into white matter (WM), gray matter (GM) and cerebrospinal fluid (CSF) is essential to study early brain development. Throughout this period, the postnatal human brain shows its most dynamic phase of development, with a rapid growth of tissues and the formation of key cognitive and motor functions _cite_ . Infant brain segmentation is also important to detect brain abnormalities occurring shortly after birth, such as hypoxic ischemic encephalopathy, hydrocephalus or congenital malformations, enabling the prediction of neuro-developmental outcomes. Magnetic resonance imaging (MRI) is commonly used for infant brains because it provides a safe and non-invasive way of examining cross-sectional views of the brain in multiple contrasts. Brain MRI in the first two years can be divided in three distinct phases: infantile (_inline_eq_ N months), isointense (N-N months) and early adult-like phase (_inline_eq_ N months) . Images in the isointense phase show patterns of isointense contrast between white and gray matter (e.g., see Fig. _ref_), which may vary across brain regions due to nonlinear brain development _cite_ . These patterns, along with various factors, for instance, limited acquisition time, increased noise, motion artifacts, severe partial volume effect due to smaller brain sizes and ongoing white matter myelination in infant brain images, make automatic segmentation of isointense infant brain MRI a challenging task. A popular approach for automatic segmentation uses atlases to model the anatomical variability of target structures _cite_ . In such approach, an atlas (or multiple atlases) is first registered to a target image and then used to propagate manual labels to this image. When several atlases are considered, labels from individual atlases can be combined into a final segmentation via a label fusion strategy _cite_ such as the STAPLE (Simultaneous Truth and Performance Level Estimation) algorithm _cite_ . Atlas-based methods have been widely used in a breadth of segmentation problems, e.g., parcellation of brain MRI into subcortical structures _cite_ . Although these methods provide state-of-the-art performance in many applications, they are usually sensitive to the registration process, and may fail if the image has a low contrast or the target structure has a large variability. This is particularly problematic in the case of infant brain segmentation, due to isointense contrasts and the high spatial variability of the infant population. To overcome the limitations of atlas-based methods, parametric _cite_ or deformable _cite_ models can be used in a refinement step. Parametric models typically state segmentation as the optimization of an energy function, which integrates pixel/voxel probabilities from the atlas with priors restricting the shape or pairwise interactions of brain tissues _cite_ . Such models often need a large number of annotated images, which are rarely available in practice. Deformable models refine atlas-produced contours in an iterative manner so as to align better with image edges. However, these models are typically structure-specific and difficult to extend to multi-tissue segmentation. Recently, deep learning methods based on convolutional neural networks (CNNs) have demonstrated outstanding performances in a wide range of computer vision and image analysis applications. In particular, CNNs have achieved state-of-the-art results for various problems _cite_, including the segmentation of infant brain MRI _cite_ . For instance, Moeskops et al. _cite_ presented a multi-scale ND CNN architecture, which yielded accurate segmentations and spatial consistency using a single image modality (i.e., TNw MRI) . To acquire multi-scale information, they considered patches and convolution kernels of multiple sizes. Independent paths were used for patches of different sizes, and the features of these paths were combined at the end of the network. Several recent studies investigated architectures based on multiple modalities as input, in order to overcome the extremely low contrast between WM and GM tissues. For example, Zhang et al. _cite_ proposed a deep CNN combining MR-TN, TN and fractional anisotropy (FA) images. Similarly, a fully convolutional neural network (FCNN) was proposed in _cite_ for segmenting isointense phase brain MR images. As further explained in Section _ref_, a FCNN is a special type of CNN that generates dense pixel predictions. Instead of simply stacking the three modalities at the network input, the network in _cite_ processes each modality within an independent path. The final segmentation is obtained by fusing the ensuing paths. These approaches have some important drawbacks. First, the architectures in _cite_ and _cite_ use sliding windows, each defining a region that is processed independently of the other windows. Such a strategy is not efficient because of the many redundant convolution and pooling operations. Furthermore, processing these regions independently yields non-structured predictions, which affects segmentation accuracy. Second, these networks use ND patches as input. This does not account for the anatomic context in directions orthogonal to the ND plane. As first shown in _cite_, and later in _cite_, in different contexts of brain structure segmentation, considering ND data directly, instead of slice-by-slice, can improve segmentation accuracy. Table _ref_ provides a brief summary of the existing methods for infant brain tissue segmentation. For a detailed review of the methods proposed to address this task, we refer the reader to the recent work of Makropoulos et al. _cite_ While fully-automatic, learning-based medical image segmentation methods have improved substantially over the last years, the performances in many applications are still insufficient for practical use, more so when the amount of training data is very limited, as is typically the case in medical applications. For instance, manual annotations of brain MRI (i.e., assigning a label to each voxel) is a highly complex and time-consuming process, which requires extensive expertise. This is particularly the case of infant brain MRIs. Therefore, both active and semi/weakly supervised learning frameworks are currently attracting substantial interest in medical image analysis _cite_ . For instance, in the recent study in _cite_, Yang et al. proposed an active learning framework, and showed its potential in the context of segmenting glands in histology images and lymph nodes in ultrasound. The purpose of _cite_ was to design algorithms that suggest a small set of images to annotate, which lead to the highest possible performance improvement when adding these new annotations to the training set. The framework in _cite_ uses an ensemble of deep CNNs to compute an agreement score for candidate instances, and suggests representative instances with the highest uncertainty. However, since suggestions are made at the image level, manual annotations of full images are still required. Using ensemble of CNNs, each trained with a different set of images, can further improve robustness by reducing test error due to variance _cite_ . The contributions of this study can be itemized as follows: The remainder of this paper is as follows. In Section _ref_, we present the proposed semi-dense architecture, and detail how an ensemble of networks can be used to suggest annotations. We also describe the evaluation protocol used in our study. Section _ref_ demonstrates the performance of our method on data from the MICCAI iSEG-N Challenge. Finally, in Section _ref_, we discuss the main contributions and results of this work, and propose some potential extensions.