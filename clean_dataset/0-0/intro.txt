Hand pose estimation from depth image _cite_ _cite_ is critical for human-computer interaction _cite_, and has been studied extensively in recently years _cite_ _cite_ _cite_ _cite_ . Among all the joints of hand, fingertips play an important role in interaction, which are related to lots of gestures such as swipe and tap _cite_ . In the meanwhile, fingertip positions are often the most difficult to learn due to various hand poses, large self-occlusion and poor depth recovery near fingertips _cite_ . Most of existing approaches _cite_ _cite_ _cite_ _cite_ _cite_ rely on the topology structure of hand, leading to relative large error on fingertips (often larger than Ncm) due to error accumulation from palm to fingertip. To solve these problems, we propose a new method for accurate detection of fingertip positions based on convolutional neural network (CNN) . Different from earlier works that employ only depth image as input _cite_ _cite_ _cite_, we take advantage of both depth information and edge information from depth image (See Fig. _ref_) . We employ random forest (RF) to extract edges as in _cite_ . Then we investigate a different architecture based on two separate streams with both depth and edge images, which are then combined by fusion strategy. After comparison with different CNN structures and fusion strategies, a deep structure with slow fusion is chosen for precise fingertip detection. We will show that such strategy is able to improve fingertip estimation performance. Evaluated on two public datasets _cite_ _cite_, our method outperforms other state-of-the-art algorithms with a ND error of N on fingertips, and obtains comparable performance on the challenging NYU hand dataset.