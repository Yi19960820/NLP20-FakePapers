We introduce EndNYou--the Imperial College London toolkit for multimodal profiling by end-to-end deep learning. EndNYou is an open-source toolkit implemented in Python and is based on Tensorflow. It provides capabilities to train and evaluate models in an end-to-end manner, i. \, e., using raw input. It supports input from raw audio, visual, physiological or other types of information or combination of those, and the output can be of an arbitrary representation, for either classification or regression tasks. To our knowledge, this is the first toolkit that provides generic end-to-end learning for profiling capabilities in either unimodal or multimodal cases. To test our toolkit, we utilise the RECOLA database as was used in the AVEC N challenge. Experimental results indicate that EndNYou can provide comparable results to state-of-the-art methods despite no need of expert-alike feature representations, but self-learning these from the data ``end to end''.