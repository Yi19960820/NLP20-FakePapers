Representation of data in multiple views can be seen in applications related to machine learning, computer vision, and natural language processing. At times it is beneficial to combine different modalities of data since an amalgamation of multiple views is likely to capture more meaningful information than a representation that is fit for only a specific modality. For example, consider the task of abstract scene recognition in a movie _cite_ with text annotations as labels. Movie data is comprised of video frames (images) along with audio. Here, images and audio are two different representations of same data with different representative features. Thus, combining these two modalities into a common subspace can help in the task of classification of abstract scenes from videos. Similarly, multi-view data have been used in audio + articulation _cite_, images + text _cite_, training transliterated corpora (bilingual data) _cite_, or bridge autoencoders _cite_ . The techniques used for common representation learning (CRL) of multi-view data can be categorized into two categories-canonical based approaches and autoencoder based methods. Canonical correlation analysis (CCA) _cite_ is matrix factorization method that maximizes the correlation between two views of data by projecting different modalities onto a common subspace. Variants of CCA include regularized CCA _cite_, Kernel-CCA (KCCA) _cite_, Nonparametric CCA (NCCA) _cite_, Deep-CCA (DCCA) _cite_, randomized non-linear component analysis (RCCA) _cite_-a low rank approximation of KCCA, and Deep-Generalized-CCA (DGCCA) _cite_ . Although CCA-based methods provide a combined correlated representations, they suffer from scalability issues _cite_ . Another problem associated with CCA-based techniques is the fact that these methods tend to have poor performance for reconstruction of views. Another broad category into which the CRL techniques can be divided is autoencoder (AE) based approaches. AE are deep neural networks that try to optimize two objective functions _cite_ . The first objective is to find a compressed hidden representation of data in a low-dimensional vector space. The other objective is to reconstruct the original data from the compressed low-dimensional subspace. Multi-modal autoencoders (MAE) are two channeled AE that specifically performs two types of reconstructions _cite_ . The first is the self-reconstruction of view from itself, and the other is the cross-reconstruction where one view is reconstructed given the other. These reconstruction objectives provide MAE the ability to adapt towards transfer learning tasks as well. One recently proposed variant of MAE is Correlation Neural Networks (CorrNet) _cite_ which presents an improvement to MAE by introducing a correlation term in the objective function that tries to maximize the correlation between the hidden representations of different views. Some limitations of the CorrNet includes usage of the simple neural layer for encoding and decoding and using the final hidden representations in the correlation loss function. Deep networks have grabbed the attention of many ever since the advent of state-of-the-art results using CNN networks. Apart from that, a lot of techniques have been worked upon to improve the classical CNN models. Regularization methods to reduce over-fitting, activation functions and modified convolution layers are some of them. Dropout technique _cite_ is a very commonly used stochastic regularization technique which is also being used in our model. For activation function, sigmoid functions are avoided as they have a problem of vanishing gradient when large networks are involved. Hence, we use the rectified linear unit (ReLU) _cite_ which is mathematically efficient. Batch normalization _cite_ has been used to increase the training rate providing us with better correlation values as compared to the previous papers. It is a stabilizing mechanism for training a neural network by scaling the output of hidden layers to zero norm and unit variance. This process of scaling reduces the change of distribution between neurons throughout the network and helps to speed up the training process. In this paper, we focus our attention on the improvement in objective function of CorrNet, thereby enhancing the learned joint representations and reconstruction of views as well. Specifically, main contributions of the paper are The rest of the paper is organized as follows. In section _ref_ we discuss previous work related to our work which is followed by the discussion of CorrMCNN in Section _ref_ . The experimental details and results are shown in section _ref_ and then our work is concluded in section _ref_ .