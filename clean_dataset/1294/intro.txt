Convolutional Neural Networks (CNNs) have proven extremely succesful in finding structure in high-dimensional data, including time-sequences such as audio and video _cite_ . Some examples of promising real-world applications are speech-and video recognition, and automatic translation _cite_ . Challenges for software development include training of the networks using large GPU clusters and gathering huge, labeled datasets _cite_ . Practical user-side evaluation faces completely different challenges, including efficient and fast performance, low resource consumption, and responsiveness, such that the software responds to recognized events as quickly as possible _cite_ . Earlier work focusing on achieving these challenges include using less-parameter convolution filters _cite_, pruning obsolete weights _cite_, and using spiking networks _cite_ . This paper deals with optimizing convolution of time-series, as used for example in ND convolutional neural networks as they are applied in human action recognition _cite_ . We observe that when forward propagating continuously updating time-sequences through a neural network that applies convolution in the time-dimension, many redundant calculations are made. In order to avoid these calculations, to save CPU resources and potentially battery life on mobile devices, we propose Deep Shifting, which copies results of convolution operations from earlier time steps, rather than re-calculating these over and over. This can save substantial calculation time, especially when the CNN looks at a large number of time-frames. This paper is organized as follows: Section N shows how Deep Shifting performs CNN operations on time-sequences without performing redundant calculations. Sections N and N examine the theoretical and practical benefits of Deep Shifting. Section N investigates the possibilities of training a network using a minimal number of neurons and operations, and the paper finishes with a discussion and conclusion.