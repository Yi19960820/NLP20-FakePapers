Recently, computer vision research has a prominent progress and achieves excellent performance. Many tasks in computer vision field need plenty pixel-level annotations to guarantee the accuracy of the corresponding solutions, such as scene understanding and instance segmentations . The pixel-level annotations indicate that each pixel in the ground truth has a label referring to its category. However, it is very difficult to obtain such pixel-level annotation datasets, because this kind of annotations is time consuming and requires substantial Ô¨Ånancial investments. The process of labeling a pixel-level ground truth generally consumes a subject several minutes. On the contrast, weakly-labeled visual data, which only indicate the categories included by images but do not provide the locations of these categories, can be obtained in a relatively fast and cheap manner. Therefore, it is important and meaningful to generate pixel-level annotation data using weakly-labeled images, i.e. weakly-supervised semantic segmentation . In this paper, we focus on conducting pixel-labeled segmentation using weakly-labeled data. However, there is a large performance gap between weakly and fully supervised image semantic segmentation . A key problem is how to infer the objects locations according to image-level categories. used objectness proposal information to guide a object localization network to generate location cues, then aggregating these cues to help semantic segmentation. Although there are lots of helpful information contained in these aggregated location cues. Meanwhile many interference informations are mixed into them. These interferences are difficult to distinguish and eliminate under weakly-supervision such that they may effect the accuracy of object localization and image semantic segmentation. employed a classification network to retrieve objects location cues based on classification activation maps. These location cues, which consist of some discriminative regions, are very reliable and robust that could be used to improve the performance of segmentation tasks. Therefore, used these location cues to train a semantic segmentation network immediately. However, the discriminative regions in location cues are too small and sparse that they do not have enough ability to tune the entire network . For obtaining complete objects location from small and sparse cues, saliency detection methods are developed to enhance the performance of weakly-supervised segmentation. Saliency information of an image uses a saliency map to indicate the regions that most attract human beings' attentions. The saliency map can used to segment the input image into foreground and background. The salient foregrounds have a clear boundary and generally contain several salient objects, therefore could be utilized to generate objects locations from precise and reliable cues as Figure _ref_ shown. propose to utilize saliency to assist semantic segmentation. However, they assign salient regions a category randomly picked from image-level labels initially, and these salient regions will be assigned to a category if the category's seed touching the salient regions afterwards. This method heavily depends on the precision of the saliency methods and may produce sub-optimal results if a salient regions just have an incorrect pixel touching a category seed. To address the aforementioned problem, we propose a novel method called saliency guided weakly-supervised segmentation network which utilize saliency information as a guidance to generate robust objects locations from sparse cues to help image segmentation. Firstly, we use a weakly objection localization network to generate locations seeds from image-level category. These seeds have high confidence and precision that could be regard as ground truths. Secondly, to resolve the sparse and small issues of location seeds, we propose a novel method called saliency guided seeded region growing. The saliency information we used is from a self-attention saliency network which utilize image inherent cues, i.e. self-attention, to generate stage-wise refined saliency maps . We use the saliency detection method as a black box in this paper and immediately use the final saliency maps to guide the process of seeded region growing from location seeds. To alleviate the effect incorrect saliency results caused, we do not assign the salient region with a same label. We use the saliency values of pixels to generate saliency weights to control the process of seeded region growing. Therefore, a pixel not in a salient regions have possibility to get corresponding label, and a wrong salient pixel may be not grew by the location seeds. The saliency guidance can make the pixels with same saliency property easy to have the same label. At last, we integrate these cues into a network for weakly-supervised image segmentation. Experimental results demonstrate that our method outperforms several methods on a common PASCAL VOCN dataset. In summary, the contributions of this paper are as followings: