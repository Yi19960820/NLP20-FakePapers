This paper presents a novel NDOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of ND positions in monocular camera images, our approach uses range-finder sensors to learn and predict NDOF pose trajectories (i.e. ND position plus ND rotation within the world coordinate system) . Our approach, T-Pose-LSTM (Temporal NDOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment-and time-specific) human activities. Our approach incorporates long-term temporal information (i.e.~date and time) with short-term pose observations as input. For deployment, it can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than NK pedestrian trajectories recorded in a care home environment over a period of three months. The experiment shows that the proposed T-Pose-LSTM model advances the state-of-the-art ND-based method for human trajectory prediction in long-term mobile robot deployments.