Homogeneous object clusters (HOC) are ubiquitous. From microscopic cells to gigantic galaxies, they tend to cluster together. Figure~ _ref_ shows typical examples. Delineating individual homogeneous objects from their cluster gives an accurate estimate of the number of instances which further enables many important applications: for example, in medicine, various blood cell counts give crucial information on a patient's health. Instance segmentation for HOCs is by no means a trivial task despite the uniformity of the target objects. Directly applying current best performing instance segmentation methods~ _cite_, many of which are based on some kind of Deep Convolutional Neural Network (DCNN), meets a bottleneck: unaffordable annotation cost. All of these segmentation models require a large number of annotated images for training purpose. Unlike typical object segmentation (e.g., car, chair), homogeneous clustered objects are densely distributed in a given image with various degrees of occlusion. Pixel-wise labeling these objects is extremely time consuming. However, in many realistic scenarios (e.g., merchandise sold in a supermarket), we have tens of thousands of categories to process. Category-specific annotation is impractical to the instance segmentation problem we address in this paper. We need to automatically generate large amount training data (HOC images with segmentation annotation) with cheap cost. Generative adversarial nets _cite_ has been widely used to generate images and is a seemingly promising direction. However, the GAN framework cannot generate images with pixel-level annotation, so the segmentation models mentioned above cannot be trained using such images. RenderGAN _cite_ is proposed to generate images from labels. However the method also cannot generate images with pixel-level annotation. Image-to-image translation _cite_ based on conditional GAN _cite_ can get the annotation from images but it requires a large collection of image-annotation pairs to train, and thus it still needs a lot of laborious annotation. Driven by the above considerations, in this paper, we propose a novel framework to tackle the challenging instance segmentation problem. Inspired by~ _cite_, our learning framework is one-shot because it learns by looking only once the single sample captured in a single short video, which avoids the cumbersome collection of large-scale image datasets for training. Then, these single-object video frames are used to automatically synthesize realistic images of homogeneous object clusters. In doing so, we can acquire a large amount of training data automatically. Therefore, our framework is annotation-free . However, generating visually realistic images is a non-trivial task, since structural constraint (i.e., cluster layout should look reasonable) and illumination should be taken into consideration. In this paper, we propose a novel image synthesis framework to capture key priors from real images depicting HOCs. Structure prior is captured by learning a structured likelihood function. We generate structurally realistic synthetic images of HOC by placing synthetic objects in a specific way that maximizes the structured likelihood given by our defined function. Illumination is simulated through an efficient illumination transformation method we develop to transform both synthetic images and real images to share a similar illumination condition. To benchmark our performance, a dataset is built that consists of N properly selected and annotated images of homogeneous clustered objects. The extensive experiments show that our approach significantly improves the segmentation performance over baseline methods on the proposed dataset. The contributions of this paper are summarized as follows: