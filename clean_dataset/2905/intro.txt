Symmetric Positive Definite (SPD) matrices are often encountered and have made great success in a variety of areas. In medical imaging, they are commonly used in diffusion tensor magnetic resonance imaging _cite_ . In visual recognition, SPD matrix data provide powerful statistical representations for images and videos. Examples include region covariance matrices for pedestrian detection _cite_, joint covariance descriptors for action recognition _cite_, image set covariance matrices for face recognition _cite_ and second-order pooling for object classification _cite_ . As a consequence, there has been a growing need to carry out effective computations to interpolate, restore, and classify SPD matrices. However, the computations on SPD matrices often accompany with the challenge of their non-Euclidean data structure that underlies a Riemannian manifold _cite_ . Applying Euclidean geometry to SPD matrices directly often results in undesirable effects, such as the swelling of diffusion tensors _cite_ . To address this problem, _cite_ introduced Riemannian metrics, e.g., Log-Euclidean metric _cite_, to encode Riemannian geometry of SPD manifolds properly. By employing these well-studied Riemannian metrics, existing SPD matrix learning approaches typically flatten SPD manifolds via tangent space approximation _cite_, or map them into reproducing kernel Hilbert spaces _cite_ . To more faithfully respect the original Riemannian geometry, recent methods _cite_ adopt a geometry-aware SPD matrix learning scheme to pursue a mapping from the original SPD manifold to another one with the same SPD structure. However, all the existing methods merely apply shallow learning, with which traditional methods are typically surpassed by recent popular deep learning methods in many contexts in artificial intelligence and visual recognition. In the light of the successful paradigm of deep neural networks (e.g., _cite_) to perform non-linear computations with effective backpropagation training algorithms, we devise a deep neural network architecture, that receives SPD matrices as inputs and preserves the SPD structure across layers, for SPD matrix non-linear learning. In other words, we aim to design a deep learning architecture to non-linearly learn desirable SPD matrices on Riemannian manifolds. In summary, this paper mainly brings three innovations: