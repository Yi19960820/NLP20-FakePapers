Deep Neural Networks (DNNs) have achieved a remarkable success in several critical application domains including computer vision, speech recognition, and natural language processing. The trend of making deeper and wider networks to achieve higher model accuracy counters the goal of providing networks with higher efficiency in terms of model size and the speed of training/inference. Efficiency and compactness are of growing concerns since many of the applications relying on deep learning models are eventually aimed at providing intelligence on resource-constrained devices at the edge. The conventional cloud outsourcing approach fails to address latency, privacy, and availability concerns~ _cite_ . This has been the catalyst for a large number of works building efficient DNN inference accelerators such as~ _cite_ . Training phase of DNNs incurs a larger memory footprint and computation complexity compared with the inference. Assuming training is a one-time task, after which the model can be deployed on the inference accelerator platform on the edge, the major trend has been to train on the cloud~ _cite_ . However, providing adaptability at the edge is necessary to maintain the desired accuracy in dynamic environment settings. To address the above requirements, there is a need to tackle two key challenges so they can effectively fit within the edge devices: (i) how to reduce memory and computation cost of the DNN model on the cloud server without compromising the application performance and accuracy. (ii) how to extend the space of model parameters to learn new tasks on-device without forgetting the knowledge learned originally. Learning new tasks should be performed using few data instances over few iterations to comply with the stringent physical performance requirements at the edge. Conventional supervised deep learning is dependent on the availability of a massive amount of labeled data; the trained models generally perform poorly when labeled data is limited. The problem of rapidly learning new tasks with a limited amount of labeled data is referred to as ``few-shot learning'', which has received considerable attention from research community in recent years~ _cite_ . However, many of the recent approaches solely consider the model's performance on the new task and thus their approach discards the primary knowledge of the older tasks. This is in contrast with the goal of providing adaptable intelligence at the edge where adding to the capabilities of the model is desired without forgetting the previous knowledge. Neglecting the physical constraints of the edge device, in terms of memory, compute power, and energy consumption is another drawback of many of the state-of-the-art few-shot learning approaches. A practical few-shot learning methodology should extend the capabilities of the model not only using the few available new data instances but also through lightweight updates to the model. This work proposes, the first lightweight few-shot learning scheme that enables efficient and adaptable edge device realization of DNNs. To enable, we create a novel end-to-end structured decomposition methodology for DNNs which allows low-cost model updates to capture the dynamics of the new data. not only performs lightweight and effective few-shot leaning but also shrinks the storage requirement and computational cost of the model to match the edge device constraints. In summary, the contributions of this work are as follows: The rest of paper is structured as follows. Section~ _ref_ provides a review of related literature and discusses drawbacks of the prior art. The global flow of is described in Section~ _ref_ . Section~ _ref_ presents the details of the structured decomposition methodology. Few-shot learning technique is explained in Section~ _ref_ . Section~ _ref_ provides the experiment setting and benchmark evaluations and is followed by conclusions in Section~ _ref_ .