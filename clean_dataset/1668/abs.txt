Recent robotic manipulation competitions have highlighted that sophisticated robots still struggle to achieve fast and reliable perception of task-relevant objects in complex, realistic scenarios. To improve these systems' perceptive speed and robustness, we present SegICP, a novel integrated solution to object recognition and pose estimation. SegICP couples convolutional neural networks and multi-hypothesis point cloud registration to achieve both robust pixel-wise semantic segmentation as well as accurate and real-time N-DOF pose estimation for relevant objects. Our architecture achieves _inline_eq_ position error and _inline_eq_ angle error in real time an initial seed. We evaluate and benchmark SegICP against an annotated dataset generated by motion capture.