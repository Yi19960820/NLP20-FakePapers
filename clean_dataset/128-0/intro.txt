Text detection in natural scene is an important component (_cite_, _cite_, _cite_, _cite_, _cite_) for various intelligent applications based on computer vision. For instance, blind navigation, multilingual translation, automotive assistance and image-based geolocation, etc. Different from conventional OCR technique, scene text detection are often challenged by perspective distortions, variation of text size, color or uncontrollable illumination intensity, etc. In recent years, various methods have been successfully applied for detecting scene text. However, they usually comprise several processing steps, e.g. character or word proposal generation (_cite_, _cite_, _cite_), proposals filtering and clustering. They often entail much effort in designing heuristic rules and tuning parameters to make each module conduct well, which conversely reduces the speed of text detection. Currently, Deep Convolutional Neural Networks (DCNN) have advanced general object detection substantially, which is also widely used in the scene text detection field. The main differences between general object detection and scene text detection have been discussed by some previous published papers such as (_cite_, _cite_), which includes that the scene text are often smaller, thinner and with rich diversity on the aspect-ratios and so on, which makes the detection of scene text a very challenging problem different from general object detection. Besides, for a better performance, almost all object detection algorithms which adopt the DCNN framework take the strategy: i.e. training the proposed network by fine-tuning a model pre-trained on ImageNet dataset _cite_ which is used for image recognition, a different task which requires the extracted features are position-insensitive . Contradictorily, the task for object detection is position-sensitive . Therefore, _cite_ proposes the position-sensitive RoI pooling layer to solve the problem. However, they only use the _inline_eq_ sliding-window feature for region proposal and single scale high level feature for the refinement of object detection, which is insufficient for general text detection task, specially for smaller text regions; Meanwhile, their unitary position-sensitive RoI pooling in general object detection is unreasonable for much variable text regions. Motivated by their work, we propose a refined scene text detection framework via a novel Feature Enhancement Network (FEN) which can directly generate word bounding boxes and be end-to-end trainable. Our key contributions in this paper are as follows: