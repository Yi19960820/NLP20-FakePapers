Currently ongoing and forthcoming large-scale photometric surveys, such as the Dark Energy Survey (DES) and the Large Synoptic Survey Telescope (LSST), aim to collect photometric data for hundreds of millions to billions of stars and galaxies. Due to the sheer volume of data, it is not possible for human experts to manually classify them, and the separation of photometric catalogs into stars and galaxies has to be automated. Furthermore, any classification approach must be probabilistic in nature. A fully probabilistic classifier enables a user to adopt probability cuts to obtain a pure sample for population studies, or to optimize the allocation of observing time by selecting objects for follow-up. Ideally, however, the probability estimates themselves would be retained for all sources and used in subsequent analyses to improve or enhance a particular measurement~ . With machine learning, we can use algorithms to automatically create accurate source catalogs with well-calibrated posterior probabilities. Machine learning techniques have been a popular tool in many areas of astronomy~ . Artificial neural networks were first applied to the problem of star-galaxy classification in the work of, and they have become a core part of the astronomical image processing software ~ . Other successfully implemented examples of applying machine learning to the star-galaxy classification problem include decision trees~, Support Vector Machines~, and classifier combination strategies~ \citep* {kimNhybrid} . Almost all star-galaxy classifiers published in the literature use the reduced summary information available from astronomical catalogs. Constructing catalogs requires careful engineering and considerable domain expertise to transform the reduced, calibrated pixel values that comprise an image into suitable features, such as magnitudes or shape information of an object. In a branch of machine learning called deep learning ~, features are not designed by human experts; they are learned directly from data by deep neural networks. Deep learning methods learn multiple levels of features by transforming the feature at one level into a more abstract feature at a higher level. For example, when an array of pixel values is used as input to a deep learning method, the features in the first layer might represent locations and orientations of edges. The second layer could assemble particular arrangements of edges into more complex shapes, and subsequent layers would detect objects as combinations of low-level features. These multiple layers of abstraction progressively amplify aspects of the input that are important for classification tasks. Deep learning has been applied successfully to galaxy morphological classification in Sloan Digital Sky Survey~ \citep [] {dielemanNrotation} and Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey~ \citep [] {huertasNcatalog} and to photometric redshift estimation~, but it has not yet been applied to the problem of source classification. In this paper, we present a star-galaxy classification framework that uses a convolutional neural network (ConvNet) model directly on the images from the SDSS and the Canada-France-Hawaii Telescope Lensing Survey (CFHTLenS) . We compare its performance with a standard machine learning technique that uses the reduced summary information from catalogs, and we demonstrate that our ConvNet model is able to produce accurate and well-calibrated probabilistic classifications with very little feature engineering by hand. In Section~ _ref_, we describe the data sets used in this paper and the pre-processing steps for preparing the image data sets. We provide a brief overview of deep learning and ConvNets in Section~ _ref_, and discuss our strategy for preventing overfitting in Section~ _ref_ . In Section~ _ref_, we describe a state-of-the-art tree-based machine learning algorithm, to which the performance of our ConvNet model is compared. We present the main results of our ConvNet model in Section~ _ref_, and we outline our conclusions in Section~ _ref_ .