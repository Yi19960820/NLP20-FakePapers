Deep convolutional neural networks have improved performance across a wider variety of computer vision tasks, especially for image classification~ _cite_, object detection~ _cite_ and segmentation~ _cite_ . Much of this improvement should give the credit to gradually deeper network architectures. In just four years, the layer number of networks escalates from several to hundreds, which learns more abstract and expressive representations from large amount of data, \eg~ _cite_ . Simply stacking more layers onto current architectures is not a reasonable solution, which incurs vanishing/exploding gradients~ _cite_ . To handle the relatively shallower networks, a variety of initialization and normalization methodologies are proposed~ _cite_, while deep residual learning~ _cite_ is utilized to deal with extremely deep ones. Though other works, \eg~ _cite_, have also announced that they can train an extremely deep network with improved performance, deep residual network~ _cite_ is still the best and most practical solution for dealing with the degradation of training accuracy as depth increases. However, it is substantial that residual networks are exponential ensembles of relatively shallow ones (usually only N-N layers deep), as an interpretation by Veit \etal~ _cite_, it avoids the vanishing/exploding gradient problem instead of resolving it directly. Intrinsically, the performance gain of networks is determined by its multiplicity, not the depth. So how to train an ultra-deep network is still an open research question with which few works concern. Most researches still focus on designing more complicated structures based on residual block and its variants~ _cite_ . Anyway, dose there exist an applicable methodology that can be used for training a genuinely deep network? In this paper, we try to find a direct feasible solution to answer above question. We think batch normalization (BN) ~ _cite_ is necessary to ensure the propagation stability in the forward pass in ultra-deep networks and the key of learning availability exists in the backward pass which propagates errors with a top-down way. We constrain the network's structure to repetitive modules consisted by Convolution, BN and ReLU~ _cite_ layers (Fig.~ _ref_) and analyze the Jacobian of the output with respect to the input between consecutive modules. We show that BN cannot guarantee the magnitude of errors to be stable in the backward pass and this amplification/attenuation effect to signal will accumulate layer-wisely which results in gradients exploding/vanishing. From the view of norm-preserving, we find that keeping the orthonormality between filter banks within a layer during learning process is a sufficient and necessary condition to ensure the stability of backward errors. While this condition cannot be satisfied in nonlinear networks equipped with BN, this orthonormal constrain can mitigate backward signal's attenuation and we prove it by experiments. An orthonormal regularizer is introduced to replace traditional weight decay regularization~ _cite_ . Experiments show that there is _inline_eq_ gains for a N-layer network on CIFAR-N. However, as depth increases, \eg deeper than N layers, the non-orthogonal impact induced by BN, ReLU and gradients updating accumulates, which breaks the dynamic isometry~ _cite_ and makes learning unavailable. To neutralize this impact, we design a modulation mechanism based on the quasi-isometry assumption between two consecutive parametric layers. We show the quasi-isometry property with both mathematical analysis and experiments. With the modulation, a global scale factor can be applied on the magnitude of errors a little unscrupulously during the backward pass in a layer-wise fashion. Combined with orthonormality, experiments show that a plain CNN shown in Fig.~ _ref_ can be trained relatively well and match the performance of its residual counterpart. The contributions of this paper are summarized as follows. N) We demonstrate the necessity of applying BN and explain the potential reason which results in degradation problem in optimizing deep CNNs; N) A concise methodology equipped with orthonormality and modulation is proposed to provide more insights to understand learning dynamics of CNNs; N) Experiments and analysis exhibit interesting phenomenons and promising research directions.