In the field of computer vision and image recognition, deep convolutional neural networks (DCNNs) have been the primary model, owing to AlexNet _cite_ having had great success during the ImageNet competitions in N. DCNNs are thus becoming the de facto solution for image recognition tasks. The DCNN is a multi-layered neural network that has the same architecture as Neocognitron _cite_, inspired by biological human visual systems. The brain's vision center has a hierarchical mechanism that understands visual stimulus _cite_ . The DCNN uses a similar hierarchical structure to extract features by using stacks of ``convolution'' and ``spatial pooling'' operations. The distinctive feature of a DCNN is its automation of obtaining tack feature representations, which suits the given tasks. Whereas DCNNs provide significant performance with image recognition tasks, they require massive amounts of training data compared to conventional machine learning models. The deep network structure exhibits higher expressive power than shallow models, which have the same complexity _cite_ . Alternatively, most deep models have a large number of free parameters. Han et al. reported that deep neural networks require one-tenth of the number of free parameters training data needed to obtain the good generalization ability _cite_ . However, when the acquisition of a training dataset is difficult (e.g., medical imagery), the data will sometimes be insufficient. Generally, for learning approaches, the amount of training data has a strong effect on model performance. Deficient training data sometimes causes generalization problems such as overfittings. A conventional approach for overcoming data deficiency is transfer learning _cite_ . This is a learning technique that reutilizes knowledge gained from other learning tasks, called the `` source domain, '' to improve model performance in the desired task, called the `` target domain .'' In the case of transfer learning for an image classification task, the model will first be trained to classify the source domain. Then, it will be trained for the target domain. In the case of DCNNs, we expect feature extraction to be improved by reutilizing its feature extraction capability. Note that this paper distinguishes two common styles of transfer learning. One is ``fine-tuning, '' which retrains only the classification part while maintaining the feature extraction part. In other words, the fine-tuning style assumes that the feature extraction part has enough ability to represent input signals. Another is ``feature transfer, '' which retrains the entire DCNN, containing the feature extraction layers, to adopt the feature extraction part for target task. This paper focuses on the latter case of transfer learning. In most transfer learning approaches for image recognition tasks, massive natural image datasets, such as ImageNet _cite_, are used as the source domain _cite_ . The reason a natural image dataset is usually adopted is that of the availability of pre-trained models and their known performance. However, the appropriateness of utilizing a natural image dataset when the target domain greatly differs from the natural images is slightly questionable, because features of the source domain do not appear in the target domain. Azizpour et al. suggested that the possibility of knowledge transfer is affected by similarities between the source and target domains. They reported that it is preferable that transfer learning takes in similar data _cite_ . However, only a few studies have focused on model performance variation by changing source and target domains, and their scope of tasks was limited to object recognition. This paper proposes a two-stage feature transfer method that focuses on textural image recognition. By this method, the DCNN will successively be trained with natural and textural images as an initial state. Afterward, all of the DCNN, which includes not only classification part but also feature extraction part, will be trained again with the textural target domain. We will show that this type of successive and multi-domain feature transfer improves the generalization performance of the model and provides robustness with a decrease in the size of the training dataset. Moreover, we discuss the why feature transfer on DCNNs works so well. We visualize how feature representations of DCNNs come from different feature transfer processes and reveal that feature transfer improves feature representations of DCNNs, corresponding to both source domains. In our experiment, we apply two-stage feature transfer to a classification task of textural X-ray high resolution computed tomography (HRCT) images of diffuse lung diseases (DLDs) and show performance improvements.