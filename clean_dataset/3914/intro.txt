recognition has been one of the most extensively studied topics in computer vision. The importance of face recognition is closely related to its great potential in multimedia applications, \eg, photo album management in social networks, human machine interaction, and digital entertainment. With years of effort, significant progress has been achieved for face recognition. However, it remains a challenging task for multimedia applications, as observed in recent works~ _cite_ . In this paper, we handle the face recognition problem for matching internet face images appeared in social networks, which is one of the most common applications in multimedia circumstances. Recognizing the face images appeared in social networks is difficult, due to the reasons mainly from the following two perspectives. First, the face images uploaded to social networks are captured in real-world conditions; therefore faces in these images usually exhibit rich variations in pose, illumination, expression, and occlusion, as illustrated in Fig.~ _ref_ . Second, face recognition in social networks is a large-scale recognition problem due to the numerous face images of potentially large amount of users. The prediction accuracy of face recognition algorithms usually degrades dramatically with the increase of face identities. Accurate face recognition depends on high quality face representations. Good face representation should be discriminative to the change of face identify while remains robust to intra-personal variations. Conventional face representations are built on local descriptors, \eg, Local Binary Patterns (LBP) ~ _cite_, Local Phase Quantization (LPQ) ~ _cite_, Dual-Cross Patterns (DCP) ~ _cite_, and Binarised Statistical Image Features (BSIF) ~ _cite_ . However, the representation composed by local descriptors is too shallow to differentiate the complex nonlinear facial appearance variations. To handle this problem, recent works turn to Convolutional Neural Networks (CNNs) ~ _cite_ to automatically learn effective features that are robust to the nonlinear appearance variation of face images. However, the existing works of CNN on face recognition extract features from limited modalities, the complementary information contained in more modalities is not well studied. Inspired by the complementary information contained in multi-modalities and the recent progress of deep learning on various fields of computer vision, we present a novel face representation framework that adopts an ensemble of CNNs to leverage the multimodal information. The performance of the proposed multimodal system is optimized from two perspectives. First, the architecture for single CNN is elaborately designed and optimized with extensive experimentations. Second, a set of CNNs is designed to extract complementary information from multiple modalities, \ie, the holistic face image, the rendered frontal face image by ND model, and uniformly sampled face patches. Besides, we design different structures for different modalities, \ie, a complex structure is designed for the modality that contains the richest information while a simple structure is proposed for the modalities with less information. In this way, we strike a balance between recognition performance and efficiency. The capacity of each modality for face recognition is also compared and discussed. We term the proposed deep learning-based face representation scheme as Multimodal Deep Face Representation (MM-DFR), as illustrated in Fig.~ _ref_ . Under this framework, the face representation of one face image involves feature extraction using each of the designed CNNs. The extracted features are concatenated as the raw feature vector, whose dimension is compressed by a three-layer SAE. Extensive experiments on the Labeled Face in the Wild (LFW) ~ _cite_ and CASIA-WebFace databases~ _cite_ indicate that superior performance is achieved with the proposed MM-DFR framework. Besides, the influence of several implementation details, \eg, the usage strategies of ReLU nonlinearity, multiple modalities, aggressive data augmentation, multi-stage training, and LN normalization, is compared and discussed in the experimentation section. To the best of our knowledge, this is the first published approach that achieves higher than N \% recognition rate using a publicly available training set on the LFW database. The remainder of the paper is organized as follows: Section II briefly reviews related works for face recognition and deep learning. The proposed MM-DFR face representation scheme is illustrated in Section III. Face matching using MM-DFR is described in Section IV. Experimental results are presented in Section V, leading to conclusions in Section VI.