Deep learning has allowed to push performance considerably across a wide range of computer vision and machine learning tasks. However, almost always, deep learning requires large amounts of training data which we are lacking in many practical scenarios, e.g. it is impractical to annotate all the concepts that surround us, and have enough of those annotated samples to train a deep network. Therefore, training data generation has become a hot research topic~ _cite_ . Generative Adversarial Networks~ _cite_ are particularly appealing as they allow generating realistic and sharp images conditioned, for instance, on object categories~ _cite_ . However, they do not yet generate images of sufficient quality to train deep learning architectures as demonstrated by our experimental results. In this work, we are focusing on arguably the most extreme case of lacking data, namely zero-shot learning~ _cite_, where the task is to learn to classify when no labeled examples of certain classes are available during training. We argue that this scenario is a great testbed for evaluating the robustness and generalization of generative models. In particular, if the generator learns discriminative visual data with enough variation, the generated data should be useful for supervised learning. Hence, one contribution of our paper is a comparison of various existing GAN-models and another competing generative model, i.e. GMMN, for visual feature generation. In particular, we look into both zero-shot learning (ZSL) where the test time search space is restricted to unseen class labels and generalized zero-shot learning (GZSL) for being a more realistic scenario as at test time the classifier has to decide between both seen and unseen class labels. In this context, we propose a novel GAN-method--namely that generates features instead of images and is trained with a novel loss improving over alternative GAN-models. We summarize our contributions as follows. (N) We propose a novel conditional generative model~ that synthesizes CNN features of unseen classes by optimizing the Wasserstein distance regularized by a classification loss. (N) Across five datasets with varying granularity and sizes, we consistently improve upon the state of the art in both the ZSL and GZSL settings. We demonstrate a practical application for adversarial training and propose GZSL as a proxy task to evaluate the performance of generative models. (N) Our model is generalizable to different deep CNN features, e.g. extracted from GoogleNet or ResNet, and may use different class-level auxiliary information, e.g. sentence, attribute, and wordNvec embeddings.