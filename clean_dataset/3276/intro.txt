Images containing fences/occlusions occur in several situations such as photographing statues in museums, animals in a zoo etc. Image de-fencing involves the removal of fences or occlusions in images. De-fencing a single photo is strictly an image inpainting problem which uses data in the regions neighbouring fence pixels in the frame for filling-in occlusions. The works of _cite_ addressed the image inpainting problem wherein a portion of the image which is to be inpainted is specified by a mask manually. As shown in Fig. _ref_ (a), in the image de-fencing problem it is difficult to manually mark all fence pixels since they are numerous and spread over the entire image. The segmented binary fence mask obtained using the proposed algorithm is shown in Fig. _ref_ (b) . These masks are used in our work to aid in occlusion-aware optical flow computation and background image reconstruction. In Fig. _ref_ (c), we show the inpainted image corresponding to Fig. _ref_ (a) obtained using the method of _cite_ . The de-fenced image obtained using the proposed algorithm is shown in Fig. _ref_ (d) . As can be seen from Fig. _ref_ (c), image inpainting does not yield satisfactory results when the image contains fine textured regions which have to be filled-in. However, using a video panned across a fenced scene can lead to better results due to availability of additional information in the adjacent frames. Although, there has been significant progress in the area of lattice detection _cite_ and restoration of fenced images/videos _cite_, segmentation of fence or occlusion from a single image and de-fencing scenes containing dynamic elements are still challenging problems. Most of the existing works assume global motion between the frames and use images of static scene elements only _cite_ . Initial work related to image de-fencing has been reported by Liu et al. _cite_, wherein fence patterns are segmented via spatial regularity and the fence occlusions are filled-in using an inpainting algorithm _cite_ . Recent attempts for image de-fencing _cite_ use the parallax cue for fence pattern segmentation using multiple frames from a video. However, these works _cite_ constrain the scene elements to be static. Another drawback of _cite_ is that if the scene does not produce appreciable depth parallax fence segmentation is inaccurate. A very recent image de-fencing algorithm _cite_ exploits both color and motion cues for automatic fence segmentation from dynamic videos. The proposed algorithm for image de-fencing uses a video captured by panning a camera relative to the scene and requires the solution of three sub-problems. The first task is automatic segmentation of fence pixels in the frames of the captured video. Importantly, unlike existing works _cite_, we propose a machine learning algorithm to segment fences in a single image. We propose to use a pre-trained convolutional neural network (CNN) for fence texel joint detection to generate automatic scribbles which are fed to an image matting _cite_ technique to obtain the binary fence mask. Note that sample portions of images marked with yellow colored squares shown in Fig. _ref_ (a) are treated as fence texels in this work. To the best of our knowledge, we are the first to detect fence texels using a pre-trained CNN coupled with an SVM classifier. Secondly, we estimate the pixel correspondence between the reference frame and the additional frames using a modified optical flow algorithm which incorporates the knowledge of location of occlusions in the observations. It is to be noted that existing optical flow algorithms find the relative shift only between pixels visible in two frames. Accurate registration of the observations is critical in de-fencing the reference image since erroneous pixel matching would lead to incorrect data fusion from additional frames. The basic premise of our work is that image regions occluded by fence pixels in the reference frame are rendered visible in other frames of the captured video. Therefore, we propose an occlusion-aware optical flow method using fence pixels located in the first step of our image de-fencing pipeline to accurately estimate background pixel correspondences even at occluded image regions. Finally, we fuse the information from additional frames in order to uncover the occluded pixels in the reference frame using an optimization framework. Since natural images are sparse, we use the fast iterative shrinkage thresholding algorithm (FISTA) to solve the resulting ill-posed inverse problem assuming _inline_eq_ norm of the de-fenced image as the regularization prior.