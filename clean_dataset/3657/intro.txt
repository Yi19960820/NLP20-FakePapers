Traditional object classification tasks require the test classes to be identical or a subset of the training classes. However, the categories in the reality have a long-tailed distribution, which means that no classification model could cover all the categories in the real world. Targeting on extending conventional classification models to unseen classes, zero-shot learning (ZSL) _cite_ has attracted a lot of interests in the machine learning and computer vision communities. The current approaches formulate ZSL as a semantic alignment problem of image features and class semantic descriptions. In these formulations an image is represented with its global features. Despite good performances on coarse-grained datasets (e.g., Animal with Attribute dataset _cite_), the global features have limitations on fine-grained datasets since more local discriminative information is required to distinguish classes. As illustrated in Fig.~ _ref_, the global features only capture some holistic information, on the contrary, the region features capture more local information that is relevant to the class semantic descriptions. To this end, the global image representations may fail in fine-grained ZSL. On the one hand, the visual differences between the fine-grained classes are often subtle, using the global image representations fails to embody the discriminative differences of local regions. On the other hand, different local regions contain distinct discriminant information, the important regions contribute more to the final prediction. The global features could not represent their importance. When trying to recognize an image from unseen categories, humans tend to focus on the informative regions based on the key class semantic descriptions. Besides, humans achieve the semantic alignment by ruling out the irrelevant visual regions, and locating the most relevant ones in a gradual way. Motivated by the above observations and the attention mechanisms that can highlight important local information and neglect irrelevant information of an image, we propose a novel stacked attention-based network to integrate both the global and discriminative local features to represent an image via progressively allocating different weights to different local visual regions based on their relevances to the class semantic descriptions. As shown in Fig.~ _ref_, the proposed approach contains an image featurization part, an attention extraction part, and a visual-semantic matching part. For the image featurization part, we extract the local features that retain the crucial spatial information of an image for the subsequent attention part. It should be noted that the region features can also be compressed into a global one by concatenating or averaging all the local region features. The attention extraction part is the core of the proposed framework, which progressively allocates the importance weights to different visual regions based on their relevance to the class semantic features. The visual-semantic matching part is a two-layer neural network to embed both the class semantic features and the integrated visual features of both the global and local weighted visual features into a multi-class classification framework. In summary, the contributions of this work are three-fold: In the experiments, we evaluate the proposed S _inline_eq_ GA framework for fine-grained ZSL on two bird datasets: Caltech UCSD Birds-N (CUB) _cite_, and North America Birds (NABird) _cite_ . The experimental results show that our approach significantly outperforms the state-of-the-art methods with large margins on both zero-shot classification and retrieval tasks.