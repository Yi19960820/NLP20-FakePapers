The AlexNet _cite_ and various other deep convolutional neural network (CNN) models have demonstrated the state-of-the-art performance in computer vision tasks such as image classification _cite_, object detection _cite_, and pose estimation _cite_ . However, the top-performance CNN models generally employ very wide and deep architecture consisting of a numerous number of synapses and neurons _cite_ . Training and deploying such complex CNN models indeed incur large computation and storage cost, which limits the implementation of a CNN on a resource-limited device. To tackle the challenges, researchers have attempted techniques to accelerate the computation of CNN models. These techniques can be roughly divided into three types: network quantization _cite_, network pruning _cite_, and knowledge distillation (KD) _cite_ . Network quantization methods attempt to convert a pre-trained full-precision CNN model into a low-precision one _cite_ . Network pruning methods attempt to remove the redundant and insignificant connections (weights) _cite_ . On the other hand, KD methods aim to train a light-weight model with the knowledge transferred from a large model that is trained. For example, Hinton ~ _cite_ collects the outputs of the softmax layer (probability distribution) of a teacher network and use them as target objectives in training the student network. Despite its simplicity, KD demonstrates promising results in several classification tasks _cite_ . However, if we consider extracting the final probability distribution as the knowledge to transfer, its application can be limited to only the classification tasks with the softmax loss function. To avoid such problem, recent studies~ _cite_ proposed to exploit intermediate representations as sharable knowledge. Specifically, they use the outputs in the convolutional layers of a teacher network. As a high-dimensional feature distribution, the knowledge in feature maps consists of the feature values and their spatial correlations, which are requisite in various deep CNN models. For transferring the shareable knowledge, they directly align the values of intermediate representations of the teacher and student network. Admittedly, it works for the transferring of the probability distribution. However, for the intermediate representation, such direct aligning cannot effectively transfer the latent spatial correlation. Given the importance of such information in computer vision tasks, the direct aligning remains as a critical limitation. It also ignores the distinction between the distribution spaces of the teacher and the student networks since their topological differences would make them generalize with the different distributions. In this paper, we aim to address the aforementioned challenges. We propose a new framework that is based on a knowledge transfer adversarial network (KTAN) . The knowledge transfer (KT) process, which is a general class of the KD method, is divided into two parts: N) knowledge extraction and N) knowledge learning processes. In the first knowledge extraction step, since the deeper convolutional layer extracts more complicated and high dimensional features, we choose the feature maps of teacher's last convolutional layer as the shared knowledge which contains pixel-level as well as spatial information. Most, if not all, of CNN architectures contain the convolutional layers, which enable our framework applicable to the networks that have no softmax layer and thus cannot use the existing KD method. In the second knowledge learning step, we adopt the concept of the Generative Adversarial Networks (GAN) and propose to employ three networks in the knowledge transfer adversarial framework: N) a teacher generative network (TGN) ; N) a student generative network (SGN) ; and N) a discriminator network (DN) . The TGN observes a large network model and generates the teacher feature map (TFM) as shared knowledge. The SGN is a light-weight network model. The TGN and SGN are firstly trained on the ground truth for initialization, respectively. Considering different sizes and channels between TFM and SFM, we present a Teacher-to-Student layer in TGN to match the size of the student feature map (SFM) . After well trained, we exploit the MSE loss in SGN to learn the similar SFM with TFM. In the adversarial training stage, the optimization target of DN tries to understand the spatial information in the shared knowledge through distinguishing whether an output came from TGN rather than SGN. Differently, SGN attempts to learn the spatial information through maximizing the probability of being classified as SFM by the discriminator. Besides, the entire student network, including convolutional layers and fully connected layers, is also optimized by the original task with ground truth. The illustration of our framework is presented in Figure N. In the end, we propose a knowledge transfer adversarial teacher-student framework for various student networks. In addition, because of the utilization of the feature maps shared knowledge, our framework is suitable for various computer vision tasks, such as classification and detection. The evaluations on image classification and object detection benchmarks demonstrate that our method certainly improves the performance of different student networks. To summarize, the contributions of this work are as follows: