In this paper we describe a solution to our entry for the emotion recognition challenge EmotiW N. We propose an ensemble of several models, which capture spatial and audio features from videos. Spatial features are captured by convolutional neural networks, pretrained on large face recognition datasets. We show that usage of strong industry-level face recognition networks increases the accuracy of emotion recognition. Using our ensemble we improve on the previous best result on the test set by about N~ \%, achieving a N \% classification accuracy without any use of visual temporal information.