Localizing humans in images is key for applications such as video surveillance, avoiding pedestrian-to-vehicle collisions, collecting statistics of players or athletes in sport videos, etc. Developing a reliable vision-based pedestrian detector is a very challenging task with more than a decade of history by now. As a result, a plethora of features, models, and learning algorithms, have been proposed to develop the pedestrian classifiers which are at the core of pedestrian detectors _cite_ . The research for boosting the accuracy of pedestrian classifiers has followed different lines. Some authors have researched image descriptors well-suited for pedestrians ({\eg}, HOG _cite_, HOG + LBP _cite_, HOG + CSS + HOF _cite_, OppHOG _cite_, Haar + EOH _cite_, Integral Channels _cite_, Macrofeatures _cite_), others have researched different image modalities ({\eg}, appearance + motion _cite_, appearance + depth + motion _cite_), others have focused on the pedestrian model ({\eg}, deformable multi-component part-based models _cite_, multi-resolution _cite_), others on the classification architecture ({\eg}, HOG-SVM/LRF-MLP cascades _cite_, Haar + EOH-AdaBoost cascades with meta-stages _cite_, random forest of HOG + LBP-SVMs _cite_), and others in the process of collecting good samples for training ({\eg}, generative approach _cite_, active learning _cite_, virtual-world data with domain adaptation _cite_) . The outcome of each of the above mentioned proposals is a pedestrian classifier, termed here as {\em base classifier}, which determines if a given image window contains a pedestrian or background. In practice, such classifiers provide a relatively high response at neighbor windows overlapping a pedestrian, while the responses around potential false positives are expected to be lower. Note that, in fact, non-maximum suppression (NMS) is usually performed as last detection stage in order to reduce multiple detections arising from the same pedestrian to a single one. An analogous reasoning applies for image sequences. If there is a pedestrian located within a frame, the same pedestrian is expected to appear close to the same location in neighbor frames. Therefore, such a location has chances of receiving high classification scores during several frames, while false positives are expected to be more spurious. In fact, this may allow removing such undesired spurious by the use of a tracker. In this paper we propose to exploit such expected {\em response correlations} for improving the accuracy of the classification stage itself. In other words, instead of only exploiting spatiotemporal coherence by means of general post-classification stages like NMS and tracking, we propose to add such a type of reasoning in the classification stage itself as well. In particular, we propose to use a two-stage classification strategy which not only rely on the image descriptors required by the base classifiers, but also on the response of the own base classifiers in a given spatiotemporal neighborhood. More specifically, we train pedestrian classifiers using a stacked sequential learning (SSL) paradigm _cite_ . Temporal SSL involves the analysis of window volumes. The different types of temporal volumes can be potentially useful for different applications depending on the motion of the camera and the targets of interest, as well as the working frame rate and the targets size. In this paper, we are specially interested in on-board pedestrian detection within urban scenarios. Therefore, camera and targets are in movement. Accordingly, in this paper we test our SSL approach for a fixed neighborhood ({\ie}, fixed spatial window coordinates across frames) and for an scheme relying on an ego-motion compensation approximation ({\ie}, varying spatial window coordinates across frames) . Moreover, in order to assess the dependency of the results with respect to the frame rate, we acquired our own pedestrian dataset at Nfps by normal driving in an urban scenario. This new dataset is used as main guide for our experiments, but we also complement our study with other challenging dataset publicly available: Caltech. In this paper we start by using a competitive baseline in pedestrian detection _cite_, namely a holistic base classifier based on HOG + LBP features and linear SVM. Note that HOG/linear-SVM is the core of more sophisticated pedestrian detectors as the popular deformable part-based model (DPM) _cite_ . Moreover, HOG with LBP are also used as base descriptors of multi-modal multi-view pedestrian models _cite_, and HOG + LBP/linear-SVM has been used for classifiers with occlusion handling _cite_, as well as for acting as node experts in random forest ensembles _cite_ . In addition, it has recently been shown that HOG + LBP/linear-SVM approaches are well suited for domain adaptation _cite_ . Altogether, we think that HOG + LBP/linear-SVM is a proper baseline to start assessing our proposal. Moreover we have extended this baseline with the HOF _cite_ motion descriptor that complements the appearance and texture features of the baseline. Overall, the obtained results show that our spatiotemporal SSL proposal boosts detection accuracy significantly. Especially, when the pedestrians are close to the camera, {\ie} in the most critical situations. Therefore, encouraging to augment the study for other pedestrian base classifiers as well as other object categories. The rest of the paper is organized as follows. In we review some works related to our proposal. Section _ref_ briefly introduces the SSL paradigm. In we develop our proposal. Section _ref_ presents the experiments carried out to assess our spatiotemporal SSL, and discuss the obtained results. Finally, draws our main conclusions.