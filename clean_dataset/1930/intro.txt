In recent years, deep learning has revolutionized many computer vision areas due to high accuracy for a wide variety of classification tasks. Although artificial neural networks have been used for visual recognition tasks since the Ns~ _cite_, recent algorithms have been successful at training large networks efficiently~ _cite_ . Given the huge amount of data that has become available, recent advances in computing have led to the emergence of deep neural nets. Even though deep learning techniques become the state-of-the-art solutions for various computer vision tasks, the requirement of a powerful GPU has made their wide deployment on general purpose PCs and mobile devices impractical. Moreover, from the `very' deep VGG-Net~ _cite_ and GoogLeNet~ _cite_ to the `extremely' deep Microsoft ResNet~ _cite_, the competition for higher accuracy with ever larger depths is strong, rendering real-time performance on mobile devices even more out of reach. In this paper, we explore ways to greatly prune very deep networks while maintaining or even improving on their classification accuracy. Our motivation stems from the current popular practice where, rather than train a deep net from scratch using all the available data, algorithm developers usually adopt a general network model and fine-tune it using a smaller dataset for the particular task. Therefore, there is a chance that some structures from the pre-trained model are not fully used for the current purpose. Our premise is that less useful structures (together with possible redundancies) could be pruned away in order to increase computational efficiency. Deep convolutional networks are generally considered to be composed of two components: the convolutional (conv) layers (alternated with activation and pooling layers) as feature extractors and fully connected (FC) layers as final classifiers . Deep nets outperform many traditional computer vision algorithms mainly because, given enough training data, the first component does well in learning the compositionality of the real world (by constructing very complicated features based on primitive ones) . More often than not, such features learned for a particular task are superior to handcrafted features designed with limited domain knowledge. The second component, FC layers, is essentially similar to logistic regression classifiers, which model the log-odds with a linear function. In this paper, we increase efficiency for each of the two components. We first investigate the firing patterns of last conv layer neurons through Fisher's Linear Discriminant Analysis (LDA) ~ _cite_ and discover that those neuron activations are highly decorrelated for each class, which permits discarding a large number of less informative neuron dimensions without loss of information. As a result, the network complexity can be significantly reduced, which not only makes feature extraction more efficient, but also simplifies classification. In the second component, we analyze possible alternatives to the expensive FC layers for the final classification. Instead of the FC layers, which model the log-odds based on linear functions, we explore multiple alternatives such as the Bayesian classifier and SVMs (with linear and RBF kernels) . Although our approach is generally applicable to a wide range of biometrics recognition problems, we use facial gender classification as an example. Our experimental results show that when using the reduced CNN features previously extracted, both a Bayesian and SVM classifiers are able to achieve comparably high performance. They can even outperform using the original net when the dataset is particularly challenging (e.g. partial occlusions, large view changes, complex backgrounds, blurs exist) . Also, the combinations of LDA-Pruned CNN nets and the Bayesian/SVM classifiers take far less space (only a few megabytes) than the original net (over N MB) while having a N times faster recognition speed. In addition, we have analyzed the relationship of accuracy change and parameters pruned away, and have compared our approach to a state of the art pruning method~ _cite_ as well as two smaller nets (i.e. AlexNet~ _cite_ and~ _cite_) . According to the results, our Fisher LDA based pruning enjoys a lower accuracy loss than~ _cite_, especially when the conv layers' pruning rate is high (say above N \%) . Furthermore, unlike~ _cite_, our pruning approach can directly lead to space and time savings. The comparison with~ _cite_ justifies the superiority of pruning a deeper net over training one of smaller depth. The remainder of the paper is structured as follows: the relevant literature is reviewed in Section~ _ref_ . In Section~ _ref_, our light weight deep networks along with alternative classifiers are introduced. Section~ _ref_ describes our experimental validation and compares our modified nets to their originals as well as other pruned structures in terms of accuracy and efficiency. In Section~ _ref_, our contribution and possible future directions are discussed. Section~ _ref_ concludes the paper.