With the impressive capability to capture visual content, deep convolutional neural networks (CNN) have demonstrated promising performance in various vision-based applications, such as classification, recognition, and object detection. However, due to the intrinsic structure design of CNN, for images with complex content, it achieves limited capability on invariance to translation, rotation, and re-sizing changes, which is strongly emphasized in the scenario of content-based image retrieval. In this paper, to address this problem, we proposed a new kernelized deep convolutional neural network. We first discuss our motivation by an experimental study to demonstrate the sensitivity of the global CNN feature to the basic geometric transformations. Then, we propose to represent visual content with approximate invariance to the above geometric transformations from a kernelized perspective. We extract CNN features on the detected object-like patches and aggregate these patch-level CNN features to form a vectorial representation with the Fisher vector model. The effectiveness of our proposed algorithm is demonstrated on image search application with three benchmark datasets.