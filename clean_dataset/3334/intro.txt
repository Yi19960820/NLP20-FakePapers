improvements in satellite sensors have enabled us to capture massive amount of remote sensing data with high spatial resolution, as well as rich spectral information. Generation of maps from such a huge amount of satellite images and updating them automatically have been long standing problems, as they are crucial for a wide range of applications in domains such as agriculture, navigation, environmental management, urban monitoring, and mapping. In this context, having a strong classification system, which performs a high-quality, pixel-wise, large-scale classification is the most essential step. The task of dense labeling or semantic segmentation consists in assigning a thematic label to every image pixel. In the last decade, with the great advances in deep neural networks, notably convolutional neural networks (CNNs), it has been possible to obtain accurate segmentations _cite_ . Among the CNN-based approaches, U-net architecture _cite_ has gained a particular attention due to its success in various segmentation problems in different domains (e.g, . medical imaging and remote sensing) . This network architecture consists of a contracting path that captures the context and a symmetric expanding path, enabling accurate localization. In addition to traditional encoder-decoder layers, U-net architecture uses skip connections, which combine low level features with the high level ones in the expanding path to increase precision of localization. Variants of this network _cite_, (e.g., U-net, including VGG-N _cite_ encoder and corresponding decoder) have been applied to remote sensing images and have shown a remarkable performance. Although it has been shown that CNNs can generate fine-grained segmentations from remote sensing images, most of the works validate their methodology on a small dataset collected from only one city, where some part is used as training data and the rest is used for validation. Working only on this kind of dataset prevents researches from exploring how well their classifier generalizes to different areas in the world, since the training as well as the validation data come from the same distribution. The recently released Inria Aerial Image Labeling Dataset _cite_ contains training and test images from completely different cities, but it provides annotations for only building and non-building classes. Another major drawback of the recently proposed methodologies is their assumption that the whole training data are available in the beginning, which is not the case in real world remote sensing applications, as new images are collected from all over the world everyday. Besides, having a large amount of standard, unique label map is almost impossible, because the label maps retrieved from different sources usually have distinct classes. In addition, it is not always possible to store enormous volume of training data. For the reasons described above, designing an incremental learning methodology, which can learn from the new training data while retaining performance for the old classes without accessing the entire previous training data is crucial. Although a good solution for this problem is necessary to generate high-quality maps from satellite images that cover a large geographic extent, yet it has remained unexplored in remote sensing community. Rather than assuming that we have all the training data initially, we aim to design an incremental learning methodology. Let us explain an example real-world problem (see Fig.~ _ref_), where we are provided images as well as label maps for building and high vegetation classes from several cities in Austria in the beginning. Later on, we are given other training data, having label maps for water class, collected from different areas in Germany. Finally, we receive new satellite images and their annotations for road and railway classes from certain cities in France. Every time when the new data come, we assume that only a small portion of the previous data is stored. In such a scenario, our goal is to add segmentation capabilities for the new classes to the previously trained network without forgetting the already learned information so that maps for all the learned classes could be generated by the network. In addition to the described problem, because labeling satellite images, covering a large geographic area requires a lot of manual work, it is quite common that annotations of different classes for the same images are provided sequentially in time. In this kind of situation, whenever the new label maps are obtained, training a new classifier from scratch is not a feasible solution. The limitations pointed out in this section motivated us to design an incremental learning methodology. In this section, we summarize the proposed methodologies related to incremental learning problem. The biggest challenge in incremental learning problem is that when the new tasks are intended to be added to a classification system, performance of the system for the previously learned tasks degrades abrubtly, which is referred as "catastrophic forgetting" in the literature _cite_ . Incremental learning has been a historically important problem. Even before neural networks have become popular, researches had been studying this issue _cite_ . More recently, various convolutional neural network based methodologies have been proposed. There have been attempts, which change architecture of the neural network as the new classes are added. In _cite_, the network is trained incrementally by sharing early layers and splitting later ones by adding new convolutional kernels. In _cite_, a tree-structured model, which grows hierarchically, is proposed. In _cite_ and _cite_, described approaches grow the network horizontally. The methodology described in _cite_ tries to solve the problem of determining number of filters to be added to each layer by reinforcement learning. The major weakness of these approaches is that since the network grows during training, the number of parameters increases drastically as the new tasks are added to the network. The methodologies proposed in _cite_ use not only the new training data but also a small portion of the old data. To determine the most important samples for the previous classes, the approach in _cite_ trains a Support Vector Machine (SVM) from the previous training data. The support vectors of the SVM correspond to the samples to be used for the former classes, while the network is adapted to the new training data. In _cite_, instead of using the old data directly, fake previous data are generated by generative adversarial networks (GANs) . It has been proven that many configurations of the network parameters may produce the same result _cite_ . Inspired by this idea, several works, which try to find a configuration of the network parameters that represents both the previous and the new training data well, have been published. The key idea behind these approaches is to find the important neurons for the old tasks and prevent these neurons from changing greatly or completely when the new tasks are added to the network. The proposed methodology explained in _cite_ is one of the approaches that falls into this category. In the loss function defined in the paper, there is an elastic weight consolidation (EWC) term, which is multiplication of importance value of parameters for the old tasks and quadratic penalty on difference between parameters of the previous and the updated networks. Importance value of the parameters is measured by the estimated diagonal Fisher information matrix. The same work has been extended in _cite_ by rotating the Fisher matrix. _cite_ is also quite similar to _cite_, but the elastic weight consolidation is performed in online fashion. In _cite_, importance of each neuron is determined by averaging gradients of the network output with respect to parameters of the neuron. In _cite_, in the training stage, features from the previous data are reconstructed in unsupervised manner using autoencoders. The features are then used to preserve information, which the old tasks rely on when the new tasks are added. _cite_ is another extension of _cite_, where trained models for all the tasks are combined via incremental moment matching (IMM) . The proposed approaches in _cite_ and _cite_ try to learn a mask, which marks important neurons for the old tasks. When the new tasks need to be added, only the masked out neurons are updated. In _cite_, paths through the network, which represent a subset of parameters are determined by using tournament selection genetic algorithm. During the training stage, only the neurons that are located along the paths are updated. When the data come sequentially, the works explained in _cite_ optimize parameters of the network by updating the posterior approximation by the Bayesian inference based methods. Distilling the knowledge approach proposed in _cite_, which enables to transfer the knowledge from a network or an assembly of several networks to a smaller network has inspired several works on incremental learning. The proposed methods in _cite_ facilitate a similar distillation loss described in _cite_ to maintain performance on the previous tasks. The proposed approach in _cite_ uses a distillation loss function, which also uses samples for the previous classes in addition to samples for the new classes. Another knowledge distillation based approach has been proposed in _cite_ . They deal with incremental object detection and classification tasks at the same time. Although the incremental learning problem has been explored in depth in the literature, none of the works described in this section studies incremental learning for dense labeling. We propose a novel incremental learning methodology for semantic segmentation problem, where the network learns segmenting new classes without deteriorating performance for the previously learned classes, even when the entire previous training data are not stored . We deal with two common real-world problems, in which the former is the situation of retrieving stream of training data, where at each time step, the data contain satellite images collected from different locations in the world and annotations for separate classes, the latter is the case, where label maps for the same geographic area are provided sequentially. To investigate how our methodology performs on the first problem, we test our approach on the Luxcarta dataset, consisting of the satellite images captured over different cities in France and Austria. For the second problem, we conduct experiments on the Vaihingen and the Potsdam benchmark datasets provided by the ISPRS _cite_ . The first problem is much more challenging, as the satellite images have high color variations and visual feature differences. Besides, for the first problem, by following a similar strategy described in _cite_, we test the trained models on the data collected from completely different geograhic areas than the ones we use during training. The benchmark dataset presented in _cite_ enables to study how well the trained models generalize to new cities for only building class. Rather than doing a binary classification, we investigate how well the trained models perform on segmenting completely different geographic extents for multiple classes. We provide rich experimental results for both problems by comparing our methodology with the ones explained in Sec.~ _ref_ . Our experimental results prove that by training only one network, it is possible to learn new classes without catastrophically forgetting the previous classes. To the best of our knowledge, this is the first work, which proposes a solution for the incremental semantic segmentation of remote sensing data.