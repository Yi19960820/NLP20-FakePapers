Automated segmentation of medical images is challenging because of the large shape and size variations of anatomy between patients. Furthermore, low contrast to surrounding tissues can make automated segmentation difficult _cite_ . Recent advantages in this field have mainly been due to the application of deep learning based methods that allow the efficient learning of features directly from the imaging data. Especially, the development of fully convolutional neural networks (FCN) _cite_ has further improved the state-of-the-art in semantic segmentation of medical images. In this article, we describe how FCNs have been derived from CNNs and how to utilize ND FCNs that can segment volumetric medical images with high accuracy and robustness. Many of the recent advances in computer visions are due to the efficient application of convolutional neural networks (CNN) on graphics processing units (GPUs) . GPU acceleration has significantly sped up computations, allowing the training of very deep and complex models on large datasets. For example, Krizhevsky et al. _cite_ nearly halved the error rate on the ImageNet challenge dataset from one year to the next by training a deep CNN on two GPU cards on over one million images. CNNs are effective because they can learn hierarchical feature representations of the image in a purely data-driven manner. This means that features which are good for classification are learned from the images just given a supervisory signal that defines the desired classification output. This so-called ``supervised learning'' has been recently applied to many fields of science, including biomedical and radiological imaging _cite_, and significantly advanced the state-of-the-art _cite_ . Typically, a CNN consists of several layers of convolutional, pooling, and fully-connected (or densely connected) neural network layers _cite_ . The convolutional layers make use of spatial correlation in the input images by sharing the filter kernel weights for the computation of each feature map. Pooling layers allow reducing the dimensions of each input feature map while preserving the most relevant feature responses. Commonly used pooling includes max-or average-pooling. Max-pooling can also add some invariance to local shifting of the objects in the input image. The outputs of each CNN layer are typically fed to non-linear activation functions (often rectified linear units (ReLUs) _cite_) . The use of non-linear activation functions allows us to model very complex mappings between the input image and the desired outputs. Figure _ref_ shows a schematic overview of a typical CNN architecture that produces a per-image prediction by using a softmax output for multi-class classification. This type of architecture has been successfully applied to many medical imaging tasks. A few examples in radiology are anatomy classification _cite_, false-positives reduction for computer-aided detection of lymph nodes or colonic polyps _cite_, the detection of pulmonary nodules _cite_, and the detection of pulmonary embolisms _cite_ . CNNs have also been successfully applied to the classification of endoscopic video sequences, e.g. in colonoscopy _cite_ or laparoscopic surgery _cite_ . One downside of CNNs is that the spatial information of the image is lost when the convolutional features are fed into the final fully connected layers of the network. However, spatial information is especially important for semantic segmentation tasks. Hence, the fully convolutional network (FCN) was proposed by Long et al. _cite_ to overcome this limitation. In FCNs, the final densely connected layers of the CNN are replaced by transposed convolutional layers in order to apply a learned up-sampling to the low-resolution feature maps within the network. This operation can recover the original spatial dimensions of the input image while performing semantic segmentation at the same time. Similar network structures have been successfully applied to semantic segmentation tasks in medical imaging _cite_ and to the segmentation of biomedical images such as histology slides _cite_ . Extensions to ND biomedical imaging data from modalities such as confocal microscopy _cite_ or magnetic resonance imaging (MRI) have been proposed _cite_ . In a typical FCN architecture, skip connections can be utilized to connect different levels of the network in order to preserve image features that are ``closer'' to the original image. This helps the network to achieve a more detailed segmentation result and can simplify or speed up training _cite_ . The typical setup of an FCN is illustrated in Fig. _ref_ for the semantic segmentation of CT image slices. Semantic segmentation of CT images has been an active area of research over the years. Classical approaches for multi-organ segmentation range from statistical shape models _cite_ to techniques that employ image registration. Many methods include some form of multi-atlas label fusion _cite_ which has been widely applied in clinical research and practice. Furthermore, approaches that combine techniques from multi-atlas registration and machine learning have been proposed _cite_ . However, the difficulties of modeling the complex shape variations between patients, especially for abdominal organs, have made it difficult for registration-based methods to perform adequately for very non-rigid organs _cite_ . Today, many successful deep learning methods from computer vision are being adapted to segmentation tasks in medical imaging. Recent examples include _cite_ and many others. Most of these methods are based on ND and ND variants of FCNs _cite_ that allow the extraction of features that are useful for image segmentation directly from the imaging data. This is crucial for the success of deep learning _cite_ and avoids the need for ``hand-crafting'' features suitable for detection of individual organs.