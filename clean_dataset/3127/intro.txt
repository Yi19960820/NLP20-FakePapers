Face attributes describe the characteristics observed from a face image. They were first introduced by ~ as mid-level features for face verification~ _cite_ and since then have attracted much attention. The last few years have witnessed their successful applications in hashing~ _cite_, face retrieval~ _cite_, and one-shot face recognition~ _cite_ . Recently, researchers have begun to investigate the possibility of synthesizing face images based on face attributes~ _cite_ . Despite their wide applications, face attribute recognition is not an easy task. One reason is that recognizing different face attributes may require attentions to different regions of the face~ _cite_ . For example, local attributes like Mustache could be recognized by just checking the region containing the mouth. Remaining face region does not provide useful information and may even hamper this particular attribute recognition. However, recognizing global attributes like Pale Skin may require information from the whole face region. Most current research studies do not pay special attention to this problem. They either detect facial landmarks and extract hand-crafted features from patches around them~ _cite_ or train a deep network to classify the attributes by taking a whole face as input~ _cite_ . In this paper, we propose a learning-based method that dynamically selects different face regions for unaligned face attribute prediction. It integrates two networks using a cascade: a face region localization (FRL) network followed by an attribute classification network. The localization network detects face areas specific to attributes, especially those that have local spatial support. The classification network selectively leverages information from these face regions to make the final prediction. For accurate face region detection, our localization network is constructed under a multi-task learning framework. The lower layers which are used to extract low level features are shared by all the tasks while the high-level semantics are learned separately. Moreover, a global average pooling is applied to force the network to learn location-sensitive information~ _cite_ . Although the network is trained in a weakly-supervised manner with attribute labels only, the detected face regions are consistent with what one may expect. As a result, face alignment algorithms which are usually sensitive to occlusion, variations of pose and illumination are not needed. For each face region (also called a part) detected by our localization network, we train a separate attribute classification network, called a part-based subnet. The localized face parts may not contain enough contextual information for predicting global attributes. Thus, a whole-image-based subnet is also trained. To combine the information from the part-based and whole-image-based subnets, a two-layer fully-connected classifier is built on top of the output attribute scores. The first layer is used to select the relevant subnet for predicting each attribute, while the second layer is designed to model the rich attribute relations. The integrated system is called the parts and whole (PaW) network. Since the face region localization network is supervised by attribute labels, it is appealing to adapt its weights to initialize the subnets in PaW. However, features from the localization network, which are mainly designed for localization purpose, are generally not very discriminative for attribute classification. To this end, a multi-net learning method is proposed. It utilizes a network with enhanced attribute classification capability to train the localization network to find a more discriminative solution. A naive implementation of the PaW network is problematic since the number of total parameters increases linearly with the number of attributes, and the subnet adapted from the FRL network is not very compact. To jointly train the PaW network end-to-end, a hint-based model compression technique is further proposed. This not only leads to a compact model with only _inline_eq_ parameters, but also reduces the training time significantly. We applied the proposed method to CelebA dataset~ _cite_ . With no use of alignment information, our method achieves an accuracy of N \%, reducing the classification error by a significant margin of N \% compared with state-of-the-art~ _cite_ . Moreover, our designed model could select the most relevant face region for predicting each face attribute. To summarize, the contributions of this paper are listed below: