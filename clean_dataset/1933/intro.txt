Object tracking is one of the first and most fundamental problems that has been addressed in computer vision. While it has attracted the interest of many researchers over several decades of computer vision, it is far from being solved~ _cite_ . The task is hard for many reasons. Difficulties could come from severe changes in object appearance, presence of background clutter and occlusions that might take place in the video. The only ground-truth knowledge given to the tracker is the bounding box of the object in the first frame. Thus, without knowing in advance the properties of the object being tracked, the tracking algorithm must learn them on the fly. It must adapt correctly and make sure it does not jump toward other objects in the background. That is why the possibility of drifting to the background poses on of the main challenges in tracking. Our proposed model, at the conceptual level, is composed of a large group of different tracking parts, functioning like a society, each with different roles and powers over the final decisions. They learn from each other using certain co-occurrence rules and are monitored according to their reliability. The way they function together gives them robustness. From a structural point of view, they are all classifiers within a large deep neural network structure, composed of two pathways, namely the FilterParts and the ConvNetPart pathways (see Figure~ _ref_) . While the first insures robustness through the co-occurrence of a large number of smaller tracker parts, the second pathway insures the ability to adapt to subtle object changes. The ConvNetPart is fully trained online, end-to-end, and uses as ground-truth high confidence tracker responses that are decided together with the whole society of parts. We will refer to the frames of high confident tracker responses as Highly Confident Frames (HCFs) . We provide more details in Section~ _ref_ . Using as ground-truth only a small set of high precision points is also related to the recent work on unsupervised object discovery in video~ _cite_ . Our approach is based on two key insights. One is the organization of the whole tracker into a large group of different types of classifiers, simpler and more complex, at multiple scales and with different levels of depth, as part of a larger neural network structure, that make decisions together based on mutual agreements. The second idea is the usage of co-occurrence constraints as basis for ensuring robustness, both for online training of the overall tracker, as well as for frame by frame inference. \noindent Relation to prior work: Existing trackers in the literature differ in terms of type of target region, appearance model, mathematical formulation and optimization. Objects can be represented by boxes, ellipses~ _cite_, superpixels~ _cite_ or blobs~ _cite_ . The appearance model can be described as one feature set over the region or as an array of features, one for each part of the target~ _cite_ . In recent years, trackers based on discriminative correlation filters (DCF), such as MOSSE~ _cite_ and KCF~ _cite_, achieved the best results on public benchmarks. Newer models like Staple~ _cite_, CCOT~ _cite_ and ECO~ _cite_ provide consistent improvements by adding to the DCF model different components, such as multi-channel feature maps and robust scale estimation~ _cite_ . CCOT, for instance, proposes to learn continuous convolution parameters by optimizing a function that results from transforming the original feature space into a continuous one and applying onto it the continuous convolutions. While learning the parameters continuously, provides adaptability to the tracker, overfitting to noise and drifting could pose a threat. To reduce overfitting, ECO comes with a generative model over training samples. Nevertheless, most recent tracking approaches still suffer from overfitting to background noise, which causes tracker failure. A common approach for top trackers in the recent literature is to model object features with deep convolutional networks (CNNs) . To address the issue of robustness against background noise in the case of online training of CNNs, the TCNN~ _cite_ algorithm, for example, maintains stability of appearance through a tree structure of CNNs. MLDF~ _cite_ uses discriminative multi-level deep features between foreground and background together with a Scale Prediction Network. Another approach, MDNET~ _cite_ is used as starting point for many CNN trackers. For instance, SSAT~ _cite_ uses segmentation to properly fit the bounding box and builds a separate model to detect whether the target in the frame is occluded or not. It uses this to consider frames for training the shape segmentation model. Other line of object tracking research is the development of part-based models, which are more resistant to appearance changes and occlusions. Their multi-part nature gives them robustness against noisy appearance changes in the video. In recent benchmarks however, they did not obtain the top results. For instance, in VOTN~ _cite_ challenge, while the number of part-based trackers, such as DPCF~ _cite_, CMT~ _cite_, DPT _cite_, BDF~ _cite_, was relatively high (N \%), the best one of the group, SHCT~ _cite_, is on the Nth place overall. SHCT~ _cite_ is a complex system using a graph structure of the object that models higher order dependencies between object parts, over time. As it is the case with deep networks, we believe complex systems are prone to overfitting to background noise without a high precision way of selecting their unsupervised online training frames. Our proposed model combines the best of two worlds. On one hand it uses a powerful deep convolutional network trained on high confidence frames, in order to learn features that better capture and adapt to object appearance changes. On the other hand, it uses the power of a large group of simpler classifiers that are learned, monitored, added and replaced based on co-occurrence constraints. Our approach is validated by the very low failure rate of our tracker, relative to the competition on the VOTN and VOTN benchmarks. \noindent Our main contributions: N) Our first contribution is the design of a tracker as a dual-pathway network, with FilterParts and ConvNetPart pathways working in complementary ways within a robust society of tracking parts. FilterParts is more robust to background noise and uses many different and relatively simple trackers learned on top of deep feature activation maps. ConvNetPart is better capable to learn object appearance and adapt to its changes. It employs a deep convolutional network that is learned end to end during tracking using unsupervised high confidence frames for ground-truth. N) Our second contribution is that every decision made for learning and inference of the tracker is based on robust co-occurrence constraints. Through co-occurrences over time we learn which FilterParts classifiers are reliable or not. Thus we can change their roles and add new ones. Also, through co-occurrences between the vote maps of the two pathways, we decide which frames to choose for training the ConvNetPart path along the way. Last but not least, through co-occurrences we decide the next object center by creating a combined vote map from all reliable parts. N) Our third contribution addresses a theoretical point, in Section~ _ref_ . We show that the efficient closed-form formulation for learning object parts simultaneously in a one sample vs. all fashion is equivalent to the more traditional, but less efficient, balanced one vs. all formulation.