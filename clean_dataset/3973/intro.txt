sign detection has been a traditional problem for intelligent vehicles, especially as a preceding step for traffic sign recognition which provides useful information such as directions and alerts for autonomous driving or driver assistance systems. Recently, traffic sign detection has received another attention from navigation systems for intelligent vehicles, where traffic signs can be used as distinct landmarks for mapping and localization. Different from natural landmarks such as corner points or edges, traffic signs have standard appearance such as shapes, colors, and patterns defined by strict regulations. This forms a primary reason that traffic signs are a preferable choice as landmarks for high-definition map reconstruction, as it allows efficient and robust landmark detection and matching under various conditions. To reconstruct detected traffic signs to a ND map, one should have point-wise correspondences of boundary corners of the signs across multiple frames, and then compute the ND coordinates of the boundary corners by triangulation using the camera pose and the internal parameters of the camera (see _cite_ for details of the ND mapping procedure) . For accurate triangulation of ND positions, it is required to estimate the boundary of signs with pixel-level accuracy. However, previous traffic sign detection systems do not meet this requirement as they only estimate the bounding box of a traffic sign. Pixel-wise prediction methods such as semantic image segmentation, which have been applied successfully for road scenes~ _cite_, can be an alternative for boundary estimation. However, it requires time-consuming algorithms that can severely degrade the performance of real-time systems. To overcome these limitations, we propose a traffic sign detection system where the position and precise boundary of traffic signs are predicted simultaneously using a single convolutional neural network (CNN) . Our novel object detection network is based on the recent advances in CNN-based object detection for object bounding box prediction~ _cite_, but tailored to predict the ND poses and shape labels of planar targets. The ND pose of a planar target can be encoded as an N-dimensional vector, \eg the coordinates of four vertices, and it can be accurately predicted by CNN which simultaneously predicts the score of each shape label. Using the predicted ND poses and shape labels, the boundary corners of a traffic sign are computed by projecting the boundary corners of a corresponding template image of the sign into the image coordinate using the predicted pose, as illustrated in Figure~ _ref_ . By using the templates of traffic signs, our method effectively utilizes strong prior information of target shapes. This enables robust boundary estimation for traffic signs that are occluded or blurry, which is often challenging in pixel-wise prediction such as contour estimation and segmentation. As a result, our method achieves detection rates higher than N mean average precision (mAP), and boundary estimation error less than N pixels with respect to input resolution of N _inline_eq_ N pixels. Since projecting boundary corners (matrix-vector products) requires negligible computation time, most of the required computation is from the forward propagation of CNN which can be accelerated by GPUs. Combining with our efforts to find a base network architecture that provides the best trade-off between accuracy and speed, our precise boundary detection system can be run on mobile platforms with frame rates higher than N frames per second (FPS) with affordable traffic sign detection and boundary estimation accuracy. The rest of paper is organized as follows. Section _ref_ reviews previous works on traffic sign detection as well as CNN-based generic object detection. The details of our method are described in Section _ref_ including the structure of our detection network, traffic sign boundary estimation using the network output, and training details. In Section _ref_, we report evaluation results on the proposed method including accuracy and speed, and intensive experiments on speed up of the network. Conclusion and future direction are summarized at the final section.