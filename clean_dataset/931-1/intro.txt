Deep convolutional neural networks (CNNs) have been a powerful model for numerous tasks related to system identification _cite_ . By training a CNN with a large set of targeted images, it can achieve the human-level performance for visual object recognition. However it is still a challenge for understanding the relationship between computation and the underlying structure components learned within CNNs _cite_ . Thus, visualizing and understanding CNNs are not trivial _cite_ . Inspired by neuroscience studies, a typical CNN model consists of a hierarchical structure of layers _cite_, where one of the most important properties for each convolutional (conv) layer is that one can use a conv filter as a feature detector to extract useful information from inputed images after the previous layer _cite_ . Therefore, after learning, conv filters are meaningful. The features captured by these filters can be represented in the original natural images _cite_ . Often, one typical feature shares some similarities with part of natural images from the training set. These similarities are obtained by using a very large set of specific images. The benefit of this is that features are relative universal for one category of objects, which is good for recognition. However, it also causes the difficulty of visualization or interpretation due to the complex nature of natural images, i.e., the complex statistical structures of natural images _cite_ . As a result, the filters and features learned in CNNs are often not obvious to be interpreted _cite_ . On the other hand, researchers begin to adapt CNNs for studying the target questions from neuroscience. For example, CNNs have been used to model the ventral visual pathway that has been suggested as a route for visual object recognition starting from the retina to visual cortex and reaching inferior temporal (IT) cortex _cite_ . The prediction of neuronal responses recorded in monkey in this case has a surprisingly good performance. However, the final output of this CNN model is representing dense computations conducted in many previous conv layers, which may or may not be related to the neuronscience underpinnings of information processing in the brain. Understanding these network components of CNN are difficult given the IT cortex part is sitting at a high level of our visual system with abstract information, if any, encoded _cite_ . In principle, CNN models can also be applied to early sensory systems where the organization of underlying neuronal circuitry is relatively more clear and simple. Thus one expect knowledge of these neuronal circuitry could provide useful and important validation for such models. For instance, a recent study employs CNNs to predict neural responses of the retinal ganglion cells to white noise and natural images _cite_ . Here we move a step further in this direction by relating CNNs with single RGCs. Specifically, we used CNNs to learn to predict the responses of single RGCs to white noise images. In contrast to the study by _cite_ where one single CNN model was used to model a population of RGCs, in the current study, our main focus is based on single RGCs to revealing the network structure components learned by CNNs. Our aim is to study what kind of possible biological structure components in the retina can be learned by CNNs. This concerns the research focus of understanding, visualizing and interpreting the CNN components out of its black box. To the end, by using a minimal model of RGC, we found the conv filters learned in CNN are essentially the subunit components of RGC model. The features represented by these filters are fallen into the receptive field of modeled RGC. Furthermore, we applied CNNs to analyze biological RGC data recorded in salamander. Surprisingly, the conv filters are resembling to the receptive fields of bipolar cells that sit in the previous layer of RGC and pool their computations to a downstream single RGC.