Empirically, we may have the following intuitive observations on how a baby learns: after the parent (s) or others teach the baby a few instances about a new concept, the initial recognition capability about the concept can be built. During continuously exploring and/or interacting with diverse instances and scenes in real life, the baby can associate the initial simple instances with other variants by using various information linkages. Based on the accumulated instances about the concept, the baby can gradually improve its recognition capability and recognize diverse instances he/she never saw. Recent successes in computer vision~ _cite_, however, largely rely on the large number of labeled instances of visual concepts, which may require considerable human efforts. The construction of an appearance-based object detector is costly and difficult because the number of training examples must be large enough to capture different variations in the object appearance. Some researchers have made efforts on improving the initial models by using very few labeled data, along with the detection/search results from web images~ _cite_ ~ _cite_ ~ _cite_ or weakly annotated videos~ _cite_ ~ _cite_ . In this paper, we make the first attempt and build a computational model for slightly-supervised object detection by drawing inspiration from the baby learning process. As illustrated in Figure~ _ref_, we propose a robust learning framework which can effectively model the prior knowledge, build the initial model by exemplar learning with very few positive instances for a new concept, and gradually learn a mature object detector by exploring more diverse instances in real-world unlabeled videos. First, we model the prior knowledge (i.e. feature representation) with a pre-trained Convolutional Neural network (CNN) in two steps. We first train a generic CNN by the large image classification dataset. The learned convolutional layers provide the effective feature representations for object recognition. We then fine-tune the CNN with the instances of previously learned visual concepts for the domain adaption from object classification to the detection task. Second, when very few positive instances of a new concept are given, the initial concept detector is built by exemplar learning~ _cite_, which trains a separate linear classifier for every exemplar in the training set based on the deep features from intermediate layers of the pre-trained CNN. Other learned visual concepts are used as negative instances to enhance the discriminative capability. Third, we accumulate more variable instances by exploring the massive unlabeled video clips from the online video sharing websites (e.g., YouTube.com) . The positive instance with highest confidence in each clip is selected as the seed, and then region-based video tracking is performed to accumulate the variable instances by constraining the appearance consistency and spatial correspondence. The concept detector can thus be progressively improved based on these newly tracked instances. After this process repeats again and again, a very mature concept detector can be obtained. With enough instances for the new concept, the pre-trained CNN can also be further improved/fine-tuned, which can provide better deep features for learning concept detectors. Our framework can thus effortlessly improve a new concept detector based on very few positive instances and large easily-obtained video data. The new concept detector is gradually improved in a never ending way as long as more videos are continuously explored. Extensive experiments on three challenging object detection datasets (Pascal VOC N/N/N) well demonstrate the superiority of our computational baby learning framework over other state-of-the-arts~ _cite_ ~ _cite_ ~ _cite_ ~ _cite_ . For all three datasets, we only need to learn one detector for each concept, while all previous works train different models for different datasets. Our framework beats other state-of-the-arts by learning from very few positive instances along with about N, N unlabeled videos for each object category. The contributions of this paper can be summarized as the followings. N) To the best of our knowledge, the proposed framework makes the first attempt to build an effective computational framework for slightly-supervised object detection with inspiration from the baby learning process, where the prior knowledge modelling, exemplar learning and learning with video contexts are integrated. N) ~Only two positive instances are required for learning a new concept detector and then the detector is refined with new variable instances from fully unlabeled videos. There is no assumption that a video must contain a specific object, which makes our framework scalable and robust for learning concept detectors in an online way. N) ~The knowledge of learned concepts can be effectively retained in our model and conveniently utilized to learn new concepts.