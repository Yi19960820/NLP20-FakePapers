In many real-world applications, robustly detecting objects with high localization accuracy, namely to predict the bounding box location with high Intersection over Union (IoU) to the groundtruth, is crucial to the quality of service. For instance, in vision based robotic arm applications, the process of generating robust and accurate operations in picking up an object are highly dependent on the object localization accuracy. In advanced driver assistance systems (ADAS), accurately localizing cars and pedestrians is also closely related to the safety of the autonomous actions. Recent progress in object detection was heavily driven by the successful application of feed-forward deep Convolutional Neural Networks (CNN) . Among many variants of the CNN based approaches, they can be roughly divded into two streams. The first is the R-CNN style _cite_ two stage methods. In these methods, plausible regions were proposed in the first stage then followed by a second stage for decision refinement. The other type of methods aimed to eliminate the region proposal stage and directly train a single stage end-to-end detector. The single stage detectors are usually easier to train and more computationally efficient in production _cite_ . However, such advantage is largely overwritten when the models are evaluated in benchmarks consider mAP for high IoU thresholds (e.g. KITTI car _cite_) since the two stage methods are usually advantageous in performance. We will later show that this weakness of the single stage methods is not attribute to the inability in recognizing objects in complex scenes but the failure in generating high quality bounding boxes. Two examples are illustrated in the left column of figure _ref_ . It can be experimentally shown that most of the low quality bounding boxes come from the failure localization of either small objects or overlapping objects. In either case, conventional bounding box regression becomes highly unreliable because the exact locations of the correct bounding boxes must be determined with the context (e.g. multi-scale information or feature around the occluded region) . That is why it is effective to resort to some form of context aware refinement procedure to remove such errors. The RoI pooling and classification stage of Faster R-CNN can be thought of a simple method to take advantage of such context by resampling feature maps. In this paper, we show that it is possible to seamlessly integrate the context aware refinement procedure in a single stage network. The insight is such procedure can be ``deep in context'' by using a novel Recurrent Rolling Convolution (RRC) architecture. In other words, contextual information can be gradually and selectively introduced to the bounding box regressor when needed. The whole process is fully data driven and can be trained end-to-end. We evaluated our method in the challenging KITTI dataset which considers mAP for high IoU thresholds. In our experiments, we used the reduced VGG-N network instead of the full VGG network or the more recent ResNet as our pre-trained base network so that we are able to fully illustrate the effectiveness of the newly added RRC. This guarantees that such improvement is not simply introduced by the more powerful backbone network. The results showed that our approach significantly outperformed all the previously published results by a single model. An ensemble of our models ranks top among all the methods submitted to the benchmark. The contributions of our work can be summarized as follows.