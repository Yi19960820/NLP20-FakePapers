Object registration is an important task in computer vision that determines the position and the orientation of an object in camera-centered coordinates _cite_ . An object of interest that was detected beforehand in a coarse ND bounding box is fed into a registration system that can superimpose the desired translation and rotation of the object onto the raw camera image. By utilizing such a system, one can propose promising solutions for various problems related to scene understanding, augmented reality, control and navigation of robotics, etc . Recent developments on visual depth sensors and their increasing ubiquity have allowed researchers to make use of the information acquired from these devices to facilitate challenging registration scenarios. \indent Iterative Closest Point (ICP) algorithm _cite_, point-to-model based methods _cite_ and point-to-point techniques _cite_ demonstrate good registration results. However, the performance of these approaches is severely degraded in cases of heavy occlusion and clutter, and similar looking distractors. In order to address these challenges, several learning based methods formulate occlusion aware features _cite_, derive patch-based (local) descriptors _cite_ or encode the contextual information of the objects with simple depth pixels _cite_ and integrate them into random forests. Most particularly, iterative random forest algorithms such as Latent-Class Hough forest (LCHF) _cite_ and iterative Multi-Output Random forest (iMORF) _cite_ obtain state-of-the-art accuracy on pose estimation. On the other hand, these methods rely on scale-invariant features, while the exploitation of rich discriminative information inherently embedded into the scale-variability is one important point been overlooked. \indent Unlike the aforementioned learning-based methods, the ones presented by Novatnack et al. _cite_ utilize the detailed information of the scale variation in order to register range images in a coarse-to-fine fashion. Although promising, they extract and match conventional salient ND key points. However, real depth sensors have several imperfections such as missing depth values, noisy measurements, foreground fattening, etc . As a result, salient feature points used in _cite_ tend to be located on these deficient parts of the depth images, and hence, they are rather unstable _cite_ . In such a scenario, ND reconstruction methods that provide more reliable shape information can be utilized _cite_ . Implicit B-Splines (IBS) _cite_ are techniques that can provide shape descriptors through their zero-sets and reconstruct surfaces. They are based on locally controlled functions that when combined with their control points produce a very rich part-based object representation. \indent Our architecture is originated from these observations. We integrate the coarse-to-fine registration approach presented in _cite_ into the random forest framework _cite_ using Histogram of Control Points (HoCP) features that we adapt from recently introduced IBSs _cite_ . We train our forest only from positive samples and learn the detailed information of the scale-variability during training. We normalize every training point cloud into a unit cube and then generate a set of scale-space images, each of which is separated by a constant factor. The parts extracted from the images in this set are represented with the scale-variant HoCP features. During inference, the parts centered on the pixels that belong to the background and foreground clutters are removed iteratively using the most confident hypotheses and the test image is updated. Since this removal process decreases the standard deviation of the test point cloud, subsequent normalization applied to the updated test image increases the relative scale of the object (foreground pixels) in the unit cube. More discriminative control point descriptors are computed at higher scales and this ensures the refinement of the object pose. In our prior work _cite_, we have evaluated the registration performance of the proposed architecture by only using fixed-size parts. We extend the work engineering an automatic variable size part extraction framework in such a way that we can further exploit the discriminative information provided by the HoCP features. This framework first roughly aligns the object of interest by extracting coarsest parts, the ones occupying the largest area in image pixels, and then iteratively refines its alignment based on finer (smaller) parts that are represented with more discriminative control point descriptors. Note that we employ a compositional approach, i.e., we concurrently detect the object in the target region and estimate its pose by aligning the parts in order to increase robustness across clutter. Figure _ref_ depicts a sample result of our architecture. To summarize, our main contributions are as follows: The rest of the paper is organized as follows: In Sect. _ref_, we present a review on the object registration. Section _ref_ demonstrates the computation procedure of the HoCP features as a scale-variant part representation, their combination with the Iterative Hough Forest (IHF), and the registration process. Experimental results are provided in Sect. _ref_ and finally, the paper is concluded in Sect. _ref_ with several remarks, and discussions.