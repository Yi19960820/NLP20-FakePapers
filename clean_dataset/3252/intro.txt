object detection, which aims to detect object that most attracts people's attention through out an image, has been widely exploited in recent years. It has also been widely utilized for many computer vision tasks, such as semantic segmentation~ _cite_, object tracking~ _cite_ and image classification~ _cite_ . Traditional saliency methods aim to generate a heat map which gives each pixel a relative value of its level of saliency _cite_ . In recent years, the fashion moves to salient object detection which generates pixel-wise binary label for salient and non-salient objects _cite_ . In comparing with the heat map, the binary label would further benefit segmentation based applications such as semantic segmentation~ _cite_, and thus attracts more attention. To achieve a high accuracy for binary labeling, there are mainly two requirements: first, multi-scale contextual reliability; and second, sharp boundary between salient and non-salient objects. The contextual reliability aims to model the relationship between regions and global scenes to determine which object is salient. And the clear boundary aims to separate the salient object and background clearly and to highlight the whole object uniformly. Unfortunately, none of the existing methods achieve both requirements simultaneously. Traditional bottom-up methods mainly rely on priors or assumptions and hand-crafted features. For example, center-surround difference~ _cite_, uniqueness prior~ _cite_ and backgroundness prior~ _cite_ . These methods can not consider high-level semantic contextual relations and do not achieve a satisfying accuracy. Recently, the deep Convolutional Neural Network (CNN) has attracted wide attention for its superior performance. CNN based methods can be divided into region-based networks and pixel-based networks. Region-based methods aim to extract features of each region (or patch), and then predict its saliency score. However, existing region-based methods lack of representing context information to model the relationship between regions and global scenes. Because of this, it may have false detection results when the scene is complex or the object is composed by several different parts, which limits their performance () . On the other hand, existing pixel-based CNN methods lack the ability to produce clear boundary between salient and non-salient objects, due to the presence of convolutional and pooling layers, and they only achieve partial contextual reliability. This limits the performance of pixel-based methods () . In this paper, we propose a novel edge preserving and multi-scale contextual network for salient object detection. The proposed framework achieves both clear boundary and multi-scale contextual robustness simultaneously for the first time. As illustrated in, the proposed structure, named RexNet, is mainly composed by two parts, the REgionNet and the conteXtNet . First, the RegionNet is inspired by the Fast R-CNN framework~ _cite_ . Fast R-CNN is recently proposed for object detection and achieves superior performance because the convolutional features of entire image are shared and features of each patch (or RoI) are extracted via the RoI pooling layer. We extend Fast R-CNN to salient object detection by introducing mask-based RoI pooling and formulating salient object detection as a binary region classification task. The image is first segmented into regions and are used as input of RegionNet, the RegionNet then predicts saliency score of each region end-to-end to form saliency map of the entire image. Since the regions are segmented by edge-preserved methods, saliency map generated by our network is naturally with sharp boundaries. Second, the ContextNet aims to provide strongly reliable multi-scale contextual information. Different from most previous works which consider context by expanding region window at a certain layer, in this paper, we consider to model context via multiple spatial scales. This is based on the observation that different layers of CNN represent different levels of semantic~ _cite_, considering context of different levels may be more sufficient. We achieve this by taking advantages of dense image prediction. For all max-pooling layers of RegionNet, we attach multiple convolutional layers to predict saliency map of different levels. Then all levels of saliency map are fused with RegionNet to generate the final saliency map. Our method generates saliency map with accurate location while keeping fine object boundaries. Other than the effectiveness, our proposed frameworks is efficient, since we take advantages of regions by extending the efficient Fast R-CNN framework, which predicts saliency score of regions by only one forwarding. We also extend our method to RGB-D saliency by applying depth refinement. Experiments on N RGB-D benchmark datasets demonstrate that the proposed RexNet outperforms other methods by a large margin. The main contributions of this paper are three-fold. First, we proposed RegionNet which generates saliency score of regions efficiently and preserves object boundaries. Second, multi-scale spatial context is considered and attached to RegionNet to boost salient object detection performance. Third, we extend our method to RGB-D saliency datasets and use depth information to further refine saliency maps. The rest of this paper is organized as follows. Section~ _ref_ discusses related work. Section~ _ref_ and Section~ _ref_ introduce the details of the proposed RegionNet and ContextNet correspondingly. Section~ _ref_ describes the training details of the proposed network. Section~ _ref_ introduces our extension to RGB-D salient object detection. Section~ _ref_ shows the experimental results and comparison with state-of-the-art methods. And conclusion is made in Section~ _ref_ .