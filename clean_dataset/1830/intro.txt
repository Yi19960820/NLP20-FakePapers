Deep implicit models~ _cite_ have shown promise on synthesizing realistic images~ _cite_ and inferring latent variables~ _cite_ . However, these approaches do not explicitly model the underlying structures of the data, which are common in practice (e.g., temporal structures in videos) . Probabilistic graphical models~ _cite_ provide principle ways to incorporate the prior knowledge about the data structures but these models often lack the capability to deal with the complex data like images. To conjoin the benefits of both worlds, we propose a flexible generative modelling framework called {\it Graphical Generative Adversarial Networks} (Graphical-GAN) . On one hand, Graphical-GAN employs Bayesian networks~ _cite_ to represent the structures among variables. On the other hand, Graphical-GAN uses deep implicit likelihood functions~ _cite_ to model complex data. Graphical-GAN is sufficiently flexible to model structured data but the inference and learning are challenging due to the presence of deep implicit likelihoods and complex structures. We build a structured recognition model~ _cite_ to approximate the true posterior distribution. We study two families of the recognition models, i.e. the {\it mean field posteriors} ~ _cite_ and the {\it inverse factorizations} ~ _cite_ . We generalize the {\it Expectation Propagation} (EP) ~ _cite_ algorithm to learn the generative model and recognition model jointly. Motivated by EP, we minimize a local divergence between the generative model and recognition model for each individual local factor defined by the generative model. The local divergences are estimated via the adversarial technique~ _cite_ to deal with the implicit likelihoods. Given a specific scenario, the generative model is determined a priori by context or domain knowledge and the proposed inference and learning algorithms are applicable to arbitrary Graphical-GAN. As instances, we present Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN) to learn the discrete and temporal structures on visual datasets, respectively. Empirically, these models can infer the latent structures and generate structured samples. Further, Graphical-GAN outperforms the baseline models on inference, generation and reconstruction tasks consistently and substantially. Overall, our contributions are: (N) we propose Graphical-GAN, a general generative modelling framework for structured data; (N) we present two instances of Graphical-GAN to learn the discrete and temporal structures, respectively; and (N) we empirically evaluate Graphical-GAN on generative modelling of structured data and achieve good qualitative and quantitative results.