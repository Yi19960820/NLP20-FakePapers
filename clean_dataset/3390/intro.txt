Person re-identification (re-id) aims to match persons across disjoint camera views distributed at different locations _cite_ . While most recent re-id methods rely on static images _cite_, video-based re-id has gained increasing attention _cite_ due to the rich space-time information inherently carried in the video tracklets. A video tracklet is a sequence of images that captures rich variations of the same person in terms of occlusion, background clutter, viewpoint, human poses, etc, which can naturally be used as informative data sources for person re-id. The majority of current techniques in video person re-id consider the supervised learning context, which imposes a strong assumption on the availability of identity (ID) labels for every camera pair therefore allowing more powerful and discriminative re-id models to be learned when given relatively small-sized training data. However, supervised learning methods are weak in scaling to real-world deployment beyond the labelled training data domains. In practice, exhaustive manual annotation at every camera pair is not only prohibitively expensive for a large identity population across a large camera network, but it is also implausible due to insufficient designated persons reappearing in every camera pair. In this regard, unsupervised video re-id is a more realistic task that is worth studying to improve the scalability of re-id models in practical use. Unsupervised learning methods~ _cite_ are particularly essential when the re-id task needs to be performed on a large amount of unlabelled video surveillance data cumulated continuously over time, whilst the pairwise ID labels cannot be easily acquired for supervised model learning. Due to the inherent nature of unsupervised learning, existing methods suffer from significant performance degradations when compared to supervised learning methods in video person re-id. For instance, the state-of-the-art rank-N re-id matching rate on MARS~ _cite_ is only N \% by unsupervised learning~ _cite_, as compared to N \% by supervised learning~ _cite_ . In fact, even the latest video-based unsupervised learning models~ _cite_ for person re-id still lack a principled mechanism to explore the more powerful representation-learning capabilities of deep Convolutional Neural Networks (CNNs) ~ _cite_ for jointly learning an expressive embedding representation and a discriminative re-id matching model in an end-to-end manner. It is indeed not straightforward to formulate a deep learning scheme for unsupervised video-based person re-id due to: (N) The general supervised learning nature of deep CNN networks: most deep learning objectives are formulated on labelled training data; (N) The cross-camera variations of the same-ID tracklet pairs from disjoint camera views and the likelihood of different people being visually similar in public space, which collectively render the nearest-neighbour distance measure unreliable to capture the cross-view person identity matching for guiding the model learning. In this work, we aim to tackle the task of unsupervised video person re-id by an end-to-end optimised deep learning scheme without utilising any ID labels. Towards this aim, we formulate a novel {\em unsupervised} Deep Association Learning (DAL) scheme designed specifically to explore two types of {\em consistency}, including (N) {\em local space-time consistency} within each tracklet from the same camera view, and (N) {\em global cyclic ranking consistency} between tracklets across disjoint camera views (Figure _ref_) . In particular, we define two margin-based association losses, with one derived from the intra-camera tracklet representation updated incrementally on account of the {\em local space-time consistency}, and the other derived from the cross-camera representation learned continuously based on the {\em global cyclic ranking consistency} . Importantly, this scheme enables the deep model to start with learning from the local consistency, whilst incrementally self-discovering more cross-camera highly associated tracklets subject to the global consistency for progressively enhancing discriminative feature learning. Overall, our DAL scheme imposes batch-wise self-supervised learning cycles to eliminate the need for manual labelled supervision in the course of model training. {\bf Our contribution} is three-fold: {\bf (I)} We propose for the first time an end-to-end deep learning scheme for unsupervised video person re-id without imposing any human knowledge on identity information. {\bf (II)} We formulate a novel {\em Deep Association Learning} (DAL) scheme, with two discriminative association losses derived from (N) {\em local space-time consistency} within each tracklet and (N) {\em global cyclic ranking consistency} between tracklets across disjoint camera views. Our DAL loss formulation allows typical deep CNNs to be readily trained by standard stochastic gradient descent algorithms. {\bf (III)} Extensive experiments demonstrate the advantages of DAL over the state-of-the-art unsupervised video person re-id methods on three benchmark datasets: PRIDN _cite_, iLIDS-VID _cite_, and MARS _cite_ .