Deep learning has launched a profound reformation and even been applied to many real-world tasks, such as image classification ~ _cite_, object detection ~ _cite_ and segmentation ~ _cite_ . These tasks obviously fall into the scope of supervised learning, which means that a lot of labeled data are provided for the learning processes. Compared with supervised learning, however, unsupervised learning tasks, such as generative models, obtain limited impact from deep learning. Although some deep generative models, e.g. RBM ~ _cite_, DBM ~ _cite_ and VAE ~ _cite_, have been proposed, these models face the difficulty of intractable functions or the difficulty of intractable inference, which in turn restricts the effectiveness of these models. Recently, Generative adversarial networks (GANs) ~ _cite_ have demonstrated impressive performance for unsupervised learning tasks. Unlike other deep generative models which usually adopt approximation methods for intractable functions or inference, GANs do not require any approximation and can be trained end-to-end through the differentiable networks. The basic idea of GANs is to simultaneously train a discriminator and a generator: the discriminator aims to distinguish between real samples and generated samples; while the generator tries to generate fake samples as real as possible, making the discriminator believe that the fake samples are from real data. So far, plenty of works have shown that GANs can play a significant role in various tasks, such as image generation ~ _cite_, image super-resolution ~ _cite_, and semi-supervised learning ~ _cite_ . In spite of the great progress for GANs in image generation, the quality of generated images by GANs is still limited for some realistic tasks. Regular GANs adopt the sigmoid cross entropy loss function for the discriminator~ _cite_ . We argue that this loss function, however, will lead to the problem of vanishing gradients when updating the generator using the fake samples that are on the correct side of the decision boundary, but are still far from the real data. As Figure _ref_ (b) shows, when we use the fake samples (in magenta) to update the generator by making the discriminator believe they are from real data, it will cause almost no error because they are on the correct side, i.e., the real data side, of the decision boundary. However, these samples are still far from the real data and we want to pull them close to the real data. Based on this observation, we propose the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. The idea is simple yet powerful: the least squares loss function is able to move the fake samples toward the decision boundary, because the least squares loss function penalizes samples that lie in a long way on the correct side of the decision boundary. As Figure _ref_ (c) shows, the least squares loss function will penalize the fake samples (in magenta) and pull them toward the decision boundary even though they are correctly classified. Based on this property, LSGANs are able to generate samples that are closer to real data. Another benefit of LSGANs is the improved stability of learning process. Generally speaking, training GANs is a difficult issue in practice because of the instability of GANs learning~ _cite_ . Recently, several papers have pointed out that the instability of GANs learning is partially caused by the objective function~ _cite_ . Specifically, minimizing the objective function of regular GAN suffers from vanishing gradients, which makes it hard to update the generator. LSGANs can relieve this problem because LSGANs penalize samples based on their distances to the decision boundary, which generates more gradients to update the generator. Recently, Arjovsky \etal~ _cite_ have proposed a method to compare the stability of GANs learning by excluding batch normalization~ _cite_ . Following this method for comparing the stability, we find that LSGANs are also able to converge to a relatively good state without batch normalization. Our contributions in this paper can be summarized as follows: The rest of this paper is organized as follows. Section _ref_ briefly reviews related work of generative adversarial networks. The proposed method is introduced in Section _ref_, and experimental results are presented in Section _ref_ . Finally, we conclude the paper in Section _ref_ .