The ability to estimate the relative pose between camera views is essential for many computer vision applications, such as structure from motion (SfM), simultaneous localization and mapping (SLAM) and visual odometry. Due to its practical importance, plenty of research effort has been devoted to the topic over the years. One popular approach to the problem is based on detecting and matching local feature points and using the obtained correspondences to determine the relative poses. The performance of such system is highly dependent on the accuracy of the local feature matches, which are commonly determined using methods like SIFT~ _cite_, DAISY~ _cite_, or SURF~ _cite_ . Unfortunately, there are many practically important cases where these hand-crafted descriptors are not able to find sufficient amount of correspondences. Particularly, repetitive structures, textureless objects, and extremely large viewpoint changes are difficult to handle. We highlight such cases in Fig.~ _ref_ . An alternative solution would be to utilize all photometric information from the images to determine the poses. However, such methods (e.g.~ _cite_) are usually not applicable to wide baseline settings, where there is large viewpoint change, or they may be computationally expensive. Recently, methods based on convolutional neural networks (CNNs) have clearly outperformed previous state-of-the-art results in many computer vision problems, such as image classification, object recognition, and image retrieval. In this work, we show how CNNs can also be applied to estimate the relative camera poses. Our contributions are as follows: N) we propose a CNN-based method, which takes RGB images from both cameras as input and directly produces the relative rotation and translation as output; N) we explore several network architectures and evaluate their performance on the DTU dataset~ _cite_ ; N) we study how different training strategies affect the results and make comparisons to popular keypoint based approaches. In addition, we investigate how spatial pyramid pooling~ _cite_ could be applied in the context of relative camera pose estimation problem. The rest of the paper is organized as follows. Section~ _ref_ describes the related work focusing on relative camera pose estimation. The proposed approach and details related to network architectures and objective functions are introduced in Section _ref_ . Finally, sections _ref_ and _ref_ present the baseline methods, experimental setup, evaluation results, discussion, and possible directions for future investigations.