Accuracy in image recognition and other related computer vision tasks strongly depends on the choice of image features. Learning a discriminative feature representation is thus an essential step in handling these tasks. Before the breakthrough brought by convolutional neural networks (CNNs), most of the approaches were based on hand-crafted feature representations. However in the current state-of-the-art, this has changed to supervised feature learning from well-organized large-scale datasets consisting of millions of images and assigned labels fully annotated by experts _cite_ . However, constructing such large-scale datasets generally requires a huge amount of manual effort and poses one of the biggest challenges in feature learning. Instead, training features in a weakly supervised or completely unsupervised fashion allows us to utilize a very large amount of available data. With the steadily increasing popularity of SNSs, large quantities of unlabeled and weakly labeled data are created every day. Most existing research on image feature learning without relying on fully labeled image datasets utilizes community contributed text tags that can be easily collected through image search platforms _cite_ or content sharing platforms _cite_ . However, the concepts underlying a single text tag depend strongly on the users who provide the text tag. Different users may annotate the same text tag for different concepts, but we cannot distinguish those different concepts solely from the text tag, which may make it difficult to train discriminative features. Instead, we present a new paradigm for learning visual features by making the full use of the human curation process on SNSs. During the process of content curation, images are manually collected from many sources such as photo sharing services and other SNSs, grouped by concept, and provided with textual descriptions in the form of text tags or sentences _cite_ . The concept of each image group is defined by the curating user, allowing for a wide range of very specific semantic concepts, such as "Green/Blue Ferrari" or "Gadgets for Lazy People", as shown in Figure _ref_ . Previous research _cite_ focusing on Pinterest, which is one of the most popular content curation platform for images, has demonstrated that most of the images collected in the same curated group can be assumed to share the same semantic concept. This readily implies that we can treat each human-curated group as a pseudo category that shares a consistent semantic concept compared with noisy community-contributed text tags. However, employing curated groups as weak labels still presents several technical problems. First, we have to handle a large number of curated groups, as when using community-contributed text tags. Second, the number of images in a curated group is much smaller than what is required to fully capture the characteristics of the curated group. In this paper, we propose a novel framework for weakly supervised image feature learning that fully exploits the properties underlying human curated content. Figure _ref_ shows an overview of the proposed method. We introduce another property of socially curated data that results from the fact that curated groups sharing several images are expected to have similar concepts. Namely, to capture the nature of a curated group we can utilize not only images in the group but also those in neighboring curated groups. We can see that the problem of predicting to which curated groups a new image belongs can be regarded as multi-task learning, where each task corresponds to the classification of images into a curated group. In addition, we note that the task of classifying images into curated groups can also be seen as classification using only positive and unlabeled data (PU classification) _cite_, since we can find many curated groups with the same concept but sharing no images with each other, due to the locality of SNSs. Link prediction techniques have been proved to be effective for this PU classification _cite_ and can be applied to large-scale graphs _cite_ . Thus, we formulate our feature learning as the problem of predicting links on a bipartite graph, where one node group corresponds to images and the other corresponds to curated groups. We then propose a novel method for link prediction that exploits observed features on nodes as well as link structures. In a similar manner to learning visual attributes _cite_, we can apply scores of linking curated groups to a given image as a new feature of the image. However, we propose a more sophisticated method for learning a new feature representation, which combines a model for link prediction and convolutional neural networks for feature extraction. Although we concentrate on the use of a specific SNS platform for still images mainly for presentation clarity, our method can be easily applied to other platforms and modalities, as long as each user collects contents into groups sharing the same semantic information. For example, users in music platforms such as Spotify, Amazon Music and iTunes can create playlists that are such curated groups. The underlying graph can then be used, e.g., to improve existing approaches for music feature learning with deep CNNs (see e.g. _cite_) . We also note that our fine-tuning approach can be directly applied to other types of graph structures representing relationships among (pseudo) labels, such social networks or knowledge graphs.