Breast cancer is one of the top causes of cancer death in women. In N, it is estimated that there are N, N new diagnoses of invasive breast cancer among women in the United States, and approximately N, N women are expected to die from the disease _cite_ . The detection of breast cancer in its early stage by mammography allows patients to get better treatments, and thus can effectively lower the mortality rate. Currently, mammogram screening is still based on experts’ reading, but this process is laborious and prone to error. Computer-aided diagnosis (CADx) system is a potential solution to facilitate mammogram screening, and the research on automatic (or semi-automatic) mammogram analysis has been a focus in medical vision field. Given the fact that a mass only occupies a small region (typically ~N \%) of a whole mammogram (i.e. the “needle in a haystack” problem _cite_), it is very hard to identify a mass from the whole image without introducing a large number of false positives. Therefore, traditionally, both hand-crafted feature based methods _cite_ and deep learning models _cite_ require manually extracted regions of interest (ROIs), which, however, affects their usefulness in clinical practice. Recently, Dhungel et al. _cite_ proposed a sophisticated framework integrating mass detection, segmentation and classification modules to do whole-image classification, which achieved state-of-the-art performance with minimal manual intervention (manually rejecting false positives after detection) . Besides, Lotter et al. _cite_ proposed a N-stage curriculum learning method to cope with the classification of whole mammograms, and Zhu et al. _cite_ developed a sparse multi-instance learning (MIL) scheme to facilitate the end-to-end training of convolution neural networks (CNNs) for whole-image classification. Nevertheless, these methods either require manual intervention and multi-stage training, or only focus on the classification problem, while the accurate location and size of masses also play a critical role in a CADx system. In this paper, we propose a CNN-based model with Hybrid Deep Supervision (Hybrid DS, HDS) to perform whole-mammogram classification and mass segmentation simultaneously. This model is based on a very deep U-Net _cite_ with residual connections _cite_ (U-ResNet) which has N convolutional layers in the main stream. To facilitate the multi-task training of the deep network and boost its performance, we extend deep supervision (DS) _cite_ to Hybrid DS by introducing multi-task supervision into each auxiliary classifier in DS, and apply this scheme to the U-ResNet model. To evaluate the proposed method, we performed extensive experiments on a publicly available full-field digital mammographic (FFDM) dataset, i.e. INbreast _cite_ . The results show that our model achieves state-of-the-art performance in both classification and segmentation metrics, and ablation studies are performed to demonstrate the efficacy of HDS scheme.