In this work, we propose a self-supervised learning method for affine image registration on ND medical images. Unlike optimisation-based methods, our affine image registration network (AIRNet) is designed to directly estimate the transformation parameters between two input images without using any metric, which represents the quality of the registration, as the optimising function. But since it is costly to manually identify the transformation parameters between any two images, we leverage the abundance of cheap unlabelled data to generate a synthetic dataset for the training of the model. Additionally, the structure of AIRNet enables us to learn the discriminative features of the images which are useful for registration purpose. Our proposed method was evaluated on magnetic resonance images of the axial view of human brain and compared with the performance of a conventional image registration method. Experiments demonstrate that our approach achieves better overall performance on registration of images from different patients and modalities with Nx speed-up in execution time.