Arterial spin labeling (ASL) perfusion MRI is a technique for measuring cerebral blood flow (CBF) _cite_ . In ASL, arterial blood water is labeled with radio-frequency (RF) pulses in locations proximal to the tissue of interest, and perfusion is determined by pair-wise comparison with separate images acquired with control labeling using various subtraction approaches _cite_ . Limited by the longitudinal relaxation rate (TN) of blood water and the post-labeling transmit process, only a small fraction of tissue water can be labeled, resulting in a very low SNR _cite_ . To improve SNR, a series of ASL images are usually acquired to take the mean perfusion map for final CBF quantification. Also, various preprocessing and analysis methods such as motion correction and outlier cleaning, have been proposed to further denoise ASL MRI _cite_ . However, those methods typically suffer from two major disadvantages. First, due to very poor original image quality, those methods achieve relative SNR improvement. Second, those methods usually involve a optimization process in the testing stage, which is very time-consuming. Recenlty, Deep learning-based denoising methods emerged and achieves state-of-the-art performance _cite_ .Instead of modeling explicit image prior, deep learning-based image denoising method learns image prior implicitly. The reasons of using CNN for denoising are as follows: First, CNN with deep or wide architecture _cite_ has the capacity and flexibility to effectively learning the image prior. Second, various well-developed training strategies and techniques are available to fasten the training process and improve the denoising performance, such as Rectifier Linear Unit (ReLU) _cite_, dropout _cite_, residual learning _cite_ and batch normalization _cite_ . Third, CNN can be trained on modern powerful GPU using parallel computation, which further improve the run time performance. To the best of our knowledge, this work is the first deep learning-based method for denoising ASL perfusion MRI images. The purpose of this study was to assess the feasibility and efficacy of deep learning-based method for denoising ASL perfusion MRI images. For ease of description, we dubbed the new DL-based ASL denoising method as ASLDLD thereafter. Our model, ASLDLD, was based on Wide Inference Network (WIN) _cite_, a N layer end-to-end Convolutional Neural Networks (CNNs) denoising model with wide structure. The ASLDLD was trained on ND ASL MRI images acuqired from N subjects, where each subject has N slices and each slice has N control/labeled image pairs. The ASLDLD takes mean of first N CBF images without smoothing (meanCBF-N) as the input noisy image and the mean of all N CBF images (meanCBF-N) with smoothing and adaptive outlier cleaning _cite_ as the reference image. In order to fasten and stabilize model learning, we adopt residual learning and batch normalization learning strategies. Furthermore, Grey matter (GM) probability map was incorporated as a regularizer because CBF map shows a similar image contrast to that of a grey matter map. ASLDLD has several advantages in denoising ASL MRI images: N) the model effectively utilized prior information which significantly improve the denoising performance. N) Because of the intrinsic of feed-forward CNN architecture, the computaion time is very fast in the test stage, which significantly reduce the computation time. (Contrast to traditional denoising method, which requires very long time to computing.) N) Comparing traditional ASL denoising methods which requires a large series of label controling image pairs (in our case, N pairs), ASLDLD only need N pairs of label controlling images. This significantly reduces the acquisition time of ASL MRI, which reduce the chance of head motions and hence reduce the chance of introducing extra noise. The rest of this paper is as follows. In section N, we discuss about the related works of deep learning-based denoising methods. In section N, we present the proposed ASLDLD architecture. Section N demonstrates the experiment of our methods on data. Last but not least, in section N, we discuss the main contributions and results of this work.