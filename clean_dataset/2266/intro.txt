Indoor space is likely to be the main workplace for service robots in the near future. In order to work well in an indoor space, the robots should possesses the ability of visual scene understanding. To do so, the semantic segmentation in indoor scene is becoming one of the most popular tasks in computer vision. Over the pass few years, fully convolutional networks (FCNs) type architectures have shown great potential on semantic segmentation task _cite_, and have dominated the semantic segmentation task of many datasets _cite_ . Some of this FCNs-type architectures focus on indoor environment, and usually utilize the depth information as the complementary information for RGB to improve the segmentation _cite_ . In general, the FCNs architectures can be generally divide into two categories, i.e., the encoder-decoder type architectures and dilated convolution architectures. The encoder-decoder architectures _cite_ have a downsample path to extract the semantic information from images and a upsample path to recover a full-resolution semantic segmentation map. By contrast, the dilated convolution architectures _cite_ employ dilated convolution such that the convolutional network expands receptive field exponentially without downsampling. With less or even zero downsampling operation, dilated architectures keep the spatial information in the image through out the whole networks, so the architectures serve as a discriminative model that classify every pixel on the image. Encoder-decoder architectures, on the other hand, lost spatial information during the discriminative encoder, and thus some of the networks apply skip-architecture to recover the spatial information during the generative decoder path. Even though the dilated convolution architectures have the advantage of keeping the spatial information, they generally have higher memory consumption on the training step. Because the spatial resolution of the activation map is not downsampled as the network proceed and it needs to be stored for gradient computation. Therefore, the high memory consumption stops the network from having a deeper structure. This could cause disadvantages on this method, since convolutional networks learn richer features as the structure gets deeper, which would benefit the inference of the semantic information. In this paper, we propose a novel structure named RedNet that employ the encoder-decoder network structure for indoor RGB-D semantic segmentation. In RedNet, the residual block is used as the building module to avoid the model degradation problem _cite_ . This allows the performance of networks to improve as the structure goes deeper. Moreover, we apply fusion structure to incorporate depth information into the network, and use skip-architecture to bypass the spatial information from encoder to decoder. Further, inspired by the training scheme in _cite_, we propose the pyramid supervision that apply supervised learning over different layers on the decoder for better optimization. The overall structure of RedNet is illustrated in Fig. _ref_ . The remainder of this paper is organized in four sections. In section _ref_, the literature on residual networks and indoor RGB-D semantic segmentation is previewed. The architecture of RedNet and the idea of pyramid supervision are stated in detail in section _ref_ . In section _ref_, the comparative experiments are conducted to evaluate the efficiency of the model. Finally, we draw a conclusion of this paper in section _ref_ . Before ending this section, the main contributions of this paper are listed as the following.