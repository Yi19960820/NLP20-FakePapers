The problem of understanding how convolutional neural nets (CNN's) work and learn is one of the fundamental problems in machine learning. A related problem is CNN's tendency to overfit and be vulnerable to the so-called adversarial behavior, where by making tiny imperceptible changes to the input networks can be made to fail. In the context of neural networks, it is important to study both the weights and the activations, as these roughly constitute the "coefficients" and the outputs in the computational model. To date, work in this area [N, N, N, N, N] has involved direct human inspection of features constructed in the network and has produced very interesting qualitative results. The first goal of the present paper is to demonstrate that data sets constructed out of the weights are organized in simple {\em topological models}, which are strongly reminiscent of the results obtained in the topological analysis of data sets of local patches in natural images [N] . Such topological models yield insight by effectively summarizing the global structure of the spaces of weight configurations, and permit the exploration of density in the data set. The key point here is that the study of the function of neural nets is a problem in {\em data analysis}, since the density of particular features is clearly relevant, and since we clearly find the presence of anomalous and spurious elements. It is important to model the most frequently occurring motifs in a simple and understandable way. The topological models we work with are part of {\em topological data analysis} (TDA) [N, N, N, N], which in addition to the construction of the models provide invariants of the shape of the data set (persistent homology), that confirm that the shape of the data is as expressed in the model. We apply methods of TDA to data sets of {\em spatial filters} of the convolutional layers. In the _inline_eq_-th convolutional layer, an activation map is constructed by sliding a filter (a set of weights) along the spatial dimensions of all activation maps in the _inline_eq_-th layer. A filter thus has dimensions _inline_eq_, where _inline_eq_ and _inline_eq_ are the width and height of the spatial receptive field of the filter while _inline_eq_ is the number of activation maps in the _inline_eq_-th layer. We define a {\em spatial filter} as one set of _inline_eq_ weights with a fixed _inline_eq_-dimension. One single filter give _inline_eq_ spatial filters and a convolutional layer with _inline_eq_ number of activation maps give _inline_eq_ spacial filters of dimension _inline_eq_ . We perform analyses of CNN's trained on the MNIST [N], CIFAR-N [N] SVHN [N], and ImageNet [N] data sets. We find that in some cases, the models recapitulate the topological structures that occurred in [N], namely the {\em primary} and {\em secondary} circles (see Figure _ref_), but that in other situations different phenomena occur. The first part of this paper constitutes an exploratory analysis of the spatial filters described above. The second goal of this paper is to investigate the findings from the first part and provide an interpretation. Noticing that deeper networks with better generalizing abilities learn stronger topological structures, we estimate that topological structure is indicative of a network's ability to generalize to unseen data. If the topological structure learned by a network is a signature of its hypothesis about its task, then, in the spirit of Occam's razor, it is unlikely that a network learns a simple and strong topological structure that would only apply to its specific dataset at hand and not generalize to related data. Indeed, we demonstrate that topological structure is indicative of a network's ability to generalize between the MNIST and SVHN datasets. Both datasets consists of images, MNIST consists of handwritten digits while SVHN is a more diverse dataset consisting of images of numbers for the addresses of houses. We show how one can improve the performance of a network trained on MNIST and evaluated on SVHN. We confirm that a network trained on SVHN generalizes better when evaluated on MNIST than vice versa, and show how the topological structure of a network trained on SVHN is 'simpler' than one trained on MNIST as predicted by our hypothesis. We also show how this measure of topological simplicity correlates with a networks performance on a held-out test set, for both MNIST and SVHN. Lastly, we show how extending a network with information obtained from our topological study may increase a networks performance on held out test data and speed up the learning process.