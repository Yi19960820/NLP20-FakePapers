Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet) . Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge N, PASCAL VOC N benchmark and Cityscapes benchmark. A single PSPNet yields the new record of mIoU accuracy N \% on PASCAL VOC N and accuracy N \% on Cityscapes.