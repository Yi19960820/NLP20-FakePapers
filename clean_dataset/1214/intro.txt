Convolutional neural networks (CNNs) have been widely adopted for visual analysis tasks such as image classification _cite_, object detection _cite_, action recognition _cite_, place recognition _cite_, ND shape classification _cite_, image colorization _cite_, and camera pose estimation _cite_ . CNNs learn rich image and video representations that have been shown to generalize well across vision tasks. When faced with a recognition task in a novel domain or application, a common strategy is to start with a CNN pre-trained on a large dataset, such as ImageNet _cite_, and fine-tune the network to the new task (Fig.~ _ref_ a) . Fine-tuning involves adapting the structure of the existing network to enable the new task, while re-using the pre-trained weights for the unmodified layers of the network. For example, a common and simple form of fine-tuning involves replacing the final fully-connected layer of the pre-trained CNN, which has an output dimensionality based on the pre-training dataset (e.g. N dimensions for ImageNet), with a new fully-connected layer with a dimensionality that matches the target dataset. Fine-tuning allows powerful learned representations to be transferred to novel domains. Typically, we fine-tune complex network architectures that have been pre-trained on large databases containing millions of images. For example, we may fine-tune AlexNet _cite_ pre-trained on ImageNet's N million images (N million parameters) . In this way, we adapt these complex architectures to smaller and more specialized domains, such as remote sensing images. However, the specialized domain may not span the full space of natural images on which the original network was pre-trained. This suggests that the network architecture may be over-parameterized, and therefore inefficient in terms of memory and power consumption, with respect to the more constrained novel domain, in which a much more lightweight network would suffice for good performance. In applications with tight constraints on memory and power, such as mobile devices or robots, a more lightweight network with comparable classification accuracy may be valuable. Given a fine-tuned network, a straightforward way to obtain a more lightweight network is to perform network pruning _cite_ (Fig.~ _ref_ b) . However, this strategy has drawbacks: (N) the fine-tuning and pruning operations are performed independently; (N) the pruning parameters are set once and cannot adapt after training has started; and (N) since state-of-the-art pruning methods are highly parameterized, manually searching for good pruning hyperparameters is often prohibitive for deep networks, leading to coarse pruning strategies (e.g. pruning convolutional and fully connected layers separately _cite_) . We propose a novel process called (Fig.~ _ref_ c) that addresses these limitations: