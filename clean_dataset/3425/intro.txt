Object localization aims to identify the location of a target object in a given scene. Recently, deep learning based methods, such as Faster R-CNN _cite_, YOLO _cite_, and SSD _cite_, have achieved significant improvement in object detection with real-time performance. These techniques _cite_, however, utilize fully-supervised learning, which require category labels and bounding box annotations for training. Because such information is considered expensive, acquiring massive amount of data annotations is difficult, drawing a limit for practical applications. To alleviate the burden on data annotations, weakly-supervised learning methods have been suggested. The weakly-supervised object localization uses only category labels during training, thus the amount of data annotations becomes manageable. Among those, Class Activation Mapping (CAM) _cite_ is a representative weakly-supervised object localization method. CAM is designed to extract a heatmap by analyzing internal layer of CNN, which is then post-processed to locate a bounding box. The main idea of CAM is that the pixels contributing to object classification coincide with the object location. However, in common occasions, even the cheapest information, object categories, may not be affordable. For a fundamental solution to annotation dependency, unsupervised object localization techniques have emerged. Unlike the weakly-supervised object localization, the unsupervised approach does not rely on any annotations about a dataset. Among the unsupervised approaches, co-localization aims to find a target object in a dataset which contains only one object category. Because the negative samples (e.g., other category objects) are not provided, this problem is inherently more challenging than the weakly-supervised object localization problem. Unlike supervised, or weakly-supervised methods, unsupervised object co-localization techniques are yet to employ deep neural networks. Existing techniques such as _cite_ rely on hand-crafted feature extractions, graph-based theories, or optimizations, placing a limit to achieving real-time performance. Meanwhile, deep neural network models are considered outstanding at feature extraction, superior to the previous hand-crafted ones in most pattern recognition problems, even achieving real-time performance. Motivated by their recent success, we aim to apply deep neural networks to unsupervised object co-localization, expecting improvements in both performance and time efficiency. Specifically, in this paper, we suggest an end-to-end unsupervised object co-localization method based on Generative Adversarial Networks (GANs) _cite_ for the first time. GAN is an unsupervised generative model that learns to generate samples following the true data distribution by implicit density estimation. GAN is composed of a generator and a discriminator. The generator is trained in a way the discriminator cannot distinguish fake images, produced by the generator, from real images. Meanwhile, the discriminator learns to distinguish them from real images. Through this adversarial competition, the generated images from GANs become more realistic, hard to distinguish from the reals. Among many generative models, GAN is known to generate most sharp and realistic images. In this paper, we take advantage of a GAN discriminator for unsupervised object co-localization. Without utilizing any priors or annotations, GAN successfully generates images that follow the true data distributions. Suppose that the generator is trained to produce a dominant object (i.e., the most frequently appearing object in a dataset), which is our target object in co-localization dataset. Then, we expect that the discriminator will pay more attention to the target object in distinguishing real or fake. Unfortunately, a GAN discriminator may not always use the target object as a decision criteria. In fact, GANs may generate not only the dominant object, but also other various objects in the dataset. Especially, recent advanced GAN algorithms improve image diversity in data generation. For example, to encourage diverse image generations, Arjovsky et al. _cite_ introduced a novel loss function, and Gulrajani et al. and Kodali et al. _cite_ added a regularization term. In this way, their GAN models capture various modes of data distribution. As a result, their discriminator may learn modes that are not related to the target object. If diverse scene components such as background objects are generated by the GAN generator, its discriminator can properly distinguish those of scene components, thus modeling them as separate modes. This is a desirable property for a GAN model, because achieving the image diversity is an important objective for GAN training. However, for the object localization, this is a prohibitive property since the diversity is negative to capture the target object; the ideal object localization should find the target object only, not other scene components. To meet the goal of object localization, we ironically return to the early models of GANs. The early GAN models have been well known to easily miss minor modes of data distribution during training. The consequent phenomenon is called, a major issue in GAN training. Although this mode collapse is considered undesirable for GAN based image generation, we expect this pathological behavior is rather useful in our application. When mode collapse occurs, we observed that the most frequently appearing object in the dataset is generated while less frequently appearing objects are lost. Based on this observation, we regard that the target object corresponds to a major mode in a data distribution, while minor modes correspond to less frequently appearing objects, such as background objects. For localization, GAN models need to focus only on the major mode, not the minor modes. Using this as our motivation, we suggest that GAN presenting low diversity in image generation can be utilized for unsupervised object co-localization tasks. We believe our contribution lies at showing such potential for the first time. Our model receives a single image as an input, and outputs a heatmap, or a bounding box. The GAN model is trained in an unsupervised manner, and the heatmap is extracted from the discriminator using CAM. Then, the heatmap is post-processed to determine the bounding box for object localization. Within the whole process, neither supervision, nor any extra labeling information, such as negative sampling, is required or used. By leveraging publicly available datasets, we demonstrate the feasibility of GAN for addressing the problem of unsupervised object co-localization. In addition, we have found that the early GAN model _cite_ is better than state-of-the-arts GAN models _cite_ for localization. Furthermore, we show that quantitative and qualitative performance of our model is even comparable to the ones with weakly-supervised object localization, which utilizes external dataset and corresponding labels. To the best of our knowledge, our proposition is the first end-to-end deep neural network model for unsupervised object co-localization, and we believe that this method can serve as an important baseline for future co-localization researches.