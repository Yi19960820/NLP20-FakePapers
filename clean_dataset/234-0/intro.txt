Learning image representations has considerably enhanced image classification results compared to geometric features such as edge descriptors, or, SIFT and HOG _cite_ patch representations. Learning may thus seem to be a more promising direction for improving image analysis rather than refining geometric image analysis. This paper aims at showing that understanding how to take advantage of geometrical image properties can define image representations, providing competitive results with state of the art unsupervised learning algorithms. It shows that refining geometric image understanding remains highly promising for image classification. Supervised deep neural network learning achieves state-of-the-art results on many databases _cite_ . However, several works _cite_ have shown that the Alex-net _cite_ trained on ImageNet still performs very well on different databases such as Caltech or PASCAL VOC. The output of this neural network can thus be considered as a ``super SIFT'' image descriptor, which is used as an input to a linear SVM classifier _cite_ . It indicates that this deep network is capturing important generic image properties, which are not dependent upon the classes used for training. In the same spirit, unsupervised deep learning _cite_ as well as unsupervised bag of words _cite_ or dictionary learning with spatial pyramid _cite_ have improved classification results previously obtained with engineered feature vectors such as SIFT or HOG, on complex object recognition databases. However, these unsupervised learning algorithms are tailored to each databases. One may wonder whether their improved performances result from an adaptation to the specific properties of each databases, or whether these unsupervised representations capture refined geometric image properties compared to SIFT or HOG features. A scattering convolution network is constructed with predefined complex wavelet filters, which are adapted to geometric image variabilities _cite_ . It provides a mathematical and algorithmic framework to incorporate refined geometric image priors within the representation. Since images are projections of ND scenes under various view points, the main source of geometric image variabilities comes from rigid movements, and deformations resulting from perspective projections. An important issue is to build adaptive invariants to these sources of variability, which preserve essential information to discriminate different classes. A translation invariant scattering network was studied in _cite_ for digit image classification and texture recognition, but which was not powerful enough to classify complex objects as in Caltech or CIFAR. A translation and rotation invariant deep scattering network was introduced in _cite_ to classify textures with strong rotations and scalings. However, imposing rotation invariance is a prior which is too strong for image object and scene classifications, which are typically not fully rotation invariant. Section _ref_ introduces a scattering representation which is translation invariant, and which efficiently represents rotation variability without imposing full rotation invariance. It yields a representation which complements SIFT type coefficients, with coefficients incorporating interactions between scales and angles. This roto-translation scattering representation is nearly complete in the sense that good quality images can be recovered from roto-translation scattering coefficients _cite_ . It is also stable to additive perturbations and small deformations, which guarantees to avoid the type of instability observed in some deep networks _cite_ . In this architecture, the loss of information only appears at the final supervised classification stage, which computes invariants adapted to the classification task. It includes an orthogonal least square supervised feature selection followed by a linear or a Gaussian kernel SVM. This scattering representation is tested in Section _ref_ over Caltech and CIFAR data bases for object classification. It yields results which are well above all other representation which do not incorporate any learning, based on SIFT type features or with random weight deep networks. It also gives competitive results with state of the art unsupervised learning procedure adapted to each databases, which indicates that these unsupervised learning algorithm do not capture geometric transformations which are more powerful than rigid movements and small deformations. Computations can be reproduced with a software that is available at {\it http: //www.di.ens.fr/data/software} .