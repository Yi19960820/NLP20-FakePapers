Synthesis of medical images has many applications. One application is image augmentation, whereby a small dataset with low diversity is amplified by approximating and randomly sampling the underlying data distribution. This can facilitate the training of more robust machine learning algorithms by dramatically increasing the size and heterogeneity of the training dataset. This is especially useful in scenarios where the patient population is small, such as for rare diseases _cite_ . Secondly, in multi-institutional studies, there may be differences in imaging protocols such that certain imaging modalities are missing for a subset or all of the patients. It would therefore be desirable to produce a complete set of data by synthesizing the missing modalities (or even additional modalities) for all patients to improve algorithm performance _cite_ . For example, brain tumor segmentation performs best when multiple MR modalities (such as TN, TN, and FLAIR) are used _cite_ . Lastly, certain imaging modalities have downsides to their acquisition. For example, CT and PET imaging impart a high dose of radiation to the patient. Effective synthesis of CT from other imaging modalities would avoid unnecessary radiation exposure _cite_ and reduce the costs incurred due to instrument time and contrast agents _cite_ . The biomedical imaging community stands to gain from robust image synthesis methods. However, two key challenges exist with existing methods. Current techniques are unable to generate high resolution images, which are important for diseases with subtle pathological features. Secondly, image synthesis methods often neglect certain biological features that are critical for diagnosis, and therefore need to be well-represented. Here, we propose a method of addressing both of these challenges. Generative adversarial networks (GANs) have been used to generate synthetic images of unprecedented realism and diversity _cite_ . Applications in imaging-including biomedical imaging-have flourished, but have been confined to relatively small image sizes _cite_ . Recently, Karras et al. devised a training scheme for GANs called progressive growing of GANs (PGGANs) that can create photorealistic images at high resolutions, with images up to N _inline_eq_ N pixels being showcased in their work _cite_ . However, their application was limited to common image benchmarking datasets such as celebrity faces and natural scenes. Application of PGGANs to biomedical data with clinically-relevant imaging biomarkers has yet to be explored. In this paper, we propose an application of the PGGAN method to two classes of medical image: retinal fundus photographs with retinopathy of prematurity (ROP), and two-dimensional magnetic resonance images taken from a publicly-available, multi-modality glioma dataset (BraTS) . We show that application of PGGANs to these data produces images at high resolution that are both realistic and phenotypically diverse. We also demonstrate that preservation of fine-grained details of pathology may be improved by having the generator produce a segmentation of a structure of interest, which is criticized alongside the raw image by the discriminator. Lastly, we show that the latent space encodes clinically relevant information by inverting the generator and transforming real images into low dimensional representations.