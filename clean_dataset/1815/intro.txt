Performing inertial navigation and localization is a promising research direction with a vast number of applications ranging from robot navigation _cite_, pedestrian navigation _cite_, activity/health monitoring _cite_ to augmented reality _cite_ . Modern micro-electro-mechanical (MEMS) inertial measurements units (IMUs) are small (a few mm _inline_eq_), cheap (several dollars a piece), energy efficient and widely employed in smartphones, robots and drones. Unlike GPS, vision, radio or other sensor modalities, an inertial tracking solution is completely self-contained and suffers less from environmental impact. Hence, exploiting inertial measurements for accurate navigation and localization is of key importance for human and mobile agents. In this work we concentrate on inertial odometry for pedestrian tracking, as a promising technique for ubiquitous indoor/outdoor positioning. A major drawback and limitation of inertial measurements from low-cost IMUs is the impact of various error sources and biases, leading to unbounded error growth _cite_ . One common solution is to combine inertial sensor with camera as visual-inertial-odometry (VIO) _cite_ _cite_ _cite_, performing well in tracking mobile robots. For pedestrian tracking, IMU has to be attached on users' foot to take advantage of zero-velocity detection and update (ZUPT) for compensating inertial systems drifts _cite_ _cite_ . Pedestrian dead reckonings (PDRs) _cite_ _cite_ were proposed to estimate trajectories by detecting and updating steps. However, relying on strict assumptions, these model-based methods are too restrictive. VIOs require careful time synchronization and calibration, and have to operate in good light conditions. Given personal walking models, ZUPTs and PDRs are assumed to work under periodic pedestrian motion. Hence, the limitations of these handcrafted models prevent the inertial solutions in everyday usage. Recent emerging deep learning based inertial odometry technique, e.g. IONet _cite_ is capable of extracting features and estimating continuous trajectories directly from raw inertial streams without any handcrafted engineering, outperforming previous model-based approaches in terms of accuracy and robustness. Other data-driven methods _cite_ _cite_ learn to predict velocities in order to constrain system error drift, achieving competitive performance. There is growing interest in applying deep neural networks to learning motion from time-series data, due to its potential for model-free generalization. These data-driven approaches require a significant amount data for training, validation and testing. In addition, highly precise labels (ground-truth values for locations, velocities, and orientations) are extremely important in supervised training. Most existing datasets aim at collecting sensor data from vehicles, in which installed IMUs are high accuracy devices (fiber gyro) and combined together with GPS, e.g. KITTI _cite_ and Oxford RobotCar _cite_ . Other datasets, e.g. Tum VI _cite_, ADVIO _cite_ were collected for visual-inertial odometry with IMUs fixed in specific positions which does not reflect the challenges of everyday usage for example, a smartphone may be handheld, placed in a pocket or bag or even placed on a trolley. In these circumstances, the cameras are occluded. For conventional pedestrian dead reckoning, there is a lack of evaluation benchmarks, which impacts fair and objective comparison of different techniques. In this paper, we present and release the Oxford Inertial Odometry Dataset (OxIOD), with abundant data (N sequences and significant distances (N km in total) . For the majority of sequences, high precision labels with locations, velocities, and orientations are provided by an Optical Motion Capturing System (Vicon) _cite_ for training and evaluating models. Longer range sequences use a Google Tango visual-intertial odometry tracker _cite_ to provide approximate ground-truth. These data were collected across different users/devices, various motions, and locations. We implement a deep learning algorithm and train and evaluate it to show the effectiveness of our proposed dataset. It is our hope that this dataset can boost objective research in learning based methods in inertial navigation.