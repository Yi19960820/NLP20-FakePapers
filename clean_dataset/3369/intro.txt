Over five million cases of skin cancer are newly diagnosed in the United States annually _cite_ . Early detection of melanoma, one of the most lethal forms of skin cancer, is critical in finding curable melanomas as well as increasing survival rate _cite_ . With a large influx of dermoscopy images, arriving of inexpensive consumer dermatoscope attachments for smart phone _cite_ and a growing shortage of dermatologists _cite_, automatic dermoscopic image analysis plays an essential role in timely skin cancer diagnosis. Especially, lesion segmentation is one of the most important steps in dermoscopy image access. However, automatic lesion segmentation from dermoscopy images is a challenging task. The relatively low contrast and obscure boundaries between early stage skin lesions and normal skin regions make it very difficult to distinguish lesion area from normal skin region. The situation deteriorates rapidly when skin lesions are blurred or excluded by artifacts such as natural hairs, veins, artificial ruler marks, color calibration charts, and air bubbles, etc. Some example images from "ISBI N Skin Lesion Analysis Towards Melanoma Detection Challenge" (ISBIN SLATMDC) _cite_ are shown in Fig. _ref_ . Many works have been done to try to deal with this difficult problem. Previously, some researchers proposed to segment lesions based on hand-crafted features _cite_ . Recently, convolutional neural network (CNN) is adopted to improve medical image segmentation accuracy _cite_ . Deep CNN based skin cancer recognition has been initially proven to achieve dermatologist-level classification accuracy _cite_ . Fully convolutional neural network (FCNN) has shown promising segmentation results in natural images (PASCAL VOC) by fusing multi-scale prediction maps from multiple layers in itself _cite_ . FCNN is based on a simple end-to-end learning and multi-scale contextual information is automatically explored in FCNN framework. Inspired by _cite_, we propose a new FCNN framework for skin lesion segmentation in this paper. We pick up the VGG N-layer net (publicly available from the Caffe model zoo) pretrained in ImageNet, discard its last classification layer, and replace all fully connected layers by convolution layers with randomly initialized weights. The weights in the remaining layers are kept to tackle small medical image dataset problem based on transfer learning. We add skipping layers to fuse multi-scale prediction maps from multiple layers. Different from _cite_ which fuses prediction maps by pixel-wise plus operation, we treat multi-scale prediction maps as multi-scale feature maps and fuse them by concatenation operation. With our concatenating fusing strategy to keep fused features in higher space, we can capture more distinguishing local features and global features. Then we add a randomly initialized _inline_eq_ convolution layer as the last layer to finish prediction with fused features as inputs. In _cite_, very deep fully convolutional residual network (FCRN) was proposed to do skin lesion segmentation. The authors in _cite_ focused on residual network and very deep net (more than N layers) . However, our proposed FCNN has different structures and is relatively shallower (less than N layers) . Our experimental results are still comparable with that from _cite_ . Our major contributions in this paper are summarized as follows: The remainder of this paper is organized as follows. We detail our method in Section _ref_ . Experimental results are reported in Section _ref_ . Section _ref_ is our discussion and conclusion.