Imaging technologies have been striving to capture the rich three-dimensional scene around us as it is. But, since ages conventional cameras have only been able to project the scene to a two-dimensional photograph. Light field imaging is a step closer in this direction. Light field captures different perspective shifts of the same scene. It enables post capture facilities like refocusing and view-point changes. This is realized by jointly modifying the camera optics and computationally processing the recorded data. The advent of light field imaging technology into affordable commercial cameras like Lytro _cite_ has renewed research interests resulting its applications in areas like cinematography, ND imaging, AR and VR etc. Many methods have been proposed for capturing light field data _cite_ . Of these, micro-lens array based acquisition by Ng et al. _cite_ has successfully been adopted into lytro camera _cite_ . Most of these methods suffer from a common problem. Due to limited sensor resolution trade-off arises between the spatial and angular resolution. These cameras have to sacrifice the spatial resolution to gain angular information. This hurts the megapixel-hungry trend with the consumer cameras. Recently, high resolution light field imaging has received a lot of attention from the research community. Early attempts used computer vision techniques to enhance spatio-angular resolution by exploiting the redundancy in ND light field _cite_ . Compressive light field imaging works backed by compressive sensing (CS) theory attempt to reconstruct full sensor resolution light field either from a set of a coded images _cite_ or a single image _cite_ . Since the reconstruction is ill-posed, data priors are essential. With the success of deep learning techniques for low-level image processing, recently, some works have proposed to use it for high resolution light field imaging _cite_ . In this work, we propose to use a deep neural network for reconstructing high resolution light field _inline_eq_ from a single coded image _inline_eq_ . Our pipeline involves N) center view reconstruction from the coded image N) disparity map estimation from the center view and coded image and N) warping center view using the disparity map to reconstruct light field. We show our results using simulations on Lytro illum dataset by Kalantari et al. _cite_ . Our major contributions are as follows: