When human look at an image, he/she always focus on a subset of the whole image, which is called visual attention. Visual attention is a neurobiological process to filter out irrelevant information and highlight most noticeable foreground information. A variety of computational models have been developed to simulate this kind of mechanism, which can be used in object tracking~ _cite_, image montage~ _cite_ and image compression~ _cite_ . In general, saliency detection algorithms can be categorized into two groups: top-down~ _cite_ or bottom-up~ _cite_ approaches. Top-down approaches are task-driven and need supervised learning. While bottom-up approaches usually use low-level cues, such as color features, distance features and heuristic saliency features. One of the most used heuristic saliency features is contrast, such as pixel-based or patch-based contrast. Most previous works on saliency detection focus on ND images. To our thoughts, this remains limited potential for further research. First, ND data instead of ND is more suitable for real application, second, as visual scene become more and more complex, utilizing ND data only is not enough for extracting salient objects. Recent advances in ND data acquisition techniques, such as Time-of-Flight sensors and the Microsoft Kinect, have motivated the adoption of structural features, improving the discrimination between different objects with the similar appearance. Saliency detection on RGB-D images will expedite a variety of real applications, such as ND content surveillance, retrieval, and image recognition. In addition to RGB information, depth has shown to be a practical cue for saliency estimation~ _cite_ . However, it is still ineffective to train a network due to the limited size of annotated RGB-D data. Besides, how to integrate the additional depth information into the RGB framework remains to be a key issue that is needed to be addressed. To resolve the above-mentioned limitation, in this paper, we propose a novel prior-model guided depth-enhanced network (PDNet) . The PDNet is composed of a master network and sub-network. The master network is a convolution-deconvolution pipeline. The convolution stage serves as a feature extractor that transforms the input image into hierarchical rich feature representation, while the deconvolution stage serves as a shape restorer to recover the resolution and segment the salient object in fine detail from background. The sub-network can be treated like an encoder convolution architecture and it process depth map as input and enhance the robustness of the master network. To address the problem of insufficient RGB-D data for training, we employ a large dataset to pre-train our master network. This pre-train setup before training our network using RGB-D data has proved to contribute dramatically to accuracy improvement. Fig.N illustrates the pipeline of our model. In summary, the main contributions of this work are as follows: