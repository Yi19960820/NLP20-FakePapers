Haze is a common atmospheric phenomena produced by small floating particles such as dust and smoke in the air. These floating particles absorb and scatter the light greatly, resulting in degradations on image quality. Under severe hazy conditions, many practical applications such as video surveillance, remote sensing, autonomous driving etc are easily put in jeopardy, as shown in Figure~ _ref_ . High-level computer vision tasks like detection and recognition are hardly to be completed. Therefore, image dehazing (a.k.a haze removal) becomes an increasingly desirable technique. Being an ill-posed restoration problem, image dehazing is a very challenging task. Similar to other ill-posed problem like super-resolution, earlier image dehazing methods assumed the availability of multiple images from the same scene. However, in practical settings, dehazing from single image is more realistic and gains more dominant popularity _cite_ . Therefore, in this paper, we focus on the problem of single image dehazing. Most state-of-the-art single image dehazing methods _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ _cite_ are based on a classic atmospheric scattering model _cite_ which is formulated as following Equation _ref_: where, _inline_eq_ is the observed hazy image, _inline_eq_ is the clear image. _inline_eq_ is called medium transmission function. _inline_eq_ is the global atmospheric light. _inline_eq_ represents pixel locations. The physical model explained the degradations of a hazy image. The medium transmission function _inline_eq_ is a distance dependent factor that reflects the fraction of light reaching camera sensor. The atmospheric light _inline_eq_ indicates the intensity of ambient light. It is not difficult to find that haze essentially brings in non-uniform, signal-dependent noise, as the scene attenuation caused by haze is correlated with the physical distance between object's surface and the camera. Apart from a few works that focused on estimating the atmospheric light _cite_, most of popular algorithms concentrate more on accurately estimation of transmission function _inline_eq_ with either prior knowledge or data-driven learning. Based on the estimated _inline_eq_ and _inline_eq_, the clear image _inline_eq_ is then recovered by using following Equation~ _ref_ . Though tremendous improvements have been made, as we know, the traditional separate pipeline does not directly measure the objective reconstruction errors. The inaccuracies resulted from both transmission function and atmospheric light estimation would potentially amplify each other and hinder the overall dehazing performance. The recently proposed AOD-Net _cite_ was the first end-to-end trainable image dehazing model. It reformulated a new atmospheric scattering model from the classic one by leveraging a linear transformation to integrate both the transmission function and the atmospheric light into an unified map _inline_eq_, as shown in Equation~ _ref_ . where the _inline_eq_ was an input-dependent transmission function. A light-weight CNN was built to estimate the _inline_eq_ map, and jointly trained to further minimize the reconstruction error between the recovered output _inline_eq_ and the ground-truth clear image. Going deeper, we consider the general relationship between observed input _inline_eq_ and recovered output _inline_eq_ as _inline_eq_, where _inline_eq_ represents some potential highly nonlinear transformation function whose parameters set is _inline_eq_ . Then the relationship represented by AOD-Net could be viewed as a specific case of the general function _inline_eq_ . In this paper, we argue that the formation of hazy image has complicated mechanism, and the classic atmospheric scattering model _cite_ is just an elegant simplified physical model based on the assumption of single-scattering and homogeneous atmospheric medium. There potentially exists some highly nonlinear transformation between the hazy image and its haze-free ground-truth. With that in mind, instead of limitedly learning the intermediate transmission function or its reformulated one from classic scattering model as AOD-Net did, we propose to build a real complete end-to-end deep network from an observed hazy image _inline_eq_ to its recovered clear image _inline_eq_ . To avoid making efforts on find "real" intermediate physical model, our strict end-to-end network pay much concerns on the qualities of dehazed output. We employ an encoder-decoder architecture similar to the U-Net _cite_ to directly learn the input-adaptive restoration model _inline_eq_ . The encoder convolves input image into several successive spatial pyramid layers. The decoder then successively recovers image details from the encoded feature mappings. In order to make full use of input information and accurately estimate structural details, progressive feature fusions are performed on different level mappings between encoder and decoder. We evaluate our proposed network on two public image dehazing benchmarks. The experimental results have shown that our method can achieve great improvements on final restoration performance, when compared with several state-of-the-art methods. The contributions of this paper are two-fold: