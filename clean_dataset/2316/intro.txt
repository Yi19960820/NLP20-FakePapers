Deep learning based architectures, especially convolutional neural networks (CNN), have become the tool of choice for processing image data, after their immense success in image classification~ _cite_ . For image segmentation, fully convolutional neural networks (F-CNNs) have set the benchmark performance in medical imaging~ _cite_ and computer vision~ _cite_ . The basic building block for all these architectures is the convolutional layer, which learns filters capturing local spatial pattern along all the input channels and generates feature maps jointly encoding the spatial and channel information. This produces feature maps that form a rich representation of the original input. A lot of recent work has aimed at improving the joint encoding of spatial and channel information~ _cite_, but much less attention has been given towards encoding of spatial and channel-wise patterns . A recent work attempted to address this issue by explicitly modeling the interdependencies between the channels of feature maps to enhance its representation. This is accomplished by an architectural component called squeeze \& excitation (SE) block~ _cite_, which can be seamlessly integrated as an add-on within a CNN. This SE block factors out the spatial dependency by global average pooling to learn a channel specific descriptor, which is used to rescale the input feature map to highlight only useful channels. As this component `squeezes' along spatial domain and `excites' or reweights along the channels, it is termed as squeeze \& excitation block. A convolutional network with such SE blocks achieved the best performance in the ILSVRC N image classification competition on the ImageNet dataset, indicating its efficiency~ _cite_ . In this article, we aim at leveraging the high performance of SE blocks for image classification to image segmentation, by integrating them within F-CNNs. We refer to the previously proposed SE block~ _cite_ as channel SE (cSE), because it only excites channel-wise, which has been shown to be highly effective for image classification. The advantage of using such a block is that every intermediate layer has the total receptive field of the input image, due to the global average pooling. We hypothesize that the pixel-wise spatial information is more informative for fine-grained segmentation tasks of highly complex anatomies, common in medical imaging. Hence, we introduce an alternate SE block, which `squeezes' along the channels and `excites' spatially, termed SE (sSE) . This is complementary to the cSE block, as it does not change the receptive field, but provides spatial attention to focus on certain regions. Finally, we propose to combine these two blocks in spatial and channel SE blocks (scSE) that recalibrate the feature maps separately along channel and space, and then combines the output. This aggregates the unique properties of each of the blocks and encourages feature maps to be more informative both spatially and channel-wise. We explore different aggregation strategies for both blocks with respect to the segmentation accuracy. To the best of our knowledge, this is the first time that squeeze \& excitation is proposed for neural networks and the first integration of squeeze \& excitation in F-CNNs. We integrate the existing (cSE) and proposed (sSE, scSE) SE blocks within three state-of-the-art F-CNN models for image segmentation to demonstrate that SE blocks are a generic network component to boost performance. We evaluate the segmentation performance in three challenging medical applications: whole-brain, whole-body and retinal layer segmentation. In whole-brain segmentation, we automatically parcellate N cortical and subcortical structures on magnetic resonance imaging (MRI) TN-weighted brain scans. In whole-body segmentation, we label N abdominal organs on contrast-enhanced CT scans. In retinal layer and fluid segmentation, we segment retinal Optical Coherence Tomography (OCT) scans into N layers and accumulated fluid in subjects with diabetic macular edema. This work is an extension of our early work~ _cite_, where we further improved the method, provide details, and added more extensive experiments together with an analysis of SE network dynamics during training. F-CNN architectures have been extensively used in a wide range of medical image segmentation tasks, providing state-of-the-art performance. One of the seminal F-CNN models, U-Net~ _cite_ was proposed for segmenting electron microscope scans. U-Net has an encoder-decoder based structure, separated by a bottleneck layer. Skip connections are included between feature maps of encoder and decoder with similar spatial resolution, to provide more contextual information to the decoder and aiding flow of gradient through the network. It was successfully leveraged for segmentation for multiple modalities of medical imaging. Skip-DeconvNet (SD-Net) ~ _cite_ was introduced, which builds on top of U-Net, modifying the decoding path by using unpooling layers~ _cite_ to promote spatial consistency in the segmentation. It is learned by optimizing a joint loss function of weighted logistic loss and Dice loss, specifically designed to address the challenge of class imbalance, which is very common in medical imaging. SD-Net was successfully used for whole-brain segmentation of MRI scans and retinal layer segmentation task in OCT scans~ _cite_ . A more recent architecture introduces dense connectivity within CNNs~ _cite_, to promote feature reusability within layer making representation learning more efficient. This idea was incorporated within F-CNNs by having dense connections within the encoder and decoder blocks, unlike U-Net and SD-Net which uses normal convolutions. Such architectures, termed fully convolutional DenseNet (FC-DenseNet) ~ _cite_, further boosted segmentation performance. A variant of this FC-DenseNet, has been used for the task of whole brain segmentation in MRI TN scans~ _cite_ . In this article, we select these commonly used F-CNN architectures as references to examine the effectiveness of the SE blocks.