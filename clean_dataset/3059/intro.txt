With the growing success of deep learning in the field of computer vision, it is natural for developers and researchers alike to be interested in deploying these new vision algorithms in devices such as smart home cameras, robots, drones, etc. However, popular computer vision algorithms that leverage deep neural nets often require high end GPUs (Graphics Processing Units) to achieve desired performance. This constraint heavily limits the number of algorithms researchers can experiment with. To overcome this problem, researchers have tried different approaches, such as designing more efficient deep learning networks like MobileNet _cite_, making computing add-on modules like Intel Movidius _cite_, or creating dedicated chips and processors such as NeuPro by CEVA _cite_ The idea of using Cloud infrastructure to aid low resource devices, is first introduced by James Kuffner _cite_, has inspired a number of research projects _cite_ _cite_ . As more and more Cloud Computing services provide deep learning frameworks, deep learning algorithms are becoming more accessible, especially when GPU enabled cloud machines provided by Amazon AWS, Google Cloud, Paperspace etc. are offering substantial computing power at affordable prices. Moreover, these cloud machines tend to have relatively high-bandwidth networks, making them suitable for real-time applications. For instance, the Nvidia Gaming as a Service (GaaS) _cite_ offers players who do not have access to high-end GPUs the opportunity to run their games in the cloud and render them on their personal devices. In this paper, we are interested in using these resources to enable low resource devices to run computationally intensive real-time computer vision algorithms. Specifically, object detection is chosen as the task for investigation. As more and more internet of things, robotics, and mobile devices become equipped with cameras, object detection will be increasingly important as it is the foundation on which higher level tasks such as navigation, planning, and surveillance can be built. State of the art object detection algorithms all heavily rely on powerful GPUs to achieve a desirable accuracy and frame-rate. In order to achieve similar performance in low computing power devices, we offload the computing tasks to a GPU enabled cloud instance. This paper makes the following contributions: The paper is organized as follows: section II reviews the current research in the field of deep learning for object detection and other efforts in running deep neural nets on low resource devices. Section III describes the research objective and problem formulations. Section IV gives the system architecture, and Section V will describe our technical approach and methodology. System experiments and performance analysis will be in section VI, while section VII concludes the paper.