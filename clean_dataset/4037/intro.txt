Text detection is a procedure that determines whether text is present in natural images and, if it is, where each text instance is located. Text in images provides rich and precise high-level semantic information, which is important for numerous potential applications such as scene understanding, image and video retrieval, and content-based recommendation systems. Consequently, text detection in natural scenes has attracted considerable attention in the computer vision and image understanding community _cite_ . However, text detection in the wild is still a challenging and unsolved problem because of the following factors. First, a text image background is very complex and some region components such as signs, bricks, and grass are difficult to distinguish from text. Second, scene text can be diverse and usually exits in various colors, fonts, orientations, languages, and scales in natural images. Furthermore, there are highly confounding factors, such as non-uniform illumination, strong exposure, low contrast, blurring, low resolution, and occlusion, which pose hard challenges for the text detection task. In the last few decades, sliding window-based and connected component-based methods have become mainstream approaches to the text detection problem. Sliding window-based methods _cite_ use different ratios and scales of sliding windows to search for the presence of possible text positions in pyramid images, incurring a high computational cost. Connected component based methods, represented by maximally stable extremal regions (MSERs) _cite_ and the stroke width transform (SWT) _cite_, extract character candidates and group them into word or text lines. In particular, previous approaches applying MSERs as the basic representation have achieved promising performance in the ICDAR N and N robust text detection competitions _cite_ . However, MSERs focuses on low-level pixel operations and mainly accesses local character component information, which leads to poor performance in some challenging situations, such as multiple connected characters, segmented stroke characters, and non-uniform illumination, as mentioned in _cite_ . Further, this bottom-up approach gives rise to sequential error accumulation in the total text detection pipeline, as stated in _cite_ . Rather than extract character candidates, Jaderberg _cite_ applied complementary region proposal methods called edge boxes (EB) _cite_ and aggregate channel feature (ACF) _cite_ to perform word detection and acquired a high word recall with tens of thousands of word region proposals. They then employed HOG features and a random forest classifier to remove non-text region proposals and hence improve precision. Bounding box regression was also used for more accurate localization. Finally, using a large pre-trained convolutional neural network (CNN) to recognize the detected word-cropped images, they achieved superior text spotting and text-based image retrieval performance on several standard benchmarks.. Actually, the region proposal generation step in the generic object detection pipeline has attracted much interest. In recent studies, object detection models based on region proposal algorithms to hypothesize class-specific or class-agnostic object locations have achieved state-of-the-art detection performance _cite_ . However, standard region proposal algorithms such as selective search (SS) _cite_, MCG _cite_, EB _cite_, generate an extremely large number of region proposals. This leads to high recall, but burdens the follow-up classification and regression models and is also relatively time-consuming. In order to address these issues, Ren _cite_ proposed region proposal networks (RPNs), which computed region proposals with a deep fully CNN. They generated fewer region proposals, but achieved a promising recall rate under different overlap thresholds. Moreover, RPN and Fast R-CNN can be combined into a joint network and trained to share convolutional features. Owing to the above innovation, this approach achieved better object detection accuracy in less time than Fast R-CNN with SS _cite_ on PASCAL VOC N and N. In this paper, inspired by _cite_, our motivation is to design a unified framework for text characteristic region proposal generation and text detection in natural images. In order to avoid the sequential error accumulation of bottom-up character candidate extraction strategies, we focus on word proposal generation. In contrast to previous region proposal methods that generate thousands of word region proposals, we are motivated to reduce this number to hundreds while maintaining a high word recall. To accomplish this, we propose the novel inception RPN (Inception-RPN) and design a set of text characteristic prior bounding boxes to hunt high-quality word region proposals. Subsequently, we present a powerful text detection network by incorporating extra ambiguous text category (ATC) information and multi-level region of interest (ROI) pooling into the optimization process. Finally, by means of some heuristic processing, including an iterative bounding box voting scheme and filtering algorithm to remove redundant boxes for each text instance, we achieve our high-performance text detection system, called DeepText. An overview of DeepText is shown in Fig. N. Our contributions can be summarized by the following points. (N) We propose inception-RPN, which applies multi-scale sliding windows over the top of convolutional feature maps and associates a set of text characteristic prior bounding boxes with each sliding position to generate word region proposals. The multi-scale sliding-window feature can retain local information as well as contextual information at the corresponding position, which helps to filter out non-text prior bounding boxes. Our Inception-RPN enables achieving a high recall with only hundreds of word region proposals. (N) We introduce the additional ATC information and multi-level ROI pooling (MLRP) into the text detection network, which helps it to learn more discriminative information for distinguishing text from complex backgrounds. (N) In order to make better use of intermediate models in the overall training process, we develop an iterative bounding box voting scheme, which obtains high word recall in a complementary manner. Besides, based on empirical observation, multiple inner boxes or outer boxes may simultaneously exist for one text instance. To tackle this problem, we use a filtering algorithm to keep the most suitable bounding box and remove the remainders. (N) Our approach achieves an F-measure of N and N on the ICDAR N and N robust text detection benchmarks, respectively, outperforming the previous state-of-the-art results. The remainder of this paper is set out as follows. The proposed methodology is described in detail in Section N. Section N presents our experimental results and analysis. Finally, the conclusion is given in Section N.