Motivated by the clinical problem of intrapapillary capillary loops (IPCL) classification, we introduce a novel dataset containing N frames from N patients (see table _ref_ for more details), and a novel unified framework for automatic feature extraction, classification and visual interpretability of results. We present a novel convolutional network architecture that focuses on the interpretability of the results as a design constraint for the network and serves as a baseline for quantitative comparison of results with future methods. We compare the visual features highlighted in the heatmaps produced by the network with those that are clinically relevant to produce a diagnosis. In the Computer-Assisted Interventions (CAI) community labelled data is often scarce. Deep learning has become extremely popular due to its success in tasks such as classification and segmentation, but a large amount of data is typically required to capture the variability of the data across patients. As researchers in this area, we are also faced with additional challenges. Clinical collaborators are interested in interpreting the results coming from computer-assisted systems. That is, understanding the process followed by deep learning approaches to make a diagnosis. This includes analysing which features present in the images lead to a certain output and if those coincide with the ones that they analyse during clinical examination of the data. Conversely, it is also interesting to discover whether automatically extracted features are different from the ones currently used in clinical practice but can nonetheless lead to a correct diagnosis. Using reduced datasets can potentially lead to models that do not generalise well. While it is true that there are efforts to build large scale CAI databases _cite_, in this paper, we have concentrated our efforts on the interpretability of classification results coming from a fully convolutional neural network trained on a small dataset. Squamous cell carcinoma (SCC) is the most frequent kind of oesophageal cancer in Asia _cite_, presenting rapidly increasing numbers in the western world in recent decades too. Early diagnosis-and resection-play a key role to increase the chances of survival _cite_, as superficial lesions present low rates of lymphatic dissemination. Detection is currently achieved by screening programs on high risk populations _cite_ . Narrow-Band Imaging magnifying endoscopy (NBI-ME) is the state-of-the-art technique employed for screening _cite_ . In addition to early diagnosis, a precise estimation of depth of invasion is crucial. Lesions that are closer to the oesophageal surface (mucosal layer) can be treated by minimally invasive endoscopic therapy rather than surgery _cite_ . NBI-ME facilitates the visualisation of micro-vascular patterns, called intrapapillary capillary loops (IPCL), which are linked to early squamous cell carcinoma and present focal, subtle, and easily missed visual features, particularly in centres with a low amount of cases. It has been also shown that the thickness and tortuosity of IPCL patterns is highly correlated with histological state and depth of invasion _cite_ . Hence, having an automated red-flag system that analyses each video frame in real-time could potentially help detect subtle IPCL patterns that might be difficult to distinguish by unspecialised endoscopists (see figure _ref_) . Recent work has explored different approaches to analyse the implicit attention mechanisms of convolutional neural networks. In _cite_, authors produce attention heatmaps as a linear combination of feature maps from the last convolutional layer. The weighting coefficients are extracted from the fully connected output neurons. Zhou et al. _cite_ allow for a fully convolutional classification by means of Global Average Pooling (GAP) . When GAP is omitted (at inference), instead of a vector of class probabilities, a Class Activation Map (CAM) is automatically generated. In addition, these maps enable for accurate object localization, a task for which the network has not been trained for.