Conventional imaging sensors detect signals lying on regular grids. On the other hand, recent advances and proliferation in sensing have led to new imaging signals lying on irregular domains. An example is brain imaging data such as Electroencephalography (EEG) and Magnetoencephalography (MEG) . Some example of MEG data used in our experiments is shown in Figure _ref_ (a) . The color in Figure _ref_ (a) is indicative of the intensity and influx / outflux of magnetic fields. The data are different from conventional ND image data in that they lie irregularly on the brain structure. The data are captured by a recumbent Elekta MEG scanner with N sensors distributed across the scalp to record the cortical activations for N milliseconds (Figure _ref_ (b)) . Therefore, MEG are high-dimensional spatiotemporal data often degraded by complex, non-Gaussian noise. For reliable analysis of MEG data, it is important to learn discriminative, low-dimensional intrinsic representation of the recorded data _cite_ . Several methods have been applied to perform dimensionality analysis of brain imaging data, e.g., principal component analysis (PCA) and its numerous variants (see _cite_ for a recent review) . In addition, it has been recognized that there are patterns of anatomical links, statistical dependencies or causal interactions between distinct units within a nervous system~ _cite_ . By modeling brain imaging data as signals residing on {\em brain connectivity graphs}, some methods have been proposed to apply the recent graph signal processing _cite_ to analyze brain imaging data _cite_ . Deep learning, on the other hand, has achieved breakthroughs in image and video analysis, thanks to its hierarchical neural network structures with layer-wise non-linear activation and high capacity _cite_ . As an important deep learning model, autoencoders (AE) / stacked autoencoders (SAE) has achieved state-of-the-art performance in extraction of meaningful low-dimensional representations for input data in an unsupervised way _cite_ . However, conventional SAEs fail to take advantage the graph information when the inputs are modeled as graph signals. In this work, we propose new AE-like neural networks that tightly integrate graph information for analysis of high-dimensional graph signals such as brain imaging data. In particular, we propose new AE networks that directly integrate graph models to extract meaningful representations. Our work leverages efficient graph filter design using Chebyshev polynomial _cite_ and recent work on deep learning on graph-structured data _cite_ . Among these models, Convolutional Nets (ConvNets) are of great interest since they achieve state-of-the-art performance for images _cite_ by extracting local features to build hierarchical representations. Image signals residing on regular grids are suitable for ConvNets. However, the problem to generalize ConvNets to signals on irregular domains, i.e. graphs, is a challenging one _cite_ . _cite_ proposed to convert the vertices on a graph into a sequence and extract locally connected regions from graphs, where the convolution is performed in spatial domain. On the contrary, the convolution in _cite_ is performed in spectral domain using recent graph signal processing theory _cite_ . _cite_ presented a formulation of ConvNets on graph in spectral domain and proposed fast localized convolutional filters. The filters are polynomial Chebyshev expansions where the polynomial coefficients are the parameters to be learned. _cite_ applied the first order approximation of _cite_ and achieved good results on the semi-supervised classification task on social networks. This work is inspired by _cite_ but focuses on new AE-like networks to extract meaningful representation in an unsupervised manner. The proposed method is depicted in Figure _ref_ . First, brain imaging data is modelled as signals residing on connectivity graphs estimated with causality analysis. Then, the graph signals are processed by the ConvNets on graph, which output high-dimensional, rich feature maps of the graph signals. Subsequently, fully connected layers are used to extract low dimensional representations. During testing, this low-dimensional representations are subject to a linear SVM classifier to evaluate their inclusion of discriminative information. Similar to _cite_, we also use the first order approximation in Chebyshev expansions _cite_ . However, our network structure is different in that we propose an integration of ConvNets on graph with SAE. The entire network is trained end-to-end in an unsupervised way to learn the low-dimensional representations for the input brain imaging data. In other words, our work is a method of dimensionality reduction. Authors in _cite_ propose to use graph Laplacian to regularize the learning of autoencoder. Their work uses a {\em sample graph} to model the underlying data manifold. Their approach is significantly different from our work that integrates graph structure into the network. Moreover, it is non-trivial to apply their method to our problem which encodes sensor correlation with a {\em feature graph} . Our contributions are threefold. First, we model the brain imaging data as graph signals with suitable brain connectivity graphs. Second, we propose new AE-like network structure that integrates ConvNets on graph with the SAE; the system is trained end-to-end in an unsupervised way. Third, we perform extensive experiments to demonstrate that our model can extract more robust and discriminative representations for brain imaging data. The proposed method can be useful for other high-dimensional graph signals.