Face Hallucination (FH) is a domain specific problem which generates high resolution (HR) face images from low resolution (LR) inputs. Different from generic image super resolution (SR) methods, FH exploits specific facial structures and textures. It generates high quality face images compared with generic image SR methods. This activates a series of FH applications ranging from image editing to video surveillance. More generally, FH is taken as a preprocessing step for face related applications. The state-of-the-art FH methods transfer facial details from HR training images to LR inputs. They aim to exploit the relationship between LR and HR images either globally or locally. One of the solutions is to align face images in pixel-wise precision between the input and training images. So dense correspondences on the training images can be established and HR facial details can be transferred into LR input image in the form of bayesian inference _cite_ or image gradient _cite_ . The transferred result usually contains more details on the facial component compared with the ones generated using generic image SR techniques. Despite the demonstrated success, the quality of FH results greatly relies on feature matching between training and input images. Because of the limited texture on the LR input (e.g., _inline_eq_), it is difficult to extract handcrafted features such as SIFT _cite_ to make a precise description, especially around facial components (i.e., nose, eyes, and mouth) . Such a limitation prevents these features to accurately establish the HR correspondence in the training images. It leads to the incorrect detail transfer and the results will be erroneous. As shown in Fig. _ref_, the nose generated from _cite_ in (b) is in different shape from that of the ground truth in (f) . Recently, Convolutional Neural Network (CNN) has been demonstrated effective in image SR _cite_ . It is formulated as a general form of sparsity representation _cite_ and aims to minimize the pixel-wise difference between network output and ground truth. It achieves state-of-the-art performance on natural images where texture patterns uniformly reside in low frequency base and high frequency details. However, direct applying CNN for FH will blur the facial structure because of the uniqueness of component details. As shown in Fig. _ref_ (c) and (d), the results generated using CNN _cite_ or ResNet _cite_ models cannot enrich the high frequency details around noses. Meanwhile, finetuning their model using face images can not make a noticeable improvement. This indicates that CNN based models can not be directly adopted on FH due to the domain specific properties. In this paper, we Learn to hallucinate face images via Component Generation and Enhancement (LCGE) . Different from existing end-to-end CNN networks, we propose a two-stage framework for FH. The first stage learns a mapping function to reconstruct the facial structure of the LR input, which benefits the establishment of HR correspondences. This mapping process is formulated via five CNNs. Each CNN corresponds to one facial component (i.e., eyes, eyebrows, noses, mouth and the remaining region) . The input face image is thus divided into five subregions and reconstructed independently using CNN. The advantage of the learned facial component is that the texture information is enriched, which alleviates the matching difficulty of LR images. In the second stage, we generate facial components for both training and input images. And a patch-wise K-NN search is performed for each input component. In this way, we can accurately establish HR correspondences without facial alignment. Then we regress to synthesize HR facial structures with fine grained details. However, the regression is conducted on different subjects, which synthesizes HR structures in different illuminations from our desired output. Finally, the details from the HR structures are transferred to the facial components based on edge-aware image filtering. It can successfully recover the missing details to enhance the components. As a result, the output image well approximates the ground-truth image in both global appearance and facial details. The contributions of this work are summarized as follows: