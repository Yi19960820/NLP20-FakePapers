Given a graph _inline_eq_ with _inline_eq_ denoting the _inline_eq_ nodes and _inline_eq_ representing the edges. Let _inline_eq_ be the corresponding adjacency matrix and _inline_eq_ be the feature set of nodes, where _inline_eq_ denotes the attribute vector for node _inline_eq_ . The aim of our graph based feature diffusion is to learn a feature representation _inline_eq_ for each node by incorporating the contextual information of the other node representations. In the following, we provide three kinds of graph based feature diffusion model _inline_eq_, as summarized in Table N. Similar diffusion models have been commonly used in ranking and label propagation process ~ _cite_ . Differently, in this paper, we propose to explore them for problem whose aim is to learn a contextual feature representation for each graph node. (N) Graph Laplacian diffusion Motivated by manifold ranking~ _cite_, we propose to compute the optimal diffused representation _inline_eq_ by solving the following optimization problem: where _inline_eq_ denotes the diffused feature of node _inline_eq_ . The first term conducts feature diffusion/propagation on graph while the second term encourages to preserve the original feature information _inline_eq_ in diffusion process. It is known that, the optimal closed-form solution for this problem is given by where _inline_eq_ and _inline_eq_, and _inline_eq_ is the Laplacian of graph. (N) Graph normalized Laplacian diffusion One can also compute the optimal diffused representation _inline_eq_ by solving the following normalized optimization problem ~ _cite_: The optimal closed-form solution for this problem is given by where _inline_eq_ is the normalized Laplacian of the graph and _inline_eq_ . (N) Graph random walk diffusion Another method to formulate the feature diffusion is based on random walk with restart (RWR) model ~ _cite_ and obtain the equilibrium representation on graph. In order to do so, we first define a transition probability matrix as Then, the RWR is conducted on graph and converges to an equilibrium distribution _inline_eq_ . Formally, it conducts update as where _inline_eq_ is the jump probability. We can obtain the equilibrium representation as Table N summarizes the feature diffusion results of the above three models. In additional to the above three models, some other models can also be explored here ~ _cite_ . There are three aspects of the above three diffusion models. (N) They conduct feature diffusion while preserve the information of original input feature _inline_eq_ in feature representation process. (N) They have explicit optimization formulation. The equilibrium representation of these models can be obtained via a simple closed-form solution. (N) They can be naturally extended to address the data with multiple graph structures, as shown in \S N. Graph embedding techniques have been widely used in dimensionality reduction and label prediction. Given a graph _inline_eq_ with adjacency matrix _inline_eq_ and _inline_eq_ . The aim of graph embedding is to generate a low-dimensional representation _inline_eq_ and _inline_eq_ for node _inline_eq_ . One popular way is to utilize linear embedding, which assumes that where _inline_eq_ denotes the linear projection matrix.