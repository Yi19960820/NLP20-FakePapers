Convolutional neural networks (CNNs) handle the case where filters extend beyond the image boundary using several heuristics, such as, or padding. These schemes are applied in an ad-hoc fashion and, being weakly related to the image content and oblivious of the target task, result in low output quality at the boundary. In this paper, we propose a simple and effective improvement that learns the boundary handling itself. At training-time, the network is provided with a separate set of boundary filters. At testing-time, we use these filters which have learned to extrapolate features at the boundary in an optimal way for the specific task. Our extensive evaluation, over a wide range of architectural changes (variations of layers, feature channels, or both), shows how the filters result in improved boundary handling. Consequently, we demonstrate an improvement of N \, \% to N \, \% across the board of typical CNN applications (colorization, de-Bayering, optical flow, and disparity estimation) .