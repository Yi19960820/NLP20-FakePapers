In the past few years, deep convolutional neural networks (DCNNs) _cite_ have achieved the state-of-the-art performance in many computer vision tasks, starting from image recognition _cite_ and object localization _cite_ and more recently extending to object detection and semantic image segmentation _cite_ . These successes are largely attributed to the capacity that large-scale DCNNs can effectively learn end-to-end from a large amount of labelled images in a supervised learning mode. In this paper, we consider to apply the popular deep learning techniques to another computer vision problem, namely object saliency detection. The saliency detection attempts to locate the objects that have the most interests in an image, where human may also pay more attention _cite_ . The main goal of the saliency detection is to compute a saliency map that topographically represents the level of saliency for visual attention _cite_ . For each pixel in an image, the saliency map can provide how likely this pixel belongs to the salient objects _cite_ . Computing such saliency maps has recently raised a great amount of research interest _cite_ . The computed saliency maps have been shown to be beneficial to various vision tasks, such as image segmentation _cite_, object recognition and visual tracking. The saliency detection has been extensively studied in computer vision, and a variety of methods have been proposed to generate the saliency maps for images. Under the assumption that the salient objects probably are the parts that significantly differ from their surroundings, most of the existing methods use low-level image features to detect saliency regions based on the criteria related to color contrast, rarity and symmetry of image patches _cite_ . In some cases, the global topological cues may be leveraged to refine the perceptual saliency maps _cite_ . In these methods, the saliency is normally measured based on different mathematical models, including decision theoretic models, Bayesian models, information theoretic models, graphical models, and spectral analysis models _cite_ . Different from the previous low level methods, we propose a novel deep learning method for the object saliency detection based on the powerful DCNNs. As shown in _cite_, relying on a pre-trained classification DCNN, we can achieve a fairly high accuracy in object category recognition for many real-world images. Even though DCNNs can recognize what kind of objects are contained in an image, it is not straightforward for them to precisely locate the recognized objects in the image. In _cite_, some rather complicated and time-consuming post-processing stages are needed to detect and locate the objects for semantic image segmentation. In _cite_, two DCNNs are applied to generate superpixel based global saliency features and local saliency features, which should be combined for the final saliency maps. In this work, we propose a much simpler and more computationally efficient method to generate a class-specific object saliency map directly from the classification DCNN model. In our approach, we use a gradient descent (GD) method to iteratively modify each input image based on the refined pixel-wise gradients to reduce a pre-defined cost function, which is defined to measure the class-specific objectness and clamp the class-irrelevant outputs to maintain image background. The gradients with respect to all image pixels can be efficiently computed using the back-propagation algorithm for DCNNs. After the back-propagation procedure, the discrepancy between the modified image and the original one is calculated as the raw saliency map for this image. The raw saliency maps are smoothed by using SLIC _cite_ superpixel maps and refined by using low level saliency features. Since we only need to run a very small number of GD iterations in the saliency detection, our methods are extremely computationally efficient (average processing time for one image in one GPU is around N second) . Experimental results on two databases, namely Pascal VOC N _cite_ and MSRANk _cite_, have shown that our proposed methods can generate high-quality salience maps, at least comparable with many slow and complicated deep learning methods. On the other hand, comparing with the traditional low-level methods, our approach excels on many difficult images, containing complex background, highly-variable salient objects, multiple objects, and/or very small objects.