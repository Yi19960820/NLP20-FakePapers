Age-related facial technologies generally address the two areas of age estimation _cite_ and age progression _cite_ . The face age-estimation problem is defined as building computer software that has the ability to recognize the ages of individuals in a given photograph. Comparatively, the face age-progression problem necessitates the more complex capability to predict the future facial likeness of people appearing in images _cite_ . Aside from the innate curiosity of individuals, research of face aging has its origins in cases of missing persons and wanted fugitives, in either case law enforcement desires plausible age-progressed images to facilitate searches. Accurate face aging also provides benefits for numerous practical applications such as age-invariant face recognition _cite_ . There have been numerous anthropological, forensic, computer-aided, and computer-automated approaches to facial age-progression. However, the results from previous methods for synthesizing aged faces that represent accurate physical processes involved in human aging are still far from perfect. This is especially so in age-progressing videos of faces, due to the usual challenges for face processing involving pose, illumination, and environment variation as well as differences between video frames. There have been two key research directions in age progression for both conventional computer-vision approaches and recent deep-learning methods--one-shot synthesis and multiple-shot synthesis . Both approaches have used facial image databases with longitudinal sample photos of individuals, where the techniques attempt to discover aging patterns demonstrated over individuals or the population represented. In one-shot synthesis approaches, a new face at the target age is directly synthesized via inferring the relationships between training images and their corresponding age labels then applying them to generate the aged likeness. These prototyping methods _cite_ often classify training images in facial image databases into age groups according to labels. Then the average faces, or mean faces, are computed to represent the key presentation or archetype of their groups. The variation between the input age and the target age archetypes is complimented to the input image to synthesize the age-progressed faces at the requested age. In a similar way, Generative Adversarial Networks (GANs) _cite_ methods present the relationship between semantic representation of input faces and age labels by constructing a deep neural network generator. It is then combined with the target age labels to synthesize output results. Meanwhile, in multiple-shot synthesis, the longitudinal aging process is decomposed into multiple steps of aging effects _cite_ . These methods build on the facial aging transformation between two consecutive age groups. Finally, the progressed faces from one age group to the next are synthesized step-by-step until they reach the target age. These methods can model the long-term sequence of face aging using this strategy. However, these methods still have drawbacks due to the limitations of long-term aging not being well represented nor balanced in face databases. Existing age-progression methods all similarly suffer from problems in both directions. Firstly, they only work on single input images. Supposing there is a need to synthesize aging faces presented in a captured video, these methods usually have to split the input video into separate frames and synthesize every face in each frame independently which may often present inconsistencies between synthesized faces. Since face images for each frame are synthesized separately, the aging patterns of generated faces of the same subject are also likely not coherent. Furthermore, most aging methods are unable to produce high-resolution images of age progression, important for features such as fine lines that develop fairly early in the aging process. This may be especially true in the latent based methods _cite_ . This paper presents a deep Reinforcement Learning (RL) approach to Video Age Progression to guarantee the consistency of aging patterns in synthesized faces captured in videos. In this approach, the age-transformation embedding is modeled as the optimal selection using Convolutional Neural Network (CNN) features under a RL framework. Rather than applying the image-based age progression to each video frame independently as in previous methods, the proposed approach has the capability of exploiting the temporal relationship between two consecutive frames of the video. This property facilitates maintaining consistency of aging information embedded into each frame. In the proposed structure, not only can a smoother synthesis be produced across frames in videos, but also the visual fidelity of aging data, i.e. all images of a subject in different or the same age, is preserved for better age transformations. To the best of our knowledge, our framework is one of the first face aging approaches in videos. Finally, this work contributes a new large-scale face-aging database to support future studies related to automated face age-progression and age estimation in both images and videos.