With the development of intelligent surveillance systems, pedestrian and vehicle detection approaches have garnered profound interest from engineers and scholars. Many impressive works _cite_ have been published in the last several years. However, object detection and recognition remain a considerably difficult issue in highly populated public places such as airports, train stations and urban arterial roads, which have distributed multiple surveillance cameras with different viewpoints, illuminations and backgrounds in cluttered environments. One object class may show large inter-class variations under these different imaging conditions. A substantial amount of training data need to be collected and labeled to model one object category detector based on statistical learning. Without this, the detector, trained in constrained video environments, will deliver poor performance under different environmental conditions. How to robustly and stably locate objects in arbitrary video environments with minimal supervision is still an open issue. Transfer learning methods _cite_ can be used to learn different view-point scene detectors from pre-training models, which reduce the efforts involved in collecting samples and retraining in response to such variations in appearance. However, negative transfer often occurs when transfering very different scenes _cite_, significantly influencing the performance of target scene detectors and limiting the application of the transfer learning. The Multi-view object detection method is an alternative strategy to locate the object in various view-points, which minimizes the influence of changing imaging conditions. However, these approaches increase the discriminability of detectors through relatively complex additional stages involving view-invariant features _cite_, the pose estimator _cite_ or the ND object model _cite_, which make them computationally expensive and require an intensive training process on large datasets. These top-down approaches will result in considerable runtime complexity. Let's focus on one surveillance camera used in one specific scenario. A common strategy is to train specific object detector from human collected and labelled training samples the scenario since each individual has limited variant poses in one scene. However, it is impossible to train scene-specific detectors for every scenario considering tedious human efforts and time costs, unless the training process requires minimal or even no supervision. A method must be found to learn a scene-specific object detector without human intervention, extending to other scenes, making sure that every scene has its own detector and achieves satisfactory detection performance under different imaging conditions and viewpoints. Although the idea sounds attractive, this task is challenging because constructing an object model without prior knowledge is difficult, and there is no effective algorithm to automatically collect and label samples for training the detector on the fly. Some studies on online-learning object detectors have been proposed and most of them adopt a similar framework, including an online learning detector and a validation strategy. However, these methods are not completely unsupervised learning methods, but only minimize manual effort, and are always initialized by several hundred human labeled training samples for one specific scene. Moreover, the number of manually labeled initial instances will increase proportionally considering the multi-scene object detection application. In addition, these approaches employ co-training methods _cite_, the background subtraction _cite_, the generative model _cite_ and tracking-by-detection appoaches _cite_ as the validation strategies to collect and label the online learning samples automatically. The performance of online-learning approaches are far from competitive with supervised methods because of the high label error in hard samples distributed around the decision hyperplane, compared to the human label in supervised training process. Recently, some scene-specific object detection approaches _cite_ have been proposed to discover and label hard proposals for training an initial generic detector without any manual annotation. Among these various solutions, Ye _cite_ has shown impressive results under challenging situations by optimizing a progressive latent model (PLM) with the difference of convex (DC) objective functions. However, it is a computational challenge to optimize a DC function straightforwardly throughout the sample space with an unsupervised manner. Furthermore, a careful initial generic detector is necessary to avoid local minima. To overcome the limitations of existing works, in this paper, a Generative-Discriminative model (GDM) is proposed to partition the sample space into three disjoint subspaces: positive, negative and hard sample space. A Generative model learns the joint probability of positive and negative samples, while hard samples are classified by a discriminative model with solving a mixed integer programming problem. Similar to the concave-convex programming procedure, the GDM can be iteratively updated by an online gradual optimized process which is insensitive to initialization. Our goal is to design an self-learning object detection framework, which can train object class detector in each particular scenario without human intervention. Instead of manually labeling several hundred initial training samples or employing a generic detector in existing methods, our scene-specific detector is obtained by simply marking several bounding boxes around the object in the first video frame via a mouse. This approach reduces human annotation effort to an effortless mouse operation within the first frame, which "determine" the interested object category in current surveillance video. Other than this, human labeled samples or general object detectors are not needed. There are two processes in our framework: In learning process, first, an initial sample set generated by affine transformation of these marked objects in the first frame. Second, a Generative-Discriminative model, trained by the initial sample set, runs as an initial detector on subsequence frames. Obviously, the initial detector has poor detection performance due to the incomplete initial training sample set. Third, for this case, we propose an online gradual optimized procedure to iterative optimize the Generative-Discriminative model (GDM) in an unsupervised manner. When the convergence condition is satisfied, the optimized process will stop and result in a hybrid classifier composed of a generative model and a discriminative model. During object detection process, the two models work together to determine the location of real objects. The generative model is first used to detect objects based on the sliding window strategy, and the detection responses, located near the classification boundary, will be further recognized by the discriminative model. Our method, triggered by several bounding boxes, is minima supervised without human effort on collecting and labelling samples, and can be easily extended to other scenes, forming scene-specific objectors in various surveillance cameras with different viewing distances and angles. Thus, this is a bottom-up method to resolve the multi-scene object detection problem. Moreover, both the use of Generative-Discriminative model (GDM) and online gradual optmized process make our method robust in tackling the most informative samples lying at the decision boundary, and the method achieves state of the art detection performance under different viewing angles, as shown in Fig. N. By self-learning within three hours, our method produces satisftying results in three different viewpoints sequences of CAVIAR _cite_ and PETSN _cite_ datasets. In addition, we obtain competitive detection performance in the SN sequences of PETSN dataset, compared to the Aggregated Channel Features (ACF) _cite_, one of the most robust supervised object detection approaches, trained by manually labeling N positive samples and N negative samples in the same viewpoint. To the best of our knowledge, this is the first time to demonstrate a scene-specific detector without additional manual annotated samples or generic detectors, compared to other object detection methods. The main contributions of this paper are: N) We present the Generative-Discriminative model (GDM), which partitions the sample space for improving the discriminability of scene-specific object classifiers while being efficient at run-time. N) We present the online gradual optimized process which allows the detector, initialized by marking several bounding boxes around the object with poor detection performance, to successively improve classification accuracy and becoming more dedicated to challenging samples lying near the decision boundary. N) We present a novel self-learning framework to train scene-specific object detectors by marking several bounding boxes around the object in the first frame, which can easily extend to various surveillance videos, and automatically achieve successful detection performance. The rest of this paper is arranged as follows: Section N briefly recalls related works. In Section N, the analysis of our approach is provided. Generative model is described in section N, discriminative model is explained in section N, and section N shows the online gradual optimized process. Experiments and results are presented in section N, which is followed by the conclusions.