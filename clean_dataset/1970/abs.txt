We present a method for simultaneously estimating ND human pose and body shape from a sparse set of wide-baseline camera views. We train a symmetric convolutional autoencoder with a dual loss that enforces learning of a latent representation that encodes skeletal joint positions, and at the same time learns a deep representation of volumetric body shape. We harness the latter to up-scale input volumetric data by a factor of _inline_eq_, whilst recovering a ND estimate of joint positions with equal or greater accuracy than the state of the art. Inference runs in real-time (N fps) and has the potential for passive human behavior monitoring where there is a requirement for high fidelity estimation of human body shape and pose.