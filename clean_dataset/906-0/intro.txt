Analysis of human behavior such as action recognition and detection is one of the fundamental and challenging tasks in computer vision. It has a wide range of applications such as intelligent surveillance system, human-computer interaction, game-control and robotics. Articulated human pose, being also referred to as skeleton, provides a very good representation for describing human actions. On one hand, skeleton data are inherently robust against background noise and provide abstract information and high-level features of human action. On the other hand, compared with RGB data, skeleton data are extremely small in size, which makes it possible to design lightweight and hardware friendly models. In this paper, we focus on the problem of skeleton-based human action recognition and detection (Figure~ _ref_) . The interactions and combinations of skeleton joints play a key role to characterize an action. Many of the early works attempted to design and extract co-occurrence features from skeleton sequences, such as pairwise relative position of each joint~ _cite_, spatial orientation of pairwise joints~ _cite_, and the statistics-based features like CovNDJ~ _cite_ and HOJND~ _cite_ . On the other hand, the Recurrent Neural Networks (RNNs) with Long-Short Term Memory (LSTM) neurons are used to model the time series of skeleton prevalently~ _cite_ . Although the LSTM networks were designed to model long-term temporal dependency, it is difficult for them to learn high-level features from skeletons directly since the temporal modeling is done on the raw input space~ _cite_ . While fully connected layers are able to learn co-occurrence features for their ability of aggregating global information from all input neurons. In~ _cite_, an end-to-end fully connected deep LSTM network was proposed to learn co-occurrence features from skeleton data. CNN models are equipped with excellent ability to extract high-level information, and they have been used to learn spatial-temporal features from skeletons~ _cite_ . These CNN-based methods represent a skeleton sequence as an image by encoding the temporal dynamics and the skeleton joints as rows and columns respectively, and then feed it into a CNN to recognize the underlying action just like image classification. However, in that case, only the neighboring joints within the convolutional kernel are considered to learn co-occurrence features. Although the receptive field covers all joints of a skeleton in later convolution layers, it is difficult to mine co-occurrences from all joints efficiently. Because of the weight sharing mechanism in spatial dimensions, CNN models can not learn free parameters for each joint. This motivates us to design a model which is able to get global response from all joints to exploit the correlations between different joints. We propose an end-to-end co-occurrence feature learning framework, which uses CNN to learn hierarchical co-occurrence features from skeleton sequences automatically. We find the output of a convolution layer is global response from all input channels. If each joint of a skeleton is treated as a channel, then the convolution layer can learn the co-occurrences from all joints easily. More specifically, we represent a skeleton sequence as a tensor of shape _inline_eq_ (the last dimension as channel) . We first learn point-level features for each joint independently using convolution layers with kernel size _inline_eq_ . And then we transpose the output of the convolution layers to make the dimension of _inline_eq_ as channel. After the transpose operation, the subsequent layers aggregate global features from all joints hierarchically. Furthermore, the two-stream framework~ _cite_ is introduced to fuse the skeleton motion feature explicitly. The main contributions of this work are summarized as follows: