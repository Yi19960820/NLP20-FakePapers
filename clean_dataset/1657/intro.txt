's cognitive distraction is a major cause of unsafe driving, which leads to severe car accidents every year~ _cite_ . Actions that underlie careless driving include interacting with passengers, using a mobile phone (e.g., for text messaging, game playing, and web browsing), and consuming food or drinks _cite_ . Such behaviors contribute significantly to delays in driver's response to unexpected events, thereby increasing the risk of collisions. Identifying drivers' behaviors is therefore becoming increasingly important for car manufacturers, who aim to build in-car intelligence that can improve safety by notifying drivers in real-time of potential hazards. Further, although full car automation is years ahead, inferring driver's behaviour is essential for vehicles with partial (``hands off'') and conditional (``eyes off'') automation, which will dominate the market at least until N~ _cite_ . This is because the driver must either be ready to take control at any time or intervene in situations where the vehicle cannot complete certain critical functions~ _cite_ . Modern driver behavior classification systems usually rely on videos acquired from in-vehicle cameras, which record the movements and the facial expressions of the driver~ _cite_ . The videos captured are routinely partitioned into sequences of image frames, which are then pre-processed for features selection~ _cite_ . Such features are fed to pre-trained classifiers to perform identification of different actions that the driver performs. Subsequently, the classifier may trigger an alarm system in manual driving cars or provide input to a driving mode selection agent in semi-autonomous vehicles. We illustrate this pipeline in Fig.~ _ref_ . During this process, the accuracy of the classifier is directly related to the performance of the system. In addition, the system should perform such classification in real-time, so as to help the driver mitigate unsafe circumstances in a timely manner. Achieving high accuracy while maintaining runtime efficiency is however challenging, yet striking appropriate trade-offs between these aims is vital for intelligent and autonomous vehicles. Underpinned by recent advances in parallel computing, deep neural networks _cite_ have achieved remarkable results in various areas, including computer vision _cite_, control _cite_, and autonomous driving _cite_, as they can automatically extract features from raw data without requiring expensive hand-crafted feature engineering. Graphics processing units (GPUs) allow to train deep neural networks rapidly and with great accuracy, and perform inferences fast. Moreover, System on Chip (SoC) designs optimized for mobile artificial intelligence (AI) applications are becoming more powerful and computationally efficient~ _cite_, and embedding deep learning in car systems increasingly affordable _cite_ . Therefore, potential exists to build high precision driver behavior classification systems without compromising runtime performance. In this paper, we design a driver behavior recognition system that uniquely combines different Convolutional Neural Network (CNN) structures, to accurately perform this task in real-time. As such, we make the following key contributions: \newpage The results obtained demonstrate the feasibility of accurate inference of driver's behavior in real-time, making important steps towards fulfilling the multi-trillion economic potential of the driverless car industry~ _cite_ . The rest of the paper is organized as follows. In Sec.~ _ref_ we discussed relevant related work. In Sec.~ _ref_ we present our data collection and pre-processing efforts, which underpin the design of our neural network solution that we detail in Sec.~ _ref_ . We demonstrate the performance of the proposed InterCNNs by means of experiments reported in Sec.~ _ref_ . Sec.~ _ref_ concludes our contributions.