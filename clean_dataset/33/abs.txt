We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., N-N MFLOPs) . The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-N error (absolute N \%) than recent MobileNet~ _cite_ on ImageNet classification task, under the computation budget of N MFLOPs. On an ARM-based mobile device, ShuffleNet achieves _inline_eq_ N _inline_eq_ actual speedup over AlexNet while maintaining comparable accuracy.