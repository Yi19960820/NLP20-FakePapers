The identification, segmentation, and quantification of structures visible in medical images is a crucial component in the processing of medical image data. In the context of spinal images, segmentation of spine has an immediate diagnostic importance in clinical decisions around fracture detection and inter-vertebral disc pathology. Segmented spines are also used in the bio-mechanical modelling of the spine for load analysis and fracture prediction. Therefore, an automated approach attempting to segment the spine should posses two key features: (N) Highly generalisable in terms of the fields-of-view (FOV) and scanner calibrations, in addition to variability in the spine's curvature, BMD (bone mineral density) distribution, and micro-architecture and (N) Capable of segmenting images from a clinical population that consists of abnormalities such as vertebral fractures, scoliotic, and kyphotic spines. A typical analysis pipeline for spinal images consists of three stages: spine localisation, vertebrae detection, and spine segmentation. The first two steps of localisation and detection are accomplished by basic routines such as shape matching (using generalised Hough transform _cite_) and spine-curve detection (using circle detection in axial slices _cite_) . This is followed by a segmentation stage which may tackled using statistical mean shape models or atlases, followed by an optimisation routine that adapts the fitted model to account for local variations _cite_ . Such a pipeline has proven to be highly effective in most of the cases. However, there is a limit to the amount of generalisability such model/shape-based approach can offer in clinical cases. Its limit is determined by the robustness of the chosen model and the amount of relaxation it can withstand during the optimisation routine post fit. It is obvious that such models cannot generalise to a fractured vertebra or a deformed spine. In such cases, learning-based approaches offer respite, provided that the data that the approach can learn from is rich and diverse enough. For example, _cite_ and _cite_ solve the problem of vertebra detection in arbitrary FOVs using random forests and multi-layer regressors respectively. Chen et al. _cite_ make use of the omni-present convolutional neural networks to detect vertebrae using an altered cost formulation that takes into account the sequence of the vertebrae. However, there is no approach that handles every problem in the analysis pipeline (localisation, detection, and segmentation) in one go, that is, takes a ND spine scan as input and generates an annotated and segmented spine volume. In this work, we propose an approach that segments and simultaneously labels the the lumbar vertebrae using deep neural networks. Given a CT scan volume of an arbitrary FOV, our approach performs a multi-class segmentation over five classes corresponding to the five lumbar vertebrae (LN to LN) and a background class. This is done in a two-staged approach: (N) Localise the lumbar region, and (N) Segment the localised lumbar vertebrae in to their respective classes. Both the stages are elaborated in detail in section _ref_ . Figure _ref_ gives a schematic overview of our approach. We use the dataset released as part of the xVertSeg challenge in MICCAI N to test the performance of our approach. We are the first to attempt this challenge, and achieve a mean Dice coefficient upwards of N \% on both the training and the test set. Section _ref_ contains the implementation and experimental details.