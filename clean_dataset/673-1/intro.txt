Capturing dependencies is of central importance in deep neural networks. For sequential data (\eg, in speech, language), operations _cite_ are the dominant solution to long-range dependency modeling. For image data, long-distance dependencies are modeled by the large receptive fields formed by deep stacks of operations _cite_ . Convolutional and recurrent operations both process a neighborhood, either in space or time; thus long-range dependencies can only be captured when these operations are applied repeatedly, propagating signals progressively through the data. Repeating local operations has several limitations. First, it is computationally inefficient. Second, it causes optimization difficulties that need to be carefully addressed _cite_ . Finally, these challenges make multi-hop dependency modeling, \eg, when messages need to be delivered back and forth between distant positions, difficult. In this paper, we present operations as an efficient, simple, and generic component for capturing long-range dependencies with deep neural networks. Our proposed non-local operation is a generalization of the classical non-local mean operation _cite_ in computer vision. Intuitively, a non-local operation computes the response at a position as a weighted sum of the features at in the input feature maps (Figure~ _ref_) . The set of positions can be in space, time, or spacetime, implying that our operations are applicable for image, sequence, and video problems. There are several advantages of using non-local operations: (a) In contrast to the progressive behavior of recurrent and convolutional operations, non-local operations capture long-range dependencies directly by computing interactions between any two positions, regardless of their positional distance; (b) As we show in experiments, non-local operations are efficient and achieve their best results even with only a few layers (\eg, N) ; (c) Finally, our non-local operations maintain the variable input sizes and can be easily combined with other operations (\eg, convolutions as we will use) . We showcase the effectiveness of non-local operations in the application of video classification. In videos, long-range interactions occur between distant pixels in space as well as time. A single non-local block, which is our basic unit, can directly capture these spacetime dependencies in a feedforward fashion. With a few non-local blocks, our architecures called are more accurate for video classification than ND and ND convolutional networks _cite_ (including the inflated variant _cite_) . In addition, non-local neural networks are more computationally economical than their ND convolutional counterparts. Comprehensive ablation studies are presented on the Kinetics _cite_ and Charades _cite_ datasets. (\eg, optical flow, multi-scale testing), our method achieves results on par with or better than the latest competitions winners on both datasets. To demonstrate the generality of non-local operations, we further present object detection/segmentation and pose estimation experiments on the COCO dataset _cite_ . On top of the strong Mask R-CNN baseline _cite_, our non-local blocks can increase accuracy on all three tasks at a small extra computational cost. Together with the evidence on videos, these image experiments show that non-local operations are generally useful and can become a basic building block in designing deep neural networks.