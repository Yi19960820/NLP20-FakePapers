Automatic focus is the first and foremost step in cell detection using microscopic images, which has wide applications in diagnoises of diseases like tuberculosis _cite_ . Auto-focus mechanisms are divided into two categories: active auto-focus and passive auto-focus _cite_ . In this paper, we concentrate on passive auto-focus problems that aim at moving the lens to a clear enough view within acceptable time by analyzing captured images. Solutions to passive auto-focus problems have two phases: the focus measure functions that map an image to a value for representing the degree of focus of the image, and the search algorithms that iteratively move the lens to find the highest or nearest peak of focus measure curves _cite_ . In order to improve traditional passive auto-focus techniques, both of the phases need to be considered. In this paper, we present an end-to-end learning approach by combining those two phases into one. \par Aiming at giving agents the ability to learn directly from raw pixels, we need methods which could learn to make decisions on a model-free problem with high-dimensional input. Deep Reinforcement Learning (DRL), which combines Deep Learning and Reinforcement Learning (RL) together, is promising for complex decision-making tasks _cite_ and thus becomes a potential solution. One typical example of DRL is the Deep Q Network (DQN), which has achieved performances that are compatible or even superior than human players in Atari games _cite_ . The basic idea of our system comes from formulating the auto-focus problem into a model-free decision-making task analogous to Atari games: we formulate the state representation with successive images and limit the optional actions to five, including coarse and fine step in both directions as well as termination. \par The contribution of this paper can be summarized as follows: The remainder of this paper is organized as follows: Section _ref_ introduces related works. Section _ref_ formulates the auto-focus RL problem and presents an overview of our method. Section _ref_ describes the experimental setup and the experiment results in both virtual and real scenarios.