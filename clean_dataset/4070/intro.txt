In many recent works~ _cite_, it has been observed that CNNs with different architectures or even different weight initializations may learn slightly different feature representations. Combining these heterogeneous models can provide richer and more diverse feature representation which can further boost the final performance. However, principled methods to directly enhance model inherent diversity are still rare. In this work, we propose a novel method to enhance such feature diversity by exploiting during the training process. The privileged information~ _cite_ refers to the information that is available at training but not at testing. For the image classification task, the privileged information can be with many different types, such as text description~ _cite_ and feature vector~ _cite_ . Using privileged information to assist the learning process has been well studied in the area of training a better classifer~ _cite_ but still rare in deep learning. In this work, we focus on learning more diverse feature representations. We aim to employ the privileged information during training to obtain a CNN model with sufficient inherent diversity, such that the model learns more diverse representations and has a stronger generalization ability than vanilla CNNs. To this end, we propose a group orthogonal convolutional neural network (GoCNN) model based on the idea of learning different groups of convolutional functions which are ``orthogonal'' to the ones in other groups,, with no significant correlation among the produced features. Optimizing orthogonality among convolutional functions reduces the redundancy and increases the diversity within the architecture. Properly defining the groups of convolutional functions in the GoCNN is not an easy task. In this work, we propose to exploit available for identifying the proper groups. Specifically, in the context of image classification, object segmentation annotations which are (partially) available in several public datasets give richer information. In addition, the background contents are usually independent on foreground objects within an image. Thus, splitting convolutional functions into different groups and enforcing them to learn features from the foreground and background separately can help construct orthogonal groups with small correlations. Motivated by this, we introduce the GoCNN architecture which explores to learn discriminative features from foreground and background separately where the foreground-background segregation is offered by the privileged segmentation annotation for training GoCNN. In this way, inherent diversity of the GoCNN can be explicitly enhanced. Moreover, benefiting from pursuing the group orthogonality, the learned convolutional functions within GoCNN are demonstrated to be foreground and background diagnostic even for extracting features from new images in the testing phase. To the best of our knowledge, this work is the first to explore a principled way to train a deep neural network with desired inherent diversity and the first to investigate how to use the segmentation privileged information to assist image classification within a deep learning architecture. Experiments on ImageNet and PASCAL VOC clearly demonstrate GoCNN improves upon vanilla CNN models significantly, in terms of classification accuracy. Moreover, as a by-product of implementing GoCNN, we also provide positive answers to the following two prominent questions about image classification: (N) Does background information indeed help object recognition in deep learning? (N) Can a more precise annotation with richer information,, segmentation annotation, assist the image classification training process non-trivially?