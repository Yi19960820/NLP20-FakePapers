We investigate the addition of symmetry and temporal context information to a deep convolutional neural network (CNN) with the purpose of detecting malignant soft tissue lesions in mammography. We employ a simple linear mapping that takes the location of a mass candidate and maps it to either the contra-lateral or prior mammogram and regions of interest (ROI) are extracted around each location. Two different architectures are subsequently explored: (N) a fusion model employing two datastreams were both ROIs are fed to the network during training and testing and (N) a stage-wise approach where a single ROI CNN is trained on the primary image and subsequently used as feature extractor for both primary and contra-lateral or prior ROIs. A 'shallow' gradient boosted tree (GBT) classifier is then trained on the concatenation of these features and used to classify the joint representation. The baseline obtained an AUC of _inline_eq_ with confidence interval _inline_eq_ . For the analysis of symmetrical differences, the first architecture where both primary and contra-lateral patches are presented during training obtained an AUC of _inline_eq_ with confidence interval _inline_eq_ and the second architecture where a new classifier is retrained on the concatenation an AUC of _inline_eq_ with confidence interval _inline_eq_ . We found a significant difference between the first architecture and the baseline at high specificity _inline_eq_ . When using the same architectures to analyze temporal change we obtained an AUC of _inline_eq_ with confidence interval _inline_eq_ for the first architecture and an AUC of _inline_eq_ with confidence interval _inline_eq_ in the second setting. Although improvements for temporal analysis were consistent, they were not found to be significant. The results show our proposed method is promising and we suspect performance can greatly be improved when more temporal data becomes available.