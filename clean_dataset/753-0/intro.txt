Caricature is an artistic creation produced by exaggerating some prominent characteristics of a face image while preserving its identity. Caricatures are widely used in social media and daily life for a variety of purposes. For example, it can be used as the profile image or to express certain emotions and sentiments on social networks. Due to the prosperity of social media, automatic caricature creation becomes an increasingly attractive research problem. In this paper, given an arbitrary face image of a person, our primary goal is to generate satisfactory or plausible caricatures of that person with reasonable exaggerations and an appropriate caricature style. To this end, we identify and define four key aspects that need to be taken into account for caricature generation: Several previous studies~ _cite_ have made attempts to solve this problem. These studies mainly focus on the generation of sketch caricature~ _cite_, black-white illustration caricature~ _cite_, and outline caricature~ _cite_ . Most of them adopt low-level image transformations and computer graphics techniques~ _cite_ to generate new images. They are either semi-automatic or complicated with multiple stages, making it difficult to be applied to large-scale caricature generation applications. Moreover, although they can generate correct deformations on some facial parts, their results are usually visually unappealing,, lacking of rich colors and vivid details. As shown in the second column of Figure~ _ref_, the conventional low-level geometric deformation based approaches~ _cite_ can only generate one specifically exaggerated caricature for one input face. Often, the content, texture and style of the generated caricature are plain and less interesting. Recently, with the progress of conditional generative adversarial networks (GANs) ~ _cite_ and their success in image generation, image translation and editing tasks~ _cite_, it is possible to use a GAN model to learn transformations from data itself to produce plausible caricatures from the input face images. However, although typical GAN-based models such as PixNPix~ _cite_ can generate realistic images, directly applying these models to this task fails to produce satisfactory outputs. Most of the previous methods cannot address all of the four key aspects together. Quite often, the generated image is almost visually the same as the input face with only minor changes in color, lacking sufficient exaggerations in facial parts. As shown in the third column of Figure~ _ref_, there is almost no exaggeration of facial features, which does not satisfy the primary goal of caricature generation. In addition, many GAN-based image-to-image translation models require strictly paired training images, the transformation should be a bijective pixel-to-pixel mapping. However, these paired data are quite difficult to obtain. For caricature generation, using such pixel-wisely paired data is not feasible for practical purposes. Inspired by the power of the conditional GANs, this paper proposes an end-to-end model named CariGAN to solve the problems encountered by the conventional GAN models. The goal is to address as much as possible the four key aspects of caricature generation. Due to the difficulty in obtaining strictly paired training data, we introduce a new setting for training GANs,, . Specifically, one pair of input face and the ground-truth caricature only share the same identity but has no pixel-to-pixel or pose-to-pose correspondence. This setting is much more challenging than the pixel-wisely paired training setting. We will describe this setting in detail in Section~ _ref_ . Furthermore, as shown in Figure~ _ref_, although conventional GAN-based models such as BicycleGAN~ _cite_ can produce caricatures with correct identities, they fail to produce reasonable exaggerations. It is worth emphasizing that the exaggeration is a vital aspect to make a vivid caricature. In our model, we retain the advantage of conventional models, employing a U-net as the generator to keep the identity unchanged during the transformation. In addition, we introduce a facial mask as a condition of GAN to precisely guide the deformations of faces, so that the generated images can have reasonable exaggerations. For the plausibility issue, although the GAN-based models can produce plausible images by forcing the distribution of the generated caricatures to be close to that of the ground truth, there are still many artifacts that decrease the degree of plausibility. To enhance the plausibility of the generated caricatures, a new is proposed. By adopting this mechanism, we can encourage the model to concentrate on refining not only the global appearance, but also the important local facial parts of the generated caricature images. Finally, many conditional GAN models suffer from the so-called ``mode collapse'' problem,, different inputs, especially random noise, can be mapped to the same mode _cite_ . The diversity of the outputs will be greatly reduced due to this problem. To address this problem, a novel is proposed to enforce that the input random noise should play a more important role in generating the styles and colors of the generated caricatures. In summary, the main contributions of this paper are as follows: The rest of this paper is organized as follows: Section~ _ref_ introduces the related work on caricature generation, conditional generative adversarial networks and multimodality encoding in GANs. Section~ _ref_ introduces the proposed model in details. Experimental settings and results of different models are provided in Section~ _ref_, and the last section concludes the whole paper.