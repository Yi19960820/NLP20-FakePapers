In this paper, we present a technique for unsupervised learning of visual representations. Specifically, we train a model for foreground and background classification task, in the process of which it learns visual representations. Foreground and background patches for training come after mining for such patches from hundreds and thousands of unlabelled videos available on the web which we extract using a proposed patch extraction algorithm. Without using any supervision, with just using _inline_eq_ unlabelled videos and the PASCAL VOC N dataset, we train a object recognition model that achieves _inline_eq_ mAP which is close to the best performing unsupervised feature learning technique whereas better than many other proposed algorithms. The code for patch extraction is implemented in Matlab and available open source at the following .