In the modern era, with the availability of large-scale datasets~ _cite_ _cite_ and powerful computational resources, deep learning techniques especially the convolutional neural networks (CNNs) have been applied to a wide range of computer vision tasks, such as image classification~ _cite_, object detection~ _cite_, semantic segmentation~ _cite_, edge detection~ _cite_, {\em etc} . Despite their great success, we still care about an important issue, which is the expensive computational overhead which limits them from being applied in some real-time scenarios. Accelerating convolutional neural networks has been attracting a lot of interests. Convolution is the most computationally expensive module in each network, and its FLOPs (the number of floating point operations) is proportional to the size of convolutional kernels, the number of input and output channels, and the spatial resolution of the output feature map. A lot of efforts have been made to eliminate the {\em redundancy} in the computation. There are two main research lines, namely, compressing pre-trained networks and designing more efficient structures. Most existing approaches work on the filter level, {\em i.e.}, accelerating convolution by reducing the number and/or precision of the multiplication and addition operations for each output. Among these, compression algorithms include sparsifying convolutional kernels~ _cite_, pruning filters or channels~ _cite_, learning low-precision filter weights~ _cite_, {\em etc.}, and structure design techniques include Xception~ _cite_, interleaved group convolutions~ _cite_, bottlenecked convolution~ _cite_, {\em etc} . Despite these methods, we note that reducing the factor of spatial resolution, while being a promising direction, is rarely studied before. This paper aims at reducing computational costs in the spatial domain. This is independent yet complementary to the efforts made in the channel domain. We propose a simple building block named {\bf spatial bottleneck}, which consists of a convolutional layer which down-samples the input feature map to a smaller size ({\em e.g.}, half width and height), and a deconvolutional layer which up-samples the feature map back to the desired size (most often, the original size) . In this way, we share a part of computation, and sparsify the sampling rate in the spatial domain. By controlling the {\em density} of spatial sampling, we can achieve different tradeoffs between recognition accuracy and model complexity. Spatial bottleneck is a generalized module which can be used to replace any single convolutional layer or the combination of two convolutional layers . We provide an example based on the deep residual networks~ _cite_ . Each residual block, either with or without channel bottleneck, can be modified into a spatial bottleneck block. Each spatial bottleneck blocks enjoy a reduced FLOPs and, consequently, a favorable speed (_inline_eq_ speedup on a regular residual block, or _inline_eq_ speedup on a channel-bottlenecked residual block) . We empirically evaluate our approach on both the CIFAR~ _cite_ and ILSVRCN~ _cite_ datasets, and show that the accelerated networks retain classification accuracy in low-resolution datasets, and perform better in recognizing high-resolution images.