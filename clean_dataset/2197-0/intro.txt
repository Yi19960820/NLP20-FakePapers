The estimation of free road surface (henceforth: road detection) is a crucial component for enabling fully autonomous driving _cite_ . Besides obstacle avoidance, road detection can also facilitate path planning and decision making, especially in those situations where lane markings are not visible (for example, because covered by snow or due to poor lightning conditions) or not present (for instance, in certain rural and urban roads) . The problem of road detection has been investigated for many years and a large variety of approaches can be found in the literature; see, for example, _cite_ for an in-depth survey of the field. Among the algorithms that perform best on the KITTI road benchmark data set _cite_, the large majority only work on monocular camera images and several make use of deep neural networks _cite_ (DNNs) . For example, in _cite_ the author trains deep deconvolutional networks using a multi-patch approach, while in _cite_ a fully convolutional neural network (FCN) is trained with automatically annotated images. Despite achieving state-of-the-art results, camera-based approaches are strongly affected by environmental illumination. As a consequence, their performance is expected to decrease considerably at night time or whenever presented with light conditions that deviate from those seen during training. LIDARs, on the other hand, carry out sensing by using their own emitted light and therefore they are not sensitive to environmental illumination. Road detection systems that rely on this type of sensor can then, in principle, provide the same level of accuracy across the full spectrum of light conditions experienced in daily driving, and for this reason they are particularly suitable for achieving higher levels of driving automation. Several algorithms have been proposed that perform road detection exclusively in LIDAR point clouds or by fusing camera and LIDAR (see for example _cite_), but, to the best of our knowledge, none has used deep learning and their performance is consistently lower than the top-performing camera-based approaches. In this paper, the problem of road detection is framed as a pixel-wise semantic segmentation task in point cloud top-view images using an FCN. The proposed system carries out road segmentation in real time, on GPU-accelerated hardware, and achieves state-of-the-art performance on the KITTI road benchmark. The paper is organized as follows: In Section~ _ref_, an overview and motivation of the proposed road detection system is presented and it is followed by a description of the procedure to transform an unstructured point cloud into top-view images in Section~ _ref_ . The FCN's architecture is presented in Section~ _ref_ . The data set, data augmentation, and details about the training of the FCN are described in Section~ _ref_ . The results and a discussion are presented in Section~ _ref_ and are followed by the conclusions in Section~ _ref_ .