With the emergence of imaging devices in the operating room, the automated analysis of videos recorded during the surgery is becoming a hot research topic. which surgical tools are being used at every moment. Therefore, several tool detection techniques have been proposed in recent years . To compare these techniques, organized at the MNCAI N workshop, Following the trend in medical image and video analysis, the best solutions all relied on convolutional neural networks (CNNs) . Compared to other computer vision tasks, surgical tool usage annotation has several specificities. First, as opposed to many computer vision tasks, including the popular ImageNet visual recognition challenges, the problem at hand is not multiclass classification (one correct label per image among multiple classes), but rather multilabel classification (multiple correct labels per image): the number of tools being used in each image varies (from zero to three in cataract surgery) . Therefore, multilabel CNNs should be used. Second, taking the temporal sequencing into account is important: knowing which tools have already been used since the beginning of the surgery greatly helps recognize which tools are currently being used. Therefore, multilabel recurrent neural networks (RNNs) may also be used advantageously. In fact, recent machine learning competitions clearly show that ensembles of CNNs outperform single CNNs: multiple CNNs with different architectures are generally trained independently and their outputs are combined afterward using standard machine learning algorithms (decision trees, random forests, multilayer perceptrons, etc.) . However, this simple strategy is suboptimal since difficult samples may be misclassified by all CNNs. And there are many difficult samples to classify in surgery videos: in particular, many tools resemble one other (e.g. two types of cannulae in cataract surgery) . Building the ensemble of CNNs using a boosting meta-algorithm can theoretically design CNNs focusing specifically on challenging samples. Boosting an ensemble of RNNs would also make sense as there are difficult samples along the time dimension as well: in particular, some tools or tool usage sequences are very rare and temporal sequencing algorithms tend to misclassify those rare cases. Therefore, we propose to jointly boost an ensemble of CNNs and an ensemble of RNNs for automatic tool usage annotation in surgery videos. In the same way as CNN boosting (or RNN boosting) allows various CNNs (or RNNs) to be complementary, this general boosting solution allows CNNs to be complementary with RNNs. In that sense, it approximates the end-to-end training of a ``CNN + RNN'' network, which is theoretically ideal but not computationally tractable. The remainder of this paper is organized as follows. Section _ref_ reviews the state of the art . Section _ref_ presents and section _ref_ reports the experiments performed on that dataset. We end with a discussion and conclusions in section _ref_ .