Skeleton is one of the most representative visual properties, which describes objects with compact but informative curves. Such curves constitute a continuous decomposition of object shapes _cite_, providing valuable cues for both object representation and recognition. Object skeletons can be converted into descriptive features and spatial constraints, which enforce human pose estimation _cite_, semantic segmentation _cite_, and object localization _cite_ . Researchers have been exploiting the representative CNNs for skeleton detection and extraction _cite_ for years. State-of-the-art approaches root in effective multi-layer feature fusion, with the motivation that low-level features focus on detailed structures while high-level features are rich in semantics _cite_ . As a pioneer work, the holistically-nested edge detection (HED) _cite_ is computed as a pixel-wise classification problem, without considering the complementary among multi-layer features. Other state-of-the-art approaches, _inline_eq_, fusing scale-associated deep side-outputs (FSDS) _cite_ and side-output residual network (SRN) _cite_ investigates the multi-layer association problem. FSDS requires intensive annotations of the scales for each skeleton point, while SRN struggles to pursuits the complementary between adjacent layers without complete mathematical explanation. The problem of how to principally explore and fuse more representative features remains to be further elaborated. Through the analysis, it is revealed that HED treats the skeleton detection as a pixel-wise classification problem with the side-output from convolutional network. Mathematically, this architecture can be equalized with a linear reconstruction model, by treating the convolutional feature maps as linear bases and the _inline_eq_ convolutional kernel values as weights. Under the guidance of the linear span theory _cite_, we formalize a linear span framework for object skeleton detection. With this framework, the output spaces of HED could have intersections since it fails to optimize the subspace constrained by each other, Fig. N. To ease this problem, we design Linear Span Unit (LSU) according to this framework, which will be utilized to modify convolutional network. The obtained network is named as Linear Span Network (LSN), which consists feature linear span, resolution alignment, and subspace linear span. This architecture will increase the independence of convolutional features and the efficiency of feature integration, which is shown as the smaller intersections and the larger union set, Fig. N. Consequently, the capability of fitting complex ground-truth could be enhanced. By stacking multiple LSUs in a deep-to-shallow manner, LSN captures both rich object context and high-resolution details to suppress the cluttered backgrounds and reconstruct object skeletons. The contributions of the paper include: