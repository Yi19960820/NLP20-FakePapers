Weakly supervised learning _cite_ has recently gained much attention as a popular solution to address labeled data scarcity in computer vision. Using only image level labels for example, one can obtain attention maps for a given input with back-propagation on a Convolutional Neural Network (CNN) . These maps relate to the network's response given specific patterns and tasks it was trained for. The value of each pixel on an attention map reveals to what extent the same pixel on the input image contributes to the final output of the network. It has been shown that one can extract localization and segmentation information from such attention maps without extra labeling effort. However, supervised by only classification loss, attention maps often only cover small and most discriminative regions of object of interest _cite_ . While these attention maps can still serve as reliable priors for tasks like segmentation _cite_, having attention maps covering the target foreground objects as complete as possible can further boost the performance. To this end, several recent works either rely on combining multiple attention maps from a network via iterative erasing steps _cite_ or consolidating attention maps from multiple networks _cite_ . Instead of passively exploiting trained network attention, we envision an end-to-end framework with which task-specific supervision can be directly applied on attention maps during training stage. On the other hand, as an effective way to explain the network's decision, attention maps can help to find restrictions of the training network. For instance in an object categorization task with only image-level object class labels, we may encounter a pathological bias in the training data when the foreground object incidentally always correlates with the same background object (also pointed out in _cite_) . Figure _ref_ shows the example class "boat" where there may be bias towards water as a distractor with high correlation. In this case the training has no incentive to focus attention only on the foreground class and generalization performance may suffer when the testing data does not have the same correlation ("boats out of water") . While there have been attempts to remove this bias by re-balancing the training data, we instead propose to model the attention map as part of the training. As one benefit of this we are able to control the attention explicitly and can put manual effort in providing minimal supervision of attention rather than re-balancing the data set. While it may not always be clear how to manually balance data sets to avoid bias, it is usually straightforward to guide attention to the regions of interest. We also observe that our explicit self-guided attention model already improves the generalization performance even without extra supervision. Our contributions are: (a) A method of using supervision directly on attention maps during training time while learning a weakly labeled task; (b) A scheme for self-guidance during training that forces the network to focus attention on the object holistically rather than only the most discriminative parts; (c) Integration of direct supervision and self-guidance to seamlessly scale from using only weak labels to using full supervision in one common framework. Experiments using semantic segmentation as task of interest show that our approach achieves mIoU N \% and N \%, respectively on the and of the PASCAL VOC N segmentation benchmark. It also confidently surpasses the comparable state-of-the-art when limited pixel-level supervision is used in training with an mIoU of N \% and N \% respectively. To the best of our knowledge these are the new state-of-the-art results under weak supervision.