A major issue in deep learning is that artificial neural networks are very bad at retaining information. When trained on a new task, standard neural networks tend to quickly and completely forget previously learned tasks, a phenomenon referred to as ``catastrophic forgetting'' . Numerous methods for alleviating catastrophic forgetting are currently being proposed, but because of the wide variety of experimental protocols used to evaluate them, directly comparing their performances is difficult. As a first contribution, this paper identifies three distinct continual learning scenarios that are hoped to make such comparisons easier. These scenarios are distinguished by whether at test time task identity is provided and, if it is not, whether task identity needs to be inferred (see section _ref_) . In section~ _ref_ we show that such differences in experimental design can explain seemingly contradictory results reported in the recent literature: even for experimental protocols involving the relatively simple classification of MNIST-digits, methods that perform well in one continual learning scenario can completely fail in another. Using these three scenarios, a second contribution of this paper is to compare recently proposed methods. The methods to be compared are discussed in section _ref_, the implementation of our experiments in section _ref_ and the results in section _ref_ . These experiments reveal that generative replay, especially when combined with distillation techniques, has the capability to perform well on all three scenarios. An important disadvantage of this approach, however, is that it can be computationally very costly. As a third contribution, in section _ref_ we propose a way to reduce these computational costs. Current approaches using generative replay train two separate models: a main model for solving the tasks and a generative model for sampling examples representative of previous tasks. We merge the generative model into the main model by equipping it with feedback or backward connections that are trained to have generative capability (e.g., a variational autoencoder with added softmax layer) . We demonstrate that this substantially reduces training time, with no or negligible loss in performance.