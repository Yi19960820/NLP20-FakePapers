Low-shot learning methods for image classification support learning from sparse data. We extend these techniques to support dense semantic image segmentation. Specifically, we train a network that, given a small set of annotated images, produces parameters for a Fully Convolutional Network (FCN) . We use this FCN to perform dense pixel-level prediction on a test image for the new semantic class. Our architecture shows a N \% relative meanIoU improvement compared to the best baseline methods for one-shot segmentation on unseen classes in the PASCAL VOC N dataset and is at least _inline_eq_ faster. The code is publicly available at: _url_ .