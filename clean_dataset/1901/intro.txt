The prevalence of digital cameras and smart phones exponentially increases the number of videos, which are then uploaded, watched and shared through internet. Automatic video content classification has become a critical and challenging problem in many real world applications, including video-based search, recommendation and intelligent robots etc. To accelerate the pace of research in video content analysis, Google AI launched the second Youtube-NM video understanding challenge, aiming to learn more compact video representation under limited budget constraints. Because of both unprecedent scale and diversity of Youtube-NM dataset _cite_, they also provided the frame-level visual and audio features which are extracted by pre-trained convolutional neural networks (CNNs) . The main challenge is how to aggregate such pre-extracted features into a compact video-level representation effectively and efficiently. NetVLAD, which was developed to aggregate spatial representation for the task of place recognition _cite_, was found to be more effective and faster than common temporal models, such as LSTM _cite_ and GRU _cite_, for the task of temporal aggregation of visual and audio features _cite_ . One of the main drawbacks of NetVLAD is that the encoded features are in high dimension. A non-trivial classification model based on those features would need hundreds of millions of parameters. For instance, a NetVLAD network with N clusters will encode a feature of N dimension as an vector of N, N dimension. A subsequent fully-connected layer with N-dimensional outputs will result in about NM parameters. The parameter inefficiency would make the model harder to be optimized and easier to be overfitting. To handle the parameter inefficiency problem, inspired by the work of ResNeXt _cite_, we developed a novel neural network architecture, NeXtVLAD. Different from NetVLAD, the input features are decomposed into a group of relatively lower-dimensional vectors with attention before they are encoded and aggregated over time. The underlying assumption is that one video frame may contain multiple objects and decomposing the frame-level features before encoding would be beneficial for models to produce a more concise video representation. Experimental results on Youtube-NM dataset have demonstrated that our proposed model is more effective and efficient on parameters than the original NetVLAD model. Moreover, the NeXtVLAD model can converge faster and more resistant to overfitting.