The last few years have seen convolutional neural networks (CNNs) emerge as an indispensable tool for computer vision. However, modern CNNs have a high computational cost of evaluation, with convolutional layers usually taking up over N \% of the time. For instance, VGG-N network _cite_ for the problem of object recognition requires _inline_eq_ floating point multiplications per image. These computational requirements hinder the deployment of such networks on systems without GPUs and in scenarios where power consumption is a major concern, such as mobile devices. The problem of trading accuracy of computations for speed is well-known within the software engineering community. One of the most prominent methods for this problem is loop perforation ~ _cite_ . In a nutshell, this technique isolates loops in the code that are not critical for the execution, and then reduces their computational cost by skipping some iterations. More recently, researchers have considered problem-dependent perforation strategies that exploit the structure of the problem~ _cite_ . Inspired by the general principle of perforation, we propose to reduce the computational cost of CNN evaluation by exploiting the spatial redundancy of the network. Modern CNNs, such as AlexNet, exploit this redundancy through the use of strides in the convolutional layers. However, using the convolutional strides changes the architecture of the network (intermediate representations size and the number of weights in the first fully-connected layer), which might be undesirable. Instead of using strides, we argue for the use of interpolation (perforation) of responses in the convolutional layer. A key element of this approach is the choice of the perforation mask, which defines the output positions to evaluate exactly. We propose several approaches to select the perforation masks and a method of choosing a combination of perforation masks for different layers. To restore the network accuracy, we perform fine-tuning of the perforated network. Our experiments show that this method can reduce the evaluation time of modern CNN architectures proposed in the literature by a factor of N _inline_eq_-N _inline_eq_ with a small decrease in accuracy.