The success of Support Vector Machines (SVMs), \eg in object recognition, stems from their well-studied optimization and their use of kernels to solve non-linear classification problems. Designing the right kernel in combination with appropriate image descriptors is crucial. Their joint design leads to a problem in that the right kernel depends on the image descriptors, while the image descriptors are designed for familiar kernels. Multiple Kernel Learning (MKL) ~ _cite_ eases kernel selection by automatically learning it as a combination of given base kernels. Although MKL has been successful in various vision tasks (\eg~ _cite_), it might lead to complex and inefficient kernels. Recently, Bazavan~ \etal~ _cite_ introduced an approach to MKL that avoids the explicit computation of the kernel. It efficiently approximates the non-linear mapping of the hand-selected kernels~ _cite_, thus delivering impressive speed-ups. We propose another way around kernel learning that also allows for efficient SVMs. Instead of combining fixed base kernels, we investigate the use of random binary mappings (BMs) . We coin our approach Multiple Binary Kernel Learning (MBKL) . Given that other methods based on binary decisions such as Random Forests~ _cite_ and Boosting decision stumps~ _cite_ have not performed equally well on image classification benchmarks as kernel SVMs, it is all the more important that we will show MBKL does. Not only does MBKL alleviate the task of selecting the right kernel, but the resulting kernel is very efficient to compute and can scale to large datasets. At the end of the paper, we report on MBKL results for _inline_eq_ computer vision benchmarks, in which we combine several common image descriptors. These descriptors are histogram-based (FlowersN~ _cite_ and Daimler~ _cite_), attribute-based (OSR~ _cite_, a-PASCAL VOCN detection~ _cite_, and UCI~ _cite_), and Sparse Quantization~ _cite_ (ImageNet~ _cite_) . We demonstrate for the first time that a classifier based on BMs can achieve performances comparable to those of the hand-selected kernels for each specific descriptor. Moreover, it is as fast as the fastest kernel approximations, but without the need of interactively selecting the kernel.