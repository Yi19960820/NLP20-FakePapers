recent years, object proposal has become crucial for modern object detection methods as an important pre-processing step~ _cite_ . It aims to identify a small number (usually at the order of hundreds or thousands) of candidate regions that possibly contain class-agnostic objects of interest in an image. Compared with the exhaustive search scheme such as sliding windows~ _cite_, object proposal methods can significantly reduce the number of candidates to be examined and benefit object detection in following two aspects: they can reduce computation time and allow for applying more sophisticated classifiers. Most of existing object proposal methods can be roughly divided into two categories: the classic low-level cues based ones and the modern convolutional neural network (CNN) based ones. The former category of methods mainly exploit low-level image features, including edge, gradient and saliency~ _cite_ to localize regions possibly containing objects. Typically they either follow a bottom-up paradigm, hierarchical image segmentation~ _cite_ or examine densely distributed windows~ _cite_ . However, it is difficult for them to balance well between localization quality and computation efficiency--they cannot provide object proposals of high quality without incurring expensive computational cost. On the other hand, CNN-based methods either directly predict the coordinates of all the objects in an image~ _cite_ or scan the image with a fully convolutional network (FCN) ~ _cite_ to find the regions of high objectness . Although they can achieve high recall rate w.r.t. \relatively loose overlap criteria, intersection over union (IoU) with a threshold value of _inline_eq_, this type of methods usually fails to provide high recall rate under more strict criteria (IoU _inline_eq_), suggesting their poor localization quality. Ideally, a generic object proposal generator should offer the following desired features: high recall rate on objects of various categories with only a few proposals, good localization quality for each specific object instance and high computation efficiency. In this work, we make an effort to develop the object proposal method toward these targets. Our method is motivated by a statistical study on the scale of objects in a collection of natural images. As shown in Figure~ _ref_, we plot the distribution of objects with varying scales (measured by number of pixels) from the training and validation sets of the PASCAL VOC detection benchmark~ _cite_ . From the figure, one can observe that the objects of small scales (less than _inline_eq_ pixels) actually dominate the distribution. Similar observations also hold in the ILSVRC N and N benchmark~ _cite_ . Unfortunately, most of existing methods perform poorly in localizing objects of such small sizes, in terms of the best overlap . Based on these empirical observations, we argue that the quality of small objects localization is one main bottleneck for further improving the recall rate and average best overlap (ABO) for object proposal methods. Therefore, we focus on tackling such a challenging problem in this work. In particular, we develop a novel CNN based object proposal method which contains a pixel-wise object proposal network, sharing the similar spirit with object segmentation networks~ _cite_ . Here the ``pixel-wise'' refers to: for pixel in an image, our proposed network model will predict a bounding box of the object containing this pixel. Such a pixel-level comprehensive object proposal strategy fully exploits the available annotations for object segmentation and substantially improves the quality of object proposals through enhancing the opportunities of accurately hitting the ground-truth object. As the receptive field of each pixel in CNN is a local region around the pixel, directly predicting the coordinates of the bounding box is challenging due to the various spatial displacements of objects. We thus propose to predict the of the bounding box w.r.t this pixel, for each pixel. We then take a further step to focus on enhancing the localization precision for small-scale objects. We propose a new strategy for object proposal, which is inspired by the divide-and-conquer philosophy. Specifically, we train two independent networks, each of which predicts bounding box coordinates for objects at different scales (small or large) . Then for each pixel, we will obtain two object proposals for choice. To adaptively fuse them, we introduce another object confidence network. The network consists of two branches--one for predicting objectness confidence and the other one for weighting the large-/small-size object localization networks. The objectness branch predicts the likelihood of each pixel coming from an object of interest, and the large-/small-size weighting branch trade-offs the contribution of the large-size and small-size networks to final prediction, by predicting the probability of the pixel belonging to an object of a large size. In the training phase, the size of an object can be easily inferred from its annotated segmentation mask, which is used for training the proposed network. For a new image without annotation, both the large-size and small-size object localization networks will predict the bounding box coordinates which are combined according to the weights from the confidence network. An overview of the proposed network model is presented in Figure~ _ref_ . Therefore, the scale-aware coordinates prediction can achieve outperforming localization quality for a wide range of object sizes as for various object sizes, the final result can always considers and fuses the bounding boxes predicted by two localization networks robustly based on a reliable large-/small-size weighting mechanism. To further improve the performance of localizing small objects, we employ a multi-scale strategy for object proposal on a new image. This is inspired by the observation that by enlarging the challenging small object into a larger one, the coordinates prediction error of the small object will be scaled down, as in the case of zooming in on a small object to obtain a clearer view for humans or cameras. Finally, a superpixel based bounding box refinement operation is applied to fine tune the proposals. In short, we make the following contributions to object proposal generation. Firstly, we introduce a segmentation-like pixel-wise localization network to densely predict the object coordinates for each pixel. Secondly, we develop a scale-aware object localization strategy which combines the predictions from a large-size and a small-size network with a weighting mechanism to boost the coordinates prediction accuracy for a wide range of object sizes. Thirdly, we conduct extensive experiments on the PASCAL VOC N and ILSVRC N datasets. The results demonstrate that our proposed approach outperforms the state-of-the-art methods by a significant margin, verifying the superiority of the proposed scale-aware pixel-wise object proposal network. The remainder of this paper is organized as follows. In Section _ref_, we review the related works on object proposal generation. In Section _ref_, we describe our scale-aware pixel-wise localization network. After showing the experimental results in Section _ref_, we draw the conclusion in Section _ref_ .