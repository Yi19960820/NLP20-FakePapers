Object detection is an important problem in computer vision. In recent years, a set of detectors based on convolutional neural networks (CNN) are proposed~ _cite_, which perform significantly better than traditional methods (e.g., _cite_) . Those detectors need to be supervised with fully labeled data, where both object category and location (bounding boxes) are provided. However, we argue that such data are expensive in terms of labeling efforts and thus are not scalable. With the increase of dataset size, it becomes extremely difficult to label the locations of all object instances. In this work, we focus on object detection with weakly labeled data, where only image-level category labels are provided, while the object locations are unknown. This type of methods is attractive since image-level labels are usually much cheaper to obtain. For each image in a weakly labeled dataset, the image-level label tells both present and absent object categories. Thus, for each category, we have positive examples where at least one instance of that category is present as well as negative ones where no objects of that category exist. Some previous methods~ _cite_ extract a set of object candidates via unsupervised object proposals (also called object candidates) ~ _cite_ and then identify the best proposals that lead to high image classification scores for existing categories. However, the best proposals for image classification do not necessarily cover the full objects. (For example, to classify an image as ``cat'', seeing the face is already sufficient and even more robust than seeing the whole body, as the fluffy fur can be confused with other animals.) Specifically, the best proposals usually focus on discriminative object parts, which oftentimes do not overlap enough with the extent of full objects, and thus become false positives for detection. To reduce the false positives due to trapping in the discriminative parts, we use segmentation masks to guide the weakly supervised detector in the typical relocalization-and-retraining loop _cite_ . The segmentation process starts with a few seeds from the object saliency maps generated by the current detector. Then segmentation masks are obtained by expanding those seeds using the ``Seed, Expand and Constrain (SEC) '' method~ _cite_ . One may use all generated masks to directly supervise the detector. However, it will be misled by the hard and noisy examples where the segmentation network fails to produce reasonably good object masks. To overcome this challenge, we propose the multiple instance curriculum learning (MICL) approach, which combines the commonly used multiple instance learning (MIL) framework with the easy-to-hard learning paradigm-curriculum learning (CL) ~ _cite_ . The work flow of the proposed MICL system is shown in Fig.~ _ref_ . It learns from the ``easy'' examples only in the re-training step of MIL. The re-trained detector is later used to re-localize the segmentation seeds and object boxes. While this process iterates, the training set is gradually expanded from easy to hard examples so the detector learns to handle more complex examples. We identify the easiness of an example by examining the consistency between the results from the detector and the segmenter, without additional supervision on ``easiness'' required by traditional CL methods. Once the proposed MICL process is finished, the detector is applied to test images directly. The contributions of this work are summarized as following. First, we incorporate a semantic segmentation network to guide the detector to learn the extent of full objects and avoid being stuck at the discriminative object parts. Second, we propose an MICL method by combining MIL with CL so that the detector is not misled by hard and unreliable examples, and our CL process does not require any additional supervision on the ``easiness'' of the training examples. Third, we demonstrate the superior performance of the proposed MICL method as compared with the state-of-the-art weakly supervised detectors.