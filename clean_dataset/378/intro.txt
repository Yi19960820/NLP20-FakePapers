Automated detection of facial expressions has gained significant importance in the recent years especially with regards to the design of real-time security surveillance systems, internet-based social networking applications _cite_ and human computer interaction systems _cite_ . The primary challenges for automated facial expression detection include variations introduced by pose, lighting, distortions, expression and occlusions. While image filtering techniques aid equalization of lightening and distortions, Eigen-value decomposition of faces (Eigen-faces) followed by Isomap clustering have been well-known to cluster variations in pose _cite_ . Additionally, several supervised classification algorithms and publicly available data bases _cite_ have shown significant success in classifying facial features, skin texture and basic expressions such as fear, sadness, happiness, anger, disgust, surprise. Most of the existing texture-based expression detection algorithms _cite_ rely heavily on facial feature extraction and classifier training, and thereby incur significant computational complexity in the training phase. In this work, we propose a novel network-based clustering algorithm that is capable of separating the marginally classifiable expression faces from the easily classifiable ones. This method has two-fold advantages. First, this method can be used to reduce the overall computational time complexity for facial expression detection in a particular test data base of faces by subjecting only the faces with marginally classifiable expressions to complex feature-based classification. Second, the network-based metrics can be used to detect the most significant faces in the training data that are vital for feature-based expression classification tasks. Such network-based identification of most significant training image set has not been done in existing works so far. Identification of the most significant training faces can improve the existing accuracies in facial expression classification on facial test data sets. The existing facial expression detection algorithms can be broadly categorized into two categories: holistic methods _cite_ that focus on features of the full face, and geometric methods that depend on important parts of the face such as eye lids, eye brows, lips, nose etc. for expression detection _cite_ _cite_ . The first category of methods focus on pre-defined template matching (active shape models) _cite_ or extraction of Eigen-face descriptors followed by clustering using neural networks _cite_ _cite_, support vector machines _cite_, Naive-Bayes or Hidden Markov models _cite_ . The second category of methods rely on the extraction of gray-scale and color features corresponding to facial features (group of edges) _cite_, texture, and changes in eye-lids, eye-brows, nose, lips, wrinkles and bulges using local binary patterns (LBP) _cite_, optical flow _cite_ and pyramid extension of the histogram of gradient (PHOG) descriptors _cite_ _cite_ . For various classifier and training data sets, existing expression classification accuracies typically range between N-N \% _cite_ _cite_ while computation time can range from N seconds to a few hours. The proposed method aims at significantly reducing the computation time and improving expression classification accuracies in data bases with a large number of faces. In this work, two classification tasks are performed that include classification of images with facial occlusions and classification of faces with happy emotion, respectively. Unsupervised classification requires only N training images for cluster identification with a run-time of less than N second per image in a N GHz NGB RAM Laptop.