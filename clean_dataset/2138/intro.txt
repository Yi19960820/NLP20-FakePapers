Photographs taken in dark environments or in poor uneven illumination conditions, such as in the night or backlighting, often become illegible due to low intensity, much compressed dynamic range, low contrast, and excessive noises. Nowadays, even mass-marketed digital cameras use high-resolution sensors and large capacity memory, unsatisfactory spatial resolutions and compression artifacts are not problems anymore. But extremely poor lighting, which is beyond users' control and defies autoexposure mechanism, remains a common, uncorrected and yet understudied cause of image quality degradation. The direct consequence of poor lighting is much compressed dynamic range of the acquired image signal. Existing image enhancement methods can expand the dynamic range via tone mapping, but they are inept to recover quality losses due to the A/D quantization of low amplitude signals. As a result, the tone-mapped images may appear sufficiently bright with good contrast, but finer details are completely erased. As the non-linear quantization operation is not invertible, the image details erased by the A/D converter, when operating on weak and low dynamic range image signals, cannot be recovered by traditional image processing methods, such as high-pass filtering. The technical challenge in dequantizing images of compressed dynamic range is how to estimate and compensate for the quantization distortions. Up to now little has been done on the above missing data problem of A/D dequantization, leaving consumers' long desire for low light cameras unsatisfied. In this work we propose a novel approach to restore and enhance images acquired in low and uneven lighting. First, the ill illumination is algorithmically compensated by emulating the effects of artificial supplementary lighting based on an image formation model. The soft light compensation is only an initial step to increase the overall intensity and expand the dynamic range. It is not equivalent to photographing using flash, for the quantization losses incurred in the A/D conversion of low dynamic range images cannot be recovered in this way. Therefore, a subsequent step of the A/D dequantization is required, and this task is particularly suited for the methodology of deep learning, as will be demonstrated by this research. Deep convolutional neural networks (DCNN) have been recently proven highly successful in image restoration tasks, including superresolution, denoising and inpainting. But as the loss of information due to quantization of low dynamic range images is not in the spatial but pixel value domain, machine learning based A/D dequantization appears to be more difficult than aforementioned other problems of image restoration, and warrants some closer scrutiny. As in all machine learning methods, the performance of the learnt dequantization neural network primarily depends the quantity and quality of the training data. Using the same physical image formation model for light compensation, we derive an algorithm to generate training images of compressed dynamic range, by degrading corresponding latent images of normal dynamic range (ground truth for supervised learning) . The artifacts of the training images closely mimic those caused by poor lighting conditions in real camera shooting. In addition to the good data quality, the generation algorithm is designed in such a way that it can take ubiquitous, widely available JPEG images as input, thus the machine learning for the A/D dequantization task can benefit from practically unlimited amount of training data.