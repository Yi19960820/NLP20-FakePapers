In robotics, automating the grasping of ordinary objects is an important open problem~ . Much progress has been made both on the hardware side (the gripper itself) and on the perception side. The development of compliant or under-actuated mechanical grippers---often referred to as ``mechanical intelligence''---which passively adapt their shape to the grasped object has greatly simplified the problem~ . However, determining good grasping locations still requires an efficient perception system. The advent of Microsoft Kinect inexpensive ND camera opened the door to rapid deployment of new and robust approaches in identifying such locations. Its market accessibility and ease-of-use provided a straightforward solution for incorporating depth and RGB information (called RGBD images) into deployed systems of various industrial settings. In this paper, we look at identifying grasping locations for two plates parallel grippers, by employing such RGBD images. As representation of a grasping location, we use Jiang et al. N-dimensional grasp rectangle ~ from which the N-dimensional gripper configuration can be easily computed. The ND oriented rectangle, shown in Fig.~ _ref_, indicates the gripper's location, orientation and physical limitations: Using the grasp rectangle representation makes grasp recognition analogous to object recognition (bounding box approaches), and soon for detection. For grasp recognition, the goal is to determine whether a grasp rectangle _inline_eq_ is a good or bad candidate. For grasp detection, the goal is to predict the configuration of the best rectangle _inline_eq_ . In this particular setting, identifying grasping locations can then be seen as a vision problem. This is particularly advantageous because several break-through works on similar vision-oriented problems have been proposed in past decades, and can thus be exploited for detecting grasping locations. Although compelling due to its small cost and ease-of-use, the Microsoft Kinect (and most structured-light devices) has some drawbacks. One is the presence of two types of noise in depth information: the axial and lateral noise model of the object distance to the camera, and the mask noise model of missing ND information. While vision-based approaches can reasonably deal with the former, the latter can be particularly cumbersome. Objects with shiny surfaces often cause structured-light ND cameras to fail which results in absence of information. To cope with this phenomenon, ~ had to develop different mask-based regularization terms to solve their multi-layer neural network convergence problems caused by using zeros as masked-out entry values. With our approach, we seek to create a theoretically founded grasp localization model which can address the Kinect mask noise inherently, without resorting to a custom regularization. The second drawback of Microsoft Kinect is the lack of available large scale RGBD grasp datasets, which makes training high-dimensional models cumbersome. As an example, ~ previously applied a convolutional neural network (CNN) for detecting grasp candidates that contained more than a million parameters. Due to the relative small amount of RGBD images in their grasp dataset (the Cornell dataset), they had to pre-train the CNN for several days on ImageNet (a RGB image dataset) and fine-tune for several hours on the Cornell one. In an industrial context where datasets are small and new objects are regularly added, a fast and robust training phase is essential. In particular, an efficient strategy to make objects easier to grasp is to add more images from different viewpoints and retrain, hence the importance of fast training phase. To satisfy the aforementioned requirements, we looked at employing dictionary learning and sparse representations (DLSR) . Sparse modeling of data is a biologically-inspired and theoretically founded approach in which observations are represented as linear combinations of few atoms from a dictionary. As previously shown in the context of object recognition and image restoration, DLSR is well-suited to deal with masked-out entries, has a significantly faster training phase than CNN and can work with small datasets~ . A standard DLSR method is divided into a dictionary learning phase, where a dictionary is trained to capture the latent structure of the data, and a feature coding phase, where the dictionary is used to transform raw observations into features. Representing observations by learning how to extract features from them makes DLSR particularly interesting in the actual context, as it steers clear of relying on expert knowledge brought by hand-designed feature engineering. Our contribution with this paper is twofold. First, we propose a DLSR-based framework for learning and extracting useful information from RGBD images that is rapidly trainable, can work with a small dataset and inherently deals with masked-out entries. The goal is to demonstrate the applicability of such an approach for grasp recognition and detection, and to compare it with other ones in the literature on the standard Cornell task (shown in Fig.~ _ref_) . Second, we present an empirical evaluations of several dictionary learning and feature coding approach combinations. Since DLSR has been around for some years, more than one variant exists for dictionary training and feature extraction. The large quantity of available methods makes choosing one particular combination troublesome, as few indications can guide our choice. By understanding the relationship between dictionary learning and feature coding, our goal is to ascertain which combinations are best suited for the task at hand by comparing performance, speed of training and parallelizability (either on CPU or GPU) . The rest of this paper is divided as follows. We make an overview of related works in section~ _ref_ . All dictionary learning approaches and encoders are detailed in section~ _ref_, along with explanations concerning data preprocessing and the overall feature extraction process. We elaborate on the experimental framework in section~ _ref_ and report the results in section~ _ref_ . Finally, we discuss the pros and cons of the approaches in section~ _ref_ and conclude in section~ _ref_ .