The ability to correctly categorize objects from previously unseen classes is a key requirement in any truly autonomous object discovery system. Zero-shot Learning (ZSL) is a learning paradigm~ _cite_ that tries to fulfil this desideratum by leveraging information that may be available for each seen/unseen class. ZSL models usually assume that this information is given in form of class attribute vectors or textual descriptions of classes. Typical approaches taken by existing ZSL models can be roughly categorized into the following: (N) Learning a mapping from the instance space to the class-attribute space and predicting the class of an unseen class test instance by finding its closest class-attribute vector~ _cite_ ; (N) Defining the classifier for each unseen class as a weighted combination of the classifiers for the seen classes, where the combination weights are typically defined using similarity scores of unseen and seen class~ _cite_, and (N) Learning a probability distribution for each seen class and extrapolating to unseen class distributions using the class-attribute information~ _cite_ . A more detailed discussion of the related work on ZSL is provided in the Related Work section. Although the aforementioned ZSL models have shown considerable promise on various benchmark datasets, a key limitation of most of these models is that, at test time, these are highly biased towards predicting the seen classes~ _cite_ . This is because the ZSL model is learned using labeled data only from the seen classes. Due to this issue, the ZSL models are usually evaluated in a restricted setting where the training and test classes are assumed to be disjoint, i.e., the test examples only come from the unseen classes and the search space is limited to the unseen classes only. The more challenging setting where the training and test classes are not disjoint is known as generalized zero-shot learning (GZSL), and is considered a more formidable problem setting. Recent work~ _cite_ has shown that the accuracies of most ZSL approaches drops significantly in this setting. In this work, we take a generative approach to the ZSL problem, which naturally helps address the generalized ZSL problem. Our approach is based on a generative model to exemplars from the unseen classes (and, optionally, also from the seen classes), and subsequently training an off-the-shelf classification model using these synthesized exemplars. Our approach is motivated by, and is similar in spirit to, recent work on synthesizing exemplars for ZSL~ _cite_, which has shown to lead to improved performance, especially in the GZSL setting. For exemplar generation, we develop a generative model based on a variational autoencoder (VAE) architecture, in which the latent code of any instance is augmented with the class-attribute vector. This architecture is further coupled with a (a multivariate regressor) that learns a mapping from the VAE generator's output to the class-attribute. This feedback helps to improve the generator by encouraging it to generate exemplars that are of highly discriminative nature. Moreover, the discriminator also allows us to operate in semi-supervised settings by incorporating unlabeled examples for which we do not know the class label (and thus no class-attributes are available for these examples) . Once the model has been learned, it can be used to generate exemplars for any unseen class (and, optionally, also seen classes), given its class-attributes, and the exemplars can be used as labeled training examples to train any off-the-shelf classification model. Notably, since the classification model is trained using labeled examples from seen as well as unseen classes, at test time, it is not biased towards predicting seen classes in the GZSL setting, as also evidenced by recent work on leveraging synthesized unseen class examples~ _cite_ . The model in _cite_ is a vanilla conditional generative model, while ours is based on an explicit feedback driven mechanism. This leads to a very different model architecture and inference, and yields much better prediction accuracies. _cite_ represented each unseen class by Gaussian distribution while _cite_ based on semantic-visual embedding with Diffusion Regularization. Also note that, in our proposed framework, the final classification stage directly predicts the actual for each test example, as opposed to predicting the ~ _cite_, which further necessitates a nearest neighbor search to find the class label. This is appealing because the nearest neighbor search approach, as is commonly used in most ZSL methods, is known to suffers from issues, such as the hubness problem~ _cite_ .