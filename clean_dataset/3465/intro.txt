Deep learning has achieved great success _cite_, through multilayer architectures that extract high-level representations from raw data. However, as the number of neurons that are used increases, so does the computational complexity and memory requirements of the algorithms that are used. Thus in _cite_, we constructed network models for deep learning that exploit the asymptotic properties of very large clusters of cells by reducing them to simplified transfer functions based on spiking Random Neural Networks (RNN) with multilayer architectures (MLA) and extreme learning machines (ELM) _cite_ . The resulting RNN-MLA architecture provided highly effective classification rates on real data sets with a reduced computational complexity as compared to other deep learning techniques. In this paper we pursue the idea that the human brain contains important areas composed of dense clusters of cells, such as the basal ganglia and various nuclei. These clusters may be composed of similar or identical cells, or of varieties of cells. Because of their density, we suggest that such clusters may allow for a substantial amount of direct communication between stomata, in addition to the commonly exploited signalling that takes place through dendrites and synapses. Thus we consider a network composed of a multi-layer structure (MLA) where each layer is composed of a finite number of dense nuclei. Each nucleus is modelled as a recurrent spiking Random Neural Network _cite_ . Each neuron in each nucleus has a statistically identical interconnection structure with the other cells in the same nucleus. This statistical regularity allows for a great individual variability among neurons both with regard to spiking times and the interconnection patterns. Within each nucleus the cells communicate with each other _cite_ in a recurrent fully connected recurrent structure that can use both synapses and direct soma-to-soma interactions. On the other hand, the communication structure between different layers of nuclei is a conventional multi-layer feedforward structure, where the nuclei in the first layer receive excitation signals from external sources, while each cell in each nucleus has an inhibitory projection to the next higher layer. This RNN-MLA architecture is shown schematically in Figure _ref_ .