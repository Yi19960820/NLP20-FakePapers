Optical microscopy is a powerful tool to comprehend biological systems, enabling researchers and physicians to acquire qualitative and quantitative data about cellular function, organ development, or diseases. However, light traveling through any imaging system undergoes diffraction, which leads to image blur _cite_ . This represents an intrinsic limit and the determining factor for the resolution of an optical instrument, and thus limits visual access to details. Indeed, the optical system only collects a fraction of the light emitted by any one point on the object, and cannot focus the light into a perfect image. Instead, the light spreads into a three-dimensional diffraction pattern. Image formation can be modeled as the convolution of the original object with a PSF, which sums up the optical aberrations _cite_ . For thin, yet not flat, samples, the PSF remains shift-invariant within small areas of the ND image, but the three-dimensional depth of the imaged object produces a local blur. Using a PSF corresponding to the blur in a deconvolution algorithm can be used to restore details in the image _cite_ . Deconvolution techniques can be categorized into three classes: (N) Non-blind methods, (N) entirely blind methods, and (N) parametric semi-blind algorithms. Non-blind methods require knowledge of the PSF _cite_ . One of the main difficulties in practice is to determine the original PSF that characterizes the actual optical system without discovering it empirically by acquiring a ND image of a fluorescent bead, which is a tedious and time-consuming calibration step. The two latter classes fall into blind deconvolution (BD) techniques, which improve the image without prior knowledge of the PSF, the object or other optical parameters. Entirely blind algorithms, such as _cite_ are based the optimization of a penalty function or a maximum a posteriori (MAP) estimation of the latent image or kernel _cite_ . However, these methods typically use strong constraints such as sharpness along the object edges and do not always generalize to unexpected or noisy types of data _cite_, which are common in microscopy images. Also, many BD techniques are computationally expensive, especially for larger convolution kernels, and assume spatially invariant PSFs. Finally, parametric or semi-blind algorithms are blind methods that are constrained by knowledge about the transfer function distribution, such as a diffraction model or a prior on the shape of the PSF (_cite_, _cite_) . Parametric models allow reducing the complexity of the optimization problem, increasing the overall robustness, and avoiding issues such as over-fitting. However, it remains hard to estimate the parameters from experimental data. We will focus on this third class of deconvolution methods, by addressing the central problem of how to best infer the parameters without measuring any of them experimentally. Machine learning recently improved the ability to classify images _cite_, detect objects, or describe content _cite_ . Convolutional Neural Networks (CNNs) _cite_, in particular, are built for learning new optimal representations of image data and perform self-regulating feature extraction _cite_ . Because of their ability to learn correlations between high-and low-resolution training samples, CNNs appear well adapted to our problem of determining the blur kernel. A similar reasoning led to recent results in _cite_ and _cite_, where the direction and amplitude of motion blur was determined by a CNN classifier from images blurred with a Gaussian kernel. Here we present a spatially-variant BD technique aimed at microscopy of thin, yet non-flat objects. Our method combines local determination of the PSF and spatially-variant deconvolution using a regularized Richardson-Lucy (RL) algorithm _cite_ . To find the PSF in a computationally tractable way, we train a CNN to perform regression of model parameters on synthetically blurred image patches. The novel aspects of our approach are: (N) Our method does not require the experimental measurement of a PSF, only synthetic training data is necessary. (N) Compared to non-parametric BD, the problem complexity remains low and therefore is more easily amenable to optimization. (N) Parameters with a physical meaning are inferred from the image itself. (N) The algorithm is computationally efficient, resulting in a near real-time kernel regression and mapping at the expense of a much longer, yet straightforward, training phase. In Section N, we describe each step of the method. In Section N, we present experiments with synthetic and acquired data. In Section N, we conclude.