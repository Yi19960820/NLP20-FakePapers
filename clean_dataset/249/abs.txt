We propose to learn the kernel of an SVM as the weighted sum of a large number of simple, randomized binary stumps. Each stump takes one of the extracted features as input. This leads to an efficient and very fast SVM, while also alleviating the task of kernel selection. We demonstrate the capabilities of our kernel on _inline_eq_ standard vision benchmarks, in which we combine several common image descriptors, namely histograms (FlowersN and Daimler), attribute-like descriptors (UCI, OSR, and a-VOCN), and Sparse Quantization (ImageNet) . Results show that our kernel learning adapts well to these different feature types, achieving the performance of kernels specifically tuned for each, and with an evaluation cost similar to that of efficient SVM methods.