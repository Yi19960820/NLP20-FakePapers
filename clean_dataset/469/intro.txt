Human intelligence is considered the epitome towards which man-made intelligent systems strive. Two specific abilities that set the human mind apart are its ability to generalize to related but unseen data and its ability to learn from small quantities of data. As machine learning methods have seen tremendous progress in recent years there has been growing focus on measuring the ability of models to generalize to unseen varieties of data and to learn from even very little of it. This is the aim of the one-shot learning problem _cite_ . Specifically, given a dataset some of whose classes are not used for training, the model is tested for its ability to classify over those unseen classes using a single example for each class. Essentially, the model must learn features that generalize across classes. The one shot learning problem has been studied under various domains like Bayesian learning _cite_ _cite_ and deep representation learning using distance metrics _cite_ . Deep networks till recently were felt unsuited for such a problem given the huge number of parameters involved and the possibility of overfitting on a problem with very little data. However recent work _cite_ _cite_ has shown that deep models, especially recurrent architectures, can perform very well on the one-shot task. The focus of our work, however is on two aspects which we believe are essential for a model to do well on the task of one shot learning-inferring an accurate semantic representation in a low dimensional manifold and strong regularization. Convolutional Neural Nets are very effective at both, as is shown by their success on many image classification tasks. We additionally enforce the first criteria by presenting a hypothesis that learning an end-to-end trainable distance measure is better than a fixed distance metric (see figure _ref_) . We do this by implementing a modification of the residual network architecture _cite_ . Specifically our modification involves using skip residual connections and we refer to the our model as Skip Residual Siamese Network (SRPN) . The model takes a pair of images and outputs a single similarity embedding vector. We train this model end-to-end for the similarity matching objective and then use it for few shot classification tasks on the Omniglot and mini-Imagenet datasets. We propose a solution to the second problem in the form of a novel architecture derived from the Generative Adversarial Networks (GAN) _cite_ . The field of generative modelling has seen rapid advancement in the past few years. This can majorly be attributed to the development of various frameworks that work well in tandem with deep neural networks. Models have been developed that are able to efficiently approximate data distributions well enough to be of practical utility. An interesting subclass of such models is that of the implicit variety _cite_ which do not prescribe a fixed parametric form for the learned distribution. These models are consequently trained using methods of comparison instead of maximizing a fixed log-likelihood function. The de facto framework for implicit models is Generative Adversarial Networks (GANs), which has been successfully used for many learning tasks. While this framework has received great interest, work towards understanding its generalization in the low-data regime and its applicability for tasks such as one shot learning has been limited. Our work attempts to bridge that gap and show that GANs provide effective regularization on unseen data distributions. Specifically, we extend the framework by trying to generate a conditional distribution which can regularize a siamese matching network. The siamese network is itself modified to incorporate a feedback that trains the generator along with the task of similarity matching. Thus, our model can be considered an instance of multi-task learning _cite_ . We show that the generated data is a strong regularizer for the similarity-matching task and helps in generalization to unseen classes. Our work is closely related to that on similarity matching using Siamese Networks _cite_, which was extended for convolutional networks for face verification in _cite_ . Koch et. al _cite_ show results using convolutional variants of these networks on the few shot classification tasks for Omniglot. Various formulations for the similarity objective such as contrastive loss _cite_ and triplet loss _cite_ and efficient methods to do the same _cite_ are also closely related. Other related approaches include those based on Deep Metric Learning such as deep embeddings for triplet loss _cite_ and better metrics for fine-grained similarity _cite_, and popular methods like Neighbourhood Component Analysis _cite_ . The few shot problem specifically has been studied from multiple perspectives, including the similarity-matching _cite_, optimization _cite_, metric learning _cite_, hierarchical graphical models _cite_ etc. Our work falls in the similarity-matching paradigm ie. the model learns to classify by individually comparing and contrasting the similarities of the given class data with the test example at hand. To the best of our knowledge, the earliest work on this problem is using Bayesian methods _cite_ _cite_ . Salakhutdinov et. al _cite_ proposed an elegant approach using hierarchical bayesian models. Lake et. al _cite_ _cite_ develop the framework of Bayesian Program Learning that naturally inculcates predicting by learning from small amounts of data. They also developed the Omniglot dataset used in our experiments. Recent work includes methods that try to use deep networks for learning embeddings which are the fed to recurrent networks for calculating embeddings _cite_ . Vinyals et. al _cite_ also propose an approach for learning the similarity embedding based on the full context of the input set as opposed to pairwise comparisons used in typical similarity matching settings, including this work. They also modify the training procedure to be similar to the testing protocol for few shot learning. Another recent work _cite_ also explicitly optimizes the one shot learning objective by essentially training the model for multiclass classification in the one shot setting. In contrast, this work aims to show that deep residual networks are naturally well suited to generalization objectives and even the proper pairwise similarity matching objective can perform the one shot task well. The recent work in _cite_ proposes a recurrent model that also outputs a pairwise embedding, however their reasoning is towards using attention to selectively infer the next step whereas we are focused on a natural, scalable extension to the CNN for one-shot learning. Another related area is that of deep generative models for one-shot learning. Edwards et. al _cite_ propose handling the one shot classification task by learning dataset statistics using the amortized inference of a variational auto-encoder. Another popular framework of Generative Modeling-GANs _cite_ and their conditional _cite_ _cite_ alternatives are the essential components of our Generative Regularizer. Our design of using the generator with a discriminator is inspired by the ImprovedGAN model _cite_ for semi-supervised learning. Another work which uses generated images for improving one shot learning is _cite_, although they train their model as a transformer for test time generations using cosine similarity in the training set to generate analogies instead of an adversarial loss. To summarize, our work proposes a model for similarity matching with two suggested improvements for similarity measures and . The specific contributions are: