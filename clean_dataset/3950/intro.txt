detection of man-made objects in particular buildings from a single very high resolution (VHR) SAR image is of great practical significance particularly in applications having stringent temporal restrictions e.g., emergency responses. However, owing to inherent complexity of SAR images caused by the so-called speckle effect together with radiometric distortions mainly originating due to side looking geometry, scene interpretation using SAR images is highly challenging. Particularly in urban areas, such distortions render the data to be mainly characterized by multi-bounce, layover and shadowing effects consequently giving rise to the need of automatic and robust algorithms for object detection from SAR images. A variety of algorithms have been published in the literature that aims at the detection and reconstruction of buildings from SAR images. Typically, most of the developed approaches rely on auxiliary information e.g., the multi-sensor data provided by the optical _cite_ _cite_ and LiDAR _cite_ sensors, Geographic Information System (GIS) data e.g., N-D building footprints _cite_, multi-dimensional data e.g., polarimetric SAR (PolSAR) _cite_, or multi-view/multi-aspect data such as interferometric SAR (InSAR) _cite_ . These approaches improved the feature extraction process by providing the complimentary information. To our knowledge, the literature using only single SAR image in the context of building detection is rather sparse. Among few existing approaches, Quartulli and Datcu _cite_ employed an automatic stochastic algorithm to reconstruct buildings from a single SAR intensity image by modeling strong signals originated via dihedral scattering at the bottom and the layover at the roof edges of the building. Zhao et al. _cite_ proposed a building detection method based on marker controlled watershed algorithm. A similar approach that exploited layover and double bounce echoes to detect and determine the number of buildings from a single high resolution image was provided in _cite_ . Ferro et al. _cite_ also developed a method that was primarily based on extracting a set of low-level bright (lines) and dark (shadows) primitives. Chen et al. _cite_ introduced a more recent N-D range detector to determine the N-D building footprints. The method could potentially reconstruct simple symmetrical building footprints but might fail for scenes containing more complex non-symmetrical building shapes. All the aforementioned approaches aim to extract buildings in an unsupervised (or data-driven) manner. Some researchers have also formulated the detection problem in a classification framework to benefit from well-developed supervised learning methods typically used in computer vision _cite_ _cite_ . However, the effective utilization of such supervised learning methods has two practical limitations: To address the first point i.e., distinctive feature extraction, a number of approaches have been proposed. E.g., raw pixels of images _cite_, magnitudes of N-D Fourier coefficients _cite_, or discrete wavelet transform _cite_ etc. have been used as features. Typically, feature extraction methods rely on heuristics in selecting appropriate features and therefore to cope with unaccounted situations (e.g., tolerance to incomplete views/poses in training data or randomness in speckle for different observations), expert knowledge is required to translate such discrepancies in the model for feature representation _cite_ . Recently, Convolution Neural Networks (CNNs), a type of multi-layered neural networks, have significantly outperformed previous methods and became state-of-the-art in image classification. Their power lies in the fact that they directly extract high-level abstract image features which allow replacing hand-crafted features by the machine learned features fitting to the task at hand. They have special characteristics (i.e., shared weights architecture, local receptive fields, pooling and spatial sub-sampling) that make them tolerant to high degree of image translations, skewing, scaling, rotation and other forms of geometric distortions. There exist abundant literature that employ CNNs to perform object detection in remote sensing images _cite_ _cite_ _cite_ . In this context, we refer the interested reader to an excellent recently published survey article containing comprehensive review of deep learning techniques applied to optical remote sensing images _cite_ . In contrast, the use of CNNs over SAR images is up to now limited but consistently increasing. For instance, Profeta et al. _cite_ experimented with various CNN architectures on the moving and stationary target (MSTAR) SAR dataset to achieve high classification accuracy. MSTAR dataset has also been utilized to perform SAR image segmentation in _cite_ and _cite_ . Ding et al. _cite_ investigated the capability of deep CNNs to address issues in SAR target recognition, such as target translations, random speckle noise, and insufficient pose images in the training data. Utilization of CNNs in polarimetric SAR image classification has been demonstrated in _cite_ . Some researchers also explored CNNs to solve the change detection problem in SAR images _cite_ . Recently, the application of CNNs over TerraSAR-X spoltlight datastacks to classify built-up area has been demonstrated in _cite_ . The problem is particularly challenging as the SAR images suffer from severe geometric distortions in urban areas and therefore they developed a robust multiscale CNN architecture to extract hierarchical features directly from SAR image patches. With the aim to develop benchmark SAR dataset, Zhao et al. _cite_ also exploited CNNs over a TerraSAR-X spotlight data in image classification context and prepared a relatively large SAR image database containing five classes of object patches, including buildings, roads, vegetation, alongside and water area. They demonstrated that the CNNs trained with fairly large training samples significantly improves the classification accuracy. Xu et al. _cite_ also demonstrated the use of CNNs over SAR images to extract buildings by manually preparing the training dataset and later incorporating modern regularization techniques (e.g., data augmentation, dropout and early stopping) to reduce testing errors. As can be imagined, the precondition for application of CNNs or any other supervised learning frameworks is the availability of annotated datasets. They are necessary not only to analyze and validate the performance of classification algorithms but are too required in the training phase where parts of annotated data are utilized to optimize prediction models. Lack of such annotated datasets is one of the major issues in application of CNNs over SAR images. Manual (or somewhat interactive) annotation, as is done in the aforementioned approaches, is one potential solution. However, due to complex multiple scattering and different microwave scattering properties of the objects appearing in the scene possessing different geometrical and material features, the manual annotation often requires expertâ€™s knowledge (see Figure _ref_) and easily becomes impractical when large scenes need to be processed. Apart from this, another possibility of generating such a reference SAR dataset is by exploiting simulation based methods as proposed e.g., in _cite_ _cite_ _cite_ . However such methods have their own limitations in a sense that they are either only capable of simulating simpler building shapes (e.g., _cite_) or typically require accurate models (N-D building models and/or accurate digital surface models) to precisely generate such ground truth data which, in most cases, is not available. Thus, in view of above, automatic annotation of SAR images, if possible, is essential. The objective of this paper is twofold: First is to demonstrate the potential of automatic preparation of SAR training datasets for larger regions; Secondly, using the automatically prepared dataset to train deep CNN architecture to detect buildings in a single very high resolution SAR image. This paper extends the initial idea _cite_ of automatic SAR annotation and performs a thorough analysis of the obtained SAR annotation and prediction results. Following is the novel workflow presented in this paper that involves: The proposed workflow leads to the following contributions to the remote sensing community. We addressed the problem of automatic generation of annotated (labelled) data which is always problematic to obtain in SAR images. In addition, we also addressed the usage of CNNs in SAR image classification which is still a relatively new research area and has not been explored much. Last but not least, since the datasets used are widely available, the annotation approach is generic and may actually lead to new perspectives in producing benchmark datasets for SAR images.