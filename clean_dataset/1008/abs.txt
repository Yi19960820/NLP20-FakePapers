\noindent  Automated classification of medical images through neural networks can reach high accuracy rates but lack interpretability.  To compare the diagnostic accuracy obtained by using content based image retrieval (CBIR) to retrieve visually similar dermatoscopic images with corresponding disease labels against predictions made by a neural network.  A neural network was trained to predict disease classes on dermatoscopic images from three retrospectively collected image datasets containing N, N and N images respectively. Diagnosis predictions were made based on the most commonly occurring diagnosis in visually similar images, or based on the top-N class prediction of the softmax output from the network. Outcome measures were area under the ROC curve for predicting a malignant lesion (AUC), multiclass-accuracy and mean average precision (mAP), measured on unseen test images of the corresponding dataset.  In all three datasets the skin cancer predictions from CBIR (evaluating the N most similar images) showed AUC values similar to softmax predictions (N, N and N versus N, N and N respectively; p-value _inline_eq_ N for all) . Similarly, the multiclass-accuracy of CBIR was comparable to softmax predictions. Networks trained for detecting only N classes performed better on a dataset with N classes when using CBIR as compared to softmax predictions (mAP N vs. N and N vs. N respectively) .  Presenting visually similar images based on features from a neural network shows comparable accuracy to the softmax probability-based diagnoses of convolutional neural networks. CBIR may be more helpful than a softmax classifier in improving diagnostic accuracy of clinicians in a routine clinical setting.