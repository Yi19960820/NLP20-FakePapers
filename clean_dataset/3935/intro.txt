In the past decade, the advances in material science enabled the fabrication of small, low cost devices in a variety of popular applications. Following these advances, untethered pill-size, swallowable capsule endoscopes with an on-board camera and wireless image transmission device have been developed and used in hospitals for screening the gastrointestinal tract and diagnosing diseases such as the inflammatory bowel disease, the ulcerative colitis and the colorectal cancer. Unlike standard endoscopy, endoscopic capsule robots are non-invasive, painless and more appropriate to be employed for long duration screening purposes. Moreover, they can access difficult body parts that were not possible to reach before with standard endoscopy (e.g., small intestines) . Such advantages make pill-size capsule endoscopes a significant alternative screening method over standard endoscopy . However, current capsule endoscopes used in hospitals are passive devices controlled by peristaltic motions of the inner organs. The control over the capsule's position, orientation, and functions would give the doctor a more precise reachability of targeted body parts and more intuitive and correct diagnosis opportunity. Therefore, several groups have recently proposed active, remotely controllable robotic capsule endoscope prototypes equipped with additional functionalities such as local drug delivery, biopsy and other medical functions . An active motion control is, on the other hand, heavily dependent on a precise and reliable real time pose estimation capability which makes the robot localization the key capability for a successful endoscopic capsule robot operation. In the last decade, several localization methods were proposed to calculate the ND position and orientation of the endoscopic capsule robot such as fluoroscopy, ultrasonic imaging, positron emission tomography (PET), magnetic resonance imaging (MRI), radio transmitter based techniques and magnetic field based techniques. The common drawback of these localization methods is that they require extra sensors and hardware design. Such extra sensors have their own drawbacks and limitations if it comes to their application in small scale medical devices such as space limitations, cost aspects, design incompatibilities, biocompatibility issue and the interference of the sensors with the activation system of the device. As a solution of these issues, a trend of vision-based localization methods have attracted the attention for the localization of such small scale medical devices. As a first attempt, structure from motion (SfM) methods have been proposed to deal with monocular endoscope localization . However, SfM methods are incapable of real time processing which makes them unsuitable for robotic localization. The use of visual simultaneous localization and mapping (VSLAM) in medical field has been researched by, who modified the extended Kalman filter SLAM (EKF-SLAM) framework from for medical applications. modified the breakthrough VSLAM method parallel tracking and mapping (PTAM) algorithm to a stereo-endoscope to build a denser ND map than previous EKF based SLAM systems. Due to the non-rigid deformations inside human body, the use of only a monocular endoscope has remained as a challenge. provided extensive validation on in-vivo human sequences, e.g. demonstrating the efficiency of EKF-SLAM for hernia defect measurements in hernia repair surgery. Following the trend of PTAM modification, another milestone VSLAM method, ORB-SLAM was adjusted into medical field and proposed as ORB SLAM-based Endoscope Tracking and ND Reconstruction method for endoscopic localization. All of the presented vision-based localization methods use landmark-based methods, where the underlying idea is to search for distinct landmark positions and track them across frames for localization. These methods show poor performance on endoscopic images mainly because such images lack distinct features that algorithms need to extract and track to perform a precise visual odometry. Another issue in front of mono camera based VSLAM algorithms is that the translation in z direction is mathematically not possible to determine up to a scale using only one camera. Moreover, all of the existing methods in literature are proposed for handheld standard endoscopic cameras. However, endoscopic capsule robot differs from standard handheld endoscope due to its own characteristic problems such as space availability, limited energy source, low camera quality and resolution. Convolutional neural networks (CNN), such as deep neural networks, convolutional deep neural networks, deep belief networks and recurrent neural networks have been applied to fields such as computer vision, automatic speech recognition, natural language processing and bioinformatics where they have produced state-of-the-art results on various tasks and outperformed already existing methods in these fields. There has been especially a wide-spread adoption of various deep-neural network architectures for computer vision related tasks because of the apparent empirical success these architectures have shown in various image classification tasks. In fact, the seminal paper ImageNet ClassiÔ¨Åcation with Deep Convolutional Neural Networks has been cited over N times . With this intention, we propose in this paper a new method for N-DoF localization of both endoscopic capsule robot and handheld standard endoscope using the CNN system. We demonstrate that CNN learns the most relevant feature vector representation related to ND position and orientation estimation of the robot from ND raw image inputs. The method we introduced solves several issues confronted with the challenge endoscopic image datasets faced by typical SLAM pipelines, such as the need to establish frame-to-frame feature correspondence which is practically not working on low textured inner organ tissues and the need to extract large baseline key frames. The main benefit of our deep learning based approach is that it does not require any additional sensor. And compared to vision based unsupervised localization methods, our supervised method making use of pre-trained information is more appropriate for endoscopic type of images since the operation environment remains more or less similar among different patients. For the first time in literature, we propose a deep learning based real time N-DoF localization method for mono camera based endoscopic capsule robot and handheld standard endoscope. As the outline of this paper, section _ref_ introduces the proposed CNN based localization method in detail. Section _ref_ presents our dataset and the experimental setup. Section _ref_ shows our experimental results for N-DoF localization of the endoscopic capsule robot. Section _ref_ discusses the drawbacks of our method and gives future directions.