A complete cognizance of a visual scene is achieved by relational reasonings of a set of detected entities in an attempt to discover the underlying structure _cite_ . Reasoning comparative relationships allows artificial intelligence to infer semantic similarities or transitive orders among objects in scenes with various perspectives and scales _cite_ . While the core of relational reasoning instrumentally depends on spatial learning _cite_, the relational networks (RNs) _cite_ have fostered the performance vastly on related tasks based on their spatial grid features. However, the number of objects in conventional RNs upsurges as their method assumes that each grid represents an object at the corresponding position within the scene regardless of the existence of an object at a grid position. Moreover, the computational cost increases quadratically as RNs are based on pairwise computation of objects' relations for relational reasoning. This computational burden is inevitable for visual reasoning problems if conventional architectures of convolutional neural networks (CNNs) _cite_ are used. Although, CNNs have allowed success in many computer vision problems _cite_, yet they still suffer from difficulties in generalization over geometric variations of scenes. This is mainly due to the receptive fields that are mapped with convolution filters at fixed areas, which derives CNNs to disregard spatial locations in the process of searching for optimal features. Either bigger size of filters that embrace multiple input entities or repetitive usage of smaller filters in deeper networks are typically used to learn spatial relationships. CNNs, however, still show limited performances for large deformations of inputs as long as the receptive fields of convolution or pooling filters stay local and small-sized _cite_ . In order to learn relationships among objects, the correlation of objects needs to be defined along with the segregation of non-object features. And, CNNs' structural loss of spatial information also needs to be overcome to handle dynamic variations of object sizes and locations. We are motivated to solve such issues through globally extending receptive fields of object features and efficiently learning correlations among objects in an end-to-end manner. To this end, we propose a modular technique named Broadcasting Convolutional Network (BCN) that can be applied in any CNNs to enable learning spatial features with absolute positional information, broadcasting the features and analyzing visual relations among given objects. This technique not only overcomes the limitations of conventional narrow-sighted convolution operations by extending the receptive fields ideally to the global manner, but also allows to define a novel neural network called the Multi-relational Network (multiRN) that outperforms on the relational reasoning tasks in terms of both performance and computational efficiency. The proposed multiRN achieves the state-of-the-art performance on the CLEVR dataset which is the representative dataset for relational reasoning. The paper is organized as follows. In Sections _ref_ and _ref_, the proposed BCN and multiRN are explained in detail. In Section _ref_, the novelty of our work is described by comparing the methods with the related works. Section _ref_ shows experimental results and finally, Section _ref_ concludes the paper.