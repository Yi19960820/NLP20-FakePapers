Over the last decades, the popularization of smartphones and the growth of social networks have made digital images and videos very common digital objects. According to several reports, almost two billion pictures are uploaded everyday on the internet. This tremendous use of digital images has been followed by a rise of techniques to alter image contents, using editing software like Photoshop for instance. The field of digital image forensics research is dedicated to the detection of image forgeries in order to regulate the circulation of such falsified contents. There have been several approaches to detect image forgeries~ _cite_, most of them either analyze inconsistencies relatively to what a normal camera pipeline would be or rely on the extraction of specific image alterations in the resulting image. Among others, image noise~ _cite_ has been shown to be a good indicator to detect splicing (copy-past from an image to another) . The detection of image compression artifacts~ _cite_ also presents some precious hints about image manipulation. Today, the danger of fake news is widely acknowledged and in a context where more than N million hours of video content are watched daily on social networks, the spread of falsified video raises more and more concerns. While significant improvements have been made for image forgery detection, digital video falsification detection still remains a difficult task. Indeed, most methods used with images can not be directly extended to videos, which is mainly due to the strong degradation of the frames after video compression. Current video forensic studies~ _cite_ mainly focus on the video re-encoding~ _cite_ and video recapture~ _cite_, however video edition is still challenging to detect. For the last years, deep learning methods has been successfully employed for digital image forensics. Amongst others, Barni et al.~ _cite_ use deep learning to locally detect double JPEG compression on images. Rao and Ni~ _cite_ propose a network to detect image splicing. Bayar and Stamm~ _cite_ target any image general falsification. Rahmouni et al.~ _cite_ distinguish computer graphics from photographic images. It clearly appears that deep learning performs very well in digital forensics, and disrupts traditional signal processing approaches. In the other hand, deep learning can also be used to falsify videos. Recently, a powerful tool called Deepfake has been designed for face capture and reenactment. This methods, initially devoted to the creation of adult content, has not been presented in any academic publication. Deepfake follows FaceNFace ~ _cite_, a non deep learning method introduced by Thies et al. that targets similar goal, using more conventional real-time computer vision techniques. This paper addresses the problem of detecting these two video editing processes, and is organized as follows: Sections~ _ref_ and~ _ref_ present more details on Deepfake and FaceNFace, with a special attention for the first one that has not been published. In Section~ _ref_, we propose several deep learning networks to successfully overcome these two falsification methods. Section~ _ref_ presents a detailed evaluation of those networks, as well as the datasets we assembled for training and testing. Up to our knowledge, there is no other method dedicated to the detection of the Deepfake video falsification technique. Deepfake is a technique which aims to replace the face of a targeted person by the face of someone else in a video. It first appeared in autumn N as a script used to generate face-swapped adult contents. Afterwards, this technique was improved by a small community to notably create a user-friendly application called FakeApp . The core idea lies in the parallel training of two auto-encoders. Their architecture can vary according to the output size, the desired training time, the expected quality and the available resources. Traditionally, an auto-encoder designates the chaining of an encoder network and a decoder network. The purpose of the encoder is to perform a dimension reduction by encoding the data from the input layer into a reduced number of variables. The goal of the decoder is then to use those variables to output an approximation of the original input. The optimization phase is done by comparing the input and its generated approximation and penalizing the difference between the two, typically using a _inline_eq_ distance. In the case of the Deepfake technique, the original auto-encoder is fed with images of resolution _inline_eq_ variables, encodes those images on _inline_eq_ variables and then generates images with the same size as the input. The process to generate Deepfake images is to gather aligned faces of two different people _inline_eq_ and _inline_eq_, then to train an auto-encoder~ _inline_eq_ to reconstruct the faces of _inline_eq_ from the dataset of facial images of _inline_eq_, and an auto-encoder _inline_eq_ to reconstruct the faces of _inline_eq_ from the dataset of facial images of~ _inline_eq_ . The trick consists in sharing the weights of the encoding part of the two auto-encoders _inline_eq_ and _inline_eq_, but keeping their respective decoder separated. Once the optimization is done, any image containing a face of _inline_eq_ can be encoded through this shared encoder but decoded with decoder of _inline_eq_ . This principle is illustrated in~Figure~ _ref_ and _ref_ . The intuition behind this approach is to have an encoder that privileges to encode general information of illumination, position and expression of the face and a dedicated decoder for each person to reconstitute constant characteristic shapes and details of the person face. This may thus separate the contextual information on one side and the morphological information on the other. In practice, the results are impressive, which explains the popularity of the technique. The last step is to take the target video, extract and align the target face from each frame, use the modified auto-encoder to generate another face with the same illumination and expression, and then merge it back in the video. Fortunately, this technique is far from flawless. Basically, the extraction of faces and their reintegration can fail, especially in the case of face occlusions: some frames can end up with no facial reenactment or with a large blurred area or a doubled facial contour. However, those technical errors can easily be avoided with more advanced networks. More deeply, and this is true for other applications, auto-encoders tend to poorly reconstruct fine details because of the compression of the input data on a limited encoding space, the result thus often appears a bit blurry. A larger encoding space does not work properly since while the fine details are certainly better approximated, on the other hand, the resulting face loses realism as it tends to resemble the input face, i.e. morphological data are passed to the decoder, which is a undesired effect. Reenactment methods, like~ _cite_, are designed to transfer image facial expression from a source to a target person. FaceNFace ~ _cite_, introduced by Thies et al., is its most advanced form. It performs a photorealistic and markerless facial reenactment in real-time from a simple RGB-camera, see~Figure~ _ref_ . The program first requires few minutes of prerecorded videos of the target person for a training sequence to reconstruct its facial model. Then, at runtime, the program tracks both the expressions of the source and target actorâ€™s video. The final image synthesis is rendered by overlaying the target face with a morphed facial blendshape to fit the source facial expression.