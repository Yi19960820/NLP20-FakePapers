Semantic image segmentation is the task of partitioning and labeling the image into pixel groups which belong to the same object class. It has been widely used for numerous applications such as robotics~ _cite_, medical applications~ _cite_, augmented reality~ _cite_, and automated driving~ _cite_ . In the recent years, three types of learning architectures have been designed to learn the necessary representations required to solve the semantic image segmentation task. These methods include architectures that: (i) encode handcrafted features extracted from the input images into rich non-hierarchical representations; (ii) learn multiple levels of feature hierarchies from the input data; (iii) make use of the ideas from both categories to extract feature hierarchies from hand-crafted features. He et al~ _cite_ is an example of the first class of architectures which utilize handcrafted region and global label features in multiscale conditional random fields to get the desired semantic segmentation. The second class of architectures includes Convolutional Neural Networks~ _cite_ and Deep Belief Networks~ _cite_ that learn multiple layers of features directly from the input images. These methods have been shown to achieve state-of-the-art segmentation performance on various datasets~ _cite_ . Despite their success, their design and optimal configuration is not well understood which makes it difficult to develop them. In addition, the vast arrays of network parameters can only be learned with the help of powerful computational resources and large training datasets. These may not be available for many applications such as stock market prediction~ _cite_, medical imaging~ _cite_ etc. The third class of models combine the concepts from both of the above-mentioned models to learn shallow or deep feature hierarchies from low-level hand-crafted descriptors. Yu~ _cite_ learned multiple layers of hierarchical features from patch descriptors using stacked denoising autoencoders. This class of models has produced promising performance on various datasets~ _cite_ . This paper proposes the Generative ScatterNet Hybrid Deep Learning (G-SHDL) network with structural priors for semantic image segmentation. The G-SHDL network is inspired by the ScatterNet Hybrid Deep Learning (SHDL) ~ _cite_ network. The SHDL network extracts handcrafted features from the input image using the ScatterNet front-end which are then used by the unsupervised learning based Stacked PCA mid-section layers to learn hierarchical features. These hierarchical features are finally used by the supervised back-end module to solve the object classification task. The approximate minimization of the reconstruction loss function for the PCA layers is obtained simply from the Eigen decomposition of the image patches~ _cite_ . This results in rapid learning of the hierarchical features. However we found that, despite the favorable increase in the rate of learning, the approximate solution of PCA loss function produces undesired checkerboard filters which limit the performance of these models. The proposed G-SHDL network is an improved version of the SHDL network that uses ScatterNet as the front-end, similar to the SHDL network, to extract hand-crafted features from the input images. However, instead of PCA layers in the middle section, the G-SHDL uses four stacked layers of convolutional Restricted Boltzmann Machine (RBM) with structural priors to learn an invariant hierarchy of features. These hierarchy features are finally used by a supervised conditional random field (CRF) to solve the more complicated task of semantic segmentation as opposed to object recognition. The main contributions of the paper are stated below: G-SHDL network is used to perform semantic segmentation on MSRC~ _cite_ and Stanford background (SB) ~ _cite_ datasets. The average segmentation accuracy for each class for both datasets is presented. In addition, an extensive comparison of the proposed pipeline with other deep supervised segmentation methods is demonstrated. The paper is divided as follows: section N briefly presents the proposed G-SHDL network, section N presents the experimental results while section N draws conclusions.