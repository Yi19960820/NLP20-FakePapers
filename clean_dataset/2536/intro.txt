Current methods for learning human pose estimation from still images require the collection of a fully annotated data set, where each training sample consists of an image of a person, together with its ground-truth joint locations. The collection of such detailed annotations is onerous and expensive, which makes this approach unscalable. We propose to alleviate the deficiency of fully supervised learning by using a diverse data set. Part of the images of the data set are labeled with expensive pose annotations, while the remaining images are labeled with inexpensive action annotations. Throughout the paper, we assume that the distribution of the images labeled with different types of annotations is the same (which is a necessary assumption for learning) and that the annotations themselves are noise-free. Under these assumptions, we argue that action information can be used to learn pose estimation. Note that earlier works have exploited the relationship between action and pose for action recognition. However, our problem is significantly more challenging due to the high uncertainty in pose given the action. In order to model this uncertainty, we propose to use a probabilistic learning formulation. A typical probabilistic formulation would learn a joint distribution of the pose and the action given an image. In order to make a prediction on a test sample, where action information is not known, it would marginalize over all possible actions. In other words, it would use one set of parameters for two distinct tasks: (i) model the uncertainty in the pose for every action; and (ii) predict the pose given an image. As our goal is to make an accurate pose prediction, we argue that such an approach would waste the modeling capability of a distribution in representing pose uncertainty in the presence of action information. In other words, the parameters of the distribution will be tuned to perform well in the presence of action information, which will not be available during testing. Instead, we use two different distributions for the two different tasks: (i) a {\em conditional distribution} of the pose given the image and the action; and (ii) a {\em prediction distribution} of the pose given the image. We jointly estimate the parameters of the two distributions by minimizing their dissimilarity coefficient~ _cite_, which measures the distance between two distributions using a task-specific loss function. By transferring the information from the conditional distribution to the prediction distribution, we learn to estimate the pose of a human using a diverse data set. Figure~ _ref_ shows the necessity of using a probabilistic model. Specifically, the figure shows the average entropy of each joint as predicted by our model on test images. We observe that the most articulate joints like wrists and ankles have highest entropy, which a non probabilistic network does not explicitly model. While our approach can be used in conjunction with any parametric family of distributions, in this work we focus on the state of the art deep probabilistic networks. Specifically, we model both the conditional and the prediction distributions using a DISCO Net~ _cite_, which allows us to efficiently sample from the two distributions. As will be seen later, the ability to sample efficiently is sufficient to make both training and testing computationally feasible. We demonstrate the efficacy of our approach using the publicly available MPII Human Pose data set~ _cite_ . We discard the pose information of a portion of the training samples but retain the action information for all the samples in order to generate a diverse data set. We provide a thorough comparison of our probabilistic approach with two natural baselines. First, a fully supervised approach, which discards the weakly supervised samples that have been labeled using only the action information. Second, a pointwise model that uses a self-paced learning~ _cite_ strategy by first learning from easy samples and then gradually increase the difficulty of the training samples. We show that, by explicitly modeling the uncertainty on the pose of diverse supervised samples, our approach significantly outperforms both the baselines under various experimental settings.