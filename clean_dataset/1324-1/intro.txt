For state-of-the-art deep single-label classification models, the correct class is often in the top-_inline_eq_ predictions, leading to a top-_inline_eq_ _inline_eq_ accuracy that is significantly higher than the top-N accuracy. This accuracy gap is more pronounced in fine-grained classification tasks, where the differences between classes are quite subtle _cite_ . For example, the Stanford Dogs fine-grained dataset on which we report results has a top-N accuracy of N \% and a top-N accuracy of N \%. Exploiting the information provided in the top-_inline_eq_ predicted classes can boost the final prediction of a model. In this work, we do not completely trust a Convolutional Neural Network (CNN) model's top-N prediction as it does not solely depend on the visual evidence in the input image, but can depend on other artifacts such as dataset bias or unbalanced training data. Instead, we target answering the following question: is the evidence upon which the prediction is made reasonable? Evidence is defined to be the grounding, in pixel space, for a specific class conditional probability in the model output. We propose {\selectfont Guided Zoom}, which uses evidence grounding as the signal to localize discriminative image regions and to assesses how much one can trust a CNN prediction over another. Since fine-grained classification requires focusing on details, the localization of discriminative object parts is crucial. Supervised approaches utilize part bounding box annotations _cite_ or have humans in the loop to help reveal discriminative parts _cite_ . Our approach does not require part annotations, thus it is more scalable compared to supervised approaches. Weakly supervised attention based methods require training CNNs with attention module (s) _cite_, while our approach is a generic framework able to improve the performance of any CNN model, even if it was not trained using an attention module. {\selectfont Guided Zoom} zooms into the evidence used to make a preliminary decision at test time and compares it with a reference pool of (evidence, prediction) pairs. The pool is constructed by accumulating (evidence, prediction) pairs for correctly classified training examples, providing additional free supervision from training data. As demonstrated in Fig.~ _ref_, our approach examines whether or not the evidence used to make the prediction is coherent with training evidence of correctly classified images. This is performed by the Evidence CNN module, which aids the Decision Refinement module to come up with a refined prediction. The main goal of {\selectfont Guided Zoom} is ensuring that evidence of the refined class prediction is more coherent with the training evidence of that class, compared to evidence of any of the other candidate top classes (see Fig.~ _ref_) . By examining network evidence, we demonstrate improved accuracy and achieve state-of-the-art results on three fine-grained classification benchmark datasets.