Image representation is one of the most important factors that affect performance on visual recognition tasks. Barbu~ \etal~ _cite_ introduced an interesting experiment that a simple classifier along with human brain-scan data substantially outperforms the state-of-the-art methods in recognizing action from video clips. With a success of local descriptors~ _cite_, many researches devoted deep study to global image representation based on a Bag-of-Word (BOW) model~ _cite_ that aggregates abundant local statistics captured by hand-designed local descriptors. The BOW representation is further improved with VLAD~ _cite_ and Fisher kernel~ _cite_ by adding higher order statistics. One major benefit of these global representations based on local descriptors is their invariance property to scale changes, location changes, occlusions and background clutters. In recent computer vision researches, drastic advances of visual recognition are achieved by deep convolutional neural networks (CNNs) _cite_, which jointly learn the whole feature hierarchies starting from image pixels to the final class posterior with stacked non-linear processing layers. A deep representation is quite efficient since its intermediate templates are reused. However, the deep CNN is non-linear and have millions of parameters to be estimated. It requires strong computing power for the optimization and large training data to be generalized well. The recent presence of large scale ImageNet _cite_ database and the raise of parallel computing contribute to the breakthrough in visual recognition. Krizhevsky~ \etal~ _cite_ achieved an impressive result using a CNN in large-scale image classification. Instead of training a CNN for a specific task, intermediate activations extracted from a CNN pre-trained on independent large data have been successfully applied as a generic image representation. Combining the CNN activations with a classifier has shown impressive performance in wide visual recognition tasks such as object classification _cite_, object detection _cite_, scene classification _cite_, fine-grained classification _cite_, attribute recognition _cite_, image retrieval _cite_, and domain transfer _cite_ . For utilizing CNN activations as a generic image representation, a straightforward way is to extract the responses from the first or second fully connected layer of a pre-trained CNN by feeding an image and to represent the image with the responses~ _cite_ . However, this representation is vulnerable to geometric variations. There are techniques to address the problem. A common practice is exploiting multiple jitterred images (random crops and flips) for data augmentation. Though the data augmentation has been used to prevent over-fitting _cite_, recent researches show that average pooling, augmenting data and averaging the multiple activation vectors in a test stage, also helps to achieve better geometric invariance of CNNs while improving classification performance by + N \% in _cite_ and + N \% in _cite_ on PASCAL VOC N. A different experiment for enhancing the geometric invariance on CNN activations was also presented. Gong~ \etal~ _cite_ proposed a method to exploit multi-scale CNN activations in order to achieve geometric invariance characteristic while improving recognition accuracy. They extracted dense local patches at three different scales and fed each local patch into a pre-trained CNN. The CNN activations are aggregated at finer scales via VLAD encoding which was introduced in ~ _cite_, and then the encoded activations are concatenated as a single vector to obtain the final representation. In this paper, we introduce a multi-scale pyramid pooling to improve the discriminative power of CNN activations robust to geometric variations. A pipeline of the proposed method is illustrated in Figure _ref_ . Similar to _cite_, we also utilize multi-scale CNN activations, but present a different pooling method that shows better performance in our experiments. Specifically, we suggest an efficient way to obtain abundant amount of multi-scale local activations from a CNN, and aggregate them using the state-of-the-art Fisher kernel~ _cite_ with a simple but important scale-wise normalization, so called multi-scale pyramid pooling . Our proposal demonstrates substantial improvements on both scene and object classification tasks compared to the previous representations including a single activation, the average pooling~ _cite_, and the VLAD of activations~ _cite_ . Also, we demonstrate object confidence maps which is useful for object detection/localization though only category-level labels without specific object bounding boxes are used in training. According to our empirical observations, replacing a VLAD kernel with a Fisher kernel does not present significant impact, however it shows meaningful performance improvements when our pooling mechanism that takes an average pooling after scale-wise normalization is applied. It implies that the performance improvement of our representation does not come just from the superiority of Fisher kernel but from the careful consideration of neural activation's property dependent on scales.