Image compression has been a fundamental and significant research topic in the field of image processing for several decades. Traditional image compression algorithms, such as JPEG~ _cite_ and JPEGN~ _cite_, rely on the hand-crafted encoder/decoder (codec) block diagram. They use the fixed transform matrixes, i.e. Discrete cosine transform (DCT) and wavelet transform, together with quantization and entropy coder to compress the image. However, they are not expected to be an optimal and flexible image coding solution for all types of image content and image formats. Deep learning has been successfully applied in various computer vision tasks and has the potential to enhance the performance of image compression. Especially, the autoencoder has been applied in dimensionality reduction, compact representations of images, and generative models learning~ _cite_ . Thus, autoencoders are able to extract more compressed codes from images with a minimized loss function, and are expected to achieve better compression performance than existing image compression standards including JPEG and JPEGN. Another advantage of deep learning is that although the development and standardization of a conventional codec has historically taken years, a deep learning based image compression approach can be much quicker with new media contents and new media formats, such as N-degree image and virtual reality (VR) ~ _cite_ . Therefore, deep learning based image compression is expected to be more general and more efficient. Recently, some approaches have been proposed to take advantage of the autoencoder for image compression. Due to the inherent non-differentiability of round-based quantization, a quantizer cannot be directly incorporated into autoencoder optimization. Thus, the works~ _cite_ and~ _cite_ proposed a differentiable approximation for quantization and entropy rate estimation for an end-to-end training with gradient backpropagation. Unlike those works, the work~ _cite_ used an LSTM recurrent network for compressing small thumbnail images (_inline_eq_), and used a binarization layer to replace the quantization and entropy coder. This approach was further extended in~ _cite_ for compressing full-resolution images. These works achieved promising coding performance; however, there is still room for improvement, because they did not analyze the energy compaction property of the generated feature maps and did not use a real entropy coder to generate the final codes. In this paper, we propose a convolutional autoencoder (CAE) based lossy image compression architecture. Our main contributions are twofold. Experimental results demonstrate that our method outperforms JPEG and JPEGN in terms of PSNR, and achieves a N \% BD-rate decrement compared to JPEGN with the popular Kodak database images. In addition, our method is computationally more appealing compared to other autoencoder based image compression methods. The rest of this paper is organized as follows. Section II presents the proposed CAE based image compression architecture, which includes the design of the CAE network architecture, quantization, and entropy coder. Section III summarizes the experimental results and compares the rate-distortion (RD) curves of the proposed CAE with those of existing codecs. Conclusion and future work are given in Section IV.