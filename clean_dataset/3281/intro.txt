of the influence of the scene illumination, the human visual system can recognize object colors through its ability known as color constancy~ _cite_ . In the image processing pipeline of almost every digital camera there is also a part dedicated to computational color constancy~ _cite_ . It first estimates the scene illumination and then uses it to chromatically adapt the image i.e. to correct the colors. For a more formal problem statement an often used image _inline_eq_ formation model written under Lambertian assumption is~ _cite_ where _inline_eq_ is a color channel, _inline_eq_ is a given image pixel, _inline_eq_ is the wavelength of the light, _inline_eq_ is the visible spectrum, _inline_eq_ is the spectral distribution of the light source, _inline_eq_ is the surface reflectance, and _inline_eq_ is the camera sensitivity of color channel _inline_eq_ . Assuming uniform illumination for the sake of simplicity makes it possible to remove _inline_eq_ from _inline_eq_ and then the observed light source color is given as The direction of _inline_eq_ provides enough information for successful chromatic adaptation~ _cite_ . Still, calculating _inline_eq_ is an ill-posed problem because only image pixel values _inline_eq_ are given, while both _inline_eq_ and _inline_eq_ are unknown. The solution to this problem is to make additional assumptions. Different assumptions have given rise to numerous illumiantion estimation methods that can be divided into two main groups. First of these groups contains low-level statistics-based methods such as White-patch~ _cite_ and its improvements~ _cite_, Gray-world~ _cite_, Shades-of-Gray~ _cite_, Grey-Edge~ (and order) ~ _cite_, Weighted Gray-Edge~ _cite_, using bright pixels~ _cite_, using bright and dark colors~ _cite_ . The second group includes learning-based methods such as gamut mapping~ (pixel, edge, and intersection based) ~ _cite_, using neural networks~ _cite_, using high-level visual information~ _cite_, natural image statistics~ _cite_, Bayesian learning~ _cite_, spatio-spectral learning~ (maximum likelihood estimate, and with gen. prior) ~ _cite_, simplifying the illumination solution space~ _cite_, using color/edge moments~ _cite_, using regression trees with simple features from color distribution statistics~ _cite_, performing various kinds of spatial localizations~ _cite_, using convolutional neural networks~ _cite_ . Statistics-based illumination estimation methods are less accurate than the learning-based ones, but they are faster and simpler to implement in embedded systems, which is one of the reasons for their widespread usage~ _cite_ . Although in the relevant literature it often appears as if they require no training, this is not true because they have parameter values that need to be fine-tuned in order to give higher accuracy. In this paper it is first shown that in most papers on illumination estimation the accuracy of statistics-based methods was not obtained by means of the necessary cross-validation, but by using the whole benchmark datasets for both training and testing, which leads to an unfair comparison between the methods. After that the corrected results are given for the best known benchmark datasets by performing the same cross-validation framework as for other learning-based methods. Finally, the so called green stability assumption is proposed that can be used to fine-tune the values of the parameters of the statistics-based methods by using only non-calibrated images without known ground-truth illumination. The obtained accuracy is practically the same as when using calibrated training images, but the whole process is much faster and it can be directly applied in practice. The paper is structured as follows: Section~ _ref_ briefly describes the best known statistics-based methods, Section~ _ref_ shows that their accuracy data should be revisited, Section~ _ref_ proposes the green stability assumption, Section~ _ref_ presents the results, and finally, Section~ _ref_ concludes the paper.