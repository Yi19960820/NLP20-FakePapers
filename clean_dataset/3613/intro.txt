In recent years, deep learning using Convolutional Neural Networks (CNNs) has shown enormous success in the field of machine learning and computer vision. CNNs provide state-of-the-art accuracy in various image recognition tasks including object recognition _cite_, object detection _cite_, tracking _cite_, and image captioning _cite_ . In addition, this technique has been applied massively in computer vision tasks such as video representation and classification of human activity _cite_ . Machine translation and natural language processing are applied deep learning techniques that show great success in this domain _cite_ . Furthermore, this technique has been used extensively in the field of speech recognition _cite_ . Moreover, deep learning is not limited to signal, natural language, image, and video processing tasks, it has been applying successfully for game development _cite_ . There is a lot of ongoing research for developing even better performance and improving the training process of DCNNs _cite_ . In some cases, machine intelligence shows better performance compared to human intelligence including calculation, chess, memory, and pattern matching. On the other hand, human intelligence still provides better performance in other fields such as object recognition, scene understanding, and more. Deep learning techniques (DCNNs in particular) perform very well in the domains of detection, classification, and scene understanding. There is a still a gap that must be closed before human level intelligence is reached when performing visual recognition tasks. Machine intelligence may open an opportunity to build a system that can process visual information the way that a human brain does. According to the study on the visual processing system within a human brain by James DiCarlo et al. _cite_ the brain consists of several visual processing units starting with the visual cortex (VN), continuing through the extrastriate areas vN, vN, the PIT (Posterior Inferotemporal Area) cortex, and finally the AIT (Anterior Inferotemporal Area) cortex which is shown in Figure N. It can be clearly seen that the visual cortex of the human brain processes information recurrently in different visual units. The recurrent connectivity of synapses in the human brain plays a big role in context modeling for visual recognition tasks _cite_ . If we observe the architecture of recently developed DCNN models, most of them incorporate many components similar to that of the human visual information processing system for recognition tasks _cite_ . However, the concept of recurrence in the visual cortex is only included in few DCNN models such as the Recurrent Convolutional Neural Network (RCNN) _cite_, and a CNN with LSTM for visual description _cite_ . Additionally, Inception-VN _cite_, and Residual _cite_ architectures are popular among the computer vision community. The intension of most recently developed DCNNs is to use Inception and Residual networks to implement larger deep networks. As the model becomes larger and deeper, the computational parameters of the architecture are increased dramatically. As a result, training the model becomes increasingly complex and thus, more computationally expensive. It is very challenging to include a recurrent property within popular Inception architectures, but recurrence is essential for improving the overall training and testing accuracy with fewer computational parameters. Others are trying to implement bigger and deeper DCNN architectures like GoogleNet _cite_, or a residual network with N layers _cite_ that achieves high recognition accuracy on different benchmark datasets. However, we are presenting an improved version of the DCNN model inspired by the information processing mechanisms of the human visual cortex, and recently developed some promising DCNN architectures like Inception-vN _cite_, and RCNN _cite_ . Therefore, we call this model the Inception Recurrent Convolutional Neural Network (IRCNN) . This model not only ensures better recognition accuracy with fewer computational parameters against the state-of-the-art DCNN architectures, but also helps to improve the overall training process of the deep learning approach. This proposed architecture generalizes both Inception networks and RCNN models. The contributions of this work are as follows: