To generate high-resolution and photo-realistic person image with arbitrary poses is important in multimedia and computer vision for its wide range of applications such as data augmentation in person re-ID _cite_, person image editing or inpainting _cite_ and video forecasting _cite_ . Various methods have been proposed to handle this problem, such as VAE _cite_, ARMs _cite_, and GANs _cite_ . Owing to impressive performances of GANs, recent works on person image generation _cite_ and high-resolution image synthesis _cite_ mostly focus on it. From the perspective of the prior knowledge, existing person image generation methods based on GANs can be categorized into two groups. The first is the global pose-guided strategy _cite_ and the second is the segmentation-guided multi-module strategy _cite_ . The former is to synthesize the target person image through a global model by inputting the conditional person image and the human pose estimation simultaneously. The latter is to parse the conditional person image into foreground, background and pose information, then synthesize the target image using multi-module models. Although the pose-guided person image generation methods can be accurate regarding target human poses, they usually neglect the detailed appearance and the texture information of the conditional person images. Segmentation-guided multi-module person image generation techniques can preserve appearance and texture features of the conditional person image more completely. However, most multi-module models are complex and difficult to train. Moreover, the pose accuracy of the resulted image by these models is still far from expectation. In many cases, above-mentioned methods are still problematic to produce person image with precise pose and preserve appearance details simultaneously. In this paper, we propose a novel Multi-scale Conditional Generative Adversarial Networks (MsCGAN) for person image generation. In Figure N, the inputs are the conditional image image and the target pose. Our goal is to synthesize the person image with the target pose, whose appearance and the texture information are also consistent with the conditional images. MsCGAN is based on pose guidance so that it can synthesize the person images with high pose accuracy. Meanwhile, MsCGAN contains two strategies to ensure the visual quality of the generated images to be consistent with the conditional image. One of them is using the global-to-local generators, which generate a coarse image of the specific pose globally, and refine the coarse image locally. The other is that multi-scale discriminators are adopted to discriminate the generated image and its downsampled images respectively, which aim to handle the visual features on multiple levels. Compared with existing methods, our proposed model has several advantages: N) Joint the global generation and the local refinement can model both the accuracy and quality of the synthetic image simultaneously. N) Images with different resolutions contain different levels of visual features, so the proposed multi-scale discriminators can increase the receptive field of the discriminator. N) The combination of the global-to-local generators and multi-scale discriminators ensure the synthetic person images have the target pose and more detailed appearance features than existing methods. Some examples are shown in Figure N. The proposed model is evaluated on the dataset Market-N _cite_, as well as the fashion dataset DeepFashion _cite_ . Moreover, we compare our results to the results of the state-of-the-art methods to demonstrate effectiveness. The main contributions of our work are summarized as follows: The rest of the paper is organized as follows. Section N introduces the details of the proposed MsCGAN. In Section N, we report and analyze extensive experimental results. Finally, we conclude the paper with future work in Section N.