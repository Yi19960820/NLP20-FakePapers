Humans naturally perceive the world as being structured into different objects, their properties and relation to each other. This phenomenon which we refer to as perceptual grouping is also known as amodal perception in psychology. It occurs effortlessly and includes a segmentation of the visual input, such as that shown in in _ref_ . This grouping also applies analogously to other modalities, for example in solving the cocktail party problem (audio) or when separating the sensation of a grasped object from the sensation of fingers touching each other (tactile) . Even more abstract features such as object class, color, position, and velocity are naturally grouped together with the inputs to form coherent objects. This rich structure is crucial for many real-world tasks such manipulating objects or driving a car, where awareness of different objects and their features is required. In this paper, we introduce a framework for learning efficient iterative inference of such perceptual grouping which we call (TAG) . This framework entails a mechanism for iteratively splitting the inputs and internal representations into several different groups. We make no assumptions about the structure of this segmentation and rather train the model end-to-end to discover which are the relevant features and how to perform the splitting. By using an auxiliary denoising task we focus directly on amortizing the posterior inference of the object features and their grouping. Because our framework does not make any assumptions about the structure of the data, it is completely domain agnostic and applicable to any type of data. The TAG framework works completely unsupervised, but can also be combined with supervised learning for classification or segmentation. Another class of recently proposed mechanisms for addressing complex structured inputs is attention~ _cite_ . These methods simplify the problem of perception by learning to restrict processing to a part of the input. In contrast, TAG simply structures the input without directing the focus or discarding irrelevant information. These two systems are not mutually exclusive and could complement each other: the group structure can help in deciding what exactly to focus on, which in turn may help simplify the task at hand. We apply our framework to two artificial datasets: a simple binary one with multiple shapes and one with overlapping textured MNIST digits on a textured background. We find that our method learns intuitively appealing groupings that support denoising and classification. Our results for the N-digit classification are significantly better than a strong ConvNet baseline despite the use of a fully connected network. The improvements for semi-supervised learning with N, N labels are even greater, suggesting that grouping can help learning by increasing the sample efficiency.