Image classification, e.g., recognizing objects and people in images, has been one of the fundamental goals of computer vision since its inception. In the past few years, Convolutional Neural Networks (CNNs), which jointly learn the features and the classifier, have proven highly effective at tackling such classification tasks~ _cite_, and have thus dramatically accelerated the advances in recognition. In essence, CNNs stack multiple layers, convolutional and fully-connected ones, with the parameters of each layer acting as filters on the output of the preceding one. By computing such linear combinations, even when followed by element-wise nonlinearities and pooling, traditional CNNs can be thought of as extracting only first-order statistics from the input images. In other words, such networks cannot extract second-order statistics, such as covariances. Psychophysics research, however, has shown that second-order statistics play an important role in the human visual recognition process~ _cite_ . This has been exploited in the past in computer vision via the development of Region Covariance Descriptors (RCDs) ~ _cite_, which encode covariance matrices computed from local image features. In fact, these descriptors have been shown to typically outperform first-order features for visual recognition tasks such as material recognition and people re-identification~ _cite_ . However, to this date, RCDs have been mostly confined to exploiting handcrafted features, and have thus been unable to match the performance of deep networks. In this paper, we introduce a new class of CNN architectures that exploit second-order statistics for visual recognition. To this end, we develop three new types of layers. The first one extracts a covariance matrix from convolutional activations. The second one computes a parametric second-order transformation of an input matrix, such as a covariance matrix. Finally, the last one performs a parametric vectorization of an input matrix. These different types of layers can be stacked into a Covariance Descriptor Unit (CDU), which, as shown in Fig.~ _ref_, replaces the fully-connected layers of a traditional CNN. Altogether, this provides us with second-order CNNs (SO-CNNs) that can be trained in an end-to-end manner. To the best of our knowledge, only very few works have considered the use of RCDs in conjunction with CNNs. In particular, ~ _cite_ extracted RCDs from features pre-computed using a CNN, but without proposing an end-to-end learning framework. By contrast, ~ _cite_ briefly studied the use of matrix outer product, which corresponds to a second-order operation, within a deep network as an application of their matrix backpropagation algorithm. While interesting, this work did not focus on extracting second-order statistics and thus remains preliminary in that respect. Here, we study this problem more thoroughly and introduce new layer types that were not considered in~ _cite_, and, as evidenced by our experiments, are key to the success of second-order CNNs. We demonstrate the benefits of our second-order CNNs on the tasks of object recognition, using the CIFARN dataset _cite_, and material recognition, using the challenging Materials in Context Database (MINC) ~ _cite_ . Our experiments demonstrate the generality of our approach by implementing it within different basic network architectures, such as FitNet~ _cite_, VGGN~ _cite_ and ResNet~ _cite_ . In all cases, we show that our second-order CNNs outperform the corresponding first-order ones, while relying on up to N \% fewer parameters for networks having large fully-connected layers. Furthermore, our method also outperforms the covariance learning framework of~ _cite_, using pre-computed deep features, and the single covariance network of~ _cite_ . We believe that this clearly evidences the potential of our second-order CNNs and, by making our code publicly available, that it will motivate other researchers to explore going beyond first-order statistics within deep learning.