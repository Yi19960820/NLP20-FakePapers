is one of the most common image degradations that arises from a number of sources, including atmospheric scatter, camera shake, defocus, and object motion. It is also manipulated by photographers to create visually pleasing effect that draws attention to humans/objects of interest. Given a natural photographic image, the goal of local blur mapping is to label every pixel as either blurry or non-blurry, resulting in a blur map. Local blur mapping is an important component in many image processing and computer vision systems. For image quality assessment, blur is an indispensable factor that affects perceptual image quality~ _cite_ . For example, the worst quality images scored by human subjects in the LIVE Challenge Database~ _cite_ mainly suffer from motion and/or out-of-focus blur. For object detection, the identified blurred regions may be excluded for efficient and robust object localization~ _cite_ . Other applications that may benefit from local blur mapping include image restoration~ _cite_, photo editing~ _cite_, depth recovery~ _cite_, and image segmentation~ _cite_ . The human visual system (HVS) is good at identifying the blurry parts of an image with amazing speed~ _cite_, but the underlying mechanism is not well understood. A traditional view of blur is that it reduces the energy (either globally or locally) at high frequencies. Several low-level features have been hand-crafted to exploit this observation. Among those, power spectral slopes~ _cite_ and image gradient statistics~ _cite_ are representative. Another view of blur perception is that it arises from the disruption of the local phase coherence at precisely localized features (\eg, step edges) ~ _cite_ . Therefore, a coarse-to-fine phase prediction may serve as an indication of blur~ _cite_ . Nearly all previous local blur mappers rely on the two assumptions either explicitly or implicitly with limited success. In particular, they fail to discriminate flat and blurred regions, and they often mix up structures with and without blurring. A visual example is shown in Fig.~ _ref_, where we can see that both the blue and red framed patches appear to be smooth but from different origins. Specifically, the textures of sand in the blue framed patch are lost due to the severe blur, while the car body in the red framed patch is flat in nature. On the other hand, the green and yellow framed patches have similar local structural features at the top with similar complexities, but the former suffers from blur, while the latter does not. All of these make the local blur mapping task difficult for local feature-based algorithms. In this regard, we argue that the fundamental problem in existing approaches is their ignorance to high-level semantic information in natural images, which is crucial in successfully identifying local blur. Therefore, we resort to deep convolutional neural networks (CNN) that have advanced the state-of-the-art in many high-level vision tasks such as image classification~ _cite_, object detection~ _cite_, and semantic segmentation~ _cite_ . Specifically, we develop the first fully convolutional network (FCN) ~ _cite_ for end-to-end and image-to-image blur mapping~ _cite_, which we name deep blur mapper (DBM) . By fully convolutional, we mean all the learnable filters in the network are convolutional and no fully connected layers are involved. As a result, DBM allows input of arbitrary size, encodes spatial information thoroughly for better prediction, and maintains a relatively low computational cost. We adopt various architectures with different depths by trimming the N-layer VGGNet~ _cite_ from different convolutional stages. By doing so, we empirically show that high-level features from deeper layers are more important than low-level features from shallower layers in resolving challenging ambiguities for local blur mapping, which conforms to our perspective of blur perception. We also experiment with more advanced directed acyclic graph based architectures that better combine low-level spatial and high-level semantic information but yield no substantial improvement, which again verify the critical role of high-level semantics in this task. Due to the limited number of training samples, we initialize all networks with weights pre-trained on the semantic segmentation task~ _cite_ that contain rich high-level information about what an input image constitutes. DBM is tested on a standard blur detection benchmark~ _cite_ and outperforms state-of-the-art methods by a large margin. Our contributions are three-fold. First, we provide a new perspective on blur perception, where high-level semantic information plays a critical role. Second, we show that it is possible to learn an end-to-end and image-to-image local blur mapper based on FCNs~ _cite_, which well addresses challenging ambiguities such as differentiating flat and blurred regions, and structures with and without blurring. Third, we explore three potential applications of the generated blur maps, \ie, blur region segmentation, blur degree estimation, and blur magnification. The rest of the paper is organized in the following manner. Section~ _ref_ reviews the related work of local blur mapping with emphasis on statistical analysis of traditional hand-crafted low-level features. Section~ _ref_ details the proposed DBM based on FCNs and their alternative architectures. Section~ _ref_ conducts extensive comparative and ablation experiments to validate the promise of DBM. Section~ _ref_ concludes the paper.