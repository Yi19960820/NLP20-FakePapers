Identifying feature correspondence is an important problem in computer vision (see references in ~ _cite_) . In general, matching features using only the appearance descriptor values can often result in many incorrect matches. To address this problem, most algorithms for feature correspondence combine information about both appearance and geometric structure among the feature locations. Several methods~ _cite_ utilize the pairwise geometric consistency, along with the pointwise descriptor similarity, to design a matching cost function which is minimized using various optimization algorithms. For example, ~ _cite_ uses spectral techniques to compute a \lq soft \rq~ assignment vector that is later discretized to produce the correct assignment of features. These works model the appearance and pairwise geometric similarity using a graph, either explicitly or implicitly, and are commonly known as graph matching algorithms. The soft assignment vector is typically computed by an eigen-decomposition of the compatibility or the match quality matrix. Several studies applied graph matching algorithms for various vision problems~ _cite_ . Caetano et.al.~ _cite_ discusses how the parameters of the matching cost function (primarily the match compatibility scores) can be learned from pairs with labeled correspondences to maximize the matching accuracy. A more recent work~ _cite_ proposes to learn similar matching scores in an unsupervised fashion by repeatedly refining the soft assignment vector. Higher order relationship among the feature points have also been investigated as the means of improving the matching accuracy. Zass et.al.~ _cite_ assumes two separate hypergraphs among the feature points on two images and propose an iterative algorithm to match the the two hypergraphs. On the other hand, Olivier et.al.~ _cite_ generalize the pairwise spectral graph matching methods for higher order relationships among the point matches. The pairwise score matrix is generalized to a high order compatibility tensor. The eigenvectors of this tensor are used as the soft assignment matrix to recover the matches. In our framework, each feature correspondence is considered as a datapoint and we assume a hypergraph structure among these datapoints (similar to~ _cite_) . That is, we conceive a subset of candidate feature matches as a hyperedge of the hypergraph. For subsets of such datapoints, we assume that the relationship among features of one image follows the same geometrical model as that present among the corresponding features in the other image. We compute the likelihood, using this geometrical model, for every subset of datapoints and use it as weight of the hyperedge. The objective is to label the datapoints, i.e., matches to be correct or incorrect, given this hypergraph structure among them. We adopt a hypergraph node labeling algorithm proposed in~ _cite_ . Given a hypergraph, where the hyperedge weights are computed using a model, this algorithm produces the optimal labeling of the nodes that maximally conforms with the hyperedge weights or likelihood values. Within the framework, the higher order interaction among subsets of datapoints is modeled using a higher order undirected graphical model or the Markov network (see~ _cite_ for details) . The labels are computed by solving the inference problem on this graphical model where a labeling cost or energy function is minimized to produce the optimal labeling. In this paper, we show that the framework of hypergraph node labeling of~ _cite_ can be applied for feature matching. In addition, we show how it is possible, and in fact advantageous, to learn (a parametric form of) the) cost function for matching given several labeled examples of feature correspondences. The learned forms of cost functions are able to appropriately weight the label disagreement cost for different subsets. For example, if the number of subsets containing more accurate matches than the inaccurate ones, the associated penalty function will attain a higher weight to balance the relative importance. The learning procedure is general, i.e., in addition to the feature matching, it can be utilized for any application of the labeling problem~ _cite_ . Point matching problem was addressed by a probabilistic graphical model before, in~ _cite_, enforcing a graph among the points for spatial consistency. The required potential (cost) functions in these two studies were pre-selected and not learned from the data. Our approach can handle match interaction in larger sets and demonstrates the advantage of learning the cost functions from the data. Feature matching problem has also been cast as an energy minimization problem in~ _cite_ . At this point, we would like to clarify what aspect of learning (hypergraph labeling for) point matching is different from earlier works. Let us suppose _inline_eq_ is the label for _inline_eq_-th candidate feature match, _inline_eq_ implies a correct match and _inline_eq_ implies an incorrect one. Let _inline_eq_ be the match compatibility score of a subset _inline_eq_ of matches of size _inline_eq_ . The popular graph and tensor matching algorithms maximize the following overall matching score to retrieve the correct matches~ _cite_ . The score function is a weighted summation of subset-wise label concurrence function, _inline_eq_ . Notice that, _inline_eq_ is a binary valued function: _inline_eq_ only when all labels _inline_eq_ are equal to N and N otherwise. Instead of using this predefined binary valued function, we investigate whether or not such label agreement function (or, conversely a disagreement cost function) can be learned from labeled matches. We believe it is particularly useful to learn this function for higher order (_inline_eq_) methods. To illustrate the necessity of such learning, we show two images in Figure~ _ref_ with candidate feature matches _inline_eq_ and _inline_eq_, all with equal matching probability, overlaid on them. It is assumed that the geometrical arrangement among matching features can be encoded by triangle. Clearly, the similarity between triangles _inline_eq_ (red) and _inline_eq_ (green) will be high resulting in a large match compatibility _inline_eq_ (where _inline_eq_) . Notice that the triangle _inline_eq_ (blue dashed) would also have relatively large similarity with _inline_eq_ . Though this subset _inline_eq_ of matches contain one incorrect match _inline_eq_, it still provides us significant geometric information about the two correct matches _inline_eq_ and _inline_eq_ . Incorporating this information in the algorithm should assist establishing more correct correspondences among the features. However, the form of _inline_eq_ does not explicitly handle this situation, even when _inline_eq_ is relaxed to take values in real domain . One needs to learn an appropriate label agreement (or disagreement cost) function to explicitly include this information in the framework. Learning the cost function can also counteract the uneven ratio of subsets with more correct matches and those with more incorrect matches. As it will be explained in details later, to determine the correspondence, we in fact of the form as follows. \noindent This paper describes how to learn appropriate subset-wise label disagreement cost functions (also referred as penalty functions) _inline_eq_ and _inline_eq_ from labeled matches. Our approach is significantly different in concept from previous learning algorithms for correspondence. The algorithms of~ _cite_ aim to learn a match compatibility function _inline_eq_ from the data to optimally reflect accurate correspondences among the features. On the contrary, our algorithm learns the label disagreement cost functions _inline_eq_ and _inline_eq_ to minimize the total label disagreements within the subsets . The next section describes how feature correspondence can be cast as a hypergraph labeling problem as defined in~ _cite_