Data collected by ND sensors (e.g. LiDAR, Kinect) are often impacted by occlusion, sensor noise, and illumination, leading to incomplete and noisy ND models. For example, a building scan occluded by a tree leads to a hole or gap in the ND building model. However, a human can comprehend and describe the geometry of the complete building based on the corrupted ND model. Our ND inpainting method attempts to mimic this ability to reconstruct complete ND models from incomplete data. Convolutional Neural Network (CNN) based methods~ _cite_ yield impressive results for ND image generation and image inpainting. Generating and inpainting ND models is a new and more challenging problem due to its higher dimensionality. The availability of large ND CAD datasets~ _cite_ and CNNs for voxel (spatial occupancy) models~ _cite_ enabled progress in learning ND representation, shape generation and completion. Despite their encouraging results, artifacts still persists in their generated shapes. Moreover, their methods are all based on ND CNN, which impedes their ability to handle higher resolution data due to limited GPU memory. In this paper, a new system for ND object inpainting is introduced to overcome the aforementioned limitations. Given a ND object with holes, we aim to (N) fill the missing or damaged portions and reconstruct a complete ND structure, and (N) further predict high-resolution shapes with fine-grained details. We propose a hybrid network structure based on ND CNN that leverages the generalization power of a Generative Adversarial model and the memory efficiency of Recurrent Neural Network (RNN) to handle ND data sequentially. The framework is illustrated in Figure~ _ref_ . More specifically, a ND Encoder-Decoder Generative Adversarial Network (ND-ED-GAN) is firstly proposed to generalize geometric structures and map corrupted scans to complete shapes in low resolution. Like a variational autoencoder (VAE) ~ _cite_, ND-ED-GAN utilizes an encoder to map voxelized ND objects into a probabilistic latent space, and a Generative Adversarial Network (GAN) to help the decoder predict the complete volumetric objects from the latent feature representation. We train this network by minimizing both contextual loss and an adversarial loss. Using GAN, we can not only preserve contextual consistency of the input data, but also inherit information from data distribution. Secondly, a Long-term Recurrent Convolutional Network (LRCN) is further introduced to obtain local geometric details and produce much higher resolution volumes. ND CNN requires much more GPU memory than ND CNN, which impedes volumetric network analysis of high-resolution ND data. To overcome this limitation, we model the ND objects as sequences of ND slices. By utilizing the long-range learning capability from a series of conditional distributions of RNN, our LRCN is a Long Short-term Memory Network (LSTM) where each cell has a CNN encoder and a fully-convolutional decoder. The outputs of ND-ED-GAN are sliced into ND images, which are then fed into the LRCN, which gives us a sequence of high-resolution images. Our hybrid network is an end-to-end trainable network which takes corrupted low resolution ND structures and outputs complete and high-resolution volumes. We evaluate the proposed method qualitatively and quantitatively on both synthesized and real ND scans in challenging scenarios. To further evaluate the ability of our model to capture shape features during ND inpainting, we test our network for ND object classification tasks and further explore the encoded latent vector to demonstrate that this embedded representation contains abundant semantic shape information. The main contributions of this paper are: