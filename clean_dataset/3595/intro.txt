In the recent past, deep networks have been successfully used in various image processing and computer vision applications~ _cite_ . Their success can be attributed to several factors such as their ability to represent complex input-output relationships, feed-forward nature of their inference (no need to solve an optimization problem during run time), availability of large training datasets, etc. \One of the positive aspects of deep networks is that fairly general architectures composed of fully-connected or convolutional layers have been shown to work reasonably well across a wide range of applications. \However, these general architectures do not use problem domain knowledge which could be very helpful in some of the applications. For example, in the case of image denoising, it has been recently shown that conventional multilayer perceptrons are not very good at handling multiple levels of input noise~ _cite_ . When a single multilayer perceptron was trained to handle multiple input noise levels (by providing the noise variance as an additional input to the network), it produced inferior results compared to the state-of-the-art BMND~ _cite_ approach. In contrast to this, the EPLL framework of~ _cite_, which is a model-based approach, has been shown to work well across a wide range of noise levels. These results suggest that we should work towards bringing deep networks and model-based approaches together. Motivated by this, in this work, we propose a novel deep network architecture for denoising based on a Gaussian conditional random field model that explicitly accounts for the input noise level. Gaussian Markov Random Fields (GMRFs) ~ _cite_ are popular models for various structured inference tasks such as denoising, inpainting, super-resolution and depth estimation, as they model continuous quantities and can be efficiently solved using linear algebra routines. However, the performance of a GMRF model depends on the choice of pairwise potential functions. For example, in the case of image denoising, if the potential functions for neighboring pixels are homogeneous (i.e., identical everywhere), then the GMRF model can result in blurred edges and over-smoothed images. Therefore, to improve the performance of a GMRF model, the pairwise potential function parameters should be chosen according to the image being processed. A GMRF model that uses data-dependent potential function parameters is referred to as Gaussian Conditional Random Field (GCRF) ~ _cite_ . Image denoising using a GCRF model consists of two main steps: \a parameter selection step in which the potential function parameters are chosen based on the noisy input image, and an inference step in which energy minimization is performed for the chosen parameters. In this work, we propose a novel model-based deep network architecture, which we refer to as deep GCRF network, by converting both the parameter selection and inference steps into feed-forward networks. The proposed deep GCRF network consists of two sub-networks: \a parameter generation network (PgNet) that generates appropriate potential function parameters based on the input image, and an inference network (InfNet) that performs energy minimization using the potential function parameters generated by PgNet. \Since directly generating the potential function parameters for an entire image is very difficult (as the number of pixels could be very large), we construct a full-image pairwise potential function indirectly by combining potential functions defined on image patches. If we use _inline_eq_ patches, then our construction defines a graphical model in which each pixel is connected to its _inline_eq_ spatial neighbors. \This construction is motivated by the recent EPLL framework of~ _cite_ . Our PgNet directly operates on each _inline_eq_ input image patch and chooses appropriate parameters for the corresponding potential function. Though the energy minimizer can be obtained in closed form for GCRF, it involves solving a linear system with number of variables equal to the number of image pixels (usually of the order of _inline_eq_) . Solving such a large linear system could be computationally prohibitive, especially for dense graphs (each pixel is connected to N neighbors when _inline_eq_ image patches are used) . Hence, in this work, we use an iterative optimization approach based on Half Quadratic Splitting (HQS) ~ _cite_ for designing our inference network. Recently, this approach has been shown to work very well for image restoration tasks even with very few (N-N) iterations~ _cite_ . Our inference network consists of a new type of layer, which we refer to as HQS layer, that performs the computations involved in a HQS iteration. Combining the parameter generation and inference networks, we get our deep GCRF network shown in Figure~ _ref_ . Note that using appropriate pairwise potential functions is crucial for the success of GCRF. Since PgNet operates on the noisy input image, it becomes increasingly difficult to generate good potential function parameters as the image noise increases. To address this issue, we introduce an additional PgNet after each HQS iteration as shown in dotted boxes in Figure~ _ref_ . Since we train this deep GCRF network discriminatively in an end-to-end fashion, even if the first PgNet fails to generate good potential function parameters, the later PgNets can learn to generate appropriate parameters based on partially restored images. \noindent Contributions: