With the increasing abundance of images, finding out images that satisfy user needs from a huge collection is more and more required, which emphasizes the importance of image search and image recommendations working as filters for users. Such tasks are not trivial, however, due to the gap in understanding the semantics of images as well as the gap in understanding the intents or preferences of users over images. Compared to their counterparts for structured data, such as search of text and recommendations of book or movie, image search and recommendations raise more challenges since images lack an immediately effective representation. How to represent images both expressively and discriminatively is of essential importance in many image-related tasks including detection, registration, recognition, classification, and retrieval. This problem had been extensively studied, and many kinds of hand-crafted features had been designed and adopted in different tasks~ _cite_ . Most of previous work focuses on low-level visual features of images, but for image search and recommendations, it is often not clear how to represent the intents or preferences of users within the framework of low-level features. One feasible solution that has been studied is to utilize the users' information as constraints to refine the image representations, making them consistent with both semantic labels and user provided hints~ _cite_ . For example, Liu \etal~ _cite_ proposes to learn an image distance metric by combining the images' visual similarity and their ``social similarity, '' defined from users' interests in images that are mined from user data in online social networks. Nonetheless, visual content of images and users' intents/preferences on images are of two different modalities, simply combining them may not turn out efficient enough. Recently, deep network models have attracted much attention of researchers in the image processing field. One significant advantage of deep networks is the learning of image representations, which are demonstrated to be more effective than hand-crafted features, especially in semantic level image understanding~ _cite_ . Moreover, deep networks have achieved great success in processing other forms of data such as speech and text~ _cite_ . Promisingly, multimodal data, such as images and users' intents/preferences, may be efficiently handled by a single integrated deep network. In this paper, we study a dual-net deep network model for the purpose of making recommendations of images to users. The network consists of two sub-networks, which map an image and the preferences of a user into a same latent semantic space, respectively. Therefore, the network achieves representations of both images and users, termed representations hereafter, and these hybrid representations are directly comparable to make decisions of recommendations. Moreover, we propose a comparative deep learning (CDL) method to train the designed deep network. Instead of a naive learning, \eg learning a distance between a user and an image, the CDL uses two images compared against one user, and learns the relative distances among them. Our key idea is depicted in Fig.~ _ref_, where for a query user, her historical data used for learning consist of ``positive'' images, \eg her favorites, and ``negative'' images, \eg her dislikes; the objective of CDL is that the distance between the user and a positive image shall be less than the distance between the user and a negative image. Thus, training data for CDL are triplets of _inline_eq_ and these data are fed into a triple-net deep network consisting of three sub-networks, one of which is for user, and the other two are for positive and negative images and are actually identical, as shown in Fig.~ _ref_ . Note that after training, we need only two sub-networks for user and image, respectively. The designed dual-net network and CDL method have been verified on an image recommendation task with real-world data sets. Experimental results display that the proposed CDL achieves superior performance than naive learning, and our proposed solution outperforms other state-of-the-art image recommendation methods significantly. The remainder of this paper is organized as follows. Related work is discussed in Section N. Then our proposed CDL-based image recommendation solution is described, the objective of CDL is formulated in Section N, followed by detailed description of the deep network model in Section N, and details of making image recommendations in Section N. Experimental results are reported in Section N, and concluding remarks in Section N.