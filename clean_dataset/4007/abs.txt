We propose an end-to-end recurrent encoder-decoder based sequence learning approach for printed text Optical Character Recognition () . In contrast to present day existing state-of-art solution [_cite_] which uses output layer, our approach makes minimalistic assumptions on the structure and length of the sequence. We use a two step encoder-decoder approach--(a) A recurrent encoder reads a variable length printed text word image and encodes it to a fixed dimensional embedding. (b) This fixed dimensional embedding is subsequently comprehended by decoder structure which converts it into a variable length text output. Our architecture gives competitive performance relative to Connectionist Temporal Classification () [_cite_] output layer while being executed in more natural settings. The learnt deep word image embedding from encoder can be used for printed text based retrieval systems. The expressive fixed dimensional embedding for any variable length input expedites the task of retrieval and makes it more efficient which is not possible with other recurrent neural network architectures. We empirically investigate the expressiveness and the learnability of long short term memory (s) in the sequence to sequence learning regime by training our network for prediction tasks in segmentation free printed text {} s. The utility of the proposed architecture for printed text is demonstrated by quantitative and qualitative evaluation of two tasks--word prediction and retrieval.