Traditional brain decoding methods employ the activation of voxels for pattern analysis of functional magnetic resonance imaging (fMRI) data _cite_ . However, recent studies show that brain networks, which are formed by correlating fMRI signals obtained from voxel pairs, provide more information compared to the temporal dynamics of voxels for brain decoding _cite_ . There has been a shift in brain decoding paradigms towards modeling the brain connectivity by networks, since they offer a proper framework to recognize brain patterns and represent the interactions among regions _cite_ . Richiardi et al.~ _cite_, _cite_ suggest various descriptors to extract features from fMRI connectivity graphs and decode cognitive states using the descriptors extracted from these graphs . Fornito et al. _cite_ propose a method to learn brain connectivity models using edge connections computed between graph nodes. Shirer et al. _cite_ employ functional connectivity models to decode continuous and free streaming cognitive states. Ekman et al. _cite_ analyze adjustments in functional connectivity models from a graph theoretical perspective. These studies propose methods to recognize connectivity patterns by modeling various types of pairwise relationships of nodes of connectivity graphs. Unlike the methods which estimate pairwise connectivity between the voxels, Onal et al. _cite_ propose a method which forms connectivity graphs by ensembling a set of local meshes. In this graph representation, the nodes correspond to the voxels. A node is connected to its p-nearest neighboring voxels to form a star mesh, where a neighborhood of a voxel is defined with respect to Euclidean distance between voxel coordinates (called spatial neighborhood), or functional similarities between voxel BOLD responses (called functional neighborhood) . They represent the BOLD response recorded at each voxel (node) as a linear combination of the BOLD responses of its neighboring voxels. The arc weights of each mesh are then estimated by Ridge regression to represent the relationship among the voxels within their spatial _cite_ or functional _cite_ neighborhood. Finally, they embed the arc weights of local meshes into a feature vector to train a classifier for brain decoding. This approach, which aggregates the locally connected meshes under a global network model, resulted in better decoding performances, compared to pairwise relationship models. It is known that brain processes information in multiple frequency bands, and different frequencies of neuronal activity have been linked to the BOLD signal _cite_ . Features of spoken sentences, visual stimuli or development of social interaction may unfold over distinct time scales _cite_ . Kauppi et al. _cite_ report that distinct regions exhibit inter-subject correlations at low, medium or high frequencies. These studies imply that different regions of the brain discriminate the conditions in different subbands. Therefore, multi-resolution analysis of fMRI signal is crucial for analyzing and decoding the cognitive states. Wavelet transforms are widely used to represent the fMRI signals in multiple resolutions with approximately decorrelated coefficients _cite_ . Bullmore et al. _cite_ reported that the brain has fractal property (also called _inline_eq_-like property), where the statistical properties that describe the structure of a system, in time or space, do not change over a range of different scales _cite_ . In this sense, wavelets are well-suited for multi-resolution fMRI analysis _cite_, _cite_ . Adaptivity of wavelets to local or non-stationary features of an fMRI signal makes them suitable choices for the analysis of the fMRI signal, which is expected to include non-stationary features of interest at several scales _cite_ . Furthermore, Discrete Wavelet Transform (DWT) has decorrelating capability for a wide class of signals having _inline_eq_-like property. In other words, even if the data is highly correlated, the correlations computed between wavelet coefficients are generally small. In this study, we assume that fMRI signals, which are reconstructed by the decorrelated wavelet coefficients for different time resolutions, carry complementary information in the corresponding feature spaces. This assumption is supported by the study of Richiardi et al. _cite_ which show that the multi-resolution signals obtained with an orthogonal DWT are quasi class-conditionally independent. Therefore, we expect that the classifiers trained using multi-resolution signals are diverse, and fusion of their decisions would yield high performance for decoding the brain signals. This approach requires a fast and efficient decision fusion method to ensemble the classifiers trained by the fMRI signals at different resolutions. Ensemble learning classifiers are used in many fMRI studies, including brain decoding. In a pioneering study by Kuncheva et al. _cite_, multiple classifiers are trained by the various subsets of samples. Recently, Alkan et al. _cite_ partition the brain into homogeneous regions with respect to functional similarity of voxel time series and train a different classifier at each region. Multiple classifiers are also trained by a set of complementing stimuli _cite_ or subbands _cite_ . Then, the results of the classifiers are ensembled by majority voting techniques. These ensemble learning methods have been shown to outperform the methods based on a single classifier. A hierarchical ensemble learning method, suggested by Ozay et al. _cite_, fuses the decisions of multiple classifiers by a meta classifier. This method, called, fuzzy stacked generalization (FSG), is shown to outperform a number of ensemble learning methods _cite_ in Multi Voxel Pattern Analysis (MVPA) . In this study, we propose a framework, called, Hierarchical Multi-resolution Mesh Networks (HMMNs), which fuses a set of multi-resolution brain networks by a hierarchical learning architecture and enables us to analyze the network topology of brain in multiple resolutions (see Figure _ref_) . The suggested framework consists of the following steps: We perform subject-transfer learning in which the classifiers are trained by the data obtained from a group of subjects and tested by the data obtained from another group. Our results reflect that the arc weights of mesh networks, which represent the connectivity among the regions, provide better graph embeddings to classify the cognitive tasks compared to pairwise correlations between regions or raw fMRI data. Furthermore, training classifiers by mesh arc weights obtained from different time resolutions, and fusing their decisions leads to better classification accuracy compared to training a single classifier by the mesh weights of original and single-resolution signal. We also analyze the node degree, node strength, betweenness centrality and global efficiency measures of the mesh networks obtained for each subband, and investigate their relationship to the classification performance. We observe significant diversity among the networks obtained for different subbands for each measure, which shows that the signals embed different characteristics of brain connectivity at each resolution. Finally, we investigate the class discrimination power of the mesh networks in each resolution. Our brain decoding results reflect that the classifiers, trained by the multi-resolution networks collaborate with each other to complement the information embedded at different subbands. HMMN model provides higher decoding performances compared to single resolution methods and multi-resolution methods based on pairwise correlation networks.