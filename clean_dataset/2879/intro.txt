In medical image processing, we often deal with problems where the images are challenging to analyze due to their low quality and only a limited training dataset is available. In these cases it can be helpful to incorporate prior knowledge. Examples are localization problems where the objects can be approximated by a simple geometrical shape or a statistical model. That is the case for X-ray images of the femur (thigh bone), which is the main focus of this paper. Localizing the femur in an X-ray image is helpful for many medical applications~ _cite_ to identify pathologies or assist during surgery. To do that, an algorithm needs to identify the anatomical parts of the bone. In the case of the femur that could be the precise location of the femoral head, the greater trochanter, etc. X-rays taken intraoperatively are often fluoroscopic X-rays in order to limit the radiation exposure of surgeons and operating room staff. Fluoroscopic X-rays are taken with a comparatively low radiation dose, which results in low SNR and contrast (see~ _ref_), making their automatic processing challenging. The scans are often made with so-called C-arms, which can be easily repositioned and rotated during the surgery. However, this also means that the images do not have a standardized appearance. In particular, scale, image-plane rotation, viewing angle, and contrast/brightness vary in a wide range and increase the search space for the object detection. During surgery, the femur is furthermore often occluded by implants and surgical tools, as shown in _ref_ . Algorithms for the detection of the femur were already proposed for different ND modalities such as MRI (_cite_), CT (_cite_), and ND radiographic X-rays (_cite_) . Detectors for parts of the femur in fluoroscopic X-rays were presented in~ _cite_ . In this paper, we develop a new approach that uses deep learning combined with prior information about the shape of the bone. We will use fluoroscopic X-ray images for our evaluation, but our approach can be applied to other ND and ND modalities as well. A classical solution to localize anatomical points on a contour is the algorithm~ _cite_ . For the algorithm, the variation of the outline and the gray-level appearances near the outline are learned from training data. However, the standard only employs a low-capacity model and fluoroscopic X-ray images have a low SNR, which means that simple models of the appearance are not sufficient for an accurate localization. Similar to the techniques in~ _cite_ a more complex patch-based neural network can be used for a refinement step. However, such an approach is inherently slow, and in~ _cite_, the authors report a computation time of N minutes. The state of the art for localizing the femur in (i.e., higher-dose and thus higher-quality) X-rays uses random forests, which can achieve high capacity, and combines them with constrained local models~ _cite_ . However, the random forests are used in a part of the algorithm where they have a strong impact on runtime. An end-to-end solution to predict the coordinates of anatomical points with a neural network usually requires many training images and thus does not work for many medical imaging applications. Pixel-wise segmentation networks, on the other hand, have been shown to work well even with limited amounts of training data~ _cite_ . They can be used to find the outline of objects, but they do not label particular points on the outline. Instead, we propose to fit the geometrical or statistical representation of the model to the output of a segmentation network, a process we call . This allows us to localize the objects as well as labeling specific points on their outline. Segmentation networks perform pixel-wise classification, typically by means of a series of convolution layers, downsampling, and upsampling operations. In the case of a single (foreground) class, the last operation in the network is a sigmoid activation function. The activation value is a measure of confidence for the presence of the foreground class, as shown in _ref_, which can be thresholded for a hard assignment. The outline of this paper is as follows. In _ref_ we introduce the first problem, where we localize the femoral head, and in _ref_ we discuss the problem of localizing keypoints on the entire femur. In _ref_ we evaluate the performance of our proposed solutions on a dataset of fluoroscopic X-ray images. Since the number of images in our dataset is relatively small, we train our networks with simulated images, which is explained in the appendix.