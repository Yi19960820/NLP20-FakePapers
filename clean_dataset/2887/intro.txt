We all love anime characters and are tempted to create our custom ones. However, it takes tremendous efforts to master the skill of drawing, after which we are first capable of designing our own characters. To bridge this gap, the automatic generation of anime characters offers an opportunity to bring a custom character into existence without professional skill. Besides the benefits for a non-specialist, a professional creator may take advantages of the automatic generation for inspiration on animation and game character design; a Doujin RPG developer may employ copyright-free facial images to reduce designing costs in game production. Existing literature provides several attempts for generation facial images of anime characters. Among them are Mattya _cite_ and Rezoolab _cite_ who first explored the generation of anime character faces right after the appearance of DCGAN _cite_ . Later, Hiroshiba _cite_ proposed the conditional generation model for anime character faces. Also, codes are made available online focusing on anime faces generation such as IllustrationGAN _cite_ and AnimeGAN _cite_ . However, since results from these works are blurred and distorted on an untrivial frequency, it still remains a challenge to generate industry-standard facial images for anime characters. In this report, we propose a model that produces anime faces at high quality with promising rate of success. Our contribution can be described as three-fold: A clean dataset, which we collected from Getchu, a suitable GAN model, based on DRAGAN, and our approach to train a GAN from images without tags, which can be leveraged as a general approach to training supervised or conditional model without tag data.