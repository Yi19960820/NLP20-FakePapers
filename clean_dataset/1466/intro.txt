Despite the effectiveness of deep convolutional neural networks (CNNs) on supervised image classification problems, zero shot learning (ZSL) remains a challenging and fundamental problem due to the rapid expansion of image categories and the lacking in labeled training data. As a special unsupervised domain adaptation, ZSL aims to transfer information from the source domain, a set of training classes with labeled data, to make predictions in the target domain, a set of test classes with only unlabeled data. Different from standard domain adaptation, in ZSL the labeled training classes and unlabeled test classes have no overlaps--they are entirely disjoint. Based on the visibility of the instance labels, the training classes and the test classes are usually referred to as and classes respectively. Existing zero-shot image recognitions have centered on deploying label embeddings in a common semantic space, e.g., in terms of high level visual attributes, to bridge the domain gap between and classes. For example, animals share some common characteristics such as `black', `yellow', `spots', `stripes' and so on. Thus each animal class, either seen or unseen, can be represented as a binary vector in the semantic attribute space, with each element denoting the appearance/absence of certain attribute. Much ZSL effort in this direction has focused on developing effective mapping models from the input visual feature space to the semantic label embedding space ~ _cite_, or learning suitable compatibility functions between the two spaces~ _cite_, to facilitate prediction information transfer from the seen classes to the unseen classes. However, these methods identify visual-semantic mappings only on the labeled seen class data, which poses a fundamental {\em domain shift} problem due to the appearance variations of visual attributes across and classes, and has negative impact on cross-class generalization (i.e., ZSL performance) _cite_ . In this paper, we propose a novel ZSL framework with an progressive ensemble network to address the domain shift problem and improve the generalization ability of ZSL. Existing ZSL works rely on a single set of label embeddings to build inter-class label relations for knowledge transfer, which can hardly to be suitable for all the unseen classes. Instead we construct a deep ensemble network that consists of multiple image classification functions with a shared feature extraction convolutional neural network and different label embedding representations. Each label embedding representation facilitates information transfer from the seen classes to a subset of unseen classes, while enhancing the diversity of the multiple classifiers. By exploiting multiple classifiers in an ensemble manner, we expect the ensemble network can overcome the prediction noise and class bias in the original label embeddings to gain robust zero-shot predictions. Moreover, we exploit the unlabeled data from unseen classes in a progressive ensemble framework to overcome the domain shift problem. In each iteration, we select the most confidently predicted unlabeled instances from each unseen class under the current ensemble network, and combine these selected instances and their predicted pseudo-labels with the original labeled seen class data together to refine the ensemble network parameters, especially its feature extraction component. By incorporating the unseen class instances into the ensemble network training and dynamically refine the selected instances in each iteration, we expect the dynamic progressive training process can effectively avoid the issue of overfitting to the seen classes and improve the generalization ability of the ensemble network on unseen classes. With the ensemble network directly handling multi-class classification over all classes, the proposed approach can be conveniently extended to address generalized ZSL. We conduct experiments on three standard ZSL datasets under both conventional ZSL and generalized ZSL settings. The empirical results demonstrate the proposed approach outperforms the state-of-the-art ZSL methods.