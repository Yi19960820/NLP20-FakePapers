Object classification~ _cite_ and object detection~ _cite_ have rapidly progressed with advancements in convolutional neural networks (CNNs) ~ _cite_ and the advent of large visual recognition datasets~ _cite_ . Modern object detectors predominantly follow the paradigm established by Girshick et al. in their seminal work on Region CNNs~ _cite_: first an object proposal algorithm~ _cite_ generates candidate regions that may contain objects, second, a CNN classifies each proposal region. Most recent detectors follow this paradigm~ _cite_ and they have achieved rapid and impressive improvements in detection performance. Except for concurrent work (e.g.~ _cite_), most previous object detection work has focused on the PASCAL~ _cite_ and ImageNet~ _cite_ detection datasets. Recently, the COCO dataset~ _cite_ was introduced to push object detection to more challenging settings. The dataset contains N, N images of fully segmented object instance in N categories, with an average of N object instances per image. COCO introduces a number of new challenges compared to previous object detection datasets: (N) it contains objects at a broad range of scales, including a high percentage of small objects, (N) objects are less iconic, often in non-standard configurations and amid clutter or heavy occlusion, and (N) the evaluation metric encourages more accurate object localization. In this paper, we revisit recent improvements in object detection by performing extensive experiments on the COCO dataset. In particular, we begin with the Fast R-CNN object detector~ _cite_, and test a number of intuitive modifications to explicitly address the unique challenges of this dataset, including small object detection, detection of objects in context, and improved localization. Our goal is to adapt the highly successful Fast R-CNN object detector to perform better in these settings, and we use COCO to drive our experiments. Inspired by recent advances in object detection, we implement three network modifications: (N) a multi-stage feature aggregator that implements skip connections in intermediate network layers to more accurately detect objects at multiple scales, (N) a foveal structure in the classifier network that helps improve localization by looking at multiple image contexts, and (N) a novel loss function and corresponding network adjustment that optimize an integral of localization overlaps and encourage higher-precision localization. These three modifications allow information to flow along multiple paths in our network, including through features from multiple network layers and from multiple object views, see . We therefore refer to our approach as a `MultiPath' network. We train our MultiPath detector using the recently proposed DeepMask object proposals~ _cite_, which, like our model, are well adapted to the COCO dataset. Our combined system, using DeepMask proposals and our MultiPath classifier, achieves a detection score of N average precision (AP) for detection with an ensemble of N models. Compared to the baseline Fast R-CNN detector~ _cite_ with Selective Search proposals~ _cite_, which achieves an AP of N, this represents a N \% improvement in performance. Moreover, for small objects we improve AP by nearly N _inline_eq_ . We also adopt our system to generate segmentation masks, and achieve an AP of N on the segmentation task. Our system placed second in the N COCO Detection Challenge in both the bounding box and segmentation tracks. Only the deeper ResNet classifier~ _cite_ outperformed our approach. Potentially, ResNet could be used as the feature extractor in our MultiPath network.