Facial expressions are important tools used to communicate the emotional reaction and/or state of a person during their daily activities. There are many expressions a human can display, and behind each emotion there are a group of components. These are the person's intentions, action tendencies, appraisals, other cognitions, neuromuscular and physiological changes, expressive behavior, and subjective feelings~ _cite_ . These components cause the movement of the facial muscles which in return creates a visual expression for others to see the emotion. ND imaging instruments provide the ability to capture all the muscle movement in an accurate way, regardless of the lighting and pose variations. From these high resolution ND facial scans, the muscle activities are visually obvious, which is beneficial for facial expression recognition. However, there are two main challenges produced by it: N) Normal ND data is a point cloud in the ND space. Automatic location detection of the frontal face and the registration with its associated ND face image is very complex and difficult. N) For facial expression recognition, different muscle activations have different impact on the shape of the face. The Facial Action Coding System (FACS) ~ _cite_ has defined the relationship between action units and the emotional state. However, the accuracy of current action unit detection is not high. The accuracy of action unit based emotion detection system is not high either. In this paper, we focus on the task of recognizing the six basic facial expressions by using both ND appearance and ND geometric shape cues. Moreover, the importance of different facial parts will be fully explored. In particular, a novel system for ND FER is designed based on accurate facial parts extraction techniques and deep CNN feature fusion schemes related to different facial parts. To accurately corp meaningful facial parts from both facial texture maps and depth maps, we propose a novel N-stage procedures consists of facial landmark localization, facial rotation correction, facial resizing, facial parts bounding box extraction and post-processing steps. To deeply explore the importance of different facial parts for FER, we propose a novel deep feature fusion sub-net which can efficiently learn the importance weights of different CNN features associated with different facial parts. The proposed system is evaluated on the public dataset and achieving the best results among other methods in the same setting. The main contributions of this paper are the following: The rest of the paper is organized as follow. Related works are reviewed in section N, and the details of the proposed approach is described in section N. In Section N, we report the experimental results and section N concludes the paper.