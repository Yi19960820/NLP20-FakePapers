Output of an ideal pattern classifier satisfies two properties. One is the invariance under replacement of a data point by another data point within the same class, and we refer this as to intra-class invariance. The other is the distinctiveness under replacement of a data point in one class by a data point in another class, and we refer this as to inter-class distinctiveness. Good classifiers more or less have these properties for untrained data. For a given class, there exists a set of transformations that leave the class label unchanged. In case of visual object recognition of ``apple", the class label stays the same under different lighting conditions, backgrounds, and poses, to name a few. One can expect that a classifier gains good intra-class invariance through learning dataset containing many images with these variations. A classifier should also show inter-class distinctiveness to distinguish one class from the other. If one construct a training dataset containing green apple class and red apple class, lighting condition must be paid careful attention, because important color feature may be spoiled under some lighting condition. Appropriate types and ranges of variations depends on the problem setting. For an image classifier to gain good intra-class invariance without compromising inter-class distinctiveness, there are largely two types of approaches. One approach is to embed some mechanisms in classifiers to give robustness against intra-class variations. One of the most successful classifiers would be Convolutional Neural Network (CNN) _cite_ . CNN has two important building blocks: convolution and spatial pooling, which give robustness against global and small local shifts, respectively. These shifts are a typical form of intra-class variation. Another approach is data augmentation, meaning that a given dataset is expanded by virtual means. A common way is to deform original data in many ways using prior knowledge on intra-class variation. Color processing and geometrical transformation (rotation, resizing, \etc) are typical operations used in visual recognition problems. Adding virtual data points amounts to making the points denser in the manifold that the class instances form. Strong regularization effects are expected through augmented data learning. Augmented data learning is also beneficial in an engineering point of view. Dataset creation is a painstaking and costly part in product development. Data augmentation allows the use of prior knowledge on recognition targets, which engineers do have in most cases, and thus provides easy and cheep substitutes. Secondly, quality of virtual data can be easily evaluated by human perception. In case of visual recognition task, one can check virtual images whether they resemble real ones by eyes. Many of state-of-the-art methods in generic object recognition problems use deep CNNs, trained on augmented datasets comprising original data and deformed data (see recent works _cite_) . It has been pointed out that CNN models with many layers have great discriminative power; on the other hand, theoretical and methodological aspects of data augmentation are not fully revealed. Data augmentation plays an essential role in boosting performance of generic object recognition. Krizhevsky \etal used a few types of image processing, such as random cropping, horizontal reflection, and color processing, to create image patches for the ImageNet training _cite_ . More recently, Wu \etal vastly expanded the ImageNet dataset with many types of image processing including color casting, vignetting, rotation, aspect ratio change, and lens distortion on top of standard cropping and flipping~ _cite_ . Although these two works use different network architectures and computational hardware, it is still interesting to see the difference in the performances levels. The top-N prediction error rate of the latter is N \%, while that of the former is N \%. Such a large gap could be an implicit evidence that richer data augmentation leads to better generalization. Paulin \etal proposed a novel method for creating augmented datasets _cite_ . It greedily selects types of transformations that maximize the classification performance. The algorithm requires heavy computational resources, thus the exhaustive pursuit is almost intractable when deep networks with a huge number of parameters are trained. Handwritten character/digit recognition has been an important problem for both industrial applications and algorithm benchmarking for a quarter century _cite_ . The problem is relatively simple in a sense that there is no degree of freedom in the background and that stroke can be easily modified. Elastic distortion is a commonly used data augmentation technique that has a good property in giving a large degrees of freedom in the stroke forms, while leaving the topological structure invariant. Indeed, data augmentation by elastic distortion is crucial in boosting classification performance _cite_ . In case of pedestrian detection, use of synthetic pedestrians in real background _cite_ and synthetic occlusion _cite_ have been proposed. Though these approaches give additional degrees of freedom in expanding training datasets, we omit such means in this work. Data augmentation can be categorized into two: off-line and on-line. In this work, off-line data augmentation means to increase the number of data points by a fixed factor before the training starts. The same instance is repeatedly used in the training stage until convergence~ _cite_ . On-line data augmentation means to increase the number of data points by creating new virtual samples at each iteration in the training stage (see representative works: ~ _cite_) . There, random deformation parameters are sampled at each iteration, hence the classifier always ``sees" new samples during the training. Cire {\c s} an \etal claims that on-line scheme greatly improves classification performance because learning a very large number of samples likely avoids over-fitting~ _cite_ . Our work is mostly inspired by their work, and is focused on the on-line deformation. Very recently, an website article reported a method named as Test-Time Augmentation~ _cite_, where prediction is made by taking average of the output from many virtual samples, though the algorithm is not fully described. Tangent Prop _cite_ is a way to avoid over-fitting with implicit use of data augmentation. Virtual samples are used to compute the regularization term that is defined as the sum of tangent distances, each of which is the distance between an original sample and a slightly deformed one. It is expected that classifier's output is stable in the vicinity of original data points, but not necessarily so in other locations. This paper proposes the optimal decision rule for a given data sample using classifiers trained with augmented data. We do not discuss methods of data deformation themselves. Throughout this paper we assume that training is done with data samples deformed in on-line fashion. That is, random deformation parameters are sampled at every iteration, and a deformed sample is used only once and discarded after a single use. Such training minimizes an expectation value of loss function over random deformation parameters. We claim that class decision must be made so as to minimize the same expectation value for a given test sample. We show by experiments that the proposed decision rule give lower classification error rates than the conventional decision rule. APAC improves test error rate of CNN by N \% for MNIST and by N \% for CIFAR-N. To the best of our knowledge, the improved error rate for MNIST is the best among non-ensemble classifiers reported in the past. Though we believe that the proposed decision rule is beneficial to any classification problem, in which augmented data learning is applied, image classification problems are mainly discussed in this paper because we have not conducted experiments in other fields.