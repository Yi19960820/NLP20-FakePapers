Self-awareness models make it possible for an agent to evaluate whether faced situations at a given time correspond to previous experiences. Self-aware computational models have been studied and several architectures have been introduced _cite_ . Such models have to provide a framework where autonomous decisions and/or teleoperation by a human can be integrated as a capability of the device itself to dynamically evaluate the contextual situation _cite_ . Recent progress of signal processing and machine learning allow an agent to obtain a self-awareness model from stored multi-sensorial data coming from previously successfully completed experiences. Self-awareness layers modeling situations perceived through different sensorial modalities and can be integrated in order to build a uniform structure of cross-modal self-awareness for an agent. Using such models, the agent gains the ability to either predict the future evolution of a situation (e.g. for internal resources modulation) or to detect situations potentially unmanageable. This ``sense of the limit'' allows an agent predicting potential abnormalities with respect to the previous experiences to involve a human operator for support in due time. In this sense, the capability of detecting abnormal situations is an important feature included in self-awareness models as it can allow autonomous systems to anticipate in time their situation/contextual awareness about the effectiveness of the decision-making sub-modules _cite_ . In _cite_ a two-layers self-awareness model has been proposed: Shared Layer (SL) and Private Layer (PL) . The analysis of observed moving agents for understanding the normal/abnormal dynamics in a given scene from an external viewpoint is a very hot topic and emerging research field _cite_ . One common approach is to detect abnormalities as deviations from externally observed Environment Centered (EC) models. EC models can be considered shared as they concern observation variables externally accessible to multiple agents. However, when a mobile observer agent is placed in the same EC reference system _cite_, the observer can also use its own private variables to detect the normal/abnormal flow of a situation under its viewpoint. The agent, however, relates its perceived private variables to actions that it performs in a given location of the environment. An abnormality can be perceived by EC models as a not-predicted EC location varying behaviour. However, an agent can also detect an abnormality with respect to what it is used to observe from a first-person viewpoint while performing the same task. This knowledge can be only estimated by the agent itself by means of its private perception variables. Detecting abnormalities by using a self-awareness model learned through multi-sensorial data acquired in the first-person by the agent can be possible while doing the same task for which a self-awareness SL model has been obtained. Such a model can be described as the PL of self-awareness. An external observer can have no access to such information (unless an explicit communication link is established with the agent) and will not be able to detect PL abnormalities, while he can still do this by using the SL model, if available. Thus, a well-trained model for PL self-awareness can allow an agent to be able to evaluate abnormalities with a more complete information set, based on the joint availability of PL and SL models, as it was shown in _cite_ . However, previous works mostly rely on a high level of supervision to learn PL self-awareness models _cite_, while in this work, we propose a weakly-supervised method based on a hierarchy of Cross-modal Generative Adversarial Networks (GANs) for establishing self-awareness on PL. This model not only can be trained in a self-supervised manner but also can provide a level of information to boost the SL model. It can provide further normality representation for enriching the one obtained in an unsupervised way from SL normality representation and vice-versa. Both SL and PL learned models, can be used to predict the dynamics of a vehicle performing a task. They can be used also to describe normal behavioural conditions of the agent with respect to the two type of observations. Furthermore, a cross-correlation of the private and shared perspectives over the same phenomenon would provide a more complete capability for detecting the incoming anomalies _cite_ . This paper proposes a novel method to learn the PL model using an incremental hierarchy of GANs. GANs _cite_ are deep networks commonly used to generate data and they have shown good performance for learning the distribution of data _cite_ . Despite the great power of GANs for modeling data distribution, it has been observed that GANs fail to learn the highly complex distributions where the data is in a high order of diversity. In other words, the GAN fails to learn the diversity, in which the generator fails to create diverse samples and the discriminator is not able to classify them as fake _cite_ . This is a very known problem in the context of training GANs and several works try to tackle that _cite_ . A natural solution to estimate data distribution with huge diversity is to break it down into smaller sets and estimate it as the mixture of multiple small distributions _cite_ . The nature of an autonomous agent self-awareness model demands to learn a highly diverse distribution. The challenge in such tasks is not only the problem of learning a complex data distribution, but also the source of supervision is limited. The concept of learning a mixture of multiple distributions starting from simple to complex has been explored before _cite_, but they mostly rely on a high level of supervision. Inspired by _cite_ we propose a self-supervised method using a set of cross-modal GANs to solve small sub-problems. This set of GANs stack in a hierarchical fashion and learns the small distributions in different levels of hierarchy. The first level is trained using the provided subset of data including most simple situations; more complex situations that can emerge in time will be abnormalities with respect to such models and their description can generate additional models. The next levels of the hierarchy are trained with the supervision provided by the first level. Namely, the scores of the first level discriminator are used to approximate the complexity of data. This can be seen as a supervision to detect whether a new model needs to be learned, and when this happens, to estimate the new model that has to be incrementally added to the hierarchy. The main novelty of this proposed approach is a weakly-supervised strategy to divide and solve a complex problem using GANs. Furthermore, at best of our knowledge, it is the first time that the discriminator scores are used to approximate the complexity of a distribution. The discriminator scores correspond to the error (, the innovations with respect to the other models already presented in the GANs hierarchy) . As result, the method is able to model highly diverse distributions, which can be seen as a tool to find a sort of set of orthogonal basis functions by subdividing into simpler sets. The rest of the papers is organized as follow: Sec. _ref_ describes the procedure of training cross-modal GANs, and the proposed hierarchy of GANs to model the PL self-awareness. In Sec. _ref_ results of evaluations are reported and discussed.