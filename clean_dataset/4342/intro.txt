Human activity analysis is a crucial yet challenging research area of computer vision. Applications of human activity recognition ranges from video surveillance, human-computer interaction, robotics and skill evaluation _cite_ . At the core of successful systems for human activity recognition lies an effective representation that can model both the spatial and temporal dynamics of human motion. Traditionally, the community has focused on activity recognition in the domain of RGB videos _cite_ . For a RGB video, complex human motion in ND euclidean space is projected on to a series of ND images and in the process, loss of valuable ND spatio-temporal information is inevitable. In recent years, we have witnessed a drastic improvement of cost-effective depth sensors in the form of Microsoft Kinect _cite_ . Naturally, computer vision methods leveraging on the ND structure provided by such ND sensors, namely RGB + D methods, have been an active area of research _cite_ . Applied to human activity recognition, ND information of how a human body articulates comes in the form of time series sequence of ND skeletons. Such representations describe human motion as a collection of trajectories in ND euclidean space of key human joints. Even without the context information and visual cues, early work _cite_ in biological perception and more recent methods _cite_ provide strong evidence that encoding humans as a ND skeleton yields both a discriminative and a robust representation for activity analysis. Given the recent progress of powerful human pose estimators from RGB or RGBD data _cite_, human activity recognition model that builds on top of ND skeletons is a promising direction. Despite this significant progress, the inner workings of such complex temporal models still remain mostly black-boxes. Without the capability to interpret learning based models, we inevitably lack the power to fully support a model's decision regardless of its correctness _cite_ . Such short-comings may hinder practical deployment of even the strongest models. The ability to understand and explain precisely how a model came to a wrong prediction is a fundamental first step towards improving the potential of our current methods. In this light, we propose Temporal Convolutional Neural Networks (TCN) _cite_ applied to ND Human Action Recognition. Through the lens of TCN, we wish to uncover what exactly learning-based temporal models leverage on especially when trained on interpretable data such as a sequence of ND skeletons. We re-design the original TCN by factoring out the deeper layers into additive residual terms which yields both interpretable hidden representations and model parameters. Using the resulting architecture, Res-TCN, we validate our approach on currently the largest ND human activity recognition dataset, NTU-RGBD and obtain state-of-the-art results.