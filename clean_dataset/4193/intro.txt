Instance retrieval is the task of finding a particular instance from a large image corpus. In practice, instance retrieval has two major challenges: N) the large visual appearance deformations due to the object's different positions, poses and illumination when being captured; and N) various distractors from the natural and less contextual backgrounds. In the past decade, a lot of work uses local invariant descriptors _cite_ to handle instance retrieval, including methods that use large visual codebooks _cite_ and methods that use compact representations _cite_ . Although promising performance has been reported on some constrained datasets _cite_ for these methods, in a more realistic and challenging scenario where the target objects are with cluttered backgrounds, instance-level retrieval still remains a challenging problem _cite_ . Recent studies show the visual descriptors produced by aggregating the convolutional feature maps (CFMs) from convolutional neural networks (CNNs) achieve state-of-the-art performance for image retrieval _cite_ . Comparing to the conventional local descriptors, these deep learned features capture more semantic information since a CNN is usually trained on large labeled image datasets _cite_ . Most existing methods aggregate the CFMs into a compact global representation for an image, where the query-to-image similarity is evaluated on the image level. How to use these deep convolutional features to distinguish the target object from distractors in cluttered backgrounds is still challenging. In this paper, we follow the direction of CNN-based methods and propose a novel reranking algorithm, namely query adaptive matching (QAM), using CFMs to address the image clutter problem during instance retrieval. The key idea of our method is that instead of relying on a global image representation, we represent each dataset image by a set of base regions. In further, we allow these base regions to freely merge into larger regions. Image features are then extracted from the combined region rather than the whole image. Moreover, we parameterize the regions that can be created via combining the base region and represent the combined feature as a function of a set of parameters. Thus, adjusting these parameters will be equivalent to choosing the region-of-interest to focus for a candidate image. Our method will cast the parameter selection issue as an optimization problem under the objective of maximizing the similarity between the query and the feature obtained from the combined region. The optimal parameters are expected to generate a focus region that mostly covers the object-of-interest. To implement this idea, we also propose two ways of generating base regions. One is based on the property of the CFM and the other one is based on the multi-scale spatial pyramid. By conducting experiments on the various instance retrieval benchmarks, we show that the proposed QAM reranking, together with the two base region generation approaches can achieve promising results which outperform the state of the art. Besides that, we also discuss several practical issues of using CFMs for instance retrieval, including the choice of deep CNN models and the convolutional layers.