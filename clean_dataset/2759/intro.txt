quality is an important parameter in machine vision problems. Though there are several no-reference image quality measures available in literature _cite_, visual quality of an input image is a subjective quantity and traditionally we rely on human perception to conclude about it. However, computer vision algorithms work differently from human vision system (HVS), and the concept of image quality for computer vision problems does not always match with human perception. Convolutional neural networks (CNNs) depend on several sets of filter outputs to perform the final classification task. Thus, it is difficult to predict the outcome of a degraded input in an intuitive way and the classification accuracy largely depends on the model architecture and the nature of the degradation. In most of the cases, we train and validate a CNN model with high quality images with minimum noise. However, in practical applications, several different kinds of degradations can be introduced in the input image that can heavily affect the performances of CNN models. These image degradations can be obtained due to poor image sensor, lighting conditions, focus, stabilization, exposure time etc. To overcome such effects, some researchers have suggested to include noisy data in the training itself _cite_ . Though, this technique produces better results than training only with high quality images, it is practically not possible to train a network with all probable degradation types that may appear in real scenarios. Starting from multi-class classification tasks to generative models, CNNs are used in numerous computer vision algorithms. State-of-the-art CNN architectures such as ResNetN, Inception vN, DenseNet etc. _cite_ have achieved exceptional results for large image classification task in ILSVRC N challenge (ImageNet) . Interestingly, it has been shown recently that well-trained complex CNN models might produce wrong results even in the presence of a small amount of carefully selected noise, although such noise does not create any problem in visual recognition _cite_ . Though the probability of occurrence of such adversarial noises might be low, it is important to know the performances of different CNN architectures under different noise conditions to build more robust systems in future. Thus, in presence of different image degradations, the performances of different deep CNN architectures in classification task consisting of different challenging images are considered in this paper. In most of the recent applications, it is generally assumed that the CNN models accept good quality images. However in many cases, it is not possible to have good quality images in computer vision problems. Thus, several authors have recently proposed different architectures and preprocessing steps to work with low quality images. In _cite_, the authors used coupled kernel embedding to recognize faces in low resolution images that also suffer from degradations due to high compression. Zou and Yuen _cite_ addressed the same problem of face recognition in low resolution by introducing discriminative constraints to achieve high quality images for recognition. In _cite_, authors introduced a modified version of well-known MNIST dataset, that includes synthetically generated noisy handwritten images, and using this dataset they proposed a novel framework that learns representations using probabilistic quadtrees and deep belief network. A noisy face database is developed in _cite_ to act as a benchmark in robust face recognition algorithms. However, in _cite_, authors did not mention any model that can achieve robust recognition results. Later, Tao et al. _cite_ proposed joint kernel sparse representation based classification algorithm that performs satisfactorily on the database proposed in _cite_ . In _cite_, Ullman et al. tried to show that human vision system (HVS) and CNNs process an image differently by defining minimal recognizable configurations (MIRC) which are the smallest cropped version of an input image for which human being can still recognize a class or action perfectly. It was shown in _cite_ that even though the cropping action reduces the information content in an image, CNNs are still not comparable to HVS. In _cite_, the authors rigorously analyzed the effect of image degradation under different noise conditions on the accuracy of CNNs in classification task. Though the authors include degradations like blur, compression, contrast etc., they did not include different common degradations like motion blur, salt and pepper noise etc. in their work. Also, the work in _cite_ does not include models like ResNetN and CapsuleNet, that integrate different architectures along with conventional CNN layers to find more complex features from an input image. In this work, we not only consider more number of image degradations, we also compare latest CNN architectures using two completely different types of datasets. The major contributions of our work are as follows.