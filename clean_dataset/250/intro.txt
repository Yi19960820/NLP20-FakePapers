Action recognition is an important research area in computer vision, which has a wide range of applications, \eg, human computer interaction, video surveillance, robotics, and \etc. Recent years, the cost-effective depth sensor combining with real-time skeleton estimation algorithms can provide reliable joint coordinates _cite_ . As an intrinsic high level representation, ND skeleton is valuable and comprehensive for summarizing a series of human dynamics in the video, and thus benefits general action analysis _cite_ . Besides its succinctness and effectiveness, it has a significant advantage of great robustness to illumination, clustered background, and camera motion. Based on these advantages, ND skeleton based activity analysis has drawn great attentions _cite_ . Very recently, human pose estimation from ND RGB videos have also been studied with deep CNN method~ _cite_ . Rather accurate ND skeleton joints could be evaluated from RGB videos. However, it seems still lack effective method to deal with this kind of ND skeleton video data for recognition purpose. Previously, hand-crafted skeleton features have been devised~ _cite_ . However, these hand-crafted features are always shallow and dataset-dependent, thus limiting their performance. Recently, deep learning based methods have achieved great success in high-level computer vision tasks such as image recognition, classification, detection, and semantic segmentation \etc. As for the ND skeleton based action recognition problem, Recurrent Neural Networks (RNNs) have been widely adopted _cite_ . RNNs could effectively extract the temporal information and learn the contextural information well. However, RNNs tend to overemphasize the temporal information especially when the training data is insufficient, thus leading to over-fitting~ _cite_ . Convolutional Neural Networks (CNNs) have also been applied to this problem _cite_ . Different from the RNNs, how to effectively represent ND skeleton data and feed into deep CNNs is still an open problem. Wang \etal _cite_ proposed the Joint Trajectory Maps (JTM), which represents both spatial configuration and dynamics of joint trajectories into three texture images through color encoding, and then fed these texture images to CNNs for classification. However, this kind of JTM is a little complicated, and may lose some important information when projecting ND skeleton into ND image. Du \etal _cite_ proposed to represent each skeleton sequence as an image, where the temporal dynamics of the sequence are encoded as changes in columns and the spatial structure of each frame is represented as column. Their encoding method is dataset dependent and translation-scale variant which means their encoding method need dataset information and human's translation and action scale may influence the final mapping results. To tackle the above shortcomings in skeleton-based video recognition problem, in this paper, we present a new framework consisting of translation-scale invariant image mapping and multi-scale deep CNN classifier. The overall flowchart of our method is illustrated in Fig.~ _ref_ . We propose to map the ND skeleton video to a color image, where the color image achieves translation and scale invariance and dataset independent. The proposed mapping could easily handle the translation and scale changes in ND skeleton data, thus is more distinctive, and dataset independent. Although the skeleton images are very different from natural images, the widely used pre-trained deep CNN model \eg, AlexNet _cite_, VGGNet _cite_, ResNet _cite_ could still be transferred to it well. It is especially valuable when there is insufficient annotated skeleton videos. The fine-tune strategy could avoid training millions of parameters afresh and improve the performance significantly~ _cite_ . More importantly, due to the special property of this kind of skeleton images, we propose a simple yet effective multi-scale deep CNN to enhance the frequency adjustment ability of our method. In addition, we extend our method to deal with ND skeleton-based video recognition problem. Surprisingly, our method could also work well. Experimental results on the popular benchmark dataset like NTU RGB-D, UTD-MHAD, MSRC-N, and GND demonstrate the effectiveness our proposed framework. We also give extensive analysis experiments to show the propoerties of our method. In conclusion, our main contributions are summarized as following: This paper are organized as following. Related works are summarized and presented in Sec.~ _ref_ . We present our method in Sec.~ _ref_, including our Translation-scale invariant image mapping method, multi-scale deep CNN and data augmentation method. Experiments on the popular benchmarks are presented in Sec.~ _ref_ . At last, more analysis experiments and results on ND skeleton data are presented in Sec.~ _ref_ .