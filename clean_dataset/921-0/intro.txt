Cancer is today the third cause of mortality worldwide. In this paper, we focus on segmentation of gliomas, which are the most frequent primary brain cancers _cite_ . Gliomas are particularly malignant tumors and can be broadly classified according to their grade into low grade gliomas (grades I and II defined by World Health Organization) and high grades gliomas (grades III-IV) . Glioblastoma multiforme is the most malignant form of glioma and is associated with a very poor prognosis: the average survival time under therapy is between N and N months. Medical images play a key role in diagnosis, therapy planning and monitoring of cancers. Treatment protocols often include evaluation of tumor volumes and locations. In particular, for radiotherapy planning, clinicians have to manually delineate target volumes, which is a difficult and time-consuming task. Magnetic Resonance (MR) images _cite_ are particularly suitable for brain cancer imaging. Different MR sequences (TN, TN-FLAIR, TN, TN + gadolinium) highlight different tumor subcomponents such as edema, necrosis or contrast-enhancing core. In recent years, machine learning methods have achieved impressive performance in a large variety of image recognition tasks. Most of the recent state-of-the-art segmentation methods are based on Convolutional Neural Networks (CNN) _cite_ . CNNs have the considerable advantage of automatically learning relevant image features. This ability is particularly important for the tumor segmentation task. CNN-based methods _cite_ have obtained the best performances on the four last editions of Multimodal Brain Tumor Segmentation Challenge (BRATS) _cite_ . Most of the segmentation methods based on machine learning rely uniquely on manually segmented images. The cost of this annotation is particularly high in medical imaging where manual segmentation is not only time-consuming but also requires high medical competences. Image intensity of cancerous tissues in MRI or CT scans is often similar to the one of surrounding healthy or pathological tissues, making the exact tumor delineation difficult and subjective. In the case of brain tumors, according to _cite_, the inter-rater overlap of expert segmentations is between N and N in terms of Dice coefficient. For these reasons, high-quality manual tumor segmentations are generally available in very limited numbers. Segmentation approaches able to exploit images with weaker forms of annotations are therefore of particular interest. In this paper, we assume that the training dataset contains two types of images: fully-annotated (with provided ground truth segmentation) and weakly-annotated, with an image-level label indicating presence or absence of a tumor tissue within the image (Fig. _ref_) . We refer to this setting as 'mixed supervision'. The latter type of annotations can be obtained at a substantially lower cost as it is less time-consuming, potentially requires less medical expertise and can be obtained without the use of a dedicated software. We introduce a novel CNN-based segmentation model which can be trained using weakly-annotated images in addition to fully-annotated images. We propose to extend segmentation networks, such as U-Net _cite_, with an additional branch, performing image-level classification. The model is trained jointly for both tasks, on fully-annotated and weakly-annotated images. The goal is to exploit the representation learning ability of CNNs to learn from weakly-annotated images while supervising the training using fully-annotated images in order to learn features relevant for the segmentation task. Our approach differs from the standard semi-supervised learning as we consider weakly-annotated data instead of totally unlabelled data. To the best of our knowledge, we are the first to combine pixel-level and image-level labels for training of models for tumor segmentation. We perform a series of cross-validated tests on the challenging task of segmentation of gliomas in MR images from BRATS N challenge. We evaluate our model both for binary and multiclass segmentation using a variable number of ground truth segmentations available for training. Since all ND images from the BRATS N contain brain tumors, we focus on the ND problem of tumor segmentation in axial slices of a MRI and we assume slice-level labels for weakly-annotated images. Using approximately N MRI with slice-level labels and a varying number of fully-annotated MRI, we show that our approach significantly improves the segmentation accuracy when the number of fully-annotated cases is limited.