This paper introduces a fast and efficient network architecture, NeXtVLAD, to aggregate frame-level features into a compact feature vector for large-scale video classification. Briefly speaking, the basic idea is to decompose a high-dimensional feature into a group of relatively low-dimensional vectors with attention before applying NetVLAD aggregation over time. This NeXtVLAD approach turns out to be both effective and parameter efficient in aggregating temporal information. In the Nnd Youtube-NM video understanding challenge, a single NeXtVLAD model with less than NM parameters achieves a GAP score of N in private leaderboard. A mixture of N NeXtVLAD models results in N, which is ranked Nrd over N teams. The code is publicly available at _url_ .