In recent years, speech emotion recognition has received increasing interest. Speech emotion recognition focuses on using linguistic and acoustic attributes as input features and machine learning models as classifiers to classify the emotions of the speaker _cite_ . These systems achieve promising results when training and testing are performed from the same corpus. However, for real applications, such systems have been demonstrated not to perform well when speech utterances from different languages and different age groups, in quite different conditions, are combined _cite_ . At present, various emotional corpora exist, but they are dissimilar in terms of the spoken language, type of emotion (i.e., naturalistic, elicited, or acted) and labelling scheme (i.e., dimensional or categorical) _cite_ . There are more than N, N spoken languages around the world, but only N languages account for N \% of the world's population . Even for N languages, very few adequate resources (speech corpus) are available for language and speech processing research. This means that research in language and speech analysis must confront the problem of data scarcity for many languages. This imbalance, variation, diversity, and dynamics in speech and language databases means that it is almost impossible to learn a model from a single corpus and then expect it to be effective in practice in general. In automatic speech emotion recognition, most studies focus on a single corpus at a time, without considering the performance of model in cross-language and cross-corpus scenarios. However, ever since transfer learning has been applied to cross-domain classification and pattern recognition problems, interest in applying it to cross-corpus emotion recognition has bee growing. Transfer learning focuses on adapting knowledge from available auxiliary resources to transfer this learning to a target domain, where a very few or even no labelled data is available _cite_ . Deep neural network (DNN) based transfer learning has recently improved image classification by using a very large dataset as source domain and small data as a target domain _cite_ . Inspired by this success, deep learning based transfer learning has recently been used for speech analysis. However, the existing research has focused on basic DNNs. The impact of using models like Deep Belief Networks (DBNs), which have strong generalisation power and are therefore suitable for cross-corpus emotion recognition, has not been thoroughly explored. A few studies have explored DBNs for speech emotion recognition (e.g., _cite_) and numerous studies focus on DBNs for features extraction _cite_ from speech signal. However, transfer learning using DBNs is very rare. Furthermore, how to maximise the transfer learning performance for cross-corpus/cross-language emotion recognition still needs to be explored further. In this study, we address the above challenges. We investigate DBNs for transfer learning over five widely-used emotional speech databases. By using the experimental results from various scenarios, we indicated how a large gain in accuracy comparable to baseline can be achieved using transfer learning technique for cross-corpus emotion recognition.