In this paper, we focus on single image super-resolution (SR), which aims at recovering a high-resolution (HR) image from a given low-resolution (LR) one. It is always the research emphasis because of the requirement of higher definition video displaying, such as the new generation of Ultra High Definition (UHD) TVs. However, most video content would not at sufficiently high resolution for UHD TVs. As a result, we have to develop efficient SR algorithms to generate UHD content from lower resolutions _cite_ . Traditional single image SR methods always try to find a new image prior or propose a new way to use the existing image priors. A lot of image prior information have been explored in the image restoration literature, such as local smooth, non-local self-similarity and image sparsity. Based on the assumption that low and high resolution images have the same sparse representation, Yang et al. _cite_ use two coupled dictionaries to learn a nonlinear mapping between the LR and the HR images. In _cite_, Glasner et al. begin to use the image multi-scale information for single image SR and obtain state-of-the-art results. Recently, due to the availability of much larger training dataset and the powerful GPU implementation, deep learning based methods achieve great success in many fields, including both high level and low level computer vision problems. Look through the literature, most state-of-the-art single image SR methods are based on deep learning. The pioneering SR method is SRCNN proposed by Dong et al. _cite_ . They establish the relationship between the traditional sparse-coding based SR methods and their network structure and demonstrate that a convolutional neural network (CNN) can learn a mapping from low resolution image to high resolution one in an end-to-end manner. Dong et al. successfully expand SRCNN for compression artifacts reduction by introducing a feature enhancement layer _cite_ . Soon after, they proposed a fast SRCNN method, which directly maps the original low-resolution image to the high-resolution one _cite_ . Different from _cite_, some works try to learn image high frequency details instead of the undegraded image. In _cite_, Kim et al. cascade many convolutional layers to form a very deep network to learn image residual. Investigating an effective way to use multi-scale information is also important. The degraded image can be successful recovered is mainly based on the assumption that patches in a natural image tend to redundantly recur many times inside the image. However, it is not only exist in the same scale but also across different scales. It has been demonstrated that make full use of multi-scale information can improve the restoration result in traditional methods _cite_ . However, the multi-scale information has been little investigated in deep learning methods. In _cite_, Kim et al. try to train a multi-scale model for different magnification SR. It is a very rough tactics to exploit the scale information since they just put different scale image as input for training. Its success can be attribute to the powerful learning ability of CNN instead of the multi-scale information being considered in the network structure. In this paper, we propose a dilated convolution based inception module to learn multi-scale information and design a deep network for single image SR. Fig. _ref_ makes a comparison between the proposed dilated convolution based inception module and the original GoogLeNet inception module. Our proposed new inception module contains multiple different scale dilated convolution that makes it can learn multi-scale image information. Furthermore, we cascade multiple dilated convolution based inception modules to constitute a deep network for single image SR. In short, the contributions of this work are mainly in three aspects: N) we proposed a dilated convolution based inception module, which can learn multi-scale information with only single scale image input; N) we design a novel deep network with the proposed dilated convolution based inception module for single image SR. N) experimental results show that our proposed new method outperforms many state-of-the-art methods.