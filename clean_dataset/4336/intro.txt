As the most common bad-weather condition, the effects of rain can degrade the visual quality of images and severely affect the performance of outdoor vision systems. Under rainy conditions, rain streaks create not only a blurring effect in images, but also haziness due to light scattering. Effective methods for removing rain streaks are required for a wide range of practical applications, such as image enhancement and object tracking. We present the first deep convolutional neural network (CNN) tailored to this task and show how the CNN framework can obtain state-of-the-art results. Figure _ref_ shows an example of a real-world testing image degraded by rain and our de-rained result. In the last few decades, many methods have been proposed for removing the effects of rain on image quality. These methods can be categorized into two groups: video-based methods and single-image based methods. We briefly review these approaches to rain removal, then discuss the contributions of our proposed DerainNet. Due to the redundant temporal information that exists in video, rain streaks can be more easily identified and removed in this domain _cite_ . For example, in _cite_ the authors first propose a rain streak detection algorithm based on a correlation model. After detecting the location of rain streaks, the method uses the average pixel value taken from the neighboring frames to remove streaks. In _cite_, the authors analyze the properties of rain and establish a model of visual effect of rain in frequency space. In _cite_, the histogram of streak orientation is used to detect rain and a Gaussian mixture model is used to extract the rain layer. In _cite_, based on the minimization of registration error between frames, phase congruency is used to detect and remove the rain streaks. Many of these methods work well, but are significantly aided by the temporal content of video. In this paper we instead focus on removing rain from a single image. Compared with video-based methods, removing rain from individual images is much more challenging since much less information is available for detecting and removing rain streaks. Single-image based methods have been proposed to deal with this challenging problem, but success is less noticeable than in video-based algorithms, and there is still much room for improvement. To give three examples, in _cite_ rain streak detection and removal is achieved using kernel regression and a non-local mean filtering. In _cite_, a related work based on deep learning was introduced to remove static raindrops and dirt spots from pictures taken through windows. However, focusing on a specific application this method uses a different physical model from the one in this paper. As our later comparisons show, this physical model limits its ability to transfer to rain streak removal. In _cite_, a generalized low-rank model; both single-image and video rain removal can be achieved through this the spatial and temporal correlations learned by this method. Recently, several methods based on dictionary learning have been proposed _cite_ . In _cite_, the input rainy image is first decomposed into its base layer and detail layer. Rain streaks and object details are isolated in the detail layer while the structure remains in the base layer. Then sparse coding dictionary learning is used to detect and remove rain streaks from the detail layer. The output is obtained by combining the de-rained detail layer and base layer. A similar decomposition strategy is also adopted in method _cite_ . In this method, both rain streaks removal and non-rain component restoration is achieved by using a hybrid feature set. In _cite_, a self-learning based image decomposition method is introduced to automatically distinguish rain streaks from the detail layer. In _cite_, the authors use discriminative sparse coding to recover a clean image from a rainy image. A drawback of methods _cite_ is that they tend to generate over-smoothed results when dealing with images containing complex structures that are similar to rain streaks, as shown in Figure _ref_ (c), while method _cite_ usually leaves rain streaks in the de-rained result, as shown in Figure _ref_ (d) . Moreover, all four dictionary learning based frameworks _cite_ require significant computation time. More recently, patch-based priors for both the clean and rain layers have been explored to remove rain streaks _cite_ . In this method, the multiple orientations and scales of rain streaks are addressed by pre-trained Gaussian mixture models. As mentioned, compared to video-based methods, removing rain from a single image is significantly more difficult. This is because most existing methods _cite_ only separate rain streaks from object details by using low level features, for example by learning a dictionary to for object representation. When an object's structure and orientation are similar with that of rain streaks, these methods have difficulty simultaneously removing rain streaks and preserving structural information. Humans on the other hand can easily distinguish rain streaks within a single image using high-level features such as context information. We are therefore motivated to design a rain detection and removal algorithm based on the deep convolutional neural network (CNN) _cite_ . CNN's have achieved success on several low level vision tasks, such as image denoising _cite_, super-resolution _cite_, image deconvolution _cite_, image inpainting _cite_ and image filtering _cite_ . We show that the CNN can also provide excellent performance for single-image rain removal. In this paper, we propose ``DerainNet'' for removing rain from single-images, which we base on the deep CNN. To our knowledge, this is the first approach based on deep learning to directly address this problem. Our main contributions are threefold: