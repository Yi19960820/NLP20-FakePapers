Insufficient lighting in image capturing can significantly degrade the visibility of images. The lost details and low contrast not only cause unpleasant subjective feelings, but also hurt the performance of many computer vision systems which are designed for normal-light images. There are a lot of causes for insufficient lighting, such as low-light environment, limited performance of photography equipment, and inappropriate configurations for the equipment. To make the buried details visible, improve the subjective experience and usability of current computer vision systems, low-light image enhancement is demanded. In the past decades, many researchers have devoted their attention to solving the problem of low-light image enhancement. Many techniques have been developed to improve the subjective and objective quality of low-light images. Histogram equalization (HE) ~ _cite_ and its variants restrain the histograms of the output images to meet some constraints. De-hazing based method~ _cite_ utilizes the inverse connection between the images with insufficient illumination and those in hazy environments. Another category of low-light enhancement methods is built on Retinex theory~ _cite_, which assumes the observed color image can be decomposed into reflectance and illumination. Single-scale Retinex (SSR) ~ _cite_ constrains the illumination map to be smooth by Gaussian filter as the early attempt. Multi-scale Retinex (MSRCR) ~ _cite_ extends SSR with multi-scale Gaussian filters and color restoration. _cite_ proposes a method to preserve naturalness of illumination with lightness-order-error measure. Fu ~ _cite_ proposed to fuse multiple derivations of the initially illumination map. SRIE~ _cite_ estimates reflectance and illumination simultaneously using a weighted variational model. After manipulating the illumination, the target result can be restored. LIME~ _cite_, on the other hand, only estimates illumination with structure prior and uses reflection as the final enhanced results. There are also Retinex-based methods for joint low-light enhancement and noise removal~ _cite_ . Although these methods may produce promising results in some cases, they still suffer from the limitation in model capacity of the decomposition for reflectance and illumination. It is difficult to design well-working constraints for image decomposition that can be applied in various scenes. Besides, the manipulations on illumination map are also hand-crafted and the performance of these methods usually relies on careful parameter tuning. With the rapid development of deep neural network, CNN has been widely used in low-level image processing, including super-resolution~ _cite_, rain removal~ _cite_ Lore ~ _cite_ uses stacked sparse denoising auto-encoder for simultaneous low-light enhancement and noise reduction (LLNet), however the nature of low-light pictures is not taken into account. To overcome these difficulties, we propose a data-driven Retinex decomposition method. A deep network, called as, that integrates image decomposition and the successive enhancement operations is built. First, a subnetwork, is used to split the observed image into lighting-independent reflectance and structure-aware smooth illumination. The Decom-Net is learned with two constraints. First, low/normal-light images share the same reflectance. Second, the illumination map should be smooth but retain main structures, which is obtained by a structure-aware total variation loss. Then, another adjusts the illumination map to maintain consistency at large regions while tailor local distributions by multi-scale concatenation. Since noise is often louder in dark regions and even amplified by the enhancement process, denoising on reflectance is introduced. For training such a network, we build a dataset of low/normal-light image pairs from real photography and synthetic images from RAW datasets. Extensive experiments demonstrate that our method not only achieves pleasing visual quality in low-light enhancement but also provides a good representation of image decomposition. The contributions of our work are summarized as follows: