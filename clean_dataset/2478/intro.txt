hyperspectral sensors can acquire images with high spectral and spatial resolutions simultaneously. For example, the Airborne Visible / Infrared Imaging Spectrometer (AVIRIS) sensor covers N continuous spectral bands across the electromagnetic spectrum with a spatial resolution of N meters. Such rich information has been successfully used in various applications such as urban mapping, environmental management, crop analysis and mineral detection. For these applications, an essential step is image classification whose purpose is to identify the label of each pixel. Hyperspectral image (HSI) classification is a challenging task. There exist two important issues _cite_, _cite_ . The first one is the curse of dimensionality. HSIs usually contain several hundreds of spectral bands. These high-dimensional data with limited numbers of training samples can easily result in the Hughes phenomenon _cite_, which means that the classification accuracy starts to decrease when the number of features exceeds a threshold. The other one is the use of spatial information. The improvement of spatial resolutions may increase spectral variations among intra-class pixels while decrease spectral variations among inter-class pixels _cite_, _cite_ . Thus, only using spectral information is not enough to obtain a satisfying result. To solve the first issue, a widely used method is to project the original data into a low-dimensional subspace, in which most of the useful information can be preserved. In the existing literatures, large amounts of works have been proposed _cite_, _cite_, _cite_ . They can be roughly divided into two categories: unsupervised FE methods and supervised ones. The unsupervised methods attempt to reveal low-dimensional data structures without using any label information of training samples. Typical methods include but are not limited to principal component analysis (PCA) _cite_, neighborhood preserving embedding (NPE) _cite_, and independent component analysis (ICA) _cite_ . Different from them, the supervised methods take advantages of the label information to learn the discriminative projections _cite_ . One typical method is linear discriminant analysis (LDA) _cite_, _cite_, which aims to maximize the inter-class distance and minimize the intra-class distance. In _cite_, a non-parametric weighted FE (NWFE) method was proposed. NWFE extends LDA by integrating nonparametric scatter matrices with training samples around the decision boundary _cite_ . Local Fisher discriminant analysis (LFDA) was proposed in _cite_, which extends the LDA by assigning greater weights to closer connecting samples. To address the second issue, many works have been proposed to incorporate the spatial information into the spectral information _cite_, _cite_, _cite_ . This is because the coverage area of one kind of material or one object usually contains more than one pixel. Current spatial-spectral feature fusion methods can be categorized into three classes: feature-level fusion, decision-level fusion, and regularization-level fusion _cite_ . For feature-level fusion, one often extracts the spatial features and the spectral features independently and then concatenate them into a vector _cite_, _cite_, _cite_, _cite_ . However, the direct concatenation will lead to a high-dimensional feature space. For decision-level fusion, multiple results are first derived using the spatial and spectral information respectively and then combined according to some strategies such as the majority voting strategy _cite_, _cite_, _cite_ . For regularization-level fusion, a regularizer representing the spatial information is incorporated into the original object function. For example, in _cite_ and _cite_, Markov random field (MRF) modeling the joint prior probabilities of each pixel and its spatial neighbors was incorporated into the Bayesian classifier as a regularizer. Although this method works well in capturing the spatial information, optimizing the objective function in MRF is time consuming especially on high-resolution data. Recently, deep learning (DL) has attracted much attention in the field of remote sensing _cite_, _cite_, _cite_ . The core idea of DL is to automatically learn high-level semantic features from data itself in a hierarchical manner. In _cite_ and _cite_, the autoencoder model has been successfully used for HSI classification. In general, the inputs of the autoencoder model is a high-dimensional vector. Thus, to learn the spatial feature from HSIs, an alternative method is flattening a local image patch into a vector and then feeding it into the model. However, this method may destroy the two-dimensional (ND) structure of images, leading to the loss of spatial information. Similar issues can be found in the deep belief network (DBN) _cite_ . To address this issue, convolutional neural network (CNN) based deep models have been popularly used _cite_, _cite_, _cite_ . They directly take the original image or the local image patch as network inputs, and use local-connected and weight sharing structure to extract the spatial features from HSIs. In _cite_, the authors designed a CNN network with three convolutional layers and one fully-connected layer. Besides, the input of the network is the first principal component of HSIs extracted by PCA. Although the experimental results demonstrate that this model can successfully learn the spatial feature of HSIs, it may fail to extract the spectral features. Recently, a three-dimensional (ND) CNN model was proposed in _cite_ . In order to extract the spectral-spatial features from HSIs, the authors consider the ND image patches as the input of the network. This complex structure will inevitably increase the amount of parameters, easily leading to the overfitting problem with a limited number of training samples. In this paper, we propose a bidirectional-convolutional long short term memory (Bi-CLSTM) network to address the spectral-spatial feature learning problem. Specifically, we regard all the spectral bands as an image sequence, and model their relationships using a powerful LSTM network _cite_ . Similar to other fully-connected networks such as autoencoder and DBN, LSTM can not capture the spatial information of HSIs. Inspired by CNNs, we replace the fully-connected operators in the network by convolutional operators, resulting in a convolutional LSTM (CLSTM) network. Thus, CLSTM can simultaneously learn the spectral and spatial features. Besides, LSTM assumes that previous states affect future sates, while the spectral channels in the sequence are correlated with each other. To address this issue, we further propose a Bi-CLSTM network. During the training process of the Bi-CLSTM network, we adopt two tricks to alleviate the overfitting problem. They are dropout and data augmentation operations.