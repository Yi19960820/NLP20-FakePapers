Automated medical image segmentation has been extensively studied in the image analysis community due to the fact that manual, dense labelling of large amounts of medical images is a tedious and error-prone task. Accurate and reliable solutions are desired to increase clinical work flow efficiency and support decision making through fast and automatic extraction of quantitative measurements. With the advent of convolutional neural networks (CNNs), near-radiologist level performance can be achieved in automated medical image analysis tasks including cardiac MR segmentation _cite_ and cancerous lung nodule detection _cite_ . High representation power, fast inference, and filter sharing properties have made CNNs the de facto standard for image segmentation. Fully convolutional networks (FCNs) _cite_ and the U-Net _cite_ are two commonly used architectures. Despite their good representational power, these architectures rely on multi-stage cascaded CNNs when the target organs show large inter-patient variation in terms of shape and size. Cascaded frameworks extract a region of interest (ROI) and make dense predictions on that particular ROI. The application areas include cardiac MRI _cite_, cardiac CT _cite_, abdominal CT _cite_ segmentation, and lung CT nodule detection _cite_ . However, this approach leads to excessive and redundant use of computational resources and model parameters; for instance, similar low-level features are repeatedly extracted by all models within the cascade. To address this general problem, we propose a simple and yet effective solution, namely (AGs) . CNN models with AGs can be trained from scratch in a standard way similar to the training of a FCN model, and AGs automatically learn to focus on target structures without additional supervision. At test time, these gates generate soft region proposals implicitly on-the-fly and highlight salient features useful for a specific task. Moreover, they do not introduce significant computational overhead and do not require a large number of model parameters as in the case of multi-model frameworks. In return, the proposed AGs improve model sensitivity and accuracy for dense label predictions by suppressing feature activations in irrelevant regions. In this way, the necessity of using an external organ localisation model can be eliminated while maintaining the high prediction accuracy. Similar attention mechanisms have been proposed for natural image classification _cite_ and captioning _cite_ to perform adaptive feature pooling, where model predictions are conditioned only on a subset of selected image regions. In this paper, we generalise this design and propose image-grid based gating that allows attention coefficients to be specific to local regions. Moreover, our approach can be used for attention-based dense predictions. We demonstrate the implementation of AG in a standard U-Net architecture () and apply it to medical images. We choose the challenging CT pancreas segmentation problem to provide experimental evidence for our proposed contributions. This problem constitutes a difficult task due to low tissue contrast and large variability in organ shape and size. We evaluate our implementation on two commonly used benchmarks: TCIA Pancreas _inline_eq_-_inline_eq_ _cite_ and multi-class abdominal _inline_eq_-_inline_eq_ . The results show that AGs consistenly improve prediction accuracy across different datasets and training sizes while achieving state-of-the-art performance without requiring multiple CNN models. CT Pancreas Segmentation: Early work on pancreas segmentation from abdominal CT used statistical shape models _cite_ or multi-atlas techniques _cite_ . In particular, atlas approaches benefit from implicit shape constraints enforced by propagation of manual annotations. However, in public benchmarks such as the TCIA dataset _cite_, Dice similarity coefficients (DSC) for atlas-based frameworks ranges from _inline_eq_ to _inline_eq_ _cite_ . In _cite_ a classification based framework is proposed to remove the dependency of atlas to image registration. Recently, cascaded multi-stage CNN models _cite_ have been proposed to address the problem. Here, an initial coarse-level model (e.g. U-Net or Regression Forest) is used to obtain a ROI and then a cropped ROI is used for segmentation refinement by a second model. Similarly, combinations of ND-FCN and recurrent neural network (RNN) models are utilised in _cite_ to exploit dependencies between adjacent axial slices. These approaches achieve state-of-the-art performance in the TCIA benchmark (_inline_eq_ DSC) . Without using a cascaded framework, the performance drops between _inline_eq_ and _inline_eq_ . Recent work _cite_ proposed an iterative two-stage model that recursively updates local and global predictions, and both models are trained end-to-end. Besides standard FCNs, dense connections _cite_ and sparse convolutions _cite_ have been applied to the CT pancreas segmentation problem. Dense connections and sparse kernels reduce computational complexity by requiring less number of non-zero parameters. Attention Gates: AGs are commonly used in natural image analysis, knowledge graphs, and language processing (NLP) for image captioning _cite_, machine translation _cite_, and classification _cite_ tasks. Initial work has explored attention-maps by interpreting gradient of output class scores with respect to the input image. Trainable attention, on the other hand, is enforced by design and categorised as hard-and soft-attention. Hard attention _cite_, e.g. iterative region proposal and cropping, is often non-differentiable and relies on reinforcement learning for parameter updates, which makes model training more difficult. Recursive hard-attention is used in _cite_ to detect anomalies in chest X-ray scans. Contrarily, soft attention is probabilistic and utilises standard back-propagation without need for Monte Carlo sampling. For instance, additive soft attention is used in sentence-to-sentence translation _cite_ and more recently applied to image classification _cite_ . In _cite_, channel-wise attention is used to highlight important feature dimensions, which was the top-performer in the ILSVRC N image classification challenge. Self-attention techniques _cite_ have been proposed to remove the dependency on external gating information. For instance, non-local self attention is used in _cite_ to capture long range dependencies. In _cite_ self-attention is used to perform class-specific pooling, which results in more accurate and robust image classification performance. In this paper, we propose a novel self-attention gating module that can be utilised in CNN based standard image analysis models for dense label predictions. Moreover, we explore the benefit of AGs to medical image analysis, in particular, in the context of image segmentation. The contributions of this work can be summarised as follows: