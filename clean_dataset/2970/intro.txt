Identifying compatible items is an important aspect in building recommendation systems. For instance, recommending matching shoes to a specific dress is important for fashion; recommending a wine to go with different dishes is important for restaurants. In addition, it is valuable to visualize what style is missing from the existing dataset so as to foresee potential matching items that could have been up-sold to the users. We believe that the generated compatible items could inspire fashion designers to create novel products and help our business clients to fulfill the needs of customers. For items with a sufficient number of viewing or purchasing intents, it is possible to take the co-viewing (or co-purchasing) records as signals of compatibility, and simply use standard techniques for a recommendation system, such as collaborative filtering, to identify compatible items. In real world application, it is quite often encountered that there are insufficient records to make a decent compatible recommendation---it is then critical to fully exploit relevant contents associated with items, such as the images for dresses, or the wineries for wines. Even leveraging such relevant information, recommending or generating compatible items is challenging due to three key reasons. First, the notion of compatibility typically goes across categories and is broader and more diverse than the notion of similarity, and it involves complex many-to-many relationships. As shown in Figure~ _ref_, compatible items are not necessarily similar and vice versa. Second, the compatibility relationship is inherently asymmetric for real world applications. For instance, students purchase elementary textbooks before buying advanced ones, house owners buy furniture only after their house purchases. Recommendation systems must take the asymmetry into consideration, as recommending car accessories to customers who bought cars is rational; recommending cars to those who bought car accessories would be improper. The two reasons above make many existing methods~ _cite_ less fit for compatibility learning, as they aim to learn a symmetric metric so as to model the item-item relationship. Third, the currently available labeled data sets of compatible and incompatible items are insufficient to train a decent image generation model. Due to the asymmetric relationships, the generator could not simply learn to modify the input image as most CGANs do in the similarity learning setting. However, humans have the capabilities to create compatible items by associating internal concepts. For instance, fashion designers utilize their internal concept of compatibility, e.g., style and material to design many compatible outfits. Inspired by this, we demonstrate extracting meaningful representation from the image contents for compatibility is an effective way of tackling such challenges. We aim at recommending and generating compatible items through learning a ``Compatibility Family''. The family for each item contains a representation vector as the embedding of the item, and multiple compatible prototype vectors in the same space. We refer to the latent space as the ``Compatibility Space''. Firstly, we propose an end-to-end trainable system to learn the family for each item. The multiple prototypes in each family capture the diversity of compatibility, conquering the first challenge. Secondly, we introduce a novel Projected Compatibility Distance (PCD) function which is differentiable and ensures diversity by encouraging the following properties: (N) at least one prototype is close to a compatible item, (N) none of the prototypes is close to an incompatible item. The function captures the notion of asymmetry for compatibility, tackling the second challenge. While our paper focuses mainly on image content, this framework can also be applied to other modalities. The learned compatible family's usefulness is beyond item recommendation. We design a compatible image generator, which can be trained with only the limited labeled data given the succinct representation that has been captured in the compatibility space, bypassing the third challenge. Instead of directly generating the image of a compatible item from a query item, we first obtain a compatible prototype using our system. Then, the prototype is used to generate images of compatible items. This relieves the burden for the generator to simultaneously learn the notion of compatibility and how to generate realistic images. In contrast, existing approaches generate target images directly from source images or source-related features. We propose a novel generator referred to as Metric-regularized Conditional Generative Adversarial Network (MrCGAN) . The generator is restricted to work in a similar latent space to the compatibility space. In addition, it learns to avoid generating ambiguous samples that lie on the boundary of two clusters of samples that have conflicting relationships with some query items. We evaluate our framework on Fashion-MNIST dataset, two Amazon product datasets, and Polyvore outfit dataset. Our method consistently achieves state-of-the-art performance for compatible item recommendation. Finally, we show that we can generate images of compatible items using our learned Compatible Family and MrCGAN. We ask human evaluators to judge the relative compatibility between our generated images and images generated by CGANs conditioned directly on query items. Our generated images are roughly Nx more likely to be voted as compatible. The main contributions of this paper can be summarized as follows: