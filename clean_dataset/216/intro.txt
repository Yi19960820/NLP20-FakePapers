Chest radiography (CR) is the most ordered clinical imaging procedure for the initial detection of abnormality in the chest. As a noninvasive, low radiation dose, and low cost imaging modality, CR is commonly used for detecting lung disease, such as lung cancer, and diagnosing conditions such as tuberculosis and pneumonia. However, some lung lesions are extremely difficult to detect due to overlapping bone structures such as ribs and clavicles. Dual energy subtraction (DES) can separate high-density material, such as bone, from soft tissue and thus improve detection _cite_ . Recent studies have also shown that DES can detect and assess coronary disease by visualizing coronary calcifications in the DE bone image _cite_ and computer-aided disease detection tasks _cite_ . DE chest radiography requires two x-ray exposures at two different tube voltages to capture two radiographs which are then linearly combined to generate bone images and soft-tissue images _cite_ . However, specialized equipment is required for DES and radiation dose is nearly doubled as compared to traditional CR. In addition, the organ motion artifacts caused by heartbeat and lung breathing motion during the time-lapse between the two kVp x-ray exposures can contaminate the image quality of DE radiographs. The ability to generate bone and soft tissue images from standard, single-shot CR would benefit this diagnostic imaging procedure. In this work, our goal is to develop a deep learning algorithm for generating virtual DE images from a standard, single-shot chest radiograph. We collected a large number of real two-exposure DE chest radiographs as training data for this task. The Convolutional Neural Network (CNN) has achieved significant success in medical image analysis field for tasks, such as chest disease detection/classification _cite_ ; CT pulmonary nodule detection _cite_ ; automatic organ segmentations _cite_, etc. However, predicting DE images using deep models remains a challenge. The structure and contextual information of a large receptive field in standard radiograph should be extracted by CNN model in a maximal manner to determine whether bony component are present and to predict the corresponding distribution. If the CNN model for fine-scale prediction is in a fully convolutional form, the size of CNN model would become very large with excessive number of parameters to learn, making it difficult to train. In order to avoid training a very large CNN model and efficiently train a CNN model to predict fine-scale DE information, we propose a deep model to generate high-quality virtual DE images from a standard, single-shot chest radiograph. Our model is based on a multi-scale and conditional adversarial network. The general pipeline of the algorithm is shown in Figure _ref_ . The algorithm is comprised of two parts: N) the bone image generator using the multi-scale fully convolutional network, and N) the soft tissue image generator which applies bone suppression on standard images. We introduce the concept of conditional adversarial loss in training the bone image generator _cite_ so that high frequency information and details are learned and preserved in the virtual bone image. To produce the virtual soft tissue image, an adapted edge and shadow suppression algorithm using cross projection tensor _cite_ is applied to suppress bone in the standard radiograph. Outputs from the algorithm are compared to a set of test data comprised of DE patient images. The algorithm performance is also evaluated by comparing to other algorithms that are applicable for virtual DE image generation. Bone suppression techniques have been developed to improve the diagnostic quality of CR exams for interpretation of disease. Current methods can be summarized into two types: learning-based methods and statistical analysis based methods. For learning-based methods, one of the early works was MTANN, proposed in _cite_, which uses traditional fully-connected neural networks with one hidden layer to predict the bone signal from a standard image. Then, the predicted bone signal can be subtract from standard image to generate an image similar to DE soft tissue image. Similar to one of the ideas in our network structure, MTANN was trained under a multi-resolution style. Each MTANN was trained separately for a certain resolution with corresponding re-sampled image using multi-resolution decomposition, and the prediction targets were the intensity values of single pixels from the DE bone images. At the testing stage, the trained MTANNs generate multi-resolution bone images and these images are combined together to produce a high-resolution bone image. Later, _cite_ further improved the MTANN to separate bone from soft tissue by training MTANN in different anatomical regions and producing DE images using total variation optimization. Such methods were extended to be used in portable CR systems _cite_ . Another one of the early works was the k-nearest neighbors (kNN) regression with optimized local feature _cite_ which used a linear dimensionality reduction method for local image features to optimize the performance of kNN regression for the prediction of bone images. However, this method cannot completely suppress the rib signal and requires a relatively long computation time for kNN regression. Our proposed deep model aims to address the limitations of previous work by generating high-resolution virtual DE images with relatively short computation times. Besides from the learning-based methods, several statistical analysis based methods for suppressing bone structures without the supervision from training data have been studied. _cite_ proposed a clavicle suppression algorithm which works by first generating a bone image from a gradient map modified along the bone border direction and then creating a soft-tissue image by subtraction of the bone image from the standard image. Later, _cite_ proposed blind-source signal separation algorithms for suppression of bone structures in standard chest radiography. _cite_ presented a ribcage segmentation algorithm based on Active Appearance Model that can accurately estimate the rib border and suppress the bone signal from standard radiography based on this prediction. In general, these statistical based methods require accurate segmentation and border annotations for the target structures, which is challenging to acquire. Although all have shown improvement in thoracic disease detection, many image details are suppressed and these methods require substantial hyper-parameter tuning. In this case, deep learning has been successfully applied in image classification, image segmentation, and image-to-image translation _cite_ . Deep learning also yields similar improvements in performance in the medical vision field for anatomical and pathological structures detection and segmentation tasks. _cite_ The boost of hardware and algorithms for deep learning have given the possibility of training CNN with many layers on large-scale datasets. Our work is closely related to the current state-of-the-art CNN models for image synthesis _cite_ and image transformation _cite_ . _cite_ proposed a conditional GAN (cGAN) that can generate realistic images given the outlines of the target image as the prior condition. _cite_ employed a GAN structure for generating high-resolution images from nominal resolution images. Our proposed method for generation of virtual DE images benefits from these excellent works on the application of GAN. The standard radiographs were used as a strong prior condition for generating virtual DE images using structure similar to cGAN _cite_ . The adversarial network structure also helps generation of super-resolution DE images (normally around N pixels _inline_eq_ N pixels) . In this paper, a customized GAN structure was designed for the generation of virtual DE bone images. In summary, our contributions are listed as follows: