Depth sensing is one of the core components of many computer vision tasks. Amplitude-modulated continuous-wave (AMCW) time-of-flight (ToF) has a brief and definite physical meaning in depth construction of scenes thus it attracts a lot of commercial attention, such as Kinect VN. It is also widely used in academic research of computer vision _cite_, including human tracking _cite_, ND scene reconstruction _cite_, robotics _cite_, object detection, gesture recognition _cite_, and scene understanding _cite_ . However, comparing with traditional RGB cameras, ToF cameras compute the depth by emitting a periodic amplitude modulated illumination signal and receive the demodulated signal reflected by the objects. Higher power of active illumination enables the ToF sensor to receive the signal with higher signal noise ratio (SNR) and higher level of confidence. Therefore, the power of illumination directly influences the performance of ToF cameras. Traditional ToF imaging algorithms are very sensitive to illumination and the depth accuracy degenerates rapidly with the decreasing illumination power. In order to obtain more accurate depth information, one way is to increase the intensity of the received active illumination signal. Other than increasing the illumination power, an alternative treatment to this issue is to increase the physical size of the pixels on the sensor to collect more light. However, this significantly decreases the depth map resolution. According to the inverse square law, one can also cut the depth sensing range of the camera. This obviously decreases the usability of the camera in many applications. Therefore, to make a ToF camera with satisfactory depth quality as well as reasonable resolution and sensing range, the painful dilemma for the illumination and the performance trade-off always troubles the designer of the camera if the conventional imaging pipeline is used. Such dilemma can be tackled if there is a way to recover high quality depth information from weak signals. A number of recent studies show that it is plausible to recover high SNR natural images from very noisy data using deep learning. _cite_ . Chen et al. _cite_ showed impressive results on recovering high quality color image from camera Bayer pattern which is captured under extremely low light condition with short exposure. Inspired by these research, we show for the first time that for ToF cameras, despite the weak signals in many areas under the extreme short exposure setting, these signals as a whole can be well utilized through a learning process which directly translates the weak and noisy ToF camera raw to high quality depth map. This creates an opportunity to address the aforementioned dilemma and makes it possible to design a very power efficient ToF camera possibly with higher resolution and longer sensing range. To enable the learning, we collect a comprehensive dataset under a variety of scenes and photographic conditions via a specialized ToF camera. The dataset contains ToF raw measurements and depth maps collected under extreme short exposure settings and long exposure settings respectively. We show in the experiments that our proposed method is able to robustly process ToF raw measurements with an exposure time that is one order of magnitude shorter than that used in a conventional ToF camera. The contributions of our work can be summarized as follows.