Artificial neural networks (ANNs) are now commonly used for image classification~ _cite_, segmentation~ _cite_, object detection and image resolution enhancement~ _cite_ . Convolutional neural networks (CNNs) in particular continue to offer significant improvements over other supervised learning techniques. While the growing field of deep learning has seen a lot of progress over the past several years, most learning networks are trained on pre-captured datasets that contain standard images (e.g., MNIST~ _cite_, CIFAR-N, or BBBC~ _cite_) . Little work with ANNs and CNNs has jointly considered the image data that they process is actually acquired-that is, whether a particular camera setup, illumination geometry or detector design might improve certain image post-processing goals. In many scenarios, and in optical microscopy in particular, the various physical parameters used to obtain an image are extremely important. For example, one must select an appropriate microscope objective lens that fits the entire area of interest within its field-of-view, but also still resolves important features of interest. Or, primarily transparent samples are often hardly visible at all under a standard bright-field microscope. Alternative techniques like phase-contrast or differential interference contrast microscopy are typically used improve sample visibility. Likewise, more recent computational approaches can also create sharper images by using structured illumination~ _cite_ . However, it is not clear which type of microscope design, illumination setting, or computational optics-based approach might yield the best results for a particular CNN-driven task. Here, we try to close the gap between how images are acquired and how they are post-processed by CNNs. We include a model of optical image formation into the first several layers of a neural network, which allows us to jointly optimize the design of a microscope and the various weights used for image classification in one step, thus forming a specific type of ``classification microscope." As an experimental demonstration, we jointly determine an optimal lighting pattern for red blood cell imaging as well as a CNN classifier to test for infection by the malaria parasite ({\it Plasmodium falciparum}) . By simply displaying two particular patterns on an LED array placed beneath our microscope, we can increase infection classification accuracy by N-N \%. We are hopeful that the presented framework will help bring together the growing field of deep learning with those who design the cameras, microscopes and other imaging systems that capture the training data that most learning networks currently use.