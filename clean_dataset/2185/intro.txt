Visual tracking has various applications ranging from video surveillance, human computer interaction to autonomous driving. The main difficulty is how to utilize the extremely limited training data (usually a bounding box in the first frame) to develop an appearance model robust to a variety of challenges including background clutter, scale variation, motion blur and partial occlusions. Discriminative correlation filters (DCFs) have attracted an increasing attention in the tracking community _cite_, due to the following two important properties. First, since spatial correlation is often computed in the Fourier domain as an element-wise product, DCFs are suitable for fast tracking. Second, DCFs regress the circularly shifted versions of input features to soft labels, i.e., generated by a Gaussian function ranging from zero to one. In contrast to most tracking-by-detection approaches _cite_ that generate sparse response scores over sampled locations, DCFs always generate dense response scores over all searching locations. With the use of deep convolutional features _cite_, DCFs based tracking algorithms _cite_ have achieved state-of-the-art performance on recent tracking benchmark datasets _cite_ . \def \def However, existing DCFs based tracking algorithms are limited by two aspects. First, learning DCFs is independent of feature extraction. Although it is straightforward to learn DCFs directly over deep convolutional features as in _cite_, DCFs trackers benefit little from the end-to-end training. Second, most DCFs trackers use a linear interpolation operation to update the learned filters over time. Such an empirical interpolation weight is unlikely to strike a good balance between model adaptivity and stability. It leads to DCFs trackers due to noisy updates. To address these two questions, we propose a Convolutional RESidual learning scheme for visual Tracking (CREST) . We interpret DCFs as the counterparts of the convolution filters in deep neural networks. In light of this idea, we reformulate DCFs as a one-layer convolutional neural network that directly generates the response map as the spatial correlation between two consecutive frames. With this formulation, feature extraction through pre-trained CNN models (e.g., VGGNet _cite_), correlation response map generation, as well as model update are effectively integrated into an end-to-end form. The spatial convolutional operation functions similarly with the dot product between the circulant shifted inputs and the correlation filter. It removes the boundary effect in Fourier transform through directly convolving in the spatial domain. Moreover, the convolutional layer is fully differentiable. It allows updating convolutional filters using back propagation. Similar to DCFs, the convolutional layer generates dense response scores over all searching locations in a one-pass manner. To properly update our model, we apply residual learning _cite_ to capture appearance changes by detecting the difference between the output of this convolutional layer and ground truth soft label. This helps alleviate a rapid model degradation caused by noisy updates. Meanwhile, residual learning contributes to the target response robustness for large appearance variations. Ablation studies (Section _ref_) show that the proposed convolutional layer performs well against state-of-the-art DCFs trackers and the residual learning further improves the accuracy. The main contributions of this work are as follows: