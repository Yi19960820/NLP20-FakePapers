Though there are still lots of arguments towards the exactly where and how visual analysis is processed within the human brain, there is considerable evidence showing that visual analysis takes place in a predominately and default coarse-to-fine sequence _cite_ as shown in Fig. _ref_ (N) . The coarse-to-fine perception is also proportional to the length of the cerebral circuit path, i.e. time. For example, when the image of Fig. _ref_ (N) is very quickly shown to a person, only very coarse visual stimuli can be perceived, such as sand and umbrella, which is usually of low spatial frequencies. Nevertheless, given a longer duration, fine-grained details with relatively higher spatial frequencies can be perceived. It is natural to ask whether our network has such a mechanism of predicting coarse information with short paths, and fine visual stimuli with longer paths. Another question is how the coarse-to-fine sequence is processed in the human brain? Recent biological experiments _cite_ reveal that functions of the two cerebral hemispheres are not exactly the same in processing of spatial frequency information. The left hemisphere (LH) and the right hemisphere (RH) are predominantly involved in the high and low spatial frequency processing respectively. As illustrated in Fig. _ref_ (N-A), the top-left figure is a large global letter made up of small local letters, called a Navon figure; the top-right figure is a scene image. The bottom-left and bottom-right are sinusoidal gratings for the images above. In Fig.~ _ref_ (N-B), given the same input visual stimuli, the highly activated regions in LH and RH are corresponding to high (in red) and low (in blue) spatial frequencies. Additionally, from the view of the evolution process, the left-right asymmetry of the brain structure may be mostly caused by the long-term asymmetrical functions performed~ _cite_ . Some researchers _cite_ believe that biological plausibility can be used as a guide to design intelligent systems. In the light of this understanding and to mimic the hemispheric specialization, we propose a dual skipping network, which is a left-right asymmetric layer skippable network. Our network can enable the coarse-to-fine object categorization in a single framework. The whole network is structured in Fig.~ _ref_ . Our network has two branches by referring to LH and RH respectively. Both branches have roughly the same initialized layers and structures. The networks are built by stacking skip-dense blocks, namely groups of densely connected convolutional layers which can be dropped dynamically. The unique connections are built by learning varying knowledge or abstraction. Transition layers aim at manipulating the capacity of features learned from preceding layers. The functionality of each branch is ``memorized'' from the given input and supervised information in the learning stage. The ``Guide'' arrow refers to a top-down facilitation of recognition that feeds the high-level information from the coarse branch to relatively lower-level visual processing modules of the fine branch inspired by a similar mechanism in the brain _cite_ . Though spatial frequency cannot be equated with the granularity of recognition, the dual skipping network might work similar to hemispheric specialization depending on the granularity of supervised information. The proposed for a single input is to utilize only a part of layers in the deep model for the purpose of computation sparsity and flexibility. The organisms like humans tend to use their energy ``wisely'' for the recognition and categorization task given visual stimuli _cite_ . Some recent studies _cite_ in neuroscience also showed that the synaptic cross-layer connectivity is common in the human neural system, especially in the same abstraction level. In contrast, classical deep convolutional neural networks (e.g. AlexNet _cite_, VGG _cite_) do not have this mechanism and have to run the entire network at inference time. On the other hand, the recent study _cite_ found that most of data samples are easy to be correctly classified without the utilization of very deep networks. In particular, we propose an affiliated gating network that learns to predict whether skipping several convolutional layers in the testing stage. Our networks are evaluated on three datasets in the coarse-to-fine object recognition tasks. The results show the effectiveness of the proposed network. \noindent Contributions. \quad In this paper, inspired by the left-right asymmetry of the brain, we propose a dual skipping network. The novelties come from several points: (N) The left and right branch network structures towards solving coarse-to-fine classification are proposed. Our network is inspired by the recent theory in neuroscience _cite_ . (N) A novel is introduced to skip some layers at the testing stage. (N) We employ the top-down feedback facilitation to guide the fine-grained classification via high-level global semantic information. (N) Additionally, we create a novel dataset named small-big MNIST (sb-MNIST) dataset with the hope of facilitating the research on this topic.