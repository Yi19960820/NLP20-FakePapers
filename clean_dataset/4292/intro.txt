Present day speech recognition has benefited from deep learning techniques, which call for very large training corpus for training the acoustic models. A majority of languages for which speech recognition technologies are developed and deployed enjoy easily available large speech and language resources and thereby permit training of deep learning based acoustic models. While this is so, there are an equal number of diverse languages which qualify to be called low-resource languages according to several criteria. Such criteria include limited availability of digital spoken language corpus, lack of script level representations (needed for acoustic model training via labeling), limited means of labeling the speech corpus (orthographic transcrption), limited access to linguistic knowledge, expertise or resources by which to acquire lexical representations, annotations etc. Within this spectrum of low-resource criteria, we specifically address the scenario where there is availability of adequate speech corpus, but having the data annotated (orthographic labeling) is expensive or not possible. Interestingly, such a low-resource setting has a parallel to high-resource settings such as voice-search applications (for high-resource languages), where it is required to have continuous re-training of deep-learning based acoustic models from user-data available in a continuing basis, but which are expensive to be labeled, due to the high throughput of the incoming data, which makes it difficult for a manual process to label such large volume data in a continuous manner. Such applications, requiring the incoming data to be labeled, call for techniques similar to that needed for low-resource settings where possible large speech corpus has to be labeled even for the first level acoustic model training. Here, we address the scenario of optimally utilizing a large speech corpus without the associated orthographic labeling, by means of semi-supervised learning and active learning protocols, by which the corpus can be labeled and used for acoustic model training. The broad frameworks of semi-supervised learning and active learning has a long history in both machine learning in general _cite_, _cite_, _cite_, _cite_, _cite_ and particularly in speech recognition _cite_, _cite_, _cite_, _cite_, _cite_, _cite_ . With respect to speech recognition, the early variants of semi-supervised learning were in the form of lightly-supervised acoustic model training _cite_, and more recently has attracted renewed attention with the requirements arising from voice-search type of applications such as referred above _cite_ and low resource setting (as is the focus here) _cite_ . Active learning has its origins in machine learning theory _cite_, further adapted to speech recognition in specific forms such as uncertainty sampling using confidence levels, entropy and sub-modular function based data selection _cite_ . Semi-supervised methods focus on how the unlabeled corpus can be decoded, with associated decoding errors (given the need to start with a poorly trained model with which to decode the larger corpus) and arrive at means of utilizing such erroneous decoding effectively for model improvement. Active learning methods focus on being able to select data from the decoded large corpus, in such a way that the selected data is most informative in the sense that this data has information complementary to the current acoustic model, and which therefore, when used for model retraining, offers the best model refinement comparable to the entire data. In this paper, in the case of semi-supervised learning, we start with a seed model trained on a very low seed training data and use it to decode the large unlabeled data and propose an iterative bootstrapping protocol for using such decoded labels to efficiently retrain the acoustic models, thus completely circumventing the need for manually labeling the large unlabeled corpus. In the case of active learning, we likewise use the seed model to decode the unlabeled corpus, but perform a `data selection' by confidence level criteria, wherein the selected data can be manually labeled, and used for acoustic model training; here the focus is on showing that such a data selection can yield a smaller proportion of the entire data to be manually labeled, but offer the same performance as the entire data would, thereby resulting in a large saving in the manual effort and cost needed to reach a specific performance on a held out test corpus.