Lossy compression (\eg~JPEG, WebP and HEVC-MSP) is one class of data encoding methods that uses inexact approximations for representing the encoded content. In this age of information explosion, lossy compression is indispensable and inevitable for companies (\eg~ Twitter and~ Facebook) to save bandwidth and storage space. However, compression in its nature will introduce undesired complex artifacts, which will severely reduce the user experience (\eg~Figure~ _ref_) . All these artifacts not only decrease perceptual visual quality, but also adversely affect various low-level image processing routines that take compressed images as input, \eg~contrast enhancement~ _cite_, super-resolution~ _cite_, and edge detection~ _cite_ . However, under such a huge demand, effective compression artifacts reduction remains an open problem. We take JPEG compression as an example to explain compression artifacts. JPEG compression scheme divides an image into N _inline_eq_ N pixel blocks and applies block discrete cosine transformation (DCT) on each block individually. Quantization is then applied on the DCT coefficients to save storage space. This step will cause a complex combination of different artifacts, as depicted in Figure~ _ref_ . Blocking artifacts arise when each block is encoded without considering the correlation with the adjacent blocks, resulting in discontinuities at the N _inline_eq_ N borders. Ringing effects along the edges occur due to the coarse quantization of the high-frequency components (also known as Gibbs phenomenon~ _cite_) . Blurring happens due to the loss of high-frequency components. To cope with the various compression artifacts, different approaches have been proposed, some of which can only deal with certain types of artifacts. For instance, deblocking oriented approaches~ _cite_ perform filtering along the block boundaries to reduce only blocking artifacts. Liew~ \etal~ _cite_ and Foi~ \etal~ _cite_ use thresholding by wavelet transform and Shape-Adaptive DCT transform, respectively. These approaches are good at removing blocking and ringing artifacts, but tend to produce blurred output. Jung~ \etal~ _cite_ propose restoration method based on sparse representation. They produce sharpened images but accompanied with noisy edges and unnatural smooth regions. To date, deep learning has shown impressive results on both high-level and low-level vision problems . In particular, the SRCNN proposed by Dong~ \etal~ _cite_ shows the great potential of an end-to-end DCN in image super-resolution. The study also points out that conventional sparse-coding-based image restoration model can be equally seen as a deep model. However, we find that the three-layer network is not well suited in restoring the compressed images, especially in dealing with blocking artifacts and handling smooth regions. As various artifacts are coupled together, features extracted by the first layer is noisy, causing undesirable noisy patterns in reconstruction. To eliminate the undesired artifacts, we improve the SRCNN by embedding one or more ``feature enhancement'' layers after the first layer to clean the noisy features. Experiments show that the improved model, namely ``Artifacts Reduction Convolutional Neural Networks (AR-CNN) '', is exceptionally effective in suppressing blocking artifacts while retaining edge patterns and sharp details (see Figure~ _ref_) . However, we are met with training difficulties in training a deeper DCN. ``Deeper is better'' is widely observed in high-level vision problems, but not in low-level vision tasks. Specifically, ``deeper is not better'' has been pointed out in super-resolution~ _cite_, where training a five-layer network becomes a bottleneck. The difficulty of training is partially due to the sub-optimal initialization settings. The aforementioned difficulty motivates us to investigate a better way to train a deeper model for low-level vision problems. We find that this can be effectively solved by transferring the features learned in a shallow network to a deeper one and fine-tuning simultaneously . This strategy has also been proven successful in learning a deeper CNN for image classification~ _cite_ . Following a similar general intuitive idea, easy to hard, we discover other interesting transfer settings in this low-level vision task: (N) We transfer the features learned in a high-quality compression model (easier) to a low-quality one (harder), and find that it converges faster than random initialization. (N) In the real use case, companies tend to apply different compression strategies (including re-scaling) according to their purposes (\eg~Figure~ _ref_) . We transfer the features learned in a standard compression model (easier) to a real use case (harder), and find that it performs better than learning from scratch. The contributions of this study are three-fold: (N) We formulate a new deep convolutional network for efficient reduction of various compression artifacts. Extensive experiments, including that on real use cases, demonstrate the effectiveness of our method over state-of-the-art methods~ _cite_ both perceptually and quantitatively. (N) We verify that reusing the features in shallow networks is helpful in learning a deeper model for compression artifact reduction. Under the same intuitive idea--easy to hard, we reveal a number of interesting and practical transfer settings. Our study is the first attempt to show the effectiveness of feature transfer in a low-level vision problem. (N) We show the effectiveness of AR-CNN in facilitating other low-level vision routines (\ie~super-resolution and contrast enhancement), when they take JPEG images as input.