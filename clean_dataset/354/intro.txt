Since N, deep learning has revolutionized many computer vision fields such as image classification, object detection, and face recognition. In the last couple of years, it has also made some impacts to the well-studied topic of image compression, and in some cases has achieved better performance than JPEGN and the H.N/HEVC-based BPG image codec _cite_, making it a very promising tool for the next-generation image compression. One advantage of deep learning is that it can extract much more accurate semantic segmentation map from a given image than traditional methods _cite_ . Recently, it was further shown that deep learning can even synthesize a high-quality and high-resolution image using only a semantic segmentation map as input _cite_, thanks to the generative adversarial networks (GAN) _cite_ . This suggests the possibility of developing efficient image compression using deep learning-based semantic segmentation and the associated image synthesis. GAN architecture is composed of two networks named discriminator and generator, which are trained at the same time _cite_ . The generator model _inline_eq_ captures the data distribution by mapping the latent _inline_eq_ to data space, while the discriminator model _inline_eq_ estimates the probability that _inline_eq_ is a real training sample or a fake sample synthesized by _inline_eq_ . These two models compete in a two-player minimax game in which the objective function is to find a binary classifier _inline_eq_ that discriminates the real data from the fake (generated) ones and simultaneously encourages _inline_eq_ to fit the true data distribution. This goal is achieved by minimizing/maximizing the binary cross entropy: where _inline_eq_ tries to minimize this objective against _inline_eq_ that tries to maximize it. In this paper, we employ GAN to propose a deep semantic segmentation-based layered image compression (DSSLIC) framework as shown in Figure _ref_ . In our approach, the semantic segmentation map of the input image is extracted by a deep learning network and losslessly encoded as the base layer of the bit-stream. Next, the input image and the segmentation map are used by another deep network to obtain a low-dimensional compact representation of the input, which is encoded into the bit-stream as the first enhancement layer. After that, the compact image and the segmentation map are used to obtain a coarse reconstruction of the image. The residual between the input and the coarse reconstruction is encoded as the second enhancement layer in the bit-stream. To improve the quality, the synthesized image from the segmentation map is designed to be a residual itself, which aims to compensate the difference between the upsampled version of the compact image and the input image. Therefore the proposed scheme includes three layers of information. Experimental results in the RGB (N: N: N) domain show that the proposed framework outperforms the H.N/HEVC-based BPG codec _cite_ in both PSNR and multi-scale structural similarity index (MS-SSIM) _cite_ metrics across a large range of bit rates, and is much better than JPEG, JPEGN, and WebP _cite_ . For example, our method can be N dB better in PSNR than BPG for some Kodak testing images. Moreover, since semantic segmentation map is included in the bit-stream, the proposed scheme can facilitate many other tasks such as image search and object-based adaptive image compression. The idea of semantic segmentation-based compression was already studied in MPEG-N object-based video coding in the N's _cite_ . However, due to the lack of high-quality and fast segmentation methods, object-based image/video coding has not been widely adopted. Thanks to the rapid development of deep learning algorithms and hardware, it is now the time to revisit this approach. This paper is organized as follows. In Section _ref_, the works related to learning-based image compression are briefly reviewed. The architecture of the proposed framework and the corresponding formulation and objective functions are described in Section _ref_ . In Section _ref_, the performance of the proposed method is evaluated and compared with the JPEG, JPEGN, WebP, and BPG codecs.