Different from RGB videos, depth data in RGB-D videos provide key complementary information for tristimulus visual data which potentially could achieve accuracy improvement for action recognition. However, most of the existing action recognition models solely using RGB videos limit the performance capacity. Additionally, the state-of-the-art action recognition models, namely ND convolutional neural networks (ND-CNNs) contain tremendous parameters suffering from computational inefficiency. In this paper, we propose a series of ND light-weight architectures for action recognition based on RGB-D data. Compared with conventional ND-CNN models, the proposed light-weight ND-CNNs have considerably less parameters involving lower computation cost, while it results in favorable recognition performance. Experimental results on two public benchmark datasets show that our models can approximate or outperform the state-of-the-art approaches. Specifically, on the RGB + D-NTU (NTU) dataset, we achieve N \% and N \% for cross-subject and cross-view measurement, and on the Northwestern-UCLA Multiview Action ND (N-UCLA) dataset, we achieve N \% accuracy of cross-view.