With the prevalence of deep architectures, significant progress has been made recently in object detection. However, most state-of-the-art object detectors~ _cite_ require instance-level bounding boxes and their associated class labels for training. Such full supervision is expensive to obtain, preventing these methods from large-scale practical applications. In order to release the burden of annotation, researchers opted to learn object detectors under weak supervision, in which only image-level labels are used. Image-level annotations are readily available in large amounts because they can be obtained by inexpensive human annotation or collected from the web. Thus, the weakly supervised setting is attractive, especially for the data-hungry models of today. Although weakly supervised object detection (WSOD) sidesteps the labor-intensive annotating process, the lack of location supervision makes it an extremely challenging problem. In recent years, increased efforts have been made in WSOD. Early attempts are often based on the multiple instance learning (MIL) framework~ _cite_, and recently more on deep convolutional neural networks (CNN) ~ _cite_ . Most of these methods learn object localizers, together with classifiers, in either an alternative or a parallel way. Object size~ _cite_, context~ _cite_, class activation maps~ _cite_ and other cues~ _cite_ are exploited to infer locations better. In this paper, we propose a novel method that integrates saliency information into an end-to-end architecture to perform WSOD. Our work is motivated by two research findings. (N) The end-to-end training is one of the key ingredients making CNNs remarkably successful in fully supervised vision tasks. Therefore, it is reasonable to expect good performance when applying to WSOD. (N) The knowledge learned in CNNs has been gradually explored. For instance, ~ _cite_ have developed a way to infer class-specific saliency maps from the CNNs pre-trained on the large-scale image-level classification tasks~ _cite_ . We believe such information can be effectively used in the WSOD task. In order to utilize saliency information derived from the pre-trained CNNs for WSOD, we make contributions in the following aspects: