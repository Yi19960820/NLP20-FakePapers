Emotion recognition is an important area of research to enable effective human-computer interaction. Human emotions can be detected using speech signal, facial expressions, body language, and electroencephalography (EEG), etc. In this paper, we focus on facial expression recognition (FER), which is a widely being studied problem _cite_ . FER has become a very interesting field of study and its applications are not limited to human mental state identification and operator fatigue detection, but also to other scenarios where computers (robots) play a social role such as an instructor, a helper, or even a companion. In such applications, it is essential that computers are able to recognize human emotions and behave according to their affective states. In healthcare, recognizing patients' emotional instability can help in early diagnosis of psychological disorders _cite_ . Another application of FER is to monitor human stress level in daily human-computer interaction. Humans can easily recognize another human's emotions using facial expressions but the same task is very challenging for machines. Generally, FER consists of three major steps as shown in the Figure _ref_ . The first step involves the detection of a human face from the whole image by using image processing techniques. In the second step, key features are extracted from the detected face. Finally, machine learning models are used to classify images based on the extracted features. Features descriptors like histograms of oriented gradients (HOG) _cite_, Local Gabor features _cite_ and Weber Local Descriptor (WLD) _cite_ are widely used techniques for FER, whereas HOG has shown to be particularly effective in literature for the task of FER _cite_ . The dimensionality of these features is usually high. Due to the complexity of multi-view features, dimension reduction and more meaningful representation of this high dimensional data is a challenging task. Therefore, techniques like Principal Component Analysis (PCA) and Local Binary Pattern (LBP), _cite_, Non-Negative Matrix Factorization (NMF), etc., are being used to overcome high dimensionality problem by representing the most relevant features in lower-dimensions. Machine learning techniques have revolutionized many fields of science including computer vision, pattern recognition, and speech processing through its powerful ability to learn nonlinear relationships over hidden layers, which makes it suitable for automatic features learning and modeling of nonlinear transformations. Deep neural networks (DNNs) can be used for feature extraction as well as for dimensionality reduction _cite_ . A large number of classification techniques has been used for FER. For example, Choi et al. _cite_ used artificial neural networks (ANNs) for classification of facial expressions. Authors in _cite_ have used Support Vector Machines (SVMs) for FER. In _cite_, authors utilized Hidden Markov Model (HMM) for FER. HMMs are mostly used for frame-level features to handle sequential data. Besides these classifiers, Dynamic Bayesian Networks _cite_ and Gaussian Mixture Model _cite_ are also utilized for learning facial expressions. The recent success of deep learning also motivates its use for FER _cite_ . In this paper, we use a novel approach based on stacked autoencoders for FER. We exploited autoencoders network for effective representation of high dimensional facial features in lower dimensions. Autoencoders represent an ANN configuration in which output units are linked to the input units through the hidden layers. A fewer number of hidden units allow them to represent input data into a low dimensional latent representation. While in stacked autoencoder, output of first layer is immediately given to second layer as an input. In other words, stacked autoencoders are built by stacking additional unsupervised feature learning hidden layers, and can be trained by using greedy methods for each additional layer. As a result, when the data is passed through the multiple hidden layers of stacked autoencoders, it encodes the input vector in a smaller representation more efficiently _cite_ . In our case, autoencoders network is more suitable as it not only reduces the dimension of data but can also detect most relevant features. In previous work, Hinton et al. _cite_ have shown that autoencoders networks can be used for effective dimension reduction and they can produce more effective representation than PCA. For our experiments, we choose Extended Cohn-Kanade (CK +) _cite_ dataset which is extensively used for automatic facial image analysis and emotion classification. The HOG features are computed from the selected area of facial expressions and their dimensions have been reduced by using stacked autoencoders on multiple levels and with multiple hidden layers to get the most optimal encoded features. SVM model in the one-vs-all scenario is used for classification on this reduced form of features. We have performed multiple experiments on the selection of optimal dimension (N-N features) of the feature vector. The feature vector with length N, obtained after the introduction of four hidden layers in autoencoders network outperformed as compared to other dimensions. Most importantly, we also use PCA for dimension reduction in order to compare the baseline results with autoencoders. Our proposed method for FER using stacked autoencoders is also outperformed when results were compared with PCA and other recent approaches published in this domain. This demonstrates the effectiveness of stacked autoencoders for the selection of the most relevant features for FER task. The rest of the paper is organized as follows. In Section _ref_, we present background and related work. In Section _ref_, the detail on each step of our proposed method is described. In Section _ref_, we explain the experimental procedure and obtained results. Finally, we conclude in Section _ref_ .