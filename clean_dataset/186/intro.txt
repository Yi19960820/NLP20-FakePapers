a convolutional neural network (CNN) _cite_, inspired by a mammalian visual cortex, showed a remarkably better object image recognition performance than conventional vision recognition schemes which employ elaborately hand-coded visual features. A CNN trained with N million visual images from ImageNet _cite_ was able to classify hundreds of object images with an error rate of N \% _cite_, and demonstrated near-human performance _cite_ . However, CNNs lack the capacity for temporal information processing. As a consequence, CNNs are less effective in handling video image patterns than static images. To address this shortcoming, a number of action recognition models have been developed. Typical deep learning models for action recognition are ND convolutional neural networks (ND-CNNs) _cite_, long-term recurrent convolutional networks (LRCNs) _cite_, and two-stream convolutional networks _cite_ . The ND-CNN extracts spatio-temporal features of videos through convolutions in the temporal and spatial domains in a fixed window _cite_ . The LRCN is a two-stage model that first extracts spatial features in its CNN stage and then extracts temporal features from its long-short term memory (LSTM) _cite_ stage _cite_ . And the two-stream convolutional network has one CNN stream for an RGB input, and the other CNN stream for an input of stacked optical flows. The two streams are joined at the end to make a categorical output _cite_ . Although the ND-CNN, LRCN, and two-stream convolutional network perform well, some of their dynamics are not consistent with neuroscientific evidences. One important piece of evidence in mammals is that the size of the spatio-temporal receptive field of each cell is increased as the level goes higher _cite_, _cite_ . And a principle from cybernetics era, so-called the downward causation _cite_, _cite_ suggests that a spatio-temporal hierarchy can be naturally developed in human brains by taking advantage of macroscopic constraints genetically assigned to them. The evidence and principle suggest that a deep learning model for action recognition should form a hierarchy by assignment of spatio-temporal constraints. And the model should extract spatial and temporal features simultaneously in their hierarchy. But the representative action recognition models lack such properties. The current study is an extension of the prior study using so-called the multiple spatio-temporal scales neural network (MSTNN) _cite_ . The neural activity in the MSTNN is governed by both spatial and temporal constraints by means of local connectivity of convolutional layers and time constants assigned to the leaky integrator neural units at each layer _cite_ respectively. These constraints make the MSTNN to develop faster and more local interaction in the lower layer whereas it develops slower and more global interactions in the higher level. This enables the MSTNN to extract spatio-temporal features in multiple levels from the exemplar data patterns. This formation of a spatio-temporal hierarchy is consistent with the biological evidence and the principle mentioned earlier. However, it is true that the temporal processing capacity of the MSTNN is quite limited by the fact that its essential dynamics is a decay dynamics exerted by leaky integrator neurons _cite_ that compose the model. At the same time, the MSTNN uses only forward connectivity without any recurrent connectivity which is considered to be the source of generating arbitrary complex dynamics, as known in the study of biological brains _cite_ . In this context, the current study attempts to add recursive dynamics to the MSTNN by introducing recurrent connectivity in the convolutional layers. This leads to our novel proposal of multiple spatio-temporal scales recurrent neural network (MSTRNN) model in the current study. In the experiments, MSTRNNs were compared with MSTNNs and LRCNs. MSTRNNs were compared to the MSTNNs to observe how the existence of recurrent structures of MSTRNNs have effect on their action recognition performances. Among the introduced representative action recognition models, the LRCN was also used as a baseline of the MSTRNN since both have CNN and recurrent neural network structures. Also, it was chosen as a baseline model of the MSTRNN to see the effect of setting spatio-temporal constraints and extracting spatial and temporal features simultaneously. The MTSRNN model was evaluated by using three different human action datasets that are distinct in types and levels of compositionality introduced to the action patterns. In the first experiment, the MSTRNN is compared with the MSTNN on a dataset that was prepared by concatenating three action patterns that appear in Weizmann dataset _cite_ . The experiment shows how the recurrent structure implemented on the MSTRNN is effective in action recognition task. Also a qualitative analysis on the neural activations generated from both models are made to show how their categorical memories are formed. The second and the third experiments were aimed to conduct comparative experiments using datasets of more natural human action patterns by controlling the level of the underlying compositionality. Because there were no public video datasets containing natural human actions with control of their compositionality level, two human action datasets were prepared for the current study. For the second experiment, a video dataset was built by considering compositions of objects and actions directed to those objects. In the experiment, the performance of the MSTRNN, MSTNN, and LRCN were compared. And analysis was made on the internal dynamics of the MSTRNN and LRCN by observing their time series activation patterns. The analysis was made to see how the multiple timescale constraint assigned to the MSTRNN can strengthen the model performance over the LRCN that does not involve with such temporal constraints. For the third experiment, triad compositions among a set of objects, object-directed actions, and modifiers for those actions are considered to prepare the dataset. The MSTRNN, MSTNN, and LRCN were again compared in the experiment. The experiment was designed to require the models to extract temporal features with longer temporal correlation for recognition of action modifiers than the one for objects and actions. By examining the recognition accuracies among these models, the advantage of the proposed model is clarified.