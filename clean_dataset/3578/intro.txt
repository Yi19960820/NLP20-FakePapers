Face aging, also known as age progression~ _cite_, aims at rendering a given face image with aging effects while still preserving personalized features. Applications of face aging techniques range from social security to digital entertainment, such as predicting contemporary appearance of missing children and cross-age identity verification. Due to the practical value of face aging, many approaches have been proposed to address this problem in the last two decades~ _cite_ . With the rapid development of deep learning, deep generative models are widely adopted to synthesize aged face images~ _cite_ . However, the most critical problem of these methods is that multiple face images of the same person at different ages are required at training stage, which is extremely expensive to collect in practice and thus their applications are largely limited. To deal with this problem, many recent studies resort to unpaired face aging data to train the model~ _cite_ . However, these approaches mainly focus on face aging itself while neglecting other critical conditional information of the input (\eg, facial attributes), thus fail to regulate the training process. Consequently, training face image pairs with mismatched attributes would mislead the model into learning translations other than aging, causing serious ghosting artifacts and even incorrect facial attributes in generation results. Fig.~ _ref_ shows some face aging results with mismatched attributes. In the rightmost face aging result under `gender', beard is mistakenly attached to the input female face image. This is because the model learns that growing a beard is a typical sign of aging but has no way to know that this does not happen to a woman, as face image pairs of young woman and old man could be treated as positive training samples if no conditional information is considered. To suppress such undesired changes of semantic information during the aging process, many recent face aging studies attempt to supervise the output by enforcing identity consistency~ _cite_ . However, as shown in Fig.~ _ref_, personalized features are well preserved in the output for all sample results, nevertheless, obvious unnatural changes of facial attributes are still observed. In other words, well maintained identity-related features do NOT imply reasonable aging results when training with unpaired data. Therefore, merely enforcing identity consistency is insufficient to eliminate matching ambiguities in unpaired training data, thus fails to achieve satisfactory face aging performance. To solve the above-mentioned issues, in this paper, we propose a framework based on generative adversarial networks (GANs) . Different from existing methods in the literature, we involve semantic conditional information of the input by embedding facial attribute vectors in both the generator and discriminator, so that the model could be guided to output elderly face images with attributes faithful to each corresponding input. Furthermore, to enhance aging details, based on the observation that signs of aging are mainly represented by wrinkles, laugh lines, and eye bags, which could be treated as local textures, we employ wavelet packet transform to extract features at multiple scales in the frequency space efficiently. To summarized, the main contributions are as follows: