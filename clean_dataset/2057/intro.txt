Skin cancer is a severe public health problem in the United States, with over N, N, N newly diagnosed cases every year. Melanoma, as the severest form of skin cancer, is responsible for _inline_eq_ of deaths associated with skin cancer _cite_ . In N, the global incidence of melanoma was estimated to be over N, N cases, with almost N, N deaths. Fortunately, if detected early, melanoma survival exceeds _inline_eq_ _cite_ . Dermoscopy is one of the most widely used skin imaging techniques to distinguish the lesion spots on skin _cite_ . It has been developed to improve the diagnostic performance of melanoma. The manual inspection from dermoscopy images made by dermatologists is usually time-consuming, error-prone and subjective (even well-trained dermatologists may produce widely varying diagnostic results) _cite_ . Nevertheless, the automatic recognition of melanoma using dermoscopy images is still a challenging task due to the following reasons: the low contrast between skin lesions and normal skin regions makes it difficult to accurately segment lesion areas; the melanoma and non-melanoma lesions may have a high degree of visual similarity; the variation of skin conditions such as skin color, natural hairs or veins, among patients produce the different appearance of melanoma, in terms of color and texture, etc. Some investigations attempted to apply low-level hand-crafted features to distinguish melanomas from non-melanoma skin lesions _cite_ . Recent works employing Convolutional Neural Networks (CNNs) have shown its improved discrimination performance in melanoma classification aiming at taking advantage of their discrimination capability to achieve performance gains _cite_ . Although these studies focused on improving computer assisted diagnostic accuracy, the diagnosis itself is hard even for experienced clinical practitioners based on dermoscopy images. The computer intervention not only assist decision making, but also can benefit clinical research to identify the biomarkers which contribute to diagnosing. Despite promising results, the clinicians typically want to know if the model is trustable and how to interpret the results. Biomarker interpretation from deep learning models for clinical use has been explored in identifying brain disease _cite_ . However, to the best of our knowledge, what kind of evidence deep learning models use for classifying skin lesions has not been explored. Experienced dermatologists diagnose skin diseases based on comprehensive medical criteria which have been verified to be useful, e.g., the ABCD rule _cite_ and the N-point checklist _cite_, etc. There is still much room to improve the understanding of melanoma recognition by reliable CNNs classifier. In this paper, we proposed a novel method based on deep convolutional neural networks and low-level image feature descriptors, which imitate clinical criteria representations, to solve skin lesion analysis towards melanoma detection problem. We aim to inspect whether the deep learning models and the dermatologists use similar criteria. There are three main approaches for interpreting the important features detected by DNNs. One approach is using gradient ascent methods to generate an image that best represents the class _cite_ . However, this method cannot handle nonlinear DNNs well. The second one uses the intermediate outputs of the network to visualize the feature patterns _cite_, but ends up with blurred heatmaps. The third approach is to visualize how the network responds to a specific corrupted input image in order to explain a particular classification made by the network _cite_, which can more precisely locate the key features and do not need to retrain the network. Here, we focus on interpreting the import features used in CNNs. Generally speaking, our interpretation method belongs to the third approach. Therefore, we propose a pipeline to identify the evidence and biomarkers in the skin lesion dermoscopic images, which contributes to the deep learning classifier. To be specific, we first trained an accurate deep learning model to classify each dermoscopic image, with a predicted probability score to each class. Secondly, we analyzed the feature importance by corrupting with conditional sampling, then compare the prediction difference.