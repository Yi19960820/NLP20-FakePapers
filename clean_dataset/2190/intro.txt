In recent years, there has been an increase in the availability of large shape collections. These large and diverse datasets are an invaluable resource for many shape analysis techniques. These dataset are especially necessary for techniques that are driven by a deep learning model as they require large quantities of good and diverse training data _cite_ . With the efforts from the community, there are many datasets _cite_ made available, some even with hundreds of thousands of shapes _cite_ . Recent work has found that analysis tools become more effective when they have access to high quality semantic segmentations _cite_ . While segmented datasets exist, they either consist of a few hundred shapes _cite_ or have poor segmentation boundaries _cite_ (we show more details on this later) . Using these for any shape analysis technique will lead to unreliable results as models are trained on inconsistent data _cite_ . Segmented datasets have already been shown incredibly useful for many applications, including shape matching _cite_, retrieval _cite_ and modeling _cite_ . Shape segmentation techniques often benefit the most from such fully labeled datasets. Supervised techniques require ground truth labels to train segmentation classifiers _cite_, and both supervised and unsupervised techniques need ground truth labels to evaluate their methods _cite_ . While existing works have shown good efforts and results _cite_, clear ground truth inconsistencies still exist _cite_ . This means both existing and new techniques could perform better with higher quality ground truth segmentations. Generating high quality segmentations for shape datasets is a time consuming and interaction heavy task. Smaller datasets, with only small number of inconsistencies or errors may be manageable through manual effort _cite_ . Massive datasets would take a great amount of user effort however _cite_ . Further, these massive datasets typically consist of non-manifold (multiple components, holes, zero thickness, etc.) and low-resolution shapes. These shapes are very difficult to process in segmentation pipelines. Recent work try to project them to point clouds _cite_, or further to KD-connected point clouds _cite_ . While these are viable techniques, and have been shown to work, there may be information loss when using point clouds e.g., connectivity and topology of the shape. Without these, certain reliable features are much harder to compute or are inaccurate when computed (e.g. _cite_, Geodesic Distance) . Although connectivity can be re-established (e.g. through K Nearest Neighbor, assuming the resolution of the point cloud is high enough), thin regions of the shape could be wrongly connected, leading to undesirable connections. For this reason, in our proposed pipeline, we largely focus on input meshes. We further show that by re-meshing these non-manifold ND models into manifold meshes, our technique can handle very large dataset very well. Previous work that generate ground truth segmentations for large dataset typically focus on active learning approach, where a user has some control over the system and influences the decisions in some way. _cite_ first used an unsupervised co-segmentation algorithm, where the user interactively selects pairs of parts between shapes to connect or disconnect. Recently, _cite_ used a supervised algorithm to label a single part at a time. Users are asked to paint two ND views of a ND shape. A learning model is trained based on the painted regions and similar shapes (according to global shape descriptors) are evaluated on that model. However, these techniques can only provide a coarse segmentation and output segmentations may have errors. Further _cite_ requires one part to be labeled at a time, so datasets with high numbers of parts will take longer and more iterations to label. Here, we developed an active framework which allows full shape segmentation of a shape dataset, to ensure good segmentation quality and it scales well to the number of parts in the dataset. One of the challenges when developing an active framework for segmentation is minimizing user interactions, while maximizing segmentation quality. To help maximize quality, we utilize a deep learning model for segmentation predictions. In general, deep learning models can take a long time to train, and typically require a large amount of training data. To resolve these, we propose to use a small, using two ND histogram features as input. The features have been shown useful in previous work _cite_ and fit the paradigm as ND histograms are like images. Our architecture allows for quick model training and we also adopt an ensemble based learning scheme _cite_ to help generalize with reduced available training data. In our experiments we compare to other feature based techniques. We show that our model can perform better than fast existing techniques and comparably with the state-of-the-art. Another challenge of an active learning framework is the exploration and analysis of model predicted results. It often takes a long time for users to choose the next ND model to segment, and there are no ground truth data to compare the predictions for ranking. To approach this challenge, we propose to use entropy, a measure of uncertainty, to define a ranking measure without needing ground truth segmentations. The ranking measure provides meaningful ordering of the predicted segment labels in an interactive tabular view. This allows users to see which shapes the deep learning model segmented well or struggled with. Our experiments show that by selecting poorly segmented ND models, with respect to the ranking measure, it reduces both time and interactions required to segment the whole dataset. Finally, another problem we observed in existing active framework (e.g. _cite_) is that they do not allow quick boundary refinement. When there are slight errors on the output segmentation, users will likely discard the results, leading to extra manual effort and longer interaction time. With this observation, we propose a segmentation refinement algorithm that takes the current segmentation and information about the shape (e.g. angle and thickness) to refine the segmentation boundaries. This process can be used iteratively. This algorithm can quickly provide high quality segmentations while greatly reducing interaction and time required to refine a shape. Our proposed framework has been demonstrated to work well on public dataset (including PSB, COSEG), and also on re-meshed dataset from ShapeNet, which contains hundreds of thousands of shapes. {Contributions} To summarize, the key contribution of this work is a new active learning framework for providing a full segmentation to large sets of ND shapes. The focus is to maintain accurate and meaningful segment boundaries, while keeping human effort and time at a minimum. There are also several novelties: In the following, Section~ _ref_ discusses the existing work for segmentation, feature extraction and entropy in geometry processing. In Section~ _ref_, we briefly overview our active learning framework. Section~ _ref_ discuss the details of the three novel subsystem. We further discuss our framework interface and flow in Section~ _ref_ before outlining our experiments and showing their results in Section~ _ref_ . Finally, in Section~ _ref_ we conclude and discuss possible future work.