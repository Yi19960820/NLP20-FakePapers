Human use the attention mechanism to recognize the world, pay different attention on different region of a image. The mixed nature of attention has been studied in the previous literature~ _cite_ . Attention-based network is widely used in sequence model to process text or audio~ _cite_ . When we were building a trigger word detection application in speech recognition problem, the model were firstly trained based by LSTM~ _cite_ . One problem confused us most is that the elements in trigger word didn't share the same weights. For example, if the trigger word is " ", "good" and "morning" should have the exactly the same importance for the whole phrase. But LSTM will prefer to give a higher importance to the word which is closer to the end which means "morning" is more likely to be activate than "good" (Fig.~ _ref_) . We built a network based on AIN (Fig.~ _ref_) to solve this problem and made a success in the real world application. Inspired by our previous work and the attention mechanism in related literature _cite_ . In this paper we propose Attention Incorporate Network (AIN), rather than sequential data processing, AIN have a huge advantage in image classification problem. Recent advances of image classification focus on a "very deep" network structure, from AlexNet~ _cite_ to DenseNet~ _cite_ the precision become higher and higher, but some problems are still remain to be solved, our model exhibits following appealing properties to solve these problem: (N) Neural Network come from human neurons, human can recognize the object easily no matter what the image shape is. But all kinds of popular network like AlexNet~ _cite_, VGG~ _cite_, Inception~ _cite_ and ResNet~ _cite_ couldn't process the image in different size. An engineering solution is to scale the image into a same shape, which isn't an aesthetic way due to human neurons won't scale the object image while recognizing it. The back logic in human neuron should be attention mechanism. Our network structure AIN training feed-forward is just like human neurons recognize the object: combine the attention matrix and image together and give a label after incorporate all the key information (Fig.~ _ref_) . The input image can be arbitrary size due to the AIN feed-forward operation which gives a more natural solution than traditional image scaling (Fig.~ _ref_) . (N) In modern convolutional network structure, image size will decrease while convolution layer get deeper. The image information will be transferred into the image channels. Pooling and Convolution with stride are the well known layers to reduces the image size. AlexNet~ _cite_ used maxpooling, Resnet~ _cite_ used ConvN _inline_eq_ N with stride of N. Information will remain only ~ (s = stride or pooling size) during feed-forward the transition layer. In AIN we used (AIL) to extract the key features of the image without information loss. Experimentally, AIN achieved a lower error comparing to pooling or covolution with stride in the same network structure.