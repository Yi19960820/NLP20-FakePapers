Convolutional Neural Networks (CNN) have been very successful for many different tasks in computer vision. However, training these deep architectures requires large scale datasets which are not always available or easily collectable. This is particularly the case for ND human pose estimation, for which an accurate annotation of ND articulated poses in large collections of real images is non-trivial: This has limited the development of end-to-end CNN architectures for real-world ND pose understanding. Learning architectures usually augment existing training data by applying synthetic perturbations to the original images, e.g., jittering exemplars or applying more complex affine or perspective transformations _cite_ . Such data augmentation has proven to be a crucial stage, especially for training deep architectures. Recent work~ _cite_ has introduced the use of data synthesis as a solution to train CNNs when only limited data is available. Synthesis can potentially provide infinite training data by rendering ND CAD models from any camera viewpoint~ _cite_ . Fisher et al.~ _cite_ generate a synthetic ``Flying Chairs'' dataset to learn optical flow with a CNN and show that networks trained on this unrealistic data still generalize very well to existing datasets. In the context of scene text recognition, Jaderberg et al.~ _cite_ trained solely on data produced by a synthetic text generation engine. In this case, the synthetic data is highly realistic and sufficient to replace real data. Although synthesis seems like an appealing solution, there often exists a large domain shift from synthetic to real data~ _cite_ . Integrating a human ND model in a given background in a realistic way is not trivial~ _cite_ . Rendering a collection of photo-realistic images (in terms of color, texture, context, shadow) that would cover the variations in pose, body shape, clothing and scenes is a challenging task. Instead of rendering a human ND model, we propose an image-based synthesis approach that makes use of motion capture data to augment an existing dataset of real images with ND pose annotations. Our system synthesizes a very large number of new images showing more pose configurations and, importantly, it provides the corresponding ND pose annotations (see Figure~ _ref_) . For each candidate ND pose in the motion capture library, our system combines several annotated images to generate a synthetic image of a human in this particular pose. This is achieved by ``copy-pasting'' the image information corresponding to each joint in a kinematically constrained manner. Given this large ``in-the-wild'' dataset, we implement an end-to-end CNN architecture for ND pose estimation. Our approach first clusters the ND poses into _inline_eq_ pose classes. Then, a _inline_eq_-way CNN classifier is trained to return a distribution over probable pose classes given a bounding box around the human in the image. Our method outperforms most state-of-the-art results in terms of ND pose estimation in controlled environments and shows promising results on images captured ``in-the-wild''. The work presented in this paper is an extension of _cite_ . Recent approaches employ CNNs for ND pose estimation in monocular images~ _cite_ or in videos~ _cite_ . Due to the lack of large scale training data, they are usually trained (and tested) on ND motion capture data in constrained environments~ _cite_ . Pose understanding in natural images is usually limited to ND pose estimation~ _cite_ ., recent work also tackles ND pose understanding from ND poses~ _cite_ . Some approaches use as input the ND joints automatically provided by a ND pose detector~ _cite_, while others jointly solve the ND and ND pose estimation~ _cite_ . Our method uses the same two training sources, i.e., images with annotated ND pose and ND motion capture data. However, we combine both sources off-line to generate a large training set that is used to train an end-to-end CNN ND pose classifier. This is shown to improve over~ _cite_, which can be explained by the fact that training is performed in an end-to-end fashion. A number of works have considered the use of synthetic data for human pose estimation. Synthetic data have been used for upper body~ _cite_, full-body silhouettes~ _cite_, hand-object interactions~ _cite_, full-body pose from depth~ _cite_ or egocentric RGB-D scenes~ _cite_ . Zuffi and Black~ _cite_ used a ND mesh-model to sample synthetic exemplars and fit ND scans. Recently, Chen et al.~ _cite_ trained a human ND pose regressor on synthetic training images rendered from such a ND mesh-model. Similarly, _cite_ trained a human detector for unusual pedestrian using synthetic data generated by a game engine. In both cases, a domain adaptation stage was necessary to generalize to real images. In~ _cite_, a scene-specific pedestrian detector was learned without real data while~ _cite_ synthesized virtual samples with a generative model to enhance the classification performance of a discriminative model. In~ _cite_, pictures of ND characters were animated by fitting and deforming a ND mesh model. Later, _cite_ augmented labelled training images with small perturbations in a similar way. These methods require a perfect segmentation of the humans in the images. Park and Ramanan~ _cite_ synthesized hypothetical poses for tracking by applying geometric transformations to the first frame of a video sequence. We also use image-based synthesis to generate images but our rendering engine combines image regions from several images to create images with associated ND poses.