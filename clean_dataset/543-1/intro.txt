Hand pose estimation from single depth image plays an important role in applications of human-computer interface (HCI) and augmented reality (AR) . Though has been studied for several years _cite_, it is still challenging due to large view variance, high joint flexibility, poor depth quality, severe self occlusion and similar part confusion. Recently, convolutional networks (ConvNets) have witnessed great growth in several computer vision tasks such as object classification _cite_ and human pose estimation _cite_ because of great modeling capacity and end-to-end feature learning. ConvNets have also been introduced to solve the problem of hand pose estimation, often with complicated structure design such as multi-branch inputs _cite_ _cite_ and multi-model regression _cite_ _cite_ _cite_ _cite_ . However, ConvNets remain unable to obtain significant advantage over traditional random forest based methods _cite_ _cite_ . Inspired by model ensemble and multi-view voting _cite_, we present a single ConvNet architecture named (Fig. _ref_) to directly regress the ND joint coordinates in monocular depth images with end-to-end optimization and inference. We implement it by training individual fully-connected (FC) layers on multiple feature regions and combining them as ensembles. As shown in our experiments, REN significantly promotes the performance of our ConvNet, which outperforms all state-of-the-art methods on two challenging hand pose benchmarks _cite_ _cite_ .