Recently, deep neural networks (DNNs) have demonstrated state-of-the-art performance in various computer vision tasks, e.g., face recognition _cite_, pedestrian detection _cite_ and pose estimation _cite_ . In contrast to the handcrafted features such as Scale-Invariant Feature Transform (SIFT) _cite_, deep learning based approaches are able to learn representative features directly from the vast amounts of data. For general nature image classification, which is of great interest to DNN models, the AlexNet model _cite_ has achieved N \% better classification accuracy than the previous hand-crafted methods in the N ImageNet competition _cite_, which provides a large scale training dataset with N million images and one thousand categories. Subsequently, inspired by such fantastic progress, DNN models continue to be the undisputed leaders in the competition of ImageNet. In particular, both VGGNet _cite_ and GoogLeNet _cite_ announced promising performance in the ILSVRC N classification challenge, which demonstrated that deeper and wider architectures can bring great benefits in learning better representations via large scale datasets. For face recognition, DeepID _cite_ trained on N, N face images of N, N identities has achieved N \% accuracy on LFW, and DeepFace _cite_ developed by Facebook yielded N \% accuracy with N million faces of N, N identities data. Moreover, Google _cite_ used over N million face samples from N million identities to train DNN models, which achieved N \% accuracy on LFW. Generally speaking, DNN is a data driven method making it feasible to achieve outstanding performance with the explosion of big data. However, such property gives rise to the fact that the capability of deep models heavily relies on the training samples. In particular, most DNN models were trained and tested based on the assumption that the input image samples are pristine without any distortions injected. As such, they can achieve promising performance on high quality samples, but the performance will be seriously degraded when encountering with low quality images. Fig.~ _ref_ provides some examples in CIFAR-N dataset _cite_ and it is shown that DNN model fails in predicting the correct classes when the input images are distorted. A recent work _cite_ evaluated several classical deep models for image classification by injecting different types of distortion into the test images. The results show that all the evaluated neural networks are susceptible to typical distortions such as blur and noise. For example, more than N \% Top N and Top N accuracy drop can be observed when the images are distorted by Gaussian blur. In real application scenarios, distortions will be introduced in image acquisition, compression, processing, transmission and reproduction. Generally speaking, restoration of such distorted images is an ill-posed problem, and even state-of-the-art algorithms cannot efficiently remove such artifacts. Therefore, evaluating the visual quality of these distorted images becomes meaningful. In the literature, there are numerous approaches proposed to assess the degradation of visual quality _cite_ . Popular image quality assessment (IQA) algorithms such as SSIM _cite_, FSIM _cite_, GSIM _cite_, VSNR _cite_, PCQI _cite_, etc., focus on the perception of quality degradation from the perspective of viewing experience. Due to the fact that the distortions can also bring difficulties in image understanding, it becomes more and more important to further investigate the applications of these IQA algorithms in the context of computer vision, as computer vision systems aim to automatically achieve the high-level understanding tasks that the human visual system can perform. This naturally inspires us to incorporate the quality measure in the DNN learning process to deal with the visual understanding with low quality images. In particular, we first train the deep neural network by augmenting the data with the mixture of pristine and distorted data. Then an IQA-based label smoothing technique is proposed to enhance the performance of deep models by fine-tuning the network with the IQA measure. In this manner, the robustness of DNN models with distorted input data can be significantly improved. Experimental results show that the proposed scheme can significantly improve the classification performance of both high and low quality images. The main contributions of the paper are as follows: The rest of the paper is organized as follows. In Section~ _ref_, we analyze the data augmentation with distorted images for deep learning. In Section~ _ref_, the proposed scheme with IQA-based label smoothing is introduced. Section~ _ref_ provides the experimental results and analyses. Finally, Section~ _ref_ concludes this paper.