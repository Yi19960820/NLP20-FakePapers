Generative adversarial networks (GANs) _cite_ are a class of generative model which are able to synthesise novel, realistic looking images of faces, digits and street numbers _cite_ . GANs involve two networks: a generator, _inline_eq_, and a discriminator, _inline_eq_ . The generator, _inline_eq_, is trained to generate synthetic images, taking a random vector, _inline_eq_, drawn from a prior distribution, _inline_eq_, as input. The prior is often chosen to be a normal or uniform distribution. Radford et al. _cite_ demonstrated that generative adversarial networks (GANs) learn a ``rich linear structure", meaning that algebraic operations in _inline_eq_-space often lead to semantically meaningful synthetic samples in image space. Since images represented in _inline_eq_-space are often meaningful, direct access to a _inline_eq_ for a given image, _inline_eq_ may be useful for discriminative tasks such as retrieval or classification. Recently, it has also become desirable to be able to access _inline_eq_-space in order to manipulate original images _cite_ . Thus, there are many reasons we may wish to invert the generator. Typically, inversion is achieved by finding a vector _inline_eq_ which when passed through the generator produces an image that is very similar to the target image. If no suitable _inline_eq_ exists, this may be an indicator that the generator is unable to model either the whole image or certain attributes of the image. We give a concrete example in Section _ref_ . Therefore, inverting the generator, additionally, provides interesting insights to highlight what a trained GAN has learned. Mapping an image, from image space, _inline_eq_, to _inline_eq_-space is non-trivial, as it requires inversion of the generator, which is often a many layered, non-linear model _cite_ . Dumoulin et al. _cite_ (ALI) and Donahue et al. (BiGAN) _cite_ proposed learning a third, decoder network alongside the generator and discriminator to map image samples back to _inline_eq_-space. Collectively, they demonstrated results on MNIST, ImageNet, CIFAR-N and SVHN and CelebA. However, reconstructions of inversions are often poor. Specifically, reconstructions of inverted MNIST digits using methods of Donahue et al. _cite_, often fail to preserve style and character class. Recently, Li et al. _cite_ proposed method to improve reconstructions, however drawbacks to these approaches _cite_ include the need to train a third network which increases the number of parameters that have to be learned, increasing the chances of over-fitting. The need to train an extra network, along side the GAN, also means that inversion cannot be performed on pre-trained networks. A more serious concern, when employing a decoder model to perform inversion, is that its value as a diagnostic tool for evaluating GANs is hindered. GANs suffer from several pathologies including over-fitting, that we may be able to detect using inversion. If an additional encoder model is trained to perform inversion _cite_, the encoder itself may over-fit, thus not portraying the true nature of a trained GAN. Since our approach does not involve training an additional encoder model, we may use our approach for ``trouble shooting'' and evaluating different pre-trained GAN models. In this paper, we make the following contributions: We begin, by describing our proposed inversion technique.