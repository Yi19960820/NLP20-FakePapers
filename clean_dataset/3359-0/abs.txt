Deep learning has significantly advanced computer vision and natural language processing. While there have been some successes in robotics using deep learning, deep learning has not been widely adopted. In this paper, we present a novel robotic grasp detection system that predicts the best grasping pose of a parallel-plate robotic gripper for novel objects using the RGB-D image of the scene. The proposed model uses a deep convolutional neural network to extract features from the scene and then uses a shallow convolutional neural network to predict the graspability of the object of interest for a specific position and orientation. Our multi-modal model achieved an accuracy of N \% and runs at real-time speeds. This redefines the state-of-the-art for robotic grasp detection.