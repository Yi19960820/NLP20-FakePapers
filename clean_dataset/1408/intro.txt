Deep learning maybe loosely defined as an attempt to train a hierarchy of feature detectors--with each layer learning a higher representation of the preceding layer. The advent of deep learning has seen a resurgence in the use of (increasingly larger) neural networks _cite_ . Among many other areas of application of deep neural networks (DNNs), handwritten character recognition is one of the areas that has been extensively explored, particularly on the MNIST dataset _cite_ . But very few works have been published for Indian languages specially for Bangla which is sixth most popular language in the world _cite_ . Bangla language consists of N vowels, N consonants, N modifiers and N compound characters. Among them, compound characters are structurally complex and some of them resemble so closely Figure _ref_) that the only sign of differences left between them are short straight lines, circular curves etc. _cite_ Due to this and the high number of classes, compound character recognition is a particularly challenging pattern recognition problem . On the other hand, Deep learning has shown promise in recent years in multiple varied fields including handwritten character, speech and object recognition _cite_, natural language processing _cite_ etc. Owing to its successful application in above areas, it is applied on the problem of handwritten Bangla compound character recognition which is much more challenging than MNIST dataset which consists of only N classes. Deep learning methods usually benefit from a substantial amount of labeled or unlabeled data to build a powerful model to represent the data. The Bangla compound character datasets used in this work (Section _ref_), is freely downloadable for OCR research and consists of N unique classes with approximately N samples per class. The amount of data available, hence, necessitates the use of easily generalizable deep learning models or techniques to synthetically augment the data while training. Although shallow learning models, which have been previously used for Bangla compound character recognition, benefit from not having such requirements, the lower recognition accuracy produced by such models offset the benefits of not requiring a large amount of data. Shallow learning models that are still popular for various tasks take an approach to pattern recognition which prioritizes the usage of feature engineering in extracting unique, robust and discriminating features. These features are then fed to machine learning models for classification or regression purposes. Over the last few decades various powerful multipurpose feature detectors have gained popularity such as HOG _cite_, SIFT _cite_, LBP _cite_, SURF _cite_ etc. which have all been developed for a particular problem. But the major problem with such methodologies is that the usage of feature detectors need to be guided by the skill of the researchers using them. Deep learning subverts the usage of handcrafted features by learning the features which are most effective for a particular problem. Inspired by Hubel and Wiesel's early work on the cat's visual cortex _cite_, the convolutional neural network improved on the Neocognitron model _cite_ . It was subsequently used in areas of handwriting recognition and more in the Ns and Ns _cite_ and showed promise for being used in deeper feedforward architectures. However, it was restricted by the limitations of computer hardware of the time. The LeNet model represented a culmination of sorts of work on CNNs in the Ns _cite_ . Although neural network models deeper than N layers had not been typically used till the mid of the first decade of the Ns, the convolutional neural network had already been established as viable machine learning architecture _cite_ . Subsequent years saw major works being done in the field of deep learning, particularly increasing usage of unsupervised training _cite_ and the greedy unsupervised layerwise training of DNNs _cite_ . The use of stacked denoising autoencoders _cite_, rectified linear activation units _cite_--which were resistant to the vanishing gradient problem _cite_--and the introduction of GPGPU Programming pushed the depth of neural networks _cite_ even further. During the last decade, the deep convolutional neural networks have carved out a large role in the discussion on deep learning. The popularization of Max Pooling _cite_, introduction of Dropout _cite_, Maxout networks _cite_ etc. led to widespread applications of DCNNs and DNNs in general. They generally encompassed character recognition, object detection, speech recognition, medical imaging amonng other pattern recognition problems _cite_ . Various datasets such as MNIST, TIMIT, ImageNet, CIFAR and SVHN saw new benchmarks set on them using DNNs. With the availability of parallel programming on GPUs _cite_, interest in the development of architectures deeper than N layers _cite_ and transferring the experience of models trained for one domain to another _cite_, the explosion of interest in deep learning research is a well established fact.