amounts of attentions have been paid to various techniques of Internet service and multimedia signal transmission for many years, which not only provide us a convenient manner of communication but also give us many choices for our life style. Meanwhile, the bandwidth of Internet has been accelerated and more stable transmission service is guaranteed by these developments. But there are still some risks of transmission failures, when the Internet congestion occurs in the overloaded case or signal packets are conveyed in the unpredictable yet unreliable channels _cite_ . Multiple description coding has been studied as a promising technique of source coding to relieve these problems by decomposing the signal into multiple redundant subsets, which are transmitted in different channels. Thus, a degraded but acceptable signals reconstruction can be produced after decoding, even though only one description is received at the clients. If more descriptions are available for users, better quality of signal reconstruction can be achieved. Multiple description coding has been widely explored in the field of image and video coding _cite_ . As one of the main techniques in multiple description image coding, multiple description scalar quantization could overcome impairments of transmission channel _cite_ . For example, in _cite_, multiple description scalar quantizers have been combined with efficient wavelet coders to generate independent multiple packets for error resilience. In _cite_, two-stage multiple description scalar quantization is presented to create central and side decoders, whose distortions are closer to the rate-distortion bound of multiple description coding under the condition of the high-resolution assumption. To cope with the L-description problem _cite_, two novel coding schemes are proposed, when the symmetric rates and symmetric distortion is constrained. In _cite_, a new achievable rate-distortion region with combinatorial message sharing is presented by introducing shared codebooks and the refinement codebook to generate L-channel multiple descriptions. Compared with multiple description scalar quantization, lattice vector quantization characterizes in good symmetric structure of lattices and avoiding complex nearest neighbor searching. In _cite_, the main problem of designing lattice vector quantizer is formulated as a labeling problem for two-channel multiple description. In _cite_, non-lattice codebook with symmetries of the coarse lattice is used to get objective quality gains for multiple description coding but without a great increase of complexity. In _cite_, multiple description lattice vector quantization is operated in an optimized way in terms of appropriate construction of wavelet coefficient vectors, choosing sub-lattice index values and different subbands quantization step on the wavelet domain. In _cite_, the index assignment of multiple description lattice vector quantization is designed to be translated into a transportation problem and greedy algorithm as well as general algorithms is developed to pursue optimality of the index assignment. Except multiple descriptions directly produced by quantization, there are many alternative strategies for multiple description coding. To generate two descriptions in transform based coding framework, correlation between pairs of transform coefficients is introduced by a pairwise correlating transform _cite_ . This correlation facilities to reduce the distortion when only a single description is received. Later, both domain-based multiple description coding and forward error correction are used for concatenated multiple description coding of frame-rate scalable video _cite_ . Meanwhile, both prioritized discrete cosine transform in video compression and multiple description codes based on forward error correction are combined together to provide a wireless channels video transmission scheme _cite_ . From literatures _cite_, it can be observed that multiple description video coding using forward error correction has been widely explored. There are several other kinds of multiple description video coding. In _cite_, a video is coded into multiple independently streams so that each stream has its own prediction and dependent state to defeat against bit error or packet loss. In multiple description motion coding algorithm, motion vector is encoded into two descriptions, which are transmitted over distinct channels to the decoder so that motion vector field is robust against transmission errors _cite_ . In the scalable wavelet video codec, each packet is encoded with a separate channel code, so that the integrity of the packets is protected and it allows to detect packet-decoding failures cases, after breaking wavelet transformation into several spatial-temporal tree blocks _cite_ . In _cite_, two architectures of multiple description video coding are built up based on motion compensation prediction loop and a poly-phase down-sampling technique is chosen to generate multiple descriptions and introduce cross redundancy among the descriptions. Although the aforementioned approaches can well alleviate the congestion of Internet and satisfy the demanding of real-time application, these approaches are not compatible to standard codec, such as JPEG, and JPEGN. To resolve this problem, some previous works have provided some feasible solutions, such as _cite_ . In _cite_, through grouping the codeblock to generate two balanced set, these two set are compressed by JPEG-N with two different quantization parameter to get four subsets, which are interlacedly merged together to create two descriptions. In _cite_, the rate-allocation strategy embedded in the JPEGN encoder is introduced for the rate-distortion optimization of multiple descriptions of images, in which single description decoding is able to compatible with JPEGN Part N decoder. In view of human eyes' always sensitivity to the changes above just noticeable difference (JND) threshold, only the significant visual information, which contributes to the JND tolerance, is encoded as the redundant information during H.N/AVC based multiple description video coding _cite_ . In _cite_, frame-level rate-distortion optimized description generation scheme takes account of temporal coding dependency to minimize the end-to-end distortion, which is built on standard H.N/AVC. Because the proposed approach is high related about the issue of compression artifact removal _cite_, we will next review several state-of-the-art works about compression artifact removal. In _cite_, pointwise shape-adaptive discrete cosine transform is leveraged for both denoising and deblocking after image compression. In _cite_, dictionary learning is introduced to reducing JPEG-compressed artifacts in view of image's sparse and redundant representations. In _cite_, collaborative filtering is designed to uncover the finest details and maintain each individual block's unique features in the sparse N-D transform-domain, which is not restrict to the denoising of compressed image, so this approach is a general denoising method. Lately, the deblocking problem is formulated as an optimization problem, where non-convex low-rank model constrained is considered to reduce blocking artifacts _cite_ . Meanwhile, the popular techniques of convolutional neural network and generative adversarial have been tried to remove artifacts _cite_ . Following the work of _cite_, we form multiple description coding baselines with a poly-phase down-sampling technique to generate multiple descriptions by combining state-of-the-art artifact removal technique with super-resolution based on very deep convolutional neural network. Specifically, the input image is down-sampled with a poly-phase down-sampling technique along the main diagonal for each _inline_eq_ non-overlapped window to form two descriptions for coding with standard codec. After decoding, several state-of-the-art artifact removal techniques, such as _cite_ are used to enhance image quality, which is followed by super-resolution to restore image from low-resolution to high-resolution with very deep convolutional neural network, such as novel super-resolution methods of _cite_ and _cite_ . The combinatorial methods with artifact removal _cite_ and super-resolution _cite_ are respectively referred to as multiple description coding baselinesN-N, namely "MDBNa", "MDBNa", "MDBNa", "MDBNa". In this similar way, when artifact removal methods of _cite_ are combined together with _cite_, they are respectively denoted as "MDBNb", "MDBNb", "MDBNb", "MDBNb". In this paper, we introduce a novel standard-compatible multiple description coding framework, in which multiple descriptions are produced by deep convolutional neural network. Our contributions are listed as follows: The rest of this paper is given as follow. We first introduce the proposed methodology in Section N. After that, we conduct a series of the experimental results to validate the efficiency in the Section N. At last, we give a conclusion in the Section N.