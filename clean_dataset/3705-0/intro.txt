This paper proposes a novel method which captures the discriminative aspects of an indoor scene to correctly predict its semantic category (e.g., bedroom, kitchen etc.) . This categorization can greatly assist in context aware object and action recognition, object localization, robotic navigation and manipulation _cite_ . However, owing to the large variabilities between images of the same class and the confusing similarities between images of different classes, the automatic categorization of indoor scenes is a very challenging problem _cite_ . Consider, for example, the images shown in Fig.~ _ref_ . The images of the top row (Fig.~ _ref_ ~a) belong to the same class and exhibit a large data variability in the form of object occlusions, cluttered regions, pose changes and varying appearances. The images in the bottom row (Fig.~ _ref_ ~b) are of three different classes and have large visual similarities. A high performance classification system should therefore be able to cope with the inherently challenging nature of indoor scenes. To deal with the challenges of indoor scenes, previous works _cite_ propose to encode either local or global spatial and appearance information. In this paper, we argue that neither of those two representations provide the best answer to effectively handle indoor scenes. The global representations are unable to model the subtle details, and the low-level local representations cannot capture object-to-object relations and the global structures _cite_ . We therefore devise mid-level representations that carry the necessary intermediate level of detail. These mid-level representations neither ignore the local cues nor lose the important scene structure and object category relationships. Our proposed mid-level representations are derived from densely and uniformly extracted image patches. In order to extract a rich feature representation from these patches, we use deep Convolutional Neural Networks (CNNs) . CNNs provide excellent generic mid-level feature representations and have recently shown great promise for large-scale classification and detection tasks _cite_ . They however tend to preserve the global spatial structure of the images _cite_, which is not desirable when there are large intra-class variations e.g., in the case of indoor scene categorization (Fig.~ _ref_) . We therefore propose a method to discount this global spatial structure, while simultaneously retaining the intermediate scene structure which is necessary to model the mid-level scene elements. For this purpose, we encode the extracted mid-level representations in terms of their association with codebooks of Scene Representative Patches (SRPs) . This enhances the robustness of the convolutional feature representations, while keeping intact their discriminative power. It is interesting to note that some previous works hint towards the incorporation of `wide context' _cite_ for scene categorization. Such high-level context-aware reasoning has been shown to improve the classification performance. However in this work, we show that for the case of highly variant indoor-scenes, mid-level context relationships prove to be the most decisive factor in classification. The intermediate level of the scene details help in learning the subtle differences in the scene composition and its constituent objects. In contrast, global structure patterns can confuse the learning/classification algorithm due to the high inter-class similarities (Sec.~ _ref_) . As opposed to existing feature encoding schemes, we propose to form multiple codebooks of SRPs. We demonstrate that forming multiple smaller codebooks (instead of one large codebook) proves to be more efficient and produces a better performance (Sec. _ref_) . Another key aspect of our feature encoding approach is the combination of supervised and unsupervised SRPs in our codebooks. The unsupervised SRPs are collected from the training data itself, while the supervised SRPs are extracted from a newly introduced dataset of `Object Categories in Indoor Scenes' (OCIS) . The supervised SRPs provide semantically meaningful information, while the unsupervised SRPs relate more to the discriminative aspects of the different scenes that are present in the target dataset. The efficacy of the proposed approach is demonstrated through extensive experiments on five challenging scene classification datasets. Our experimental results show that the proposed approach consistently achieves state of the art performance. The major contributions of this paper are: N) . We propose a new mid-level feature representation for indoor scene categorization using large-scale deep neural nets (Sec. _ref_), N) Our feature description incorporates not only the discriminative patches of the target dataset but also the general object categories that are semantically meaningful (Sec. _ref_), N) . We collect the first large-scale dataset of object categories that are commonly present in indoor scenes. This dataset contains more than N indoor object classes (Sec. _ref_), N) . To improve the efficiency and performance of our approach, we propose to generate multiple smaller codebooks and a feasible feature encoding (Sec. _ref_), and N) . We introduce a novel method to encode feature associations using max-margin hyper-planes (Sec. _ref_) .