Humans, with their strong visual system, have no difficulties reasoning about foreground and background objects in a two-dimensional image. At the same time, humans have the ability of amodal perception, \ie to reason about the invisible, occluded parts of objects _cite_ . Robots that should navigate in their environment and pick or place objects need to know if the objects are occluded or hidden by one or several other instances. This problem leads to the task of semantic amodal segmentation, \ie, the combination of segmenting each instance within an image by predicting its amodal mask and determining which parts of the segmented instances are occluded and what the corresponding occluder is. The amodal mask is defined as the union of the visible mask (which we will also refer to as modal mask as opposed to the amodal mask) and the invisible occlusion mask of the object. Predicting amodal and visible masks simultaneously provides a deeper understanding of the scene. For example, it allows to calculate regions of occlusion and lets the robot know which objects have to be removed or in which direction to move in order to get free access to the object of interest. As shown in the example of, we not only want to reason about the visible parts of objects in the image, but also want to predict the extension of the objects into their occluded, invisible parts. We propose a model that can predict the visible, invisible, and amodal masks for each instance simultaneously without much additional computational effort. Predicting the invisible part of an object is difficult: If the object is occluded by an object from another category, the model has no visual cues how to extend the visible mask into the occluded object part. There are generally no edges or other visual features that indicate the contour of the occluded object. In contrast, if the object is occluded by another instance of the same category, it is very hard for the model to judge where to stop expanding the mask into the occlusion part as the category-specific features are present all around. Note that throughout the paper, we will call annotations containing only visible masks and models predicting visible masks, in contrast to annotations and methods. We will also use the terms occlusion masks and invisible masks as synonyms. In summary, our paper contains the following contributions: