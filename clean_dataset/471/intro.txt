Deep convolutional neural networks have achieved remarkable success in the field of computer vision. While far from new~ _cite_, the increasing availability of extremely large, labeled datasets along with modern advances in computation with specialized hardware have resulted in state-of-the-art performance in many problems, including essentially all visual learning tasks. Examples include image classification~ _cite_, object detection~ _cite_, and semantic segmentation~ _cite_ . Despite a rich history of practical and theoretical insights about these problems, modern deep learning techniques typically rely on task-agnostic models and poorly-understood heuristics. However, recent work~ _cite_ has shown that specialized architectures incorporating classical domain knowledge can increase parameter efficiency, relax training data requirements, and improve performance. Prior to the advent of modern deep learning, optimization-based methods like component analysis and sparse coding dominated the field of representation learning. These techniques use structured matrix factorization to decompose data into linear combinations of shared components. Latent representations are inferred by minimizing reconstruction error subject to constraints that enforce properties like uniqueness and interpretability. Unlike feed-forward alternatives that construct representations in closed-form via independent feature detectors, this optimization-based approach naturally introduces conditional dependence between features in order to best explain data, a useful phenomenon commonly referred to as ``explaining away'' within the context of graphical models~ _cite_ . An example of this effect is shown in Fig.~ _ref_, which compares sparse representations constructed using feed-forward soft thresholding with those given by optimization-based inference with an _inline_eq_ penalty. While many components in an overcomplete set of features may have high-correlation with an image, constrained optimization introduces competition between components resulting in more parsimonious representations. Component analysis methods are also often guided by intuitive goals of incorporating prior knowledge into learned representations. For example, statistical independence allows for the separation of signals into distinct generative sources~ _cite_, non-negativity leads to parts-based decompositions of objects~ _cite_, and sparsity gives rise to locality and frequency selectivity~ _cite_ . Due to the difficulty of enforcing intuitive constraints like these with feed-forward computations, deep learning architectures are instead often motivated by distantly-related biological systems~ _cite_ or poorly-understand internal mechanisms such as covariate shift~ _cite_ and gradient flow~ _cite_ . Furthermore, while a theoretical understanding of deep learning is fundamentally lacking~ _cite_, even non-convex formulations of matrix factorization are often associated with guarantees of convergence~ _cite_, generalization~ _cite_, uniqueness~ _cite_, and even global optimality~ _cite_ . In order to unify the intuitive and theoretical insights of component analysis with the practical advances made possible through deep learning, we introduce the framework of Deep Component Analysis (DeepCA) . This novel model formulation can be interpreted as a multilayer extension of traditional component analysis in which multiple layers are learned jointly with intuitive constraints intended to encode structure and prior knowledge. DeepCA can also be motivated from the perspective of deep neural networks by relaxing the implicit assumption that the input to a layer is constrained to be the output of the previous layer, as shown in Eq.~ _ref_ below. In a feed-forward network (left), the output of layer _inline_eq_, denoted _inline_eq_, is given in closed-form as a nonlinear function of _inline_eq_ . DeepCA (right) instead takes a generative approach in which the latent variables _inline_eq_ associated with layer _inline_eq_ are to optimally reconstruct _inline_eq_ as a linear combination of learned components subject to some constraints _inline_eq_ . From this perspective, intermediate network ``activations'' cannot be found in closed-form but instead require explicitly solving an optimization problem. While a variety of different techniques could be used for performing this inference, we propose the Alternating Direction Method of Multipliers (ADMM) ~ _cite_ . Importantly, we demonstrate that after proper initialization, a single iteration of this algorithm is equivalent to a pass through an associated feed-forward neural network with nonlinear activation functions interpreted as proximal operators corresponding to penalties or constraints on the coefficients. The full inference procedure can thus be implemented using Alternating Direction Neural Networks (ADNN), recurrent generalizations of feed-forward networks that allow for parameter learning using backpropagation. A comparison between standard neural networks and DeepCA is shown in Fig.~ _ref_ . Experimentally, we demonstrate that recurrent passes through convolutional neural networks enable better sparsity control resulting in consistent performance improvements in both supervised and unsupervised tasks without introducing any additional parameters. More importantly, DeepCA also allows for other constraints that would be impossible to effectively enforce with a single feed-forward pass through a network. As an example, we consider the task of single-image depth prediction, a difficult problem due to the absence of three-dimensional information such as scale and perspective. In many practical scenarios, however, sparse sets of known depth outputs are available for resolving these ambiguities to improve accuracy. This prior knowledge can come from additional sensor modalities like LIDAR or from other ND reconstruction algorithms that provide sparse depths around textured image regions. Feed-forward networks have been proposed for this problem by concatenating known depth values as an additional input channel~ _cite_ . However, while this provides useful context, predictions are not guaranteed to be consistent with the given outputs leading to unrealistic discontinuities. In comparison, DeepCA enforces the constraints by treating predictions as unknown latent variables. Some examples of how this behavior can resolve ambiguities are shown in Fig.~ _ref_ where ADNNs with additional iterations learn to propagate information from the given depth values to produce more accurate predictions. In addition to practical advantages, our model also provides a novel perspective for conceptualizing deep learning techniques. Due to the decoupling of layers provided by relaxing the feed-forward function composition constraints, DeepCA can be equivalently expressed as a shallow model augmented with architecture-dependent structure imposed on the model parameters. In the case of rectified linear unit (ReLU) activation functions~ _cite_, this allows for the direct application of results from sparse approximation theory, suggesting new insights towards better understanding why deep neural networks are so effective.