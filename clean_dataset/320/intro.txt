Face analytics is essential for human-centric multimedia research and applications. Face analytics tasks include face detection~ _cite_, facial landmark localization~ _cite_, face attribute prediction~ _cite_, face parsing~ _cite_, facial emotion recognition~ _cite_, face recognition~ _cite_, ~ . Traditionally, different face analytics tasks are treated separately and performed by designing different models. But in some scenarios, people need to address multiple face analytics tasks. For example, for facial emotion recognition task, people also need to address facial landmark localization task as the input to facial emotion recognition task needs to be aligned by the detected facial landmarks. So it is attractive to design an integrated face analytics network which performs multiple tasks in one go. In this work we propose an integrated face analytics network (named iFAN) . Different from existing approaches where separate models are used for different tasks, iFAN is a powerful model to solve different tasks simultaneously, enabling full task interactions within the model. See Figure~ _ref_ . In additon, the iFAN uses a novel cross-dataset hybrid training strategy to effectively learn from multiple data sources with orthogonal annotations, which solves the bottleneck of lacking complete training data for all involved tasks. The proposed iFAN uses a carefully designed network architecture that allows for informative interaction between tasks. It consists of four components: a shareable feature encoder, feature decoders, feature re-encoders and a task integrator. The shareable feature encoder, which is the backbone network, learns rich facial features that are discriminative for different tasks. Each of the feature decoders produces the prediction on top of the learned features for one specific task. To promote interactions among different tasks within iFAN, the feature re-encoders and task integrator are introduced. The feature re-encoders in iFAN transform the task specific predictions back to feature spaces. We use the term ``re-encoder'' to stress the function of converting the predictions back to the feature space. Specifically the feature re-encoders take as input raw predictions and generate encoded features of the predictions. The feature re-encoders can align the features for different tasks to similar semantic levels to facilitate the task interaction process. Based on the representations from re-encoders, the task integrator in iFAN integrates the encoded predictions of different tasks into multi-resolution and multi-context features that facilitate the inter-task interactions. Specifically, with access to the encoded predictions of all tasks, the task integrator provides the full context information for the task interactions. It introduces a feedback loop, which connects the integrated context information back to the backbone network, which is beneficial for performing multiple tasks simultaneously. To the end of jointly addressing different tasks, one bottleneck is the absence of datasets with complete training data for all the tasks of interest. Usually each dataset only provides annotations for a specific task (emotion category for emotion recognition, segmentation mask for face parsing), and it is very hard to find a dataset with a complete set of labels for all the tasks of interest. Thus we propose a new cross-dataset hybrid training strategy to enable iFAN to learn from multiple data sources and perform well on all tasks simultaneously. The proposed cross-dataset hybrid training strategy can effectively model the statistical differences across different datasets to reduce the negative impacts of such differences. With the proposed training strategy, the iFAN does not require complete annotations for all the tasks over a single dataset. Instead, this training strategy allows iFAN to learn from multiple data sources without annotation overlapping. Such ``plug-in and play'' feature greatly increases the flexibility of iFAN. The iFAN uses only one network for multiple face analytics tasks, enabling users to customize their own combination of tasks for iFAN to perform simultaneously. The model size, computation complexity and inference time are linearly reduced compared with separate models. Moreover, iFAN goes a step further to analyze the correlations between the tasks, which enables interaction with each other for performance boost. It is worth noting that iFAN is different from multi-task learning. Unlike the simple parameter sharing scheme in commonly used multi-task learning models, iFAN explicitly models the interaction between different tasks. More than merely sharing a common feature space, the outputs from different tasks also jointly influence the predictions of other tasks. Besides, the proposed iFAN is able to learn from multiple data sources with no overlapping, where traditional multi-task learning approaches will fail. Thus the expensive cost of collecting comprehensive training data for all involved tasks can be substantially reduced. Our work is also different from transfer learning which considers to learn the same task from different datasets. In contrast, our proposed cross-dataset hybrid learning is able to utilize the useful knowledge on learning different tasks from non-overlapping datasets.