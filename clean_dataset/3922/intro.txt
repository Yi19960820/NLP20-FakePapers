Back-propagation and gradient based learning _cite_ ushered a new era in the field of machine learning and artificial intelligence. The ImageNet challenge _cite_ has induced a number of new image classification architectures starting from AlexNet _cite_ to even deeper networks like ZFNet _cite_, VGGNet _cite_, ResNet _cite_, GoogleNet _cite_ . However, these deep networks are found to be susceptible to image distortion as far as classification is concerned _cite_ . It is observed that adding a little amount of distortion in the test set leads the network to misclassify an object as something else with surprisingly high confidence: some as high as N \% _cite_ . The above-mentioned popular CNN models are reported to exceed human performance level on ImageNet _cite_ . Nevertheless, in a number of instances, the subject of an image is easily recognizable by human but these CNN models fail to correctly classify in presence of negligible distortion. Figure _ref_ provides further visual evidence of this claim as VGGN fails to correctly predict class labels of a set of distorted input. Most of the work in the literature tackle this problem by data augmentation or fine-tuning networks with mutually exclusive training image of chosen distortion. While it does increase the accuracy of the network, this does not perform better than models trained on a single distortion type _cite_ . Moreover, the fact that the network has to be fine-tuned on all possible distorted image data separately makes it even more undesirable. All these facts culminate to an intriguing question. Is it possible to attain such a network that is not fine-tuned to any explicit distortion type and is generally robust enough after being trained only once on the original training data? In this work, We propose Discrete Cosine Transform based deep network DCT-Net which significantly increases the deep network's invariance to a variety of unseen image distortions. We show that after the input is transformed into frequency domain, dropping DCT coefficients or certain frequency components help the deep network to learn a more robust representation of the training images leading to a quality invariant CNN. The input diversity stemming from the integrated DCT module provides an assorted visual representation of the training data and the network gets to learn features from a wide array of variants of a single image. DCT-Net no longer heavily relies on minute image details for learning and therefore when faced with a degraded version of an image, it can still classify correctly. Overfitting to training data has been a well-known issue with deep networks and dropout is a widely used technique to counter this problem _cite_ . Rather than using constant dropout probability through the entire training period, we incorporate a training adaptive version of it in DCT-Net to improve the test accuracy even further. The initial dropout probability is incremented when the network starts converging to training data. Gaussian noise and blur are the two most common forms of image quality degradation. In addition to these two, we evaluate our network on salt and pepper noise, motion Blur and speckle noise. Speckle noise is often inherent to sound/electromagnetic wave-based imaging systems but has similarity to Gaussian granular noise _cite_ . This paper is organized as follows: Section _ref_ sheds light on our motivation behind this work. Section _ref_ discusses related works. In Section _ref_, we introduce and formulate the proposed DCT-Net with adaptive dropout. In Section _ref_, we discuss about the data sets and provide a performance comparison of existing works with our proposed approach. Section _ref_ concludes this paper.