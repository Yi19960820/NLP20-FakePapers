Hyperspectral imaging _cite_ collects rich spectral information from a large number of densely-spaced contiguous frequency bands. It produces three dimensional _inline_eq_ data volumes, where _inline_eq_ represent spatial dimensions and _inline_eq_ represents spectral dimension. Hyperspectral image classification _cite_ is the task of assigning a class label to every pixel. This paper studies land-cover classification in hyperspectral images where the task is to predict the type of land-cover present in the location of each pixel. There are several challenges associated with hyperspectral data the most critical of which are as follows _cite_ . \indent Several approaches have been followed in literature for HSI classification. The simplest of them are based on _inline_eq_-nearest neighbors (_inline_eq_-NN) . In these methods, given a test sample, Eucledian distance in the input space or a transformed space is used to find the _inline_eq_ nearest training examples and a class is assigned on the basis of them. In _cite_ and _cite_ some modified versions of the _inline_eq_-NN algorithm have been proposed for HSI classification. Support Vector Machine (SVM) classifier is a maximum margin linear classifier _cite_ . Melghani et al. _cite_ introduced SVM Classifier for HSI classification. SVM based methods, in general, follow a two step approach. Li et al. _cite_ propose local Fisher's Discriminant Analysis for dimensionality reduction and Gaussian Mixture Model (GMM) for classification. Mianji et al. _cite_ propose Gaussian Non-linear Discriminant Analysis for dimensionality reduction and Relevance Vector Machine for classification. Samat et al. _cite_ introduced Extreme Learning Machine (ELM) for HSI classification. ELM _cite_ is a two layer artificial neural network in which the input to hidden weights are randomly chosen and the hidden to output weights are learned by minimizing a least squares objective function. In _cite_ LBP is used to extract texture based local descriptors which are combined with global descriptors like Gabor and spectral features and fed into an ELM for classification. Lu et al. _cite_ proposed a set-to-set distance based method for HSI classification. Recently deep neural networks _cite_ have been employed for landcover classification in HSI. Deep learning methods for HSI classification _cite_ focus on spectral-spatial context modeling in order to address the problem of spatial variability of spectral signatures. They fall into two broad categories. The first category _cite_ follows a two-step procedure. The second category of methods use Convolutional Neural Networks (CNN) _cite_ for feature learning and classification in an end-to-end fashion. CNN uses extensive parameter-sharing to tackle the curse of dimensionality. Hu et al. _cite_ introduced CNN for HSI classification. The proposed architecture is designed to learn abstract spectral signatures in a hierarchical fashion but does not take into account spatial context. In _cite_ compressed spectral features from a local discriminant embedding method are concatenated with spatial features from a CNN and fed into a multi-class classifier. Yu et al. _cite_ and Chen et al. _cite_ propose end-to-end CNN architectures for spectral-spatial feature learning and classification. In _cite_ the idea of classifying pixel-pair features using CNN is introduced to compensate for data scarcity. Also a voting strategy is proposed for test time to provide robustness in heterogeneous regions. In this paper we present a deep neural network architecture that learns band-specific spectral-spatial features and gives state-of-the-art performance without any kind of data-set augmentation or input pre-processing. The architecture consists of three cascaded blocks. Block N takes a _inline_eq_ input volume (_inline_eq_ number of spectral channels) and performs a preliminary feature transformation on the spectral axis. It splits the spectral channels into bands and feeds to Block N where parallel neural networks are used to extract low and mid-level spectral-spatial features. The outputs of the parallel networks are fused by concatenation and fed into Block N which summarizes them to form a high-level representation of the input. This is eventually classified by logistic regression. Extensive use of convolutional layers and weight sharing among the parallel networks of Block N keeps the parameter budget and computational complexity low. Band-specific representation learning and fusion via concatenation in Block N makes the network discriminative towards spectral locality of low and mid level features. Experiments on benchmark hyperspectral image classification data sets show that the proposed network converges faster and gives superior classification performance than other deep learning based methods in literature. Our source code is publicly available on the Web . The contributions of this paper can be summarized as follows: Section _ref_ gives a detailed description of the proposed architecture along with the design methodology followed. Experimental results are presented in Section _ref_ . Comparison with existing methods is also reported. Section _ref_ concludes the paper with a summary of the proposed method and scope of future work.