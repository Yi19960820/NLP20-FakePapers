Pose estimation from images is a recurring challenge in computer vision, for example for tasks such as camera pose estimation, body joint localization, and object tracking. Such tasks have recently benefited from learned models _cite_, but various problems persist when applying one-shot pose estimation to video data. In fact, disregarding temporal information can result in very noisy estimates and in the confusion of visually similar but spatially distinct image features, such as those that result from the left and right legs in the case of body joint localization. For this reason, temporal filters are a popular approach for improving the accuracy of pose estimation. Among these methods, because of their simplicity and general applicability, Kalman filters (KF) ~ _cite_ are an extremely widely-used choice. Moreover, the extended Kalman filter (EKF) ~ _cite_ is capable of handling non linear systems for both the measurement and transition models. However, in many tasks, these measurement and transition models cannot be specified a priori, and in these situations the application of Kalman filters is severely limited. In particular, in these in these tasks we must devise carefully tuned measurement and transition models, and even once devised they tend to be overly simplistic. For example, in the aforementioned computer vision tasks the trajectories of objects and body parts do not follow any simple motion model. In such scenarios, Kalman filters are often applied under the assumptions of constant velocity or constant acceleration, which are clearly crude approximations to reality. To overcome such limitations, attempts have been made to directly learn motion models from training data, for example with support vector machines (SVMs) ~ _cite_ or with long short-term memory (LSTM) _cite_ . Learning motion models can alleviate the modeler from time-consuming Kalman filter selection and optimization and simultaneously enrich the underlying motion model. However, using learned motion models to enforce temporal consistency in pose estimation has to cope with the constraint that sufficient training data needs to be available in order to cover all possible motion paths of the tracked object. In this work, we propose the LSTM Kalman filter (LSTM-KF), a new architecture which lets us learn the internals of the Kalman filter. In particular, we learn the motion model and all noise parameters of the Kalman filter, thus letting us gain the benefits of learning while letting us successfully train our models with less data. The LSTM-KF architecture is illustrated in Fig.~ _ref_ . This framework can be used to temporally regularize the output of any one-shot estimation technique, which from here forward will be considered a generic black-box estimator. Specifically, our estimation model learns to predict the uncertainty of the initial prediction as well as the uncertainty of the incoming measurement, which is crucial in order to properly perform the update step. In addition, a learned motion model is employed also for the prediction step. Importantly, the estimator is not confined to the learned motion model, as it keeps on being refined by measurements during the update step. As a result, the filter learns to implicitly regularize the pose over time without the need for a hand-crafted transition or measurement model. We believe that our approach is advantageous with respect to learning-based Kalman filter techniques such as those in~ _cite_ . On one hand, in contrast to SVR _cite_, LSTM is able to estimate filter parameters using a model that depends on all previously observed inputs. On the other hand, by explicitly incorporating the prediction of LSTM with measurements in a Kalman update fashion, we relax the requirement on the LSTM to implicitly learn to fuse measurements with the state prediction for all possible motion paths, as attempted in~ _cite_ . Indeed, our model splits up the task of learning temporal regularization onto three distinct LSTMs that each have a defined objective: predicting the new state, estimating the prediction noise, and estimating the measurement noise. Due to this split of objectives in a Kalman filter fashion, each individual LSTM learns a simpler task and our model will automatically start to rely on the measurements in case of low accuracy predictions. We evaluate the LSTM-KF using three relevant pose estimation tasks: body landmark localization, object tracking, and camera pose estimation, using real data from benchmark datasets. LSTM-KF outperforms both Kalman filters with different transition models and LSTM. In the next section, we discuss related work. Next, we review Kalman filtering and long short-term memory in detail. In Section _ref_, we introduce the LSTM Kalman filter (LSTM-KF), including the underlying model, the modified prediction and update steps, and the full architecture which joins three LSTM modules with the Kalman filter. Next we move on to results, where we see LSTM-KF outperform other temporal regularization techniques, including standalone Kalman filters and standalone LSTM. Finally, we conclude and discuss future work.