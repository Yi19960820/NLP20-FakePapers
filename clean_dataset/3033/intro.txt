Multi-object tracking (MOT) is a key problem in computer vision with many applications such as video surveillance, activity analysis, and abnormality detection~ _cite_ . It is challenging in unconstrained environments due to influencing factors such as illumination variance, camera motion, target interactions, and more importantly, lengthy occlusions. Most existing multi-object tracking methods fall into the tracking-by-detection category, where the goal is to link detections in the video belonging to the same target. Recent tracking methods adopt person re-identification techniques based on pairwise similarity of detections~ _cite_ for this data association. However, this can lead to wrong associations, especially if there are lengthy occlusions. By contrast, considering a group of detections before and after an occlusion as a tracklet can improve the re-identification accuracy. Moreover, we argue that these association errors can be further reduced if pedestrian tracking is formulated as a hierarchical clustering problem that iteratively merges detections into longer tracklets. This way, the association complexity increases gradually as opposed to a one-step approach that directly aims to obtain the final solution. When evaluating possible associations between detections in crowded scenes where multiple pedestrians are closely located and/or overlapping in the image, it is essential to jointly reason about both their visual appearance and spatio-temporal properties. Recently, several works~ _cite_ use neural networks to process visual appearance, and separately compute hand-crafted features to incorporate spatio-temporal information from the bounding boxes. Logistic regression or some learning technique is then used to assign weights to these features in order to compute an overall similarity metric. Even though this mitigates the need to empirically set weights through trial-and-error, we argue that hand-crafted features nonetheless do not generalize well since they make certain assumptions about the underlying motion model, and as in~ _cite_, some of these features may have to be computed separately for each video sequence to account for the difference in camera parameters. Additionally, such approaches lack the ability to jointly reason about spatio-temporal and visual cues in a strong manner since the features are computed separately and combined only at the final step. In this paper, we propose a multiple people tracking framework (illustrated in Fig. _ref_) that hierarchically merges tracklets to overcome occlusions and minimize association errors. Our main contributions are: (N) A novel end-to-end deep network for assessing tracklet similarity that can jointly reason about visual and spatio-temporal cues in a generalized manner without requiring hand-crafted features and/or tunable parameters; (N) an extension of Kernighan-Lin with Joins algorithm~ _cite_ that enables the tracklet clustering problem to be formulated as a constrained minimum-cost multicut graph problem, and; (N) a new state-of-the-art in the MOT Challenge~ _cite_ .