Detecting generic objects in high-resolution images is one of the most valuable pattern recognition tasks, useful for large-scale image labeling, scene understanding, action recognition, self-driving vehicles and robotics. At the same time, accurate detection is a highly challenging task due to cluttered backgrounds, occlusions, and perspective changes. Predominant approaches~ _cite_ use deformable template matching with hand-designed features. However, these methods are not flexible when dealing with variable aspect ratios. Wang \etal recently proposed a radically different approach, named, for generic object detection~ _cite_ . It extends classic cascaded boosting classifiers ~ _cite_ with a two-layer feature extraction hierarchy which is dedicatedly designed for region based object detection. The innovative framework is capable of dealing with variable aspect ratios, flexible feature sets, and improves upon Deformable Part-based Model by N \%~ _cite_ in terms of mean average precision. Despite the success of these sophisticated detection methods, the features employed in these frameworks are still traditional features based on low-level cues such as histogram of oriented gradients (HOG) ~ _cite_, local binary patterns (LBP) ~ _cite_ or covariance~ _cite_ built on image gradients. As with the success in large scale image classification~ _cite_, object detection using a deep convolutional neural network also shows promising performance~ _cite_ . The dramatic improvements from the application of deep neural networks are believed to be attributable to their capability to learn hierarchically more complex features from large data-sets. Despite their excellent performance, the application of deep CNNs has been centered around image classification, which is computationally expensive when transferring to object detection. For example, the approach in~ _cite_ needs around N minutes to evaluate one image. Furthermore, their formulation of the problem does not take advantage of venerable and successful object detection frameworks such as DPM or which are powerful designs for modeling object deformation, sub-categories and multiple aspect ratios. These observations motivate us to propose an approach to efficiently incorporate a deep neural network into conventional object detection frameworks. To that end, we introduce the (DNP), a local feature densely extracted from an image with arbitrary resolution using a well trained deep convolutional neural network. The DNPs not only encode high-level features learned from a large image data-set, but are also local and flexible like other dense local features (like HOG or LBP) . It is easy to integrate DNPs into the conventional detection frameworks. More specifically, the receptive field location of a neuron in a deep CNN can be back-tracked to exact coordinates in the image. This implies that spatial information of neural activations is preserved. Activations from the same receptive field but different feature maps can be concatenated to form a feature vector for the receptive field. These feature vectors can be extracted from any convolutional layers before the fully connected layers. Because spatial locations of receptive fields are mixed in fully connected layers, neuron activations from fully connected layers do not encode spatial information. The convolutional layers naturally produce multiple feature vectors that are evenly distributed in the evaluated image crop (a _inline_eq_ crop for example) . To obtain dense features for the whole image which may be significantly larger than the network input, we resort to ``network-convolution'' which shifts the crop location and forward-propagate the neural network until features at all desired locations in the image are extracted. As the result, a typical PASCAL VOC image only needs to run the neural network several times to produce DNPs for the whole image depending on the required feature stride, promising low computational cost for feature extraction. To adapt our features for the framework, we build normalized histograms of DNPs inside each sub-region of arbitrary resolution within the detection window and add these histograms to the feature pool for the boosting learning process. DNPs can also be easily combined with traditional features in the framework as explained in Sec.~ _ref_ . Our experiments show that the proposed DNPs are very effective and also complementary to traditional features. On PASCAL N VOC detection benchmark, our framework with and DNPs achieved N \% mAP compared to N \% with the original ; on PASCAL VOC N, it achieves N \% mAP compared to N \% with the original . It outperforms the recent approach by ~ _cite_ with N \% mAP. Furthermore, our DNP features are extracted from the fifth convolutional layer of the deep CNN without fine-tuning on the target data-set, while~ _cite_ used the seventh fully connected layer with fine-tuning. Importantly, for each PASCAL image, our feature extraction finishes in N seconds, compared to approximately N minutes from our replication of~ _cite_ . The major contribution of the paper is two-fold: N) We propose a method to incorporate a discriminatively-trained deep neural network into a generic object detection framework. This approach is very effective and efficient. N) We apply the proposed method to the object detection framework and achieved competitive and state-of-the-art performance on the PASCAL VOC datasets.