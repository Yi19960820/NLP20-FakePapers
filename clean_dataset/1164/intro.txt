The celebrated sparse representation model has led to impressive results in various applications over the last decade _cite_ . In this context one typically assumes that a signal _inline_eq_ is a linear combination of a few columns, also called atoms, taken from a matrix _inline_eq_ termed a dictionary; i.e. _inline_eq_ where _inline_eq_ is a sparse vector. Given _inline_eq_, finding its sparsest representation, called sparse pursuit, amounts to solving the following problem where _inline_eq_ stands for the model mismatch or an additive noise strength. The solution for the above can be approximated using greedy algorithms such as Orthogonal Matching Pursuit (OMP) _cite_ or convex formulations such as BP _cite_ . The task of learning the model, i.e. identifying the dictionary _inline_eq_ that best represents a set of training signals, is called dictionary learning and several methods have been proposed for tackling it, including K-SVD _cite_, MOD _cite_, online dictionary learning _cite_, trainlets _cite_, and more. When dealing with high-dimensional signals, addressing the dictionary learning problem becomes computationally infeasible, and learning the model suffers from the curse of dimensionality. Traditionally, this problem was circumvented by training a local model for patches extracted from _inline_eq_ and processing these independently. This approach gained much popularity and success due to its simplicity and high-performance _cite_ . A different approach is the Convolutional Sparse Coding (CSC) model, which aims to amend the problem by imposing a specific structure on the global dictionary involved _cite_ . In particular, this model assumes that _inline_eq_ is a banded convolutional dictionary, implying that this global model assumes that the signal is a superposition of a few local atoms, or filters, shifted to different positions. Several works have presented algorithms for training convolutional dictionaries _cite_, circumventing some of the computational burdens of this problem by relying on ADMM solvers that operate in the Fourier domain. In doing so, these methods lost the connection to the patch-based processing paradigm, as widely practiced in many signal and image processing applications. In this work, we propose a novel approach for training the CSC model, called slice-based dictionary learning. Unlike current methods, we leverage a localized strategy enabling the solution of the global problem in terms of only local computations in the original domain. The main advantages of our method over existing ones are: The rest of this paper is organized as follows: Section _ref_ reviews the CSC model. The proposed method is presented in Section _ref_ and contrasted with conventional approaches in Section _ref_ . Section _ref_ shows how our method can be employed to tackle the tasks of image inpainting and separation, and later in Section _ref_ we demonstrate empirically our algorithms. We conclude this work in Section _ref_ .