The problem of image restoration from a sequence of frames under the atmospheric turbulence is challenging due to the dramatic downgrade in the image quality from the geometric distortions and the space-time varying blurs. Multiple factors such as temperature changes, air turbulent flow, densities of air particles, carbon dioxide level and humidity lead to the occurrence of several turbulence layers with various changes in the refractive index _cite_ _cite_ . These factors together explain the higher chance of obtaining corrupted video sequences in locations where the variation among these factors is large. In practice, either techniques in hardware-based adaptive optics _cite_ _cite_ or methods in image processing _cite_ _cite_ _cite_ _cite_ _cite_ are employed to remove the turbulence distortion in the images, but those prevailing models from either way can barely address to the majority of these factors. \par Due to the fact that the atmospheric turbulence is complicated to be modeled, a deep learning approach which does not heavily require the underlying assumptions is more reasonable to tackle the problem than models relying on certain assumptions on the turbulence. We are thus motivated to investigate the possibility to remove geometric distortions and restore a good-quality image by using a generative model that does not explicitly take the above-mentioned factors into consideration. However, the unavailability of massive turbulence-distorted video frames disables the application of deep learning approaches to tackle the problem. \par In this paper, we introduce a simple and yet effective data augmentation method to overcome the problem of data scarcity. The method models real turbulence with different deformations and different extent of blurs in order to provide sufficient training data. Since the artificial turbulence is randomly generated with different strength of deformations and blurs, a variety of turbulence-distorted videos can be produced from a single image. In general, it is known that the performance of image restoration is commensurate with the training sample size. Nevertheless, with the data augmentation method, the size requirement of the training data is not too restrictive and demanding in our proposed deep network to restore the turbulence-distorted images. \par With the augmented training data, a deep network can be trained to solve the deturbulence problem. We propose a subsampled Wasserstein Generative Adversarial Network ({\bf WGAN}) with multiframe input and _inline_eq_ cost to simultaneously remove geometric distortions and blurring effects of turbulence-distorted image sequences. {\bf WGAN} is known for its effectiveness in generating a clear image from noises. Together with the _inline_eq_ cost applied to the network, important features of the images can be restored even though they are corrupted. To gather enough information, it is natural to take multiple frames from the video as the input of the turbulence-removal network. Using multiple frames as input is essential to obtain a clear image from a turbulence-distorted video. \par In the testing stage, we propose to incorporate a subsampling algorithm to the trained network for better performance. Usually, turbulence-distorted video consists of mildly distorted frames. The subsampling method extracts those sharp and mildly distorted frames in order to achieve an even better restoration result. We experimentally show that by incorporating the subsampling method, the performance of removing geometric distortions and blurs of the degraded images can be significantly improved. The main contributions of this paper are listed as follows: