Hyperspectral images contain rich spectral information coming from contiguous spectral bands. In the spectral domain, pixels are represented by vectors for which each component is a measurement corresponding to specific wavelengths _cite_ . The length of the vector is equal to the number of spectral bands that the sensor collects. For hyperspectral images, several hundreds of spectral bands of the same scene are typically available, which form the features of a pixel. Current operational imaging systems provide images for various applications, e.g., in ecology, geology and precision agriculture _cite_ . A relevant task of hyperspectral image processing is classification, which aims at building a classifier using the pixel features in order to assign each pixel to one of a given set of classes _cite_ . Current state-of-the-art methods take a spectral-spatial approach, meaning that they use neighborhood information of labeled pixels. Spectral-spatial methods are based on diverse techniques, such as Markov random fields _cite_, discriminative feature construction _cite_, modification and fusion of classifiers _cite_, label propagation, active learning and semi-supervised learning _cite_, the use of external unlabeled data _cite_ and deep (convolutional) neural networks _cite_ . Furthermore, object-based methods utilize geometric features of the image extracted by means of segmentation techniques _cite_ . These methods achieve excellent performance on benchmark hyperspectral image classification tasks when a large number of labeled pixels for training is provided _cite_ . However, pixel labeling is an expensive task. Therefore, a problem of more practical relevance is to perform hyperspectral image classification with only a few manually-labeled pixels for training. A second problem is the inherent class unbalance of hyperspectral images, where some classes have many pixels, while other classes have only a few. In this paper, we propose to tackle these problems using a simple shallow Convolutional Neural Network (CNN) and three `tricks': spectral-locality-aware regularization, smoothing-based data augmentation and label-based data augmentation. The shallow architecture is used to prevent overfitting caused by the few labeled pixels and the many features. Locality-aware regularization forces neighboring wavelengths to have similar contributions to the generated features of the neural network. Smoothing-based data augmentation takes advantage of the spectra of neighboring pixels, and label-based data augmentation exploits labels of neighboring pixels in favor of small classes. Extensive experiments indicate the effectiveness of the proposed method, which achieves comparable or better accuracy performance than existing methods, such as deep neural networks~ _cite_, multiple kernel learning _cite_, probabilistic class structure regularized sparse representation and low-rank {Gabor filtering} _cite_ (see the results in) . Spectral-spatial methods exploit information from neighborhood pixels. Since the training and testing pixels are drawn from the same image, their features are likely to overlap in the spatial domain due to the shared source of information: for instance, _cite_ employed input patches, the central pixel of which is in the training set, and _cite_ applied Gabor filters to an _inline_eq_-size neighborhood of training pixels. As a consequence, the resulting learning setting used in spectral-spatial methods has an intrinsic positive bias induced by the overlap between training and test samples. In order to investigate such a bias, we~consider also a non-overlapping learning setting, where only the labeled pixels initially selected for training are used for building a classifier. Below, we briefly mention a few selected spectral-spatial approaches and methods for hyperspectral image classification. We refer the reader to _cite_ for a recent survey of hyperspectral image classification methods. We can divide methods for hyperspectral image classification into three broad categories: (N) ~pre-processing-based; (N) end-to-end methods; (N) hybrid methods. Pre-processing-based methods construct features prior to training a classifier. Recent methods in this category include the Discriminative Low-Rank Gabor Filtering (DLRGF) method by _cite_ for spectral-spatial feature extraction prior to classification, a deep CNN with ND input patches and R-PCA _cite_ and a deep stacked auto-encoder with ND input patches and PCA _cite_ . End-to-end methods learn features while training a classifier. These methods include (multiple) kernel learning methods, which use kernels to implicitly map the input space into a high dimensional non-linear space (see the recent survey _cite_), and sparse representation-based methods, like _cite_, which learn a sparse representation of test pixels by the linear combination of a few training samples from a given dictionary, whereas its corresponding sparse representation coefficients encode the class information implicitly. Hybrid methods involve multi-step procedures, which include pre-and/or post-processing steps. For instance, the superpixel-based graphical model by _cite_ consists of three steps: the superpixel generation using the watershed segmentation algorithm after performing gradient fusion among multiple spectral bands; the superpixel-based graphical model development with the aid of pixel-level attributes; and the loopy belief propagation algorithm applied at the superpixel level. Here, a superpixel is a group of spatially-connected similar pixels. Object-based methods segment an image and simultaneously try to assign to each segment a class _cite_ . Methods specifically related to the one we propose are based on convolutional neural networks and data augmentation. Due to the success of convolutional neural networks in image classification, a plethora of CNN-based methods for hyperspectral image classification have been proposed. They~differ mainly in the architecture that they use, the specific loss function that is optimized and the representation of the input data, that is as single pixels, patches of pixels, cubes of pixels, etc. Moreover, some CNN-based methods use preprocessing, often PCA, to either build a low dimensional set of non-linear input features or to extract additional information (e.g., edge detection) . These methods include _cite_, a deep CNN with ND input patches and R-PCA _cite_, a deep stacked auto-encoder with ND input patches and PCA _cite_, a contextual deep CNN _cite_, a multi-hypothesis prediction _cite_, a~low-rank Gabor filtering method _cite_, a deep CNN with ND pixel spectra _cite_, a~deep CNN with ND pixel spectra, ND pixel patches or ND pixel cubes _cite_, a deep CNN with ND pixel spectra and _cite_ a~deep CNN with uniform smoothing kernel and ND pixel spectra. Fortunately, the authors of the latter method shared the source code with us, which we could then use in our comparative experimental analysis. Data augmentation is used to enhance the performance of deep neural networks for image classification. This approach has also been used in the context of hyperspectral image classification, in deep CNN-based methods. For instance, _cite_ used blocks of _inline_eq_ pixels as samples and rotated and flipped the resulting training samples to enlarge the training set. In the deep CNN-based method by _cite_, the number of training samples was augmented four times by mirroring the training samples across the horizontal, vertical and diagonal axes. Our new data augmentation procedure is different because it takes into account the spatial locality of the data. In _cite_, it has been observed that the dependence caused by overlap between the training and testing samples may be artificially enhanced by some spatial information processing techniques used in spectral-spatial classification methods, such as spatial filtering and morphological operators. Therefore, ~the~authors introduced an alternative controlled random sampling strategy for spectral-spatial methods to reduce the overlap between training and testing samples and provided a more objective evaluation. However, the proposed strategy uses information on the class distribution, which may not be available in real-life scenarios. The non-overlapping learning setting that we propose overcomes this limitation.