One-class classification is a classical machine learning problem that has received considerable attention in the recent literature _cite_, _cite_, _cite_, _cite_, _cite_, _cite_ . The objective of one-class classification is to recognize instances of a concept by only using examples of the same concept _cite_ as shown in Figure~ _ref_ . In such a training scenario, instances of only a single object class are available during training. In the context of this paper, all other classes except the class given for training are called alien classes. During testing, the classifier may encounter objects from alien classes. The goal of the classifier is to distinguish the objects of the known class from the objects of alien classes. It should be noted that one-class classification is different from binary classification due to the absence of training data from a second class. One-class classification is encountered in many real-world computer vision applications including novelty detection _cite_, anomaly detection _cite_, _cite_, medical imaging and mobile active authentication _cite_, _cite_, _cite_, _cite_ . In all of these applications, unavailability of samples from alien classes is either due to the openness of the problem or due to the high cost associated with obtaining the samples of such classes. For example, in a novelty detection application, it is counter intuitive to come up with novel samples to train a classifier. On the other hand, in mobile active authentication, samples of alternative classes (users) are often difficult to obtain due to the privacy concerns _cite_ . Despite its importance, contemporary one-class classification schemes trained solely on the given concept have failed to produce promising results in real-world datasets (_cite_, _cite_ has achieved an Area Under the Curve in the range of N \%-N \% for CIFARN dataset _cite_ _cite_) . However, we note that computer vision is a field rich with labeled datasets of different domains. In this work, in the spirit of transfer learning, we step aside from the conventional one-class classification protocol and investigate how data from a different domain can be used to solve the one-class classification problem. We name this specific problem One-class transfer learning and address it by engineering deep features targeting one-class classification tasks. In order to solve the One-class transfer learning problem, we seek motivation from generic object classification frameworks. Many previous works in object classification have focused on improving either the feature or the classifier (or in some cases both) in an attempt to improve the classification performance. In particular, various deep learning-based feature extraction and classification methods have been proposed in the literature and have gained a lot of traction in recent years _cite_, _cite_ . In general, deep learning-based classification schemes have two subnetworks, a feature extraction network (_inline_eq_) followed by a classification sub network (_inline_eq_), that are learned jointly during training. For example, in the popular AlexNet architecture _cite_, the collection of convolution layers may be regarded as (_inline_eq_) where as fully connected layers may collectively be regarded as (_inline_eq_) . Depending on the output of the classification sub network (_inline_eq_), one or more losses are evaluated to facilitate training. Deep learning requires the availability of multiple classes for training and extremely large number of training samples (in the order of thousands or millions) . However, in learning tasks where either of these conditions are not met, the following alternative strategies are used: \noindent (a) Multiple classes, many training samples: This is the case where both requirements are satisfied. Both feature extraction and classification networks, _inline_eq_ and _inline_eq_ are trained end-to-end (Figure~ _ref_ (a)) . The network parameters are initialized using random weights. Resultant model is used as the pre-trained model for fine tuning _cite_, _cite_, _cite_ . \noindent (b) Multiple classes, low to medium number of training samples: The feature extraction network from a pre-trained model is used. Only a new classification network is trained in the case of low training samples (Figure~ _ref_ (b)) . When medium number of training samples are available, feature extraction network (_inline_eq_) is divided into two sub-networks-shared feature network (_inline_eq_) and learned feature network (_inline_eq_), where _inline_eq_ . Here, _inline_eq_ is taken from a pre-trained model. _inline_eq_ and the classifier are learned from the data in an end-to-end fashion (Figure~ _ref_ (c)) . This strategy is often referred to as fine-tuning _cite_ . \noindent (c) Single class or no training data: A pre-trained model is used to extract features. The pre-trained model used here could be a model trained from scratch (as in (a)) or a model resulting from fine-tuning (as in (b)) _cite_, _cite_ where training/fine-tuning is performed based on an external dataset. When training data from a class is available, a one-class classifier is trained on the extracted features (Figure~ _ref_ (d)) . In this work, we focus on the task presented in case (c) where training data from a single class is available. Strategy used in case (c) above uses deep-features extracted from a pre-trained model, where training is carried out on a different dataset, to perform one-class classification. However, there is no guarantee that features extracted in this fashion will be as effective in the new one-class classification task. In this work, we present a feature fine tuning framework which produces deep features that are specialized to the task at hand. Once the features are extracted, they can be used to perform classification using the strategy discussed in (c) . In our formulation (shown in Figure~ _ref_ (e)), starting from a pre-trained deep model, we freeze initial features (_inline_eq_) and learn (_inline_eq_) and (_inline_eq_) . Based on the output of the classification sub-network (_inline_eq_), two losses compactness loss and descriptiveness loss are evaluated. These two losses, introduced in the subsequent sections, are used to assess the quality of the learned deep feature. We use the provided one-class dataset to calculate the compactness loss . An external multi-class reference dataset is used to evaluate the descriptiveness loss . As shown in Figure~ _ref_, weights of _inline_eq_ and _inline_eq_ are learned in the proposed method through back-propagation from the composite loss. Once training is converged, system shown in setup in Figure~ _ref_ (d) is used to perform classification where the resulting model is used as the pre-trained model. In summary, this paper makes the following three contributions. Rest of the paper is organized as follows. In Section~ _ref_, we review a few related works. Details of the proposed deep one-class classification method are given in Section~ _ref_ . Experimental results are presented in Section~ _ref_ . Section~ _ref_ concludes the paper with a brief discussion and summary.