Recently, the multimodal learning between image and language _cite_ has become an increasingly popular research area of artificial intelligence (AI) . In particular, there have been rapid progresses on the tasks of bidirectional image and sentence retrieval _cite_, and automatic image captioning _cite_ . In order to further advance the multimodal learning and push the boundary of AI research, a new ``AI-complete'' task, namely the visual question answering (VQA) _cite_ or image question answering (QA) _cite_, is recently proposed. Generally, it takes an image and a free-form, natural-language like question about the image as the input and produces an answer to the image and question. Image QA differs with the other multimodal learning tasks between image and sentence, such as the automatic image captioning. The answer produced by the image QA needs to be conditioned on both the image and question. As such, the image QA involves more interactions between image and language. As illustrated in Figure _ref_, the image contents are complicated, containing multiple different objects. The questions about the images are very specific, which requires a detailed understanding of the image content. For the question `` '', we need not only identify the blue objects in the image but also compare their sizes to generate the correct answer. For the question `` '', we need to identify the object `` '' in the non-salient region of the image and figure out its quantity. A successful image QA model needs to be built upon good representations of the image and question. Recently, deep neural networks have been used to learn image and sentence representations. In particular, convolutional neural networks (CNNs) are extensively used to learn the image representation for image recognition _cite_ . CNNs _cite_ also demonstrate their powerful abilities on the sentence representation for paraphrase, sentiment analysis, and so on. Moreover, deep neural networks _cite_ are used to capture the relations between image and sentence for image captioning and retrieval. However, for the image QA task, the ability of CNN has not been studied. In this paper, we employ CNN to address the image QA problem. Our proposed CNN model, trained on a set of triplets consisting of (image, question, answer), can answer free-form, natural-language like questions about the image. Our main contributions are: