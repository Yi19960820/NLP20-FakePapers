As the railway operator for a country of over one billion people, China Railway is one of world's largest, selling N million tickets per day _cite_ . During peak holiday travel periods, this rate can increase to as much as N thousand tickets per minute. Tickets for China Railway trains can be purchased through their website, _url_ . Due to the high demand of tickets, their website is a primary target for sophisticated scalpers, who use automated attacks to purchase large volumes of tickets in order to resell them for a significant profit. Thus, it is critical that China Railway employ a strong captcha system to protect China's citizens from being swindled. In response to these threats, China Railway created a captcha that is similar to Google's reCaptcha _cite_ . When attempting to purchase a ticket, a user is presented with a phrase, written in distorted Chinese characters, and eight images. The user must select all of the images that are relevant to the specified phrase. For an example, see Figure _ref_ . There are a few significant aspects of this system that make this task particularly difficult for automated agents. First, unlike the other text in the captcha, the relevant phrase is actually a distorted, low-resolution image of Chinese characters. Henceforth, we will refer to the images of the phrases as codes in order to avoid confusion with the other images presented in the captcha. In addition to the codes, the presented images are also of low quality and subject to random noise. The low quality of both types of images makes it difficult to develop effective algorithms. Finally, and most importantly, there is a complete absence of labeled data for both the codes and the images. This severely restricted our ability to leverage recent advancements in supervised learning that have become popular in recent years _cite_ . Thus, we turn to an unsupervised, graph-based approach to solve this problem. For an automated system to defeat this captcha, it must learn to associate the codes and their corresponding images. In formulating our approach, we made the following assumptions. First, when a code is presented, we assume that there is at least one relevant image. Second, we assume there may be more than one relevant image but irrelevant images tend to appear only once and at random. Based on these assumptions, we were able to exploit two kinds of co-occurrence relationships for this task: between pairs of images and between codes and images, based on their co-occurrence in each captcha. We see a few distinct subproblems of this task. Our approach needs to learn to map variations of a single code to the same point in latent space. Second, we need to cluster images of the same type of object. Finally, we need to learn the correct association between the latent representations of the codes and the image clusters. By exploiting the co-occurrence information, we can couple the learning and inference of these processes using a graph. Our goal was to construct a large graph to relate both images to each other as well as the codes and the images. To do this, we first trained a deep convolutional neural network (DCNN) to develop feature representations for Chinese characters that were robust to a variety of deformations and transformations. We randomly selected N Chinese phrases, including some ground truth phrases, and generated thousands of random transformations of each of these phrases to use as our training set. Using this DCNN, we then projected all of the codes into a probability distribution in this N-dimensional ``latent'' space. Note that the exact choice of the N phrases was unimportant because our goal was not to classify the codes; we simply wanted a useful latent space in which to cluster them. However, we did include some ground truth phrases in this set of N in order to evaluate this DCNN component in isolation, as will be discussed in Section _ref_ . Next, we constructed a weighted graph of N million images. In the graph, each vertex was associated with an image, and we connected pairs of image vertices based on feature similarity and their co-occurrence statistics. These vertices were further linked to an additional set of vertices, one for each of the _inline_eq_ codes, via a dongle. The dongle was used to encode the number of times an image appeared in a captcha and thus our confidence in the relationship between the images and codes. Associated with each of these code vertices was its N-dimensional latent representation, denoted _inline_eq_ . For each of the code vertices, we connected it to the dongle of an image vertex if the code and the image co-occurred in some captcha. Finally, we performed label propagation on this graph, as described in _cite_, to learn a latent representation for each of the images. Armed with the representations of the codes and images in the same latent space, we then chose the relevant images given a presented code. A representative subsection of the resulting graph is shown in Figure _ref_, and for more details, see Section _ref_ . Our results are promising. Our system solved N \% of test image challenges with an average response time of around N seconds. This is especially impressive because findings show that average human performance is between N \% and N \% on image-based captchas depending on the specific captcha implementation _cite_ . In addition, there is promise of improvement over a recently released system by _cite_ . Their model solved about N \% of Google's image reCaptcha challenges _cite_, although direct comparisons of the two systems are difficult due to differences in the captcha implementations. The major contributions of this work are as follows: