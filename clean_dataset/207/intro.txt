Generative models aim to solve the problem of density estimation by learning the model distribution _inline_eq_, which approximates the true but unknown data distribution of _inline_eq_ using a set of training examples drawn from _inline_eq_ _cite_ . The generative adversarial networks (GANs) _cite_ family of generative models implicitly estimate a data distribution without requiring an analytic expression or variational bounds of _inline_eq_ . GANs have been mainly used for image generation, with impressive results, producing sharp and realistic images of natural scenes. The flexibility of the model definition and high quality outcomes has seen GANs applied to many real-world applications, including super-resolution, colorization, face generation, image completion, etc. _cite_ . Training a GAN requires two separate networks with competitive goals: a discriminator, _inline_eq_, to distinguish between the real and fake data; and a generator, _inline_eq_, to create as real as possible data to fool the discriminator. Consequently, the generator implicitly models _inline_eq_, which approximates _inline_eq_ . This problem may be formulated as a minimax game _cite_, \vskip-N \} \ + \ _ {z \sim _ {}} \left \, \] \vskip-N where _inline_eq_ denotes expectation, _inline_eq_ and _inline_eq_ are samples drawn from _inline_eq_ and _inline_eq_ respectively. When the generator produces perfect samples (i.e., _inline_eq_), the discriminator cannot distinguish between real and fake data, and the game ends because it reaches a Nash equilibrium. Although GANs have been successful in the image generation field, training process instabilities, such as extreme sensitivity of network structure and parameter tuning, are well-known disadvantages. Training instability produces two major problems: gradient vanishing and mode collapse. Gradient vanishing becomes a serious problem when any subset of _inline_eq_ and _inline_eq_ are disjointed such that the discriminator separates real and fake data perfectly; i.e., the generator no longer improves the data because the discriminator has reached its optimum _cite_ . This produces poor results, because training stops even though _inline_eq_ has not learned _inline_eq_ properly. Mode collapse is where the generator repeatedly produces the same or similar output because _inline_eq_ only encapsulates the major or single modes of _inline_eq_ to easily fool the discriminator. The trade-off between image quality and mode collapse has been theoretically and empirically investigated in previous studies _cite_, and generally either visual quality or image diversity has been achieved, but not both simultaneously. Visual quality can be achieved by minimizing reverse Kullback-Leibler (KL) divergence, which is suggested in standard GANs including _cite_ . Meanwhile, image diversity is strongly correlated with minimizing forward KL divergence _cite_ . Recent techniques _cite_ have introduced a gradient penalty to regularize the divergence (or distance) for training GANs, and break the trade-off. The gradient penalty smooths the learning curve, improving training stability. Consequently, the gradient penalty is effective to improve both visual quality and image diversity, and has been evaluated for various GAN architectures. We propose an unsupervised approach to regularize the discriminator using representative features. This approach is similar to the gradient penalty, in that it also aims to stabilize training and break the trade-off between visual quality and image diversity, but does not modify the GAN objective function (i.e., the same divergence or loss definition are employed as a baseline GAN) . Rather, we introduce representative features from a pre-trained autoencoder (AE) and transfer them to a discriminator to train the GAN. Because the AE learns to minimize forward KL divergence, adding its representative features to the discriminator of standard GAN lead the discriminator to consider two divergences (i.e., reverse and forward KL) . Since forward KL tends to average the overall modes of data distributions during training _cite_, our representation features provide the overall mode information. Meanwhile, the objective of baseline discriminator pursues the reserve KL, thus tends to choose a single (few) mode of the data distribution. In other words, the discriminator is implicitly interrupted by representative features for discrimination, and encouraged to consider the overall data distribution. The pre-trained AE learns from _inline_eq_ samples and is then fixed. Isolating representative feature extraction from GAN training guarantees that the pre-trained AE embedding space and corresponding features have representative power. Since the representative features are derived from the pre-trained network, they are more informative during early stage discriminator training, which accelerates early stage GAN training. In addition, representative features provide the overall mode information as mentioned earlier, thus preventing GANs from mode collapse. Although the representative features no longer distinguish real and fake images in the second half of training, the discriminative features continue to learn toward improving the discrimination power. Note that the total loss of the proposed model consists of loss of representative and discriminative features, and the discriminator learns the balance between them from the training data automatically. Therefore, the proposed approach stably improve both visual quality and image diversity of generated samples. We call this new architecture a representative feature based generative adversarial network (RFGAN) . The major contributions of this paper are as follows. Section~ _ref_ reviews recent studies and analyzes how the proposed RFGAN relates to them. Section~ _ref_ discusses RFGAN architecture and distinctive characteristics, and Section~ _ref_ summarizes the results of extensive experiments including simulated and real data. The quantitative and qualitative evaluations show that the proposed RFGAN simultaneously improved image quality and diversity. Finally, Section~ _ref_ summarizes and concludes the paper, and discusses some future research directions.