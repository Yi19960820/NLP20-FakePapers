practice relies heavily on visual examination of skin lesions. Thus, it is not surprising that interest in Computer Vision based diagnosis technology in this field is growing. The goal of automatically understanding dermatological images is tremendously challenging, however, since much like human vision itself what is understood about how diagnostic expertise actually operates is subjective and limited. Many of those who take up this challenge focus on detection of Cutaneous (skin) Melanoma through dermoscopy image analysis. Melanoma is the most life-threatening form of skin cancer. Dermoscopy is a non-invasive, in-vivo skin examination technique that uses optical magnification and cross-polarized lighting to allow enhanced visualization of lesion characteristics which are often not discernible by the naked eye. Early detection of melanoma is paramount to patients' prognosis towards greater survival. The challenges involved in clinical diagnosis of early melanoma have provoked increased interest in computer-aided diagnosis systems through automatic analysis of digital dermoscopy images. In this paper, we focus on the identification of blue-whitish structures (BWS), one of the most important findings through dermoscopic examination in making a diagnosis of invasive melanoma _cite_ . The term Blue-white structures is a unified heading for features also known as Blue-white veil and Regression structures (this is discussed below in \S _ref_) . To this aim, a typical approach would be based on the classical paradigm of supervised learning requiring extensively annotating each dermoscopic image with instances of BWS, in all training images. This is difficult (or even impossible) to be carried accurately and consistently due to subjectivity of feature definition and poor inter-observer agreement. The dermoscopy data in fact available to us has motivated a different, more challenging, research problem. In this dataset _cite_, image-level labels encode only whether an image contains a dermoscopic feature or not, but the features themselves are not locally annotated. In Computer Vision this situation is referred to as weakly-labelled data. To approach this problem, we use the multiple instance learning (MIL) paradigm. MIL is a relatively new learning paradigm, and has broad applications in computer vision, text processing, etc. Unlike standard supervised learning, where each training instance is labeled, MIL is a type of weakly supervised learning, where the instance labels are ambiguous (more on this in \S _ref_) . Our goal is to learn to identify and localize BWS using this weakly-labelled data (i.e. \with minimal supervision) . Learning to localize dermoscopic features with minimal supervision is an important class of problem. It provides an improvement on the scope of modelling for computerized image analysis of skin lesions because the vast majority of data available are in fact weakly-labeled. Surprisingly, this class of problem is the least studied in the relevant literature.