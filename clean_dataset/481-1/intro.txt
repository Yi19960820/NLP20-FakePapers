We are amid a transition from traditional pathology to digital pathology where scanners are replacing microscopes rapidly. Capturing the tissue characteristics in digital formats opens new horizons for diagnosis in medicine. On on hand, we will need to store thousands and thousands of specimens in large physical archives of glass samples. This will be a relief for many hospitals with limited space. On the other hand, acquiring an image from the specimen enables more systematic analysis, collaborations possibilities and, last but not least, the computer-aided diagnosis for pathology, arguable the final frontier of vision-based disease diagnosis. However, like any other technology, digital pathology comes with its own challenges; whole-scan imaging generally generates gigapixel files that also require (digital) storage and are not easy to analyze via computer algorithms. Detection, segmentation, and identification of tissue types in huge digital images, e.g., N, N _inline_eq_ N, N pixels, appears to be a quite daunting task for computer vision algorithms. Looking at the computer vision community, the emergence of deep learning and its vast possibilities for recognition and classification seems to be a lucky coincidence when we intend to address the above-mentioned obstacles of digital pathology. Diverse deep architectures have been trained with large set of images, e.g., project or database, to perform difficult tasks like object classification and face recognition. The results have been more than impressive; one may objectively speak of a computational revolution. Accuracy numbers in mid and high Ns have become quite common when deep networks, trained with millions of images, are tested to recognize unseen samples. In spite of all progress, one can observe that the applications of deep learning in digital pathology hast not fully started yet. The major obstacle appears to be the lack of large labelled datasets of histopathology scans to properly train some type of multi-layer neural networks, a requirement that may still be missing for some years to come. Hence, we have to start designing and training deep nets with the available datasets. Training from scratch when we artificially increase the number of images, i.e., data augmentation, is certainly the most obvious action. But we can also use nets that have been trained with millions of (non-medical) images to extract . As a last possibility, we could slightly train (fine-tune) the pre-trained nets to adjust them to the nature of or data before we use them as feature extractors or classifiers. In this paper, we investigate the usage of deep networks for via training from scratch, feature extraction, and fine-tuning. The results show that employing a pre-trained network (trained with non-medical images) may be the most viable option.