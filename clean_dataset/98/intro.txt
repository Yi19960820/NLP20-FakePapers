The development of deep learning makes remarkable progresses in many tasks _cite_ . To achieve all of them, large amounts of thousands and even millions of labeled data are required for the deep learning approach to obtain satisfactory performance. However, collecting and annotating abundant data is notoriously expensive. Therefore, few-shot learning _cite_ which requires the model to learn from a few data, has attracted researchers' attention in recent years. Learning from few-data is challenging for Computer Vision. In comparison, we human beings can rapidly learn new categories from very few examples. Recently, meta-learning _cite_ has shown promising performance to improve the few-shot learning for Computer Vision. However, existing meta-learning methods commonly ignore prior-knowledge _cite_ and attention mechanism _cite_ which have been both demonstrated important for human cognitive and learning process. We illustrate a few-shot classification problem in Fig. _ref_ for a better understanding of the role of prior-knowledge and attention mechanism in human few-shot learning. In Fig. _ref_, we unconsciously leverage our learned knowledge about the world to understand and express these images into high-level compact representations, such as plant, animal, tree, and table However, according to the four training images, we discover that only the feature of the tree and table are useful for us to recognize these two classes of images. Then, we quickly adjust ourselves to pay attention to the critical features and make the decision based on the focused features. Evidently, we can summarize two main modules in human few-shot learning: a stable Representation module that utilizes prior-knowledge to express the image into compact feature representations; and a smart attention-based decision logical module that adapts accurately and performs recognition based on the feature representations . While existing meta-learning approaches commonly train meta-learners to learn adaptive networks directly based on the original input data with no attention mechanism and prior-knowledge. In this paper, inspired by the human cognition process, we present a novel paradigm of meta-learning approach with three developments to introduce attention mechanism and prior-knowledge step-by-step for meta-learning. Here, we briefly introduce the proposed methods. N) The first method is A ttention based M eta-L earning (AML) which leverages attention mechanism to enable the meta-learner paying more attention on essential feature. N) For the meta-learner enjoying not only attention but also prior-knowledge, we present another method R epresentation and A ttention based M eta-L earning (RAML) . Its network contains a Representation module and an attention-based prediction (ABP) module. The Representation module is similar to the same module of human vision. It learns the prior-knowledge in a supervised fashion and is responsible for understanding and extracting stable compact feature representations from the input image. The ABP module plays the same role as the smart attention-based decision logic module of human vision. It enables the meta-learner to precisely adjusting first its attention to the most discriminative feature representations of input images and second the corresponding predictions. N) In the third method, to take full advantage of endless unlabeled data, we design a novel method where the Representation module learns the past knowledge in unsupervised fashion _cite_ . We call this method U nsupervised R epresentation and A ttention based M eta-L earning (URAML) . With URAML, we show in our experiments that the growth of the number of unlabeled data and the development of unsupervised learning both improve the performance of URAML apparently. In addition, we show a Task-Over-Fitting (TOF) problem for existing meta-learning and present a Cross-Entropy across Tasks (CET) metric to evaluate how much a meta-learning method is troubled by the TOF problem. An example of the TOF problem is, the meta-learner trained on N-way N-shot tasks is not as capable as the one trained on N-way N-shot tasks when they are tested on N-way N-shot tasks, and vice versa. However, in practical applications, it is uncertain how much data and how many shot times are available to the meta-learner to learn. Therefore, we argue that the trained meta-learner should generalizes well to different _inline_eq_-shot tasks. The possible reason behind the TOF problem is that existing meta-learners are vulnerable to the features irrelevant to the presented tasks since they ignoring both priori knowledge and attention mechanism. Our experiment validates that by incorporating prior-knowledge and attention mechanism, our methods suffer less from the TOF problem than existing meta-learning methods. We summarize the main contributions of our work as: