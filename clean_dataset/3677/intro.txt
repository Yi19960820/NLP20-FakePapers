The performance of machine learning (ML) algorithms depends on data representation because different representations can entangle different explanatory factors of variation behind the data. Although prior knowledge can help us design representations, the vast demand of ML algorithms in various AI domains cannot be met as feature engineering is labor-intensive and needs domain expert knowledge. Therefore, the ML algorithms that can automatically learn good representations of data will definitely make it easier for people to extract useful information when building classifiers or predictors. Among all the criteria of learning good representations discussed in, disentangling factors of variation is an important one that helps separate various explanatory factors. For example, given a human-face image, we can obtain various facial characteristics about the person, including gender, hair style, facial expression, with/without eyeglasses and so on. However, it is quite difficult to train a single classifier which can handle different facial characteristics or attributes entangled in a single image. If we could obtain a disentangled representation of the face image, we can train a single classifier for multiple attributes. In this paper, we propose a supervised method called DNA-GAN to obtain the disentangled representations of images. The idea of DNA-GAN is motivated by the DNA double helix structure, in which different kinds of traits are encoded in different DNA pieces, respectively. We make a similar assumption that different visual attributes in an image are controlled by different pieces of encodings in its latent representations. In DNA-GAN, an encoder is used to encode an image to the attribute-relevant part and the attribute-irrelevant part, where different pieces in the attribute-relevant part encode information of different attributes, and the attribute-irrelevant part encodes other information. For example, given a facial image, we are trying to obtain a latent representation that each individual part controls different attributes, such as hairstyles, genders, expressions and so on. These attributes are expected to be encoded into disentangled attribute-relevant parts in the latent representations, whereas other information such as background should be encoded into attributes-irrelevant parts. Through annihilating the recessive pieces and swapping certain pieces, we can obtain some novel crossbreeds that can be decoded into new images. With the help of the adversarial discriminator loss and the reconstruction loss, DNA-GAN can reconstruct the input images and generate new images with new attributes. Each attribute is disentangled from the other gradually though a process of iterative training. Finally, we are able to obtain the disentangled representations from the latent representations. The summary of contributions of our work is as follows: