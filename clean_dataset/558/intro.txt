The localisation and identification of anatomical structures is a significant part of any medical image analysis routine. In spine's context, labelling of vertebrae has immediate diagnostic and modelling significance, e.g.: localised vertebrae are used as markers for detecting kyphosis or scoliosis, vertebral fractures, in surgical planning, or for follow-up analysis tasks such as vertebral segmentation or their bio-mechanical modelling for load analysis. \noindent Vertebrae labelling. Like several analysis approaches off-late, vertebrae labelling has seen successful utilisation of machine learning. One of the incipient and notable works by Glocker et al. _cite_, followed by _cite_ used context-based features with regression forests and Markov models for labelling. In spite of their intuitive motivation, these approaches suffer a setback due to limited FOVs or presence of metal insertions. On a similar footing, _cite_ proposed a deep multi-layer perceptron using long-range context features. With the emergence of convolutional neural networks (CNN), Chen et al. _cite_ proposed a joint-CNN as a combination of a random forest for initial candidate selection followed by a CNN trained to identify the vertebra based on its appearance and a conditional dependency on its neighbours. Without hand-crafting features this approach performed remarkably well. However, since the CNN works on a limited region around the vertebra, it results in a high variability of the localisation distance. Recently, Yang et al., with _cite_ and _cite_, proposed a deep, volumetric, fully-convolutional ND network (FCN) called DININ with deep-supervision. The output of DININ is improved in subsequent stages that employ either message-passing across channels or a convolutional LSTM followed by further tuning with a shape dictionary. Owing to equivariance of the convolutional operator and limited receptive field, an FCN doesn't always learn the anatomy of the region-of-interest. This is a severe limitation as human-equivalent learning utilises anatomical details aided with prior knowledge. An immediate remedy is to increase the receptive field by going deeper. However, this comes at the cost of higher model complexity or is just unfeasible due to memory constraints when working with volumetric data. \noindent Prior \& adversarial learning in CNNs. Recent work in _cite_ and _cite_ propose encoding (anatomical) segmentation priors into an FCN by learning the shape representation using an auto encoder (AE) . The segmentation is expressed in terms of a pre-learnt latent space for evaluating a prior-oriented loss, which is then used to guide the FCN into predicting an anatomically sound segmentation. Our approach shares similarities with this approach with certain fundamental differences: (N) Our approach is aimed at localisation, which requires a redefinition of the notion of anatomical . (N) We employ an AE for shape regularisation, but do not `pre-train' it to learn the latent space. We train the AE adversarially in tandem with the FCN. Parallels can be drawn between end-to-end learning of priors and learning the distribution of priors using generative adversarial networks (GANs) . Both have two networks, a predictor (generator) and an auxiliary network which works on the `goodness' of the prediction. In medical image analysis where scan sizes are large and data are few, inspired from an energy-based adversarial generation framework (Zhao et al., _cite_), it is preferable to employ an adversary providing an anatomically-inspired supervision instead of the usual binary adversarial supervision (vanilla GAN) . \noindent Our contribution. In this work, we propose an end-to-end solution for vertebrae labelling by adversarially training an FCN, thereby encoding the local spine structure into it. More precisely, relying on the sufficiency of information in certain ND projections of ND data, we propose: (N) A butterfly-shaped network that operates on ND sagittal and coronal reformations, combining information across these views at a large receptive field, (N) Encoding the spine's structure into the Btrfly net using an energy-based, fully-convolutional, adversarial auto encoder acting as a discriminator. Our approach attains identification rates above N \% without any post-processing stages, achieving state-of-art performance.