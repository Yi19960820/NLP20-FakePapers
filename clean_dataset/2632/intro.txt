Deep Convolutional Neural Network based models are today the state-of-the-art for most computer vision tasks. Seeds of the idea of deep learning were sown around the late N's ~ _cite_ and it gained popularity in N when AlexNet ~ _cite_ won the challenging ILSVRC (ImageNet Large-Scale Visual Recognition Challenge) N competition ~ _cite_, demonstrating an astounding improvement over the then state-of-the-art image classification techniques. AlexNet reported a top-N test error rate of N \%. This was soon followed by an upsurge of deep models for computer vision tasks from all over the community. ZFNet ~ _cite_, the winner of ILSVRC N improved upon AlexNet to bring down the top-N test error rate to N \%. Through their novel visualization techniques, they provided good intuition to the workings on CNNs and illustrated more ways to improve performance. They argued that this renewed interest (since they were proposed in N ~ _cite_) in CNNs is due to the accessibility of large training sets and increased computational power, thanks to GPUs. VGGNet ~ _cite_ demonstrated that a simpler, but deeper model can be used to bring the error further down to N \%. Their work reinforced the idea that Convolutional Neural Networks have to be deep enough for the hierarchical representation of visual data to be effective. Then came the even deeper GoogLeNet ~ _cite_, the winner of ILSVRC N, that became the first CNN to be fundamentally architecturally different from AlexNet. GoogLeNet introduced the idea that CNN layers didn't always have to be stacked up sequentially. ResNet ~ _cite_ was even deeper, a phenomenal N layer deep network and won ILSVRC N with an incredible error rate of N \%, beating humans in the image classification task. Similarly, for object detection tasks, the first significant advancement in deep learning was made by RCNNs ~ _cite_, which was followed by Fast RCNN ~ _cite_ and then Faster RCNN ~ _cite_ for performance improvement. More recently, YOLO ~ _cite_ and YOLON ~ _cite_ have emerged as the state-of-the-art in object detection. YOLO's architecture is inspired by GoogLeNet and consists of N convolutional layers followed by two fully connected layers. State-of-the-art face recognition techniques such as DeepFace ~ _cite_, DeepIDN ~ _cite_, Deep Face Recognition ~ _cite_ and FaceNet ~ _cite_ also consist of deep convolutional networks. Similar is the story with state-of-the-art scene recognition techniques ~ _cite_, and other computer vision tasks such as age and gender classification~ _cite_ etc. Every coin, however, has two sides and so is the case with this golden coin of deep learning. While deeper models are increasingly improving for computer vision tasks, they pose challenges of increased training complexity, enormous data requirements and high labeling costs. Training complexity and huge data requirements is due to the depth of the network and large number of parameters to be learnt. A large deep neural net with a large number of parameters to learn (and hence a large degree of freedom) has a very complex and extremely non-convex error surface to traverse and thus it requires a great deal of data to successfully search for a reasonably optimal point on that surface. AlexNet, for example was trained on ImageNet data ~ _cite_, which contained over N million annotated images from a total of over N, N categories. It was trained on two GTX N GPUs for five to six days. ZFNet used N million images and trained on a GTX N GPU for twelve days. VGGNet has N million parameters to learn and was trained on N Nvidia Titan Black GPUs for two to three weeks. GoogLeNet was trained on ``a few high-end GPUs within a week''. ResNet was trained on an N GPU machine for two to three weeks. One way researchers have addressed this challenge is through architectural modifications to the network. For example, by making significant architectural changes, GoogLeNet improved utilization of the computing resources inside the network thus allowing for increased depth and width of the network while keeping the computational budget constant. Similarly, by explicitly reformulating the layers as learnt residual functions with reference to the layer inputs, instead of learning unreferenced functions, ResNet allows for easy training of much deeper networks. Highway networks ~ _cite_ introduce a new architecture allowing a network to be trained directly through simple gradient descent. With the goal of reducing training complexity, some other studies ~ _cite_ have also focused on model compression techniques. On similar lines, studies like ~ _cite_ propose simpler network architectures in favor of availability of limited training data. In this work, however, we are addressing this approach. Other approaches advocate use of pre-trained models, trained on large data sets and presented as `ready-to-use' but they rarely work out of the box for domain specific computer vision tasks (such as detecting security sensitive objects) . It thus becomes important to create customized models, which again potentially require significant amount of training data. Domain adaptation techniques like transfer learning and fine tuning allow creation of customized models with much lesser data. Transfer learning allows models trained on one task to be easily reused for a different task ~ _cite_ . Several studies ~ _cite_ have analyzed the transferability of features in deep convolutional networks across different computer vision tasks. It has been demonstrated that transferring features even from distant tasks can be better than using random features and that deep convolutional features can be the preferred choice in most visual recognition tasks. In a yet another interesting approach for reducing data requirements, Spatial Transfer Networks ~ _cite_ explore the idea of transforming the image (and not the architecture) to make the model invariant to images with different scales and rotations which could have otherwise been achieved only by a lot more data. In our work, we demonstrate the utility of subset selection methods in alleviating this big data problem. Orthogonal to the challenge of training complexity is the challenge of unavailability of labeled data. Human labeling efforts are costly and grow exponentially with the size of the dataset ~ _cite_ . Again, several approaches have been proposed to address this problem. In ~ _cite_ the authors describe a weakly supervised convolutional neural network (CNN) for object classification that relies only on image-level labels, yet can learn from cluttered scenes containing multiple objects to produce their approximate locations. Zero-shot learning ~ _cite_ and one-shot learning ~ _cite_ techniques also help address the issue of lack of annotated examples. On the other hand, active learning approaches try to minimize the labeling costs. The core idea behind active learning ~ _cite_ is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. In our work we demonstrate the utility of various subset selection functions in active learning setting thereby identifying an even smaller set of data points to label for computer vision tasks, yet incurring minimal performance loss. A common approach for training data subset selection is to use the concept of a coreset ~ _cite_, which aims to efficiently approximate various geometric extent measures over a large set of data instances via a small subset. Submodular functions naturally model the notion of diversity, representation and coverage and hence submodular function optimization has been applied to recommendation systems to recommend relevant and diverse items which explicitly takes the coverage of user interest into account ~ _cite_ . It has also been applied to data summarization and data partitioning ~ _cite_ .Training data subset selection has been studied as a problem of submodular maximization, where appropriate submodular functions are chosen to measure the utility of each subset for an underlying task ~ _cite_ . There have been very few studies in active learning and subset selection for Computer Vision tasks. In ~ _cite_, Gavves et al combine techniques from transfer learning, active learning and zero-shot learning to reuse existing knowledge and reduce labeling efforts. Zero-shot learning techniques don't expect any annotated samples, unlike active learning and transfer learning which assume either the availability of at least a few labeled target training samples or an overlap with existing labels from other datasets. By using a max-margin formulation (which transfers knowledge from zero-shot learning models used as priors) they present two basic conditions to choose greedily only the most relevant samples to be annotated, and this forms the basis of their active learning algorithm. Using information theoretic objective function such as mutual information between the labels, Sourati et al have developed a framework ~ _cite_ for evaluating and maximizing this objective for batch mode active learning. Another recent study has adapted batch active learning to deep models ~ _cite_ . Most batch-active learning techniques involve the computation of Fisher matrix which is intractable for deep networks. Their method relies on computationally tractable approximation of the Fisher matrix, thus making them relevant in the context of deep learning. Our work is more closely related to the work of ~ _cite_ which has shown the mathematical connection of submodularity to the data likelihood functions for Naive Bayes and Nearest Neighbor classifiers, thereby allowing for formulation of the data subset selection problems for these classifiers as constrained submodular maximization. They extend this framework to active learning, combining the uncertainty sampling method with a submodular data subset selection framework. They argue that while traditional active learning techniques aim at labeling the most informative instances, these methods neglect the notion of representativeness which can be useful to reduce the size of the subset further by eliminating redundancy. Their work is mainly theoretical and was applied in the context of text recognition. This work attempts to study the role of subset selection in computer vision tasks, where we apply the framework of submodular subset selection and active learning to large scale image recognition tasks. Our submodular subset selection framework naturally combines the notion of informativeness as well as representativeness. Our work can easily be extended to other query strategies like . Extending the work of ~ _cite_, in this work, we make three significant contributions: