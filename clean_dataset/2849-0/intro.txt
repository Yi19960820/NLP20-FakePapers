Deep neural networks have drawn broad attention due to its impressive performance on a variety of tasks. Training a deep neural network usually requires a large labeled dataset. However, collecting and annotating a dataset for each new task is time-consuming and expensive. Fortunately, there are often a large amount of data available from other related domains and tasks and using the auxiliary data may alleviate the necessity of annotating a new dataset. However, due to factors such as image condition and illumination, datasets from two domains usually have different distributions. When the model trained on one dataset is tested on the other, the performance often greatly drops due to the `domain shift' problem. Domain adaption, as a sub-line of transfer learning, aims to solve the `domain shift' problem. For unsupervised domain adaption, where all samples in the target domain are unlabeled, many studies try to align the statistical distributions of the source and target domains using various mechanisms, such as maximum mean discrepancy (MMD) ~ _cite_, correlation alignment (CORAL) ~ _cite_ and Kullback-Leibler (KL) divergence~ _cite_ . Recently, adversarial learning is adopted to align the distributions by extracting features which are indistinguishable by the domain discriminator _cite_ . Usually two separate encoders are trained, one for source domain and one for target domain. The source encoder is usually pretrained first and fixed during domain adaption. In this paper, we propose a simple but effective model for unsupervised domain adaption. Inspired by the fact that humans can correctly recognize an object without being aware of its domain, we design a Domain-Invariant Adversarial Learning (DIAL) network, consisting of an encoder, a classifier, and a discriminator (Fig. _ref_), for representations that are both domain-invariant and discriminative. Unlike the models using two separate feature extractors for the source and target domains, DIAL shares a single encoder between two domains and has no need to know the source of images during testing. The extracted features are then sent to the adversarial discriminator. The encoder and the discriminator play a min-max game, with the goal that the source of features cannot be distinguished by the discriminator. In this way, the encoder is expected to learn domain-invariant representations and ignore domain-specific information. Furthermore, to enforce the discriminative power of feature representations, with the labeled data in the source domain, we introduce the center loss. We also align the conditional distribution of the source and target domains, which has been largely ignored by existing adversarial-based domain adaption methods. However, aligning conditional distribution _inline_eq_ is quite challenging due to the absence of labels in target domain. We thus resort to the pesudo labels in target domain and align the class-conditional distribution _inline_eq_, which is expected to guide the target features to fall into correct clusters. With the above design, the feature representations of the two domains are learned simultaneously, unlike previous studies where the source features are fixed during adaptation. We evaluate the proposed DIAL on several unsupervised benchmarks and achieve new state-of-the-art results. The main contributions of this paper are summarized as following.