Face hallucination, which generates high-resolution (HR) facial images from low-resolution (LR) inputs, has attracted great interests in the past few years. However, most of existing works do not take the recovery of identity information into consideration such that they cannot generate faces closed to the real identity. Fig. _ref_ shows some examples of hallucinated facial images generated by bicubic and several state-of-the-art methods. Though they generate clearer facial images than bicubic, the identity similarities are still low, which means that they cannot recover accurate identity-related facial details. On the other hand, human perception of face heavily relies on identity information _cite_ . Pixel-level cues cannot fully account for the perception process of the brain. These facts suggest that recovering identity information may improve both the recognizability and performance of hallucination. Motivated by the above observations, this paper proposes Super-Identity Convolutional Neural Network (SICNN) for identity-enhanced face hallucination. Different from previous methods, we additionally minimize the identity difference between the hallucinated face and its corresponding high-resolution face. To do so, (i) we introduce a robust identity metric space in the training process; (ii) we define a super-identity loss to measure the identity difference; (iii) we propose a novel training approach to efficiently utilize the super-identity loss. More details as follows: For identity metric space, we use a hypersphere space _cite_ as the identity metric space due to its state-of-the-art performance of facial identity representation. Specifically, our SICNN is composed of a face hallucination network cascaded with a recognition network to extract identity-related feature, and an Euclidean normalization operation to project the feature into the hypersphere space. For loss function, perceptual loss _cite_, computed by feature Euclidean distance, can construct convincing HR images. Differently, in our work, we need to minimize the identity distance of face pairs in the metric space. Here, we modified the perceptual loss to the super-identity loss calculated by normalized Euclidean distance (equivalent to geodesic distance) between the hallucinated face and its corresponding high-resolution face in the hypersphere identity metric space. This also facilitates our analysis on the training process (see Sec. _ref_) . For training approach, using conventional training approaches to directly train the model with super-identity loss is difficult due to the large margin between the hallucination domain and the HR domain in the hypersphere identity metric space. This is critical during the early training stage when face hallucination network cannot predict high quality hallucinated face images. Moreover, the hallucination domain keeps changing during the hallucination network learning, which makes the training with super-identity loss unstable. We summarize this challenge as a problem. To overcome this problem, we propose a Domain Integrated Training algorithm that alternately updates the face recognition network and the hallucination network by minimizing the different loss in each iteration. In this alterative optimization, the hallucinated face and HR face will gradually move closer to each other in the hypersphere identity metric space while keep the discrimination of this metric space. The main contributions of this paper are as summarized as follows: