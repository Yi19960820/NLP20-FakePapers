Single image super-resolution (SISR) is a classical problem in low-level computer vision, which reconstructs a high-resolution (HR) image from a low-resolution (LR) image. Actually, an infinite number of HR images can get the same LR image by downsampling. Hence, the SR problem is inherently ill-posed and no unique solution exists. In order to mitigate this problem, numerous SISR methods have been proposed in the literature, including interpolation-based methods, reconstruction-based methods and example-based methods. Since the former two kinds of methods usually suffer dramatically drop in restoration performance with larger upscaling factors, the recent SR methods fall into the example-based methods which try to learn prior knowledge from LR and HR pairs. Recently, due to the strength of deep convolutional neural network (CNN), many CNN-based SR methods try to train a deep network to gain better reconstruction performance. Kim~ \etal propose a N-layer CNN model known as VDSR~ _cite_, which adopts residual learning and adaptive gradient clipping to ease training difficulty. To control the model parameters, the authors construct a deeply-recursive convolutional network (DRCN) ~ _cite_ by adopting recursive layer. To mitigate training difficulty, Mao~ \etal propose a very deep residual encoder-decoder network (RED) ~ _cite_, which consists of a series of convolutional and subsequent transposed convolution layers to learn end-to-end mappings from the LR images to the ground truths. Tai~ \etal propose a deep recursive residual network (DRRN) ~ _cite_, which employs parameters sharing strategy to alleviate the requirement of enormous parameters of the very deep networks. Although achieving prominent performance, most of deep networks still have some drawbacks. Firstly, in order to achieve better performance, deepening or widening the network has been a design trend. But the result is that these methods demand large computational cost and memory consumption, which are less applicable in practice, such as mobile and embedded vision applications. Moreover, the traditional convolutional networks usually adopt cascaded network topologies, ~ \eg, VDSR~ _cite_ and DRCN~ _cite_ . In this way, the feature maps of each layer are sent to the sequential layer without distinction. However, Hu~ \etal~ _cite_ experimentally demonstrate that adaptively recalibrating channel-wise features responses can improve the representational power of a network. To address these drawbacks, we propose a novel information distillation network (IDN) with lightweight parameters and computational complexity as illustrated in Figure~ _ref_ . In the proposed IDN, a feature extraction block (FBlock) first extracts features from the LR image. Then, multiple information distillation blocks (DBlocks) are stacked to progressively distill residual information. Finally, a reconstruction Block (RBlock) aggregates the obtained HR residual representations to generate the residual image. To get a HR image, we implement an element-wise addition operation on the residual image and the upsampled LR image. The key component of IDN is the information distillation block, which contains an enhancement unit and a compression unit. The enhancement unit mainly comprises two shallow convolutional networks as illustrated in Figure~ _ref_ . Each of them is a three-layer shallow module. The feature maps of the first module are extracted through a short path (N-layer) . Thus, they can be regarded as the local short-path features. Considering that the deep networks have more expressive power, we send a portion of the local short-path features to another module. By this way, the feature maps of the second module naturally become the local long-path features. Different from the approach in~ _cite_, we divide feature maps into two parts. One part represents reserved short-path features and another expresses the short-path features that will be enhanced. After getting long and short-path feature maps, we aggregate these two types of features for gaining more abundant and efficient information. In summary, the enhancement unit is mainly to improve the representation power of the network. As for the compression unit, we adopt a simple convolutional layer to compress the redundancy information in features of the enhancement unit. The main contributions of this work are summarized as follows: