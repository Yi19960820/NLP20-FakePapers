Divide-and-conquer is a widely-adopted problem-solving philosophy which has been demonstrated to be successful in many computer vision tasks, e.g. \object detection and tracking _cite_ _cite_ . Instead of solving a complete and huge problem, divide-and-conquer suggests decomposing the problem into several sub-problems and solving them in different constrained contexts. Figure~ _ref_ illustrates this idea with a binary classification problem. Finding a decision boundary in the original problem space is difficult and leads to a sophisticated nonlinear model, but linear decision models could be more easily obtained when solving the sub-problems. The traditional decision tree, which splits the input feature space at each splitting node and gives the prediction at a leaf node, inherently uses the divide-and-conquer strategy as an inductive bias. The designs of input features and splitting functions are key to the success of this model. Conventional methods usually employ hand-crafted features such as the pixel-difference feature _cite_ and Harr-like feature _cite_ . However, the input space for vision tasks are usually high-dimensional and often lead to a huge pool of candidate features and splitting functions that are impractical for an exhaustive evaluation. In practice the huge candidate pool is randomly sampled to form a small candidate set of splitting functions and a local greedy heuristic such as entropy minimization is adopted to choose the "best" splitting function which maximizes data "purity", limiting the representation learning ability of the traditional decision tree. Deep neural decision forests _cite_ was proposed to enable a decision tree with deep representation learning ability. In _cite_, the outputs of the last fully connected layer of a CNN are utilized as stochastic splitting functions. A global loss function is differentiable with respect to the network parameters in this framework, enabling greater representation learning ability than the local greedy heuristics in conventional decision trees. Deep regression forests _cite_ was later proposed for regression problems based on the general framework of _cite_ . However, the success in introducing representation learning ability comes with the price of transforming decision trees into stochastic trees which make “soft” decision at each splitting node. As a result, all splitting functions have to be evaluated as every leaf node contributes to the final prediction, yielding a significant time cost. Pruning branches that contribute little to the final prediction should effectively reduce the computational cost with little accuracy degradation. Unfortunately, the network topology used in previous works _cite_ requires a complete forward pass of the entire CNN to compute the routing probability for each splitting node, making pruning impractical. A major advantage of the divide-and-conquer strategy (e.g. \random forests) is its high efficiency in many time-constraint vision tasks such as face detection and face alignment. Simple and ultrafast-to-compute features such as pixel difference, only extract sparse information (e.g. two pixels) from the image space. However, existing deep neural decision/regression forests _cite_ completely ignore the computational complexity of splitting nodes and in turn greatly limit their efficiency. In this work, we propose a general tree-like model architecture, named Deep Hierarchical Machine (DHM), which utilizes a flexible model topology to decouple the evaluation of splitting nodes and a probabilistic pruning strategy to avoid the evaluation of unnecessary paths. For the splitting nodes, we also explore the feasibility of inheriting the sparse feature extraction process (i.e. \the pixel-difference feature) of the traditional random forests and design a deep sparse hierarchical machine (DSHM) for high efficiency. We evaluate our method on standard image classification and facial landmark coordinate regression tasks and show its effectiveness. Our implementation can be easily incorporated into any deep learning frameworks and the source code and pre-trained models will be available on the website . In summary, our contributions are: