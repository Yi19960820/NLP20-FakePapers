tracking is a crucial task in computer vision that deals with the problem of localizing one arbitrary target object in a video, given only the target position in the first frame. Typically, bounding boxes are used for representing the target position. Arbitrary target object implies that a dedicated target model is needed for each target during testing. This is typically accomplished through online learning where the online training set is extracted from the test video and a target model is initialized and updated on the fly. In this work, we tackle the problem of model update: after an initial target model is built using reliable supervision in the first frame, how to exploit information in subsequent frames and update the initial model along with tracking? Model update is challenging because of . The only reliable supervision for building a target model is the information in the first frame. After that, the online training set is collected based on predicted target position, which is not always reliable. When small errors in the training samples accumulate, model update can cause the drifting problem. Moreover, the extracted online training set is highly correlated since most of the training samples are simply the translated and scaled version of a base sample. Correlated samples are easy to fit and do not help much with the generalization to hard samples. Recent works _cite_ have investigated the possibility of no model update at all, and achieved remarkable tracking performance. These approaches can be interpreted as learning an invariant and discriminative feature extractor such that the target remains stable in the feature space and is separable from the background. However, learning a representation that is both invariant and discriminative for a long time is intrinsically difficult, as with time evolves, features that once are discriminative may become irrelevant and vice versa. Consider that when a red car drives into a dark tunnel, the red color becomes irrelevant, although it is discriminative before entering the tunnel. Instead of striving to construct a perfect model at the first frame, model update tries to keep up with the current target appearance along with tracking by constantly incorporating the new target information, and therefore eases the burden of feature representation. Moreover, by gradually adapting to the current video context, the tracking problem can be considerably simplified _cite_ . In scenarios where target exhibits multi-modality, model update is indispensable. Generally, model update can be formulated as an online learning problem with two stages. First, an online training set is collected along with tracking. Then, the target model is learned on the training set using algorithms like stochastic gradient descent (SGD) . Existing update methods typically suffer from the problem of large training set and slow convergence thus being too slow for practical use. Moreover, due to unreliable training data, regularizations and rules are carefully designed based on expertise in the field to avoid model drifting. In this work, we advocate the paradigm for object tracking that . Offline learning is performed before the actual tracking takes place and the learned model is shared among all test videos. Online learning, in contrast, is conducted during tracking and the learned model is specific to each test video. Our key innovation is to learn the online learning algorithm itself using large numbers of offline videos, i.e., . The offline-learned update method, which we call the learned updater, takes in the online training set and outputs the updated target model. Please refer to Fig.~ _ref_ for visual illustrations. The benefit of learning to update is threefold: N) After seeing all kinds of target variations in the offline training phase, the learned updater is able to capture among videos. These learned patterns are implicitly used during testing to avoid unlikely update (e.g., update to background) and thus can be seen as a form of regularization, which enables our learned updater to handle the unreliable online training set. N) The learned updater is able to update the target model based on not only the online training set, but also rules learned from the offline dataset. Therefore, the learned updater is able to see beyond the highly correlated online training set and makes the updated model capable of generalizing to more challenging scenarios. N) The learned patterns enable fast inference of the learned updater. As a result, our learned updater improves the performance of base trackers while running faster than realtime on GPU with a single forward pass of the neural network per frame. In this paper, we formulate model update as a meta-learning problem (a.k.a learning to learn) _cite_ and learn a model updater. Specifically, our learned updater is embodied as a RNN, which is well known for its ability to model sequential/temporal variations. Previous efforts to model target variations based on RNNs mostly fail to deliver satisfactory tracking performance due to inadequate offline training videos. In this work, we contribute several techniques to overcome data deficiencies and train RNNs effectively. With a properly trained updater, our tracker achieves state-of-the-art performance among realtime trackers. As a first attempt of learning to update for object tracking, we demonstrate its application on two base trackers: a template-based tracker for its simplicity and a correlation filter-based tracker for its wide adoption. Our learned updater considerably improves the base trackers and outperforms relevant model update baselines including the exponential moving average (EMA)-and the SGD-based update method. In summary, our contributions are threefold: N) We propose a novel model update method for object tracking that (i) is formulated as a meta-learning problem, capable of learning target variation patterns and facilitating effective tracking, and (ii) runs faster than realtime (N fps with SiamFC tracker and N fps with CFNet tracker) while requiring small memory footprint, thus being suitable for practical applications; N) We propose several techniques to train our RNN-based updater effectively; N) We validate our method in common object tracking benchmarks and show that it (i) consistently outperforms relevant model update baselines, and (ii) obtains state-of-the-art performance among realtime trackers.