recognition is one of the most active research fields in the computer vision community, and the broad applications include robotics _cite_, video surveillance _cite_, and medical caring _cite_ . For action recognition, in terms of feature extraction and feature representation, the two categories of approaches for action recognition are based on conventional handcrafted features and deep learning features, respectively. Both the conventional and deep learning based approaches have achieved remarkable improvements for action recognition recently. A migration from the handcrafted features based approaches to deep learning based methods happens since the emerge of AlexNet _cite_ . The reasons behind that are three folds. Firstly, rich features extracted from different levels are beneficial. Second, a large amount of training data are used to optimize the tremendous parameters, which is helpful to enhance learning ability of the network. Third, very deep neural networks are designed to enhance the fitting ability for the classification task. Roughly, deep learning based approaches can be cast into four categories according to the network modalities, which are ND-CNNs, Recurrent Neural Network (RNNs), ND-ND mixed models and ND-CNNs. ND-CNNs and recurrent neural network (RNNs) _cite_ are firstly employed in action recognition. Soon they were replaced by ND-CNNs. ND-CNNs can seamlessly extract features in the spatial-temporal domain. It proves that ND-CNNs with spatial-temporal kernels perform better than ND-CNNs with spatial kernels for action recognition _cite_ . CND is the first one that uses ND network for action recognition. Later other variants emerges, and the overall evolution follow the rules from ``shallow'' ND-CNNs to ``deep'' ND-CNNs. Despite the promising performance, two problems should be solved in state-of-the-art action recognition methods mentioned above. N) Depth is beneficial to improve the performance of action classification as compared to using RGB video alone. Most existing approaches only take RGB images as inputs, and the appearance and motion cues are usually employed in video sequences to recognize human actions _cite_ . Although impressive advances have been achieved, the lack of ND structures of the objects as well as the scenes make those approaches struggle to handle the scenarios with heavy occlusions and similar objects. With the development of Microsoft Kinect _cite_, commodity range sensors make it feasible to generate depth at scale. Depth provides valuable sources including temporal correlation, emotion expression and motion patterns, which are the key factors for distinguishing human actions under some circumstances. Therefore, depth information can be viewed as a vital complementary to RGB sequence for improving the performance of action recognition. Some work spent efforts on combining RGB and depth information for action recognition _cite_, and demonstrated the effectiveness of modality fusion. Existing networks which use both RGB and depth videos as inputs suffer one of the two drawbacks: the first one is that they usually carry a large amount of parameters and lead to heavy computation. Otherwise with light-weight networks, the performance is not competitive. N) Although ND-CNNs achieved state-of-the-art performance, they usually contain a large amount of parameters, leading to high computational cost and a demand for large training data. Among the few existing ND-CNNs for action recognition, the most representative one is inflated ND network (IND) _cite_ . It is trained on Kinetics _cite_, and uses a two-stream inflated ND CNN to achieve the state-of-the-art performance for action recognition. The success of IND provides some important hints, including: First, as the core parts, inception ND modules provide possibilities for the network to learn more various and robust features. Second, with the large-scale training data, deep ND networks are more likely to achieve performance gain in terms of classification accuracy. As a milestone for action recognition, IND possesses many superior qualities. There still are two disadvantages, which may be further improved. A large amount of parameters. Within the IND network, each inception module is extending ND-CNN of the inception VN _cite_ to ND-CNN module. It contains a large amount parameters and is very computationally heavy. By inspecting the network structure, we find that nine inception modules taking up over N \% of the total parameters, and the computations mainly come from the convolutional operations with ND kernels. In addition, tremendous parameters in network always accompany very demanding memory cost. Most recently, a trend is to tailor a large network into light-weight network. Two representative studies are ShuffleNet _cite_ and MobileNet _cite_ . However, this line of work mainly focuses on ND-CNNs. It is worth mentioning that depth-wise convolution and group convolution play an important role in designing light-weight networks. In fact, ND-CNNs are of much stronger demand for light-weight design per the aforementioned reasons, yet little work exists for tackling this problem. ND-CNNs are more complex compared to ND-CNNs. So are the light-weight operations in ND-CNNs than that in ND-CNNs. Specifically, under the conditions that the depth and width are similar, ND-CNNs are of higher computational cost and need larger memory storage than ND-CNNs. Fig.~ _ref_ shows the comparison between the ND convolution and the ND counterpart. It can be found that their main differences include input dimensions, kernel dimensions and the ways of convolution. For example, for the kernel of size N, a ND kernel only has N parameters, whereas a ND kernel has N parameters. When convolving a input of size _inline_eq_ with a kernel of size N, the FLOPs of ND convolution and ND convolution are _inline_eq_ and _inline_eq_, respectively. The computational costs of ND-CNNs are at least one magnitude higher than that of ND-CNNs, that is _inline_eq_ vs. \ _inline_eq_ . Data hungry. In addition, due to its heavy structure, to achieve a better performance, enormous samples are required during training. Although the deeper ND-CNNs generally have larger capability, ND-CNNs may suffer from over-fitting, if there are not sufficiently large training datasets. For deep learning based methods, although using both RGB and depth data generally achieves better performance than using RGB data alone in action recognition _cite_, most existing RGB-D datasets contain less than Nk videos. The magnitude is far less than that of RGB datasets, such as ImageNet _cite_ and Kinetics _cite_ . As a result, the lack of training data would inevitably limit the potential of deep neural network. To summarize, despite the great efforts and the rapid progress in the past few years, action recognition is still a challenging task. There is much room for improvement. First, we can enrich the input data by employing multimodal data, such as RGB and depth videos. Second, we can optimize the structures of conventional ND-CNNs by adopting light-weight design. In this paper, in order to overcome the aforementioned problems in ND-CNNs, and being inspired by the design of IND and light-weight ND-CNNs, we propose a set of light-weight ND-CNN networks for action recognition using RGB-D data as inputs. The proposed networks include an inception with spatial and temporal convolution network (IST), a shuffle spatial and temporal convolution network (SST) and a group shuffle spatial and temporal convolution network (GSST), which optimize the ND-CNNs at the ND structure level as well as the channel level. Our contributions as follows.