t is generally assumed that the training and test data are drawn from the same distribution in statistical learning theory. Unfortunately, this assumption does not hold in many applications. A well studied strategy to address this issue is domain adaptation~ _cite_ which employs previous labelled source domain data to boost the task in a new target domain with a few or even no labelled data. In this paper, we focus on the problem of unsupervised domain adaptation in which source data are labelled, but available data in the target domain are unlabelled. One approach to this problem is referred to as feature transformation-based domain adaptation~ _cite_, which transforms the original feature into another space where the distributions of the two domains would be similar. A classifier can then be trained in the space for both source and target data. Another approach~ _cite_, referred to as classifier-based domain adaptation, aims at adapting a classifier directly by constraining the standard learning framework on the source labelled data to the unlabelled target data. However, there may not exist such a classifier that could perform well on both domains, especially when the domain shift is large. An alternative approach is to jointly learn two classifiers, one is optimized for the source domain and the other is optimized for the target domain. Yang et al.~ _cite_ proposed a method to learn two classifiers for the source and target domain respectively by assuming both the source and target data are labelled (i.e. supervised domain adaptation) . Duan et al.~ _cite_ propose a multi source domain adaptation method while the target domain labelled data are also assumed to be available. How to jointly learn source and target classifiers for unsupervised domain adaptation is a challenging problem despite the recent attempt in~ _cite_ based on Residual Transfer Network (RTN) . This paper proposes a multi-task learning-based method for classifier-based domain adaptation. It aims at jointly learning the source and target classifiers without requiring labelled data in the target domain. Specifically, the target task is treated as an unsupervised clustering task by exploiting the intrinsic structure of unlabelled target data. In the meantime, the class information from the source domain is leveraged to assign the right class labels to the target clusters by taking the class distribution shift between the domains into consideration. The proposed method has been evaluated through comprehensive experiments on a synthetic dataset and real world cross domain visual recognition tasks. The experimental results demonstrate that the proposed method outperforms several state-of-the-art domain adaptation methods.