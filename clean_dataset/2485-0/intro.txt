In this paper we tackle visual recognition problems where partial evidence or partial information about an input image is available at test time. For instance, if we know for certain that an image was taken at the, this should change our beliefs about the types of objects that could be present, e.g. an would be unlikely. This is because something is for certain about the image even before performing any visual recognition. We argue that this setting is realistic in many applications. For instance, images on the web are usually surrounded by text, images on social media have user comments, many images contain geo-location information, images taken with portable devices contain other sensor information. More generally, images in standard computer vision datasets are effectively partially annotated with respect to a single task or modality. Assuming only visual content as inputs, while convenient for benchmarking purposes, does not reflect many end-user applications where extra information is available during inference. We propose here a general framework to address this problem in any task involving deep convolutional neural networks trained with multiple target outputs (i.e.~multi-label classification) or multiple tasks (i.e.~multi-task learning) . We provide an example in Figure~ _ref_, where a set of labels are:,,, while we are trying to predict the other labels:,, . Convolutional neural networks (CNNs) have become the state-of-the-art in most visual recognition tasks. Their extraordinary representation ability has allowed researchers to address problems at an unprecedented scale with remarkable accuracy. While reasoning under partial evidence using probabilistic graphical models would involve marginalization over the variables of interest, CNNs do not model a joint distribution, therefore making such type of reasoning non-trivial. The typical pipeline using CNNs for visual recognition involves training the model using stochastic gradient descent (SGD) and the back-propagation algorithm~ _cite_ using an annotated image dataset, and then performing forward-propagation during inference given only visual input. In this paper, we challenge this prevailing inference procedure in CNNs where information only flows in one direction, and the model structure is static and fixed after training. We propose instead feedback-based propagation (feedback-prop) where forward and backward-propagation steps use intermediate neural activations to share information among output variables during inference. We show the effectiveness of our approach on multi-label prediction under incomplete and noisy labels, hierarchical scene categorization, and multi-task learning with object annotations and image descriptions. Our main hypothesis is that by an intermediate set of neural activations using partial labels for a given input sample, we would also be able to make more accurate predictions for the complement set of labels. We demonstrate this behavior using our feedback-prop inference for multiple tasks and under multiple CNN models. There is remarkable evidence in previous research aimed at interpreting intermediate representations in CNNs showing that they encode basic patterns of increasing visual complexity (i.e. edges, attributes, object parts, objects) that are shared among target outputs~ _cite_ . Since the underlying shared representations of a CNN capture common patterns among target outputs, we find that they can act as pivoting variables to transfer knowledge among variables in the target space. We show that feedback-prop is general, simple to implement, and can be readily applied to a variety of problems where a model is trained to predict multiple labels or multiple tasks. Our code and data are available . Our contributions can be summarized as follows: