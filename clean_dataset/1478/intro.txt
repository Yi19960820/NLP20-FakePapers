Convolutional neural networks (CNNs) become the most powerful tool for high-level computer vision tasks, such as object detection _cite_, image classification _cite_ and semantic segmentation _cite_ . Along this line, CNNs were also used to solve image processing problems. Representative applications are image/video super-resolution _cite_, artifact and noise removal _cite_, completion/inpainting _cite_, learning image filtering _cite_, image deconvolution _cite_, \etc Compared to very successful classification and detection, low-level-vision neural networks encounter quite different difficulties when they are adopted as {\it regression} tools. The first problem is about the receptive field, which is the region in the input layer connected to an output neuron. A reasonably large receptive field can capture global information applied to inference. In VGG _cite_ and ResNet _cite_, a large receptive field is achieved mainly by stacking convolution and pooling layers. For low-level-vision CNNs _cite_, the pooling layers are commonly removed in order to regress the same-resolution output and preserve image details. To still obtain acceptable receptive fields with the convolution layers, the two solutions are to use large kernels (\eg _inline_eq_ or _inline_eq_) _cite_ and stack many layers _cite_ . We found unexceptionally these two schemes both make the system run slowly due to heavy computation and consume a lot of memory. To illustrate it, we show the relation between the size of a receptive field and running time of current low-level-vision CNNs in Figure _ref_ . It is observed based on this plot that most existing low-level-vision CNNs, such as SRCNN _cite_, Filter-CNN _cite_, VDSR _cite_, and Shepard-CNN _cite_, achieve receptive fields smaller than _inline_eq_ (pixels) . Their applications are accordingly limited to local-information regression ones such as super-resolution, local filtering, and inpainting. On the other hand, Deconv-CNN _cite_ uses _inline_eq_ field size. But its computation cost is very high as shown in Figure _ref_ . Contrary to these common small receptive fields, our important finding is that {\it large or even whole-image fields are essential for many low-level vision tasks} because most of them, including image completion, restoration, colorization, matting, global filtering, are based on global-information optimization. In this paper, we address this critical and general issue, and design a new network structure to achieve very-large receptive fields without sacrificing much computation efficiency, as illustrated in Figure _ref_ . The second difficulty is on multiscale information fusion. It is well known that most image content is with multiscale patterns as shown in Figure _ref_ . As discussed in _cite_, the small-scale information such as edge, texture and corners are learned in early layers and object-level knowledge comes from late ones in a deep neural network. This analysis also reveals the fact that {\it color and edge information vanishes in late hidden layers} . For pixel labeling work, such as semantic segmentation _cite_ and edge detection _cite_, early feature maps were extracted and taken into late layers to improve pixel inference accuracy. We address this issue differently for low-level-vision tasks that do not involve pooling. Although it seems that the goal of retaining early-stage low-level edge information contradicts large receptive field generation in a deep network, our solution shows they can accomplished simultaneously with a general network structure. To address aforementioned difficulties, we propose {\it convolutional neural pyramid (CNP)}, which can achieve quite large receptive fields while not losing efficiency as shown in Figure _ref_ . It intriguingly enables multiscale information fusion for general image tasks. The convolutional neural pyramid structure is illustrated in Figure _ref_ where a cascade of features are learned in two streams. The first stream across different pyramid levels plays an important role for enlarging the receptive field. The second stream learns information in each pyramid level and finally merges it to produce the final result. Our CNP benefits a wide spectrum of applications. As demonstrated in Figure _ref_, we achieve the state-of-the-art performance in depth/RGB restoration, image completion/inpainting, noise/artifact removal, \etc Other applications include learning image filter, image colorization, optical flow and stereo map refinement, image enhancement, and edge refinement. They are shown in the experiment section and our supplementary file. Our framework is very efficient in computation. On an Nvidia Titan X display card, N frames are processed per second for a QVGA-size input and N frames per second for a VGA-size input for {\it all} image tasks.