Most of the current state-of-the-art architectures for image segmentation rely on an encoder-decoder structure to obtain high-resolution predictions and, at the same time, to exploit large context information. One way to increase network receptive fields is to perform downsampling operations like pooling or convolutions with large stride. Reduction of spatial resolution is twice beneficial because it also lightens the computational burden. Even state-of-the-art architectures that make use of dilated convolutions _cite_, employ some downsampling operators in order to maintain the computation feasible. Semantic maps are usually predicted at _inline_eq_ or _inline_eq_ of the target resolution and then they are upsampled using nearest neighbor or bilinear interpolation. We focus on Semantic Segmentation of street scenes for automotive applications where a model needs to be run continuously on vehicles to take fast decisions in response to environmental events. For this reason, our design choices are the result of a trade-off between processing speed and accuracy. Our work focuses on a fast architecture with a lightweight decoder that makes use of a more effective upsampling operator. Our contributions are the following: _cite_ represent the pioneer works that employed CNNs for semantic segmentation. FCN _cite_ laid the foundations for modern architectures where CNNs are employed in a fully-convolutional way. Authors used a pre-trained encoder together with a simple decoder module that takes advantage of skip-connections from lower layers to exploit high-resolution feature maps. They obtained a significant improvement both in terms of accuracy and efficiency. DeepLab _cite_ made use of Dilated Convolutions _cite_ to increase the receptive field of inner layers without increasing the overall number of parameters. After the introduction of Residual Networks (Resnets) _cite_ most methods employed a very deep Resnet as encoder \eg DeepLabvN _cite_ ResnetN _cite_ FRRN _cite_, pushing forward the performance boundary on semantic segmentation task. PSPNet _cite_ and DeepLabvN _cite_ introduced context layers in order to expand the theoretical receptive field of inner layers. All these methods attain high accuracy on different benchmarks but at high computational costs. \noindent Efficiency-oriented architectures. ENet authors _cite_ headed towards a high-speed architecture, dramatically raising model efficiency, but sacrificing accuracy. SegNet _cite_ introduced an efficient way to exploit high-resolution information by saving max-pooling indices from the encoder and using them during upsampling. ICNet _cite_ design is based on a three branches architecture exploiting deep supervision for training. ERFNet _cite_ implements an efficient Residual Factorized Convolution layer in order to achieve high a accuracy while being particularly efficient.