Crowd counting, which aims at estimating the total number of people in unconstrained crowded scenes, has received increasing research interests in recent years due to its potential application in many real-world scenarios, such as video surveillance~ _cite_ and traffic monitoring~ _cite_ . Despite recent progress, crowd counting remains a challenging issue, especially in the face of extreme occlusions, changes in lighting and camera perspective. In recent two years, deep convolutional neural networks have been widely used in crowd counting and have made substantial progress~ _cite_ . The success of most existing deep models stems from the effective modeling of the scale variation of people/heads and the varying degrees of regional crowd density. However, all of these methods, without exception, obtain the density estimation of the whole image by merging the prediction results of a number of pre-designed fixed sub-network structures (working on the whole image or image patches) . Specifically, they are either proposed to fuses the features from multiple convolutional neural networks with different receptive fields to handle the scale variation of people groups~ _cite_, or directly divide crowd scene into multiple non-overlapping patches and provide a pool of regression networks for each patch selection~ _cite_ . Although these strategies can, to a certain extent, improve the adaptability of the prediction to images of diverse density regions or people of various scales, the limited enumeration of a fixed number of tailor-designed networks or several sizes of receptive fields can not well cope with all the scenarios after all. Most importantly, none of these algorithms take into account the impact of different pose and photographic angles on crowd density estimation while crafting their network structures. As shown in Figure~ _ref_, the camera viewpoints in various scenes create different perspective effects and may result in large variation of scales, in-plane and out-plane rotation of people. To address the aforementioned concerns, we propose a Deep Recurrent Spatial-Aware Network for crowd counting. The core of our network is a Recurrent Spatial-Aware Refinement (RSAR) module, which recurrently conducting refinement on an initial crowd density map through adaptive region selection and residual learning. Specifically, the RSAR module consists of two alternately performed components: i) a Spatial Transformer Network is incorporated in each LSTM step for simultaneously region cropping and warping, which allows the network to adaptively cope with the various degrees of congestion, people scale and rotation variation in the same scene; ii) a Local Refinement Network refines the density map of the selected region. In general, the main contributions of this work are three-fold.