\par One aspect of a successful human-machine interface (e.g. human-robot interaction, chatbots, speech, handwriting~ \ldots) is the ability to have a personalized interaction. This affects the overall human experience, and allow for a more fluent interaction. At the moment, there is a lot of work that uses machine learning in order to learn to model for such interactions. However, most of these models do not address the issue of personalized behavior: they try to average over the different examples from different people in the training set. Identifying the human styles during the training and inference time open the possibility of biasing the models output to take into account the human preference. In this paper, we focus the problem of styles in the context of handwriting. \par However, defining and extracting handwriting styles is a challenging problem, since there is no formal definition for these styles (i.e. it is an ill-posed problem) . A style is both social--depends on writer's training, especially at middle school--and idiosyncratic--depends on the writer's shaping (letter roundness, sharpness, size, slope~ \ldots) and force distribution across time. To add to the problem, till recently, there were no metrics to assess the quality of handwriting generation. \par There are two questions: what is the task itself? and what is the style used to achieve this task?. In handwriting, the task space is well defined (i.e. which letter we want to write), thus, allowing us to focus on the second part, of extracting styles for achieving this task. In this paper, we address the problem of style extraction by using an conditioned-temporal deep autoencoder model. The conditioning is on the letter identity. The reason we use an autoencoder is that there is no explicit way that we know about to evaluate the quality of the handwriting styles other than using them to generate handwriting, and evaluate this generation. _cite_ introduced benchmarks and evaluation metrics in order to assess the quality of generating handwritten letters. In comparison to the those benchmarks and metrics, we achieve higher performance, while extracting a meaningful latent space. \par We also hypothesize that the latent space of styles is generic, i.e. that it will generalize over unseen writers, thus achieving a ``transfer of style''. To test this hypothesis, we assess our model on N new writers. We compare the tracings generated by this model to a benchmark model already proposed for online handwriting generation. \par In addition, we explore the latent space of our model for each letter separately. This revealed that there is a limited number of 'unique' styles per letter, categorical as well as continuous. We report our analysis for some of the letters, since a full analysis is out of the scope for this paper. \par Thus, our contributions in this paper are the following: