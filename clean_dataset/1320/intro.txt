melanoma is among the most rapidly growing cancers in the world _cite_ and dermoscopy is the most commonly used _inline_eq_ _inline_eq_ imaging modality that provides a better visualization of subsurface structures of pigmented skin lesions _cite_ . While this technique allows dermatologists to detect early stage melanoma that are not visible by human eyes, visual interpretation alone is a time-consuming procedure and prone to inter-and intra-observer variabilities. Therefore, automated and accurate analysis of melanoma has become highly desirable in assisting dermatologists for improving their efficiency and objectivity when interpreting dermoscopic images in clinical practice _cite_ . Automatic skin lesion segmentation is an essential component in computer-aided diagnosis (CAD) of melanoma _cite_ _cite_ . However, this is a very challenging task due to significant variations in location, shape, size, color and texture across different patients. In addition, some dermoscopic images have low contrast between lesion and surrounding skin, and suffer from artifacts and intrinsic features such as hairs, frames, blood vessels and air bubbles. Existing lesion segmentation methods based on clustering, thresholding, region growing, or deformable models have shown limited success in solving this difficult problem when applying to a large amount of image data _cite_ . Recent development of deep learning has revolutionized the field of machine learning and computer vision. Deep learning techniques, especially deep convolutional neural networks _cite_, have been rapidly adopted in various medical image analysis problems, including body recognition _cite_, lesion detection _cite_, image registration _cite_, segmentation _cite_ and classification _cite_ . In particular, Yu et al. _cite_ introduced a deep residual network with more than _inline_eq_ layers for automatic skin lesion segmentation, in which several residual blocks _cite_ were stacked together to increase the representative capability of their model. In _cite_, Bi et al. proposed a multi-stage approach to combine the outputs from multiple cascaded fully convolutional networks (FCNs) to achieve a final skin lesion segmentation. In our recent study _cite_, we developed a fully automatic method for skin lesion segmentation by leveraging a _inline_eq_-layer deep FCN that is trained end-to-end and does not rely on prior knowledge of the data. Furthermore, we designed a novel loss function based on Jaccard distance that is directly related to image segmentation task and eliminates the need of sample re-weighting. Experimental results showed that our method outperformed other state-of-the-art algorithms on two benchmark datasets-one is from ISBI N challenge titled as _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ _cite_, and the other is the PHN dataset _cite_ . In this paper, we present a major extension of our previous work to further enhance our model in automatic skin lesion segmentation. Specifically, N) we investigate the potential of using a deeper network architecture with smaller convolutional kernels such that the new model has increased discriminative capacity to handle a larger variety of image acquisition conditions; N) besides Red-Green-Blue (RGB) channels, we also investigate the use of channels in other color spaces, such as Hue-Saturation-Value (HSV) and CIELAB _cite_, as additional inputs to our network that aim for a more efficient training while controlling over-fitting; N) we evaluate the proposed framework on ISBI N _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ _inline_eq_ challenge datasets. Experimental results demonstrated a significant performance gain as compared to our previous model, ranking itself as the first place among _inline_eq_ final submissions.