Age progression is the process of aesthetically rendering a given face image to present the effects of aging. It is often used in entertainment industry and forensics, e.g., forecasting facial appearances of young children when they grow up or generating contemporary photos for missing individuals. The intrinsic complexity of physical aging, the interferences caused by other factors (e.g., PIE variations), and shortage of labeled aging data collectively make face age progression a rather difficult problem. The last few years have witnessed significant efforts tackling this issue, where aging accuracy and identity permanence are commonly regarded as the two underlying premises of its success _cite_ _cite_ _cite_ _cite_ . The early attempts were mainly based on the skin's anatomical structure and they mechanically simulated the profile growth and facial muscle changes w.r.t. the elapsed time _cite_ _cite_ _cite_ . These methods provided the first insight into face aging synthesis. However, they generally worked in a complex manner, making it difficult to generalize. Data-driven approaches followed, where face age progression was primarily carried out by applying the prototype of aging details to test faces _cite_ _cite_, or by modeling the dependency between longitudinal facial changes and corresponding ages _cite_ _cite_ _cite_ . Although obvious signs of aging were synthesized well, their aging functions usually could not formulate the complex aging mechanism accurately enough, limiting the diversity of aging patterns. The deep generative networks have exhibited a remarkable capability in image generation _cite_ _cite_ _cite_ _cite_ and have also been investigated for age progression _cite_ _cite_ _cite_ _cite_ . These approaches render faces with more appealing aging effects and less ghosting artifacts compared to the previous conventional solutions. However, the problem has not been essentially solved. Specifically, these approaches focus more on modeling face transformation between two age groups, where the age factor plays a dominant role while the identity information plays a subordinate role, with the result that aging accuracy and identity permanence can hardly be simultaneously achieved, in particular for long-term age progression _cite_ _cite_ . Furthermore, they mostly require multiple face images of different ages of the same individual at the training stage, involving another intractable issue, intra-individual aging face sequence collection _cite_ _cite_ . Both the aforementioned facts indicate that current deep generative aging methods leave room for improvement. In this study, we propose a novel approach to face age progression, which integrates the advantage of Generative Adversarial Networks (GAN) in synthesizing visually plausible images with prior domain knowledge in human aging. Compared with existing methods in literature, it is more capable of handling the two critical requirements in age progression, identity permanence and aging accuracy. To be specific, the proposed approach uses a Convolutional Neural Networks (CNN) based generator to learn age transformation, and it separately models different face attributes depending upon their changes over time. The training critic thus incorporates the squared Euclidean loss in the image space, the GAN loss that encourages generated faces to be indistinguishable from the elderly faces in the training set in terms of age, and the identity loss which minimizes the input-output distance by a high-level feature representation embedding personalized characteristics. It ensures that the resulting faces present desired effects of aging while the identity properties remain stable. By estimating the data density of each individual target age cluster, our method does not demand matching face pairs of the same person across two age domains as the majority of the counterpart methods do. Additionally, in contrast to the previous techniques that primarily operate on cropped facial areas (usually excluding foreheads), we emphasize that synthesis of the entire face is important since the parts of forehead and hair also significantly impact the perceived age. To achieve this and further enhance the aging details, our method leverages the intrinsic hierarchy of deep networks, and a discriminator of the pyramid architecture is designed to estimate high-level age-related clues in a fine-grained way. Our approach overcomes the limitations of single age-specific representation and handles age transformation both locally and globally. As a result, more photorealistic imageries are generated (see Fig. N for an illustration of aging results) . The main contributions of this study include: (N) We propose a novel GAN based method for age progression, which incorporates face verification and age estimation techniques, thereby addressing the issues of aging effect generation and identity cue preservation in a coupled manner; (N) We highlight the importance of the forehead and hair components of a face that are closely related to the perceived age but ignored in other studies; it indeed enhances the synthesized age accuracy; (N) We set up new validating experiments in addition to existent ones, including commercial face analysis tool based evaluation and insensitivity assessment to the changes in expression, pose, and makeup. Our method is not only shown to be effective but also robust to age progression.