That motion shown in two adjacent images or frames in an video is called optical flow. Optical flow estimation is the algorithms to estimating motion between two images or frames. The most general version of optical flow is to compute the independent of motion at each pixel of an image. As recently, the convolutional neural networks have been widely used in many areas of computer vision. We want estimate the optical flow by introducing a network architecture without any full connective layers and downsampling. Because we have a intuition that if we want to get a output that is as the same size as input, the downsampling of a network maybe unnecessary. However, as the experiments went on, we found that this kind of network performs bad no matter what kind of techniques were used in training until the downsampling layers were introduced. Several experiments and researches were done in order to gave a reasonable explanation and unveil the intrinsic problems inside this phenomenon. Finally, we proposed a deeper network with downsampling and upsampling layers that works quite well in this problem. This new network will take two resources as input. One is the raw images pairs, the other is an approximately flow that derive from some other quick methods. We want this CNNs can both fine tuning the approximately flow and take it as guide to compute a more accurately flow.