Depth information has been proven useful for face recognition. However, existing depth-image-based face recognition methods still suffer from noisy depth values and varying poses and expressions. In this paper, we propose a novel method for normalizing facial depth images to frontal pose and neutral expression and extracting robust features from the normalized depth images. The method is implemented via two deep convolutional neural networks (DCNN), normalization network (_inline_eq_) and feature extraction network (_inline_eq_) . Given a facial depth image, _inline_eq_ first converts it to an HHA image, from which the ND face is reconstructed via a DCNN. _inline_eq_ then generates a pose-and-expression normalized (PEN) depth image from the reconstructed ND face. The PEN depth image is finally passed to _inline_eq_, which extracts a robust feature representation via another DCNN for face recognition. Our preliminary evaluation results demonstrate the superiority of the proposed method in recognizing faces of arbitrary poses and expressions with depth images.