The structure in the large dataset could be represented by generative models, and this prospective is well studied these years. The generative models learn from the training dataset, and represent a mechanism that specify a stochastic procedure to produce samples from a probability distribution. These has been much progress in the neural network based generative models within adversarial framework. The adversarial framework is first pioneered by the generative adversarial network (GAN) _cite_ . In this framework, both a generator and a discriminator are trained through the adversarial training strategy where a two-player game is played in the training process. The generator learns to map a noise vector of a low-dimensional distribution (such as standard Gaussian or normal distribution) to points in a high-dimensional space. Simultaneously, a discriminator network is trained to distinguish between real and generated samples. This is achieved through setting up a min-max game between the generator and discriminator. The adversarial framework is shown to be successful in the generation of complex distributions. However, this generative process requires an access to a large number of full-observed samples from the desired distribution. This large-scale dataset is hard to be obtained practically. In fact, the capture of the large-scale dataset is expensive. For example, a large number of sensing images of the brain is costly to be achieved. Besides, the sensing images are very noisy in the real world. Therefore, a training strategy for obtaining a generative model directly from noisy or incomplete samples are in great demand.