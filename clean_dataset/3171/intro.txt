Utilizing the success and the potential of Deep Neural Networks to solve hard Artificial Intelligence tasks requires neural models that are capable of performing rapid learning ~ . For models to embody such rich learning capabilities, we believe that a crucial characteristic will be the employment of dynamic representations--representations that are formed by observing a growing and continually evolving set of features. We call the space that is formed by such evolving representations the dynamic representation space . In this paper, we present a novel model for one-shot learning that utilizes a crude approximation of such a dynamic representation space. This is done by constructing the representation space lazily and relative to a particular (test) sample every time. For the purpose of producing such relative representations, we develop a novel class of models called Attentive Recurrent Comparators (ARCs) . We first test ARCs across many tasks that require assessment of visual similarity. We find that ARCs that do not use any convolutions show comparable performance to Deep Convolutional Neural Networks on challenging datasets like CASIA WebFace and Omniglot. Though dense ARCs are as capable as ConvNets, a combination of both ARCs and convolutions (ConvARCs) produces much more superior models. In the task of estimating the similarity of two characters from the Omniglot dataset, ARCs and Deep ConvNets both achieve about N \% accuracy, whereas ConvARCs achieve N \% accuracy. In the task of face verification on the CASIA Webface dataset, ConvARCs achieved N \% accuracy surpassing the N \% accuracy achieved by a CNN baseline considered. We then use ARCs as a means for developing a lazy, relative representation space and use it for one-shot learning. On the challenging Omniglot one-shot classification task, our model achieved an accuracy of N \%, significantly surpassing the current state-of-the-art set by all other methods. This is also the first super-human result achieved for this task with a generic model that uses only pixel information. ARCs are inspired by our interpretation of how humans generally compare a set of objects. When a person is asked to compare two objects and estimate their similarity, the person does so by repeatedly looking back and forth between the two objects. With each glimpse of the object, a specific observation is made. These observations which are made in both objects are then cumulatively used to come to a conclusion about their similarity. A crucial characteristic of this process is that new observations are made conditioned on the previous context that has been investigated so far by the observer. The observation and it's contextual location are all based on intermediate deductions--deductions that are themselves based on the observations made so far in the two objects. A series of such guided observations and their entailing inferences are accumulated to form a final the judgement on their similarity. We will refer to how humans compare objects as the human way . In stark contrast to this, current similarity estimating systems in Deep Learning are analogues of the Siamese similarity learning system~ . In this system, a fixed set of features is detected in both the objects. The two objects are compared based on mutual agreement of the detected features. More concretely, comparison between two objects in this system consists of measuring the distance between their vector embeddings or representations. A neural network that is specifically trained to detect the most salient features in an object for a task defines the object to embedding mapping. Detection of features in one object is independent of the features present in the other object. There is a major underlying difference between the human approach discussed above and the siamese approach to the problem. In the human way, the information from the two objects is fused from the very beginning and this combined information primes the subsequent steps in comparison. There are multiple lookups on each of the objects and each of these lookups are conditioned on the observations of both the objects so far. In the siamese way, when the embeddings are compared the information fuses mostly at an abstract level and only in the last stage. Inspired by the human way, we develop an end-to-end differentiable model that can learn to compare objects called Attentive Recurrent Comparators (ARCs) . Fundamentally, the excellent performance of ARCs shows the value of "early fusion" of information across the context and the value of dynamic representations. Further, it also gives merit to the view that attention and recurrence together can be as good as convolutions in a few special cases. Finally, the superior similarity learning capability of ARCs can be of independent interest as an alternative to siamese neural networks for tasks such as face recognition and voice verification.