During the last years, artificial agents have been increasingly able to outperform humans in a variety of challenges across many different domains _cite_ . While it seems that computers have obvious advantages over humans in many areas, such as calculus or industrial assembly, they have very recently also managed to outperform humans on tasks that are comparatively easy for humans while being utterly complex problems for artificial agents. Recognizing faces in an image is a good example for such a task, as every human is able to do it within the fraction of a second. In computer vision, face recognition is a very difficult challenge, where a lot of research is still being conducted. Until recently, artificial agents were not able to achieve results comparable to those of humans, even with the most advanced approaches and the best available hardware. The methodology that finally allowed computer vision to outperform humans on object recognition tasks _cite_ is the, which we will inspect more closely in this survey. Almost N years ago, _cite_ already proposed the LeNet, a novel DCNN architecture for object recognition, but only in N an implementation by _cite_, the AlexNet, was first able to beat more traditional geometrical approaches on the most popular object recognition contest-the ILSVRC _cite_ . Ever since, DCNNs have been achieving state-of-the-art results on object recognition tasks. This paper will give a detailed overview of the evolution of DCNN architectures and how they are applied to object recognition challenges. The paper is structured as follows: In Sect. _ref_, we will take a closer look at the deep convolutional neural network and how it works. Afterwards, in Sect. _ref_, we will inspect how DCNNs are used for three different object recognition tasks: classification, localization and detection. In Sect. _ref_, the most influential DCNN architectures, including the LeNet and AlexNet we mentioned earlier, are presented in chronological order and explained. Finally, in Sect. _ref_, we will sum up the key aspects covered in this paper and list selected resources for further research.