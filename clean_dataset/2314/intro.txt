Connectomics is an emerging discipline of neuroscience dedicated to the reconstruction of neural structures and connectivity from brain images. Electron Microscopy (EM) can provide extremely detailed images (at nanomemter scale) of animal brain tissues for a comprehensive neural reconstruction. Recording at such high resolution generates a massive amount of data from a relatively small brain region; a _inline_eq_ volume of rat cortex amounts to N, N images of size _inline_eq_ when imaged at _inline_eq_ nm _inline_eq_ resolution. Automated or semi-automated processing is the most viable strategy to process datasets at this scale. Segmentation of neuron regions in EM volumes has become the central tool for many (semi-) automated neural reconstruction efforts _cite_ . Almost all these segmentation approaches utilize a pixel classifier to distinguish cell boundary (or membrane) pixels from cell interior (or other organelle) pixels. A set of annotated pixels is required to train such a classifier. Most of the existing segmentation algorithms _cite_ require an exhaustive ground-truth volume, where each pixel (or voxel) within the volume is annotated by expert users for training. The type of annotation is generally a label for boundary pixels. Exhaustive annotation of a sufficiently large volume demands significant time and effort from an expert in cell biology. Our experience suggests a _inline_eq_ x _inline_eq_ x _inline_eq_ EM volume would require _inline_eq_ weeks of dedicated labeling effort from a neurobiologist. Such a manual labeling step becomes a substantial bottleneck for the overall neural reconstruction process. This impediment is compounded for large datasets collected from multiple brain areas with biologically different cell characteristics and difference in tissue preparation techniques. Several researchers in the EM segmentation community realized this issue and proposed different algorithms for training pixel classifiers from a relatively small (and often sparse) set of training examples. The interactive software Ilastik _cite_ for learning a Random Forest pixel detector has become very popular in the bioinformatics community. Rather than asking for dense pixelwise labels, Ilastik provides a user interface to identify training examples that could potentially improve the classifier performance given the current classifier output overlaid on the input image. The works of Kaynig et. al. _cite_ and Parag et.al. _cite_ also proposed methods for sparse selection of a subset of training examples and demonstrated their advantages for EM segmentation. However, the strong dependence of the random forest classifiers on hand-tuned features has the potential to limit their performances on images from different EM preparation/imaging techniques and, more generally, from other data modalities. In this paper, we present a method for interactive training of a Convolutional Neural Network (CNN) classifier _cite_ for EM image segmentation. The user paints on an input image to mark the pixels corresponding to a particular class. Presented with the pixel classification performance of the CNN, the user marks one or more areas that s/he thinks would improve the quality of the segmentation. We propose an efficient training algorithm to yield near real-time feedback to the user. Our training method (Section _ref_) is designed to emphasize the most recent user input while retraining the CNN. In addition, the learning algorithm also keeps track of past training examples that were adversely affected by this update and prioritizes them for learning in the next iteration. For segmentation purposes, our training strategy enables us to train a CNN with less than _inline_eq_ of the total training examples, that is a few hundred thousands out of millions of total training examples. Compared to a CNN of the same architecture trained on all ground-truth images, our technique achieves slightly better segmentation accuracy. Our results corroborate well with past studies _cite_ that found that interactive training tends to produce a classifier that performs better for segmentation. The primary objective of training the pixel detector using our method is region segmentation. Therefore, we use Variation of Information (VI), which has become a standard measure in connectomics~ _cite_, to quantitatively compare segmentation performance. To our knowledge, ours is the first effort for interactive training of deep networks for EM segmentation. Although the method is primarily targeted and tested on EM data, we believe several problems in biomedical image segmentation could benefit from our method, including mitosis detection~ _cite_, cell segmentation on histopathology images~ _cite_, and cell tracking _cite_ .