The performance of face recognition systems depends heavily on facial representation, which is naturally coupled with many types of face variations, such as views, illuminations, and expressions. As face images are often observed in different views, a major challenge is to untangle the face identity and view representations. Substantial efforts have been dedicated to extract identity features by hand, such as LBP _cite_, Gabor _cite_, and SIFT _cite_ . The best practise of face recognition extracts the above features on the landmarks of face images with multiple scales and concatenates them into high dimensional feature vectors _cite_ . Deep neural nets _cite_ have been applied to learn features from raw pixels. For instance, learned identity features by training a convolutional neural net (CNN) with more than four million face images and using ND face alignment for pose normalization. Deep neural net is inspired by the understanding of hierarchical cortex in human brain _cite_ and mimicking some aspects of its activities. Human not only can recognize identity, but can also imagine face images of a person under different viewpoints, making face recognition in human brain robust to view changes. In some sense, human brain can infer a ND model from a ND face image, even without actually perceiving ND data. This intriguing function of human brain inspires us to develop a novel deep neural net, called multi-view perceptron (MVP), which can disentangle identity and view representations, and also reconstruct images under multiple views. Specifically, given a single face image of an identity under an arbitrary view, it can generate a sequence of output face images of the same identity, one at a time, under a full spectrum of viewpoints. Examples of the input images and the generated multi-view outputs of two identities are illustrated in Fig. _ref_ . The images in the last two rows are from the same person. The extracted features of MVP with respect to identity and view are plotted correspondingly in blue and orange. We can observe that the identity features of the same identity are similar, even though the inputs are captured in very different views, whilst the view features of images in the same view are similar, although they are across different identities. Unlike other deep networks that produce a deterministic output from an input, MVP employs the deterministic hidden neurons to learn the identity features, whilst using the random hidden neurons to capture the view representation. By sampling distinct values of the random neurons, output images in distinct views are generated. Moreover, to yield images in a specific order of viewpoints, we add regularization that images under similar viewpoints should have similar view representations on the random neurons. The two types of neurons are modeled in a probabilistic way. In the training stage, the parameters of MVP are updated by back-propagation, where the gradient is calculated by maximizing a variational lower bound of the complete data log-likelihood. With our proposed learning algorithm, the EM updates on the probabilistic model are converted to forward and backward propagation. In the testing stage, given an input image, MVP can extract its identity and view features. In addition, if an order of viewpoints is also provided, MVP can sequentially reconstruct multiple views of the input image by following this order. This paper has several key contributions . (i) We propose a multi-view perceptron (MVP) and its learning algorithm to factorize the identity and view representations with different sets of neurons, making the learned features more discriminative and robust. (ii) MVP can reconstruct a full spectrum of views given a single ND image, mimicking the capability of multi-view face perception in human brain. The full spectrum of views can better distinguish identities, since different identities may look similar in a particular view but differently in others as illustrated in Fig. _ref_ . (iii) MVP can interpolate and predict images under viewpoints that are unobserved, in some sense imitating the reasoning ability of human. Related Works. In the literature of computer vision, existing methods that deal with view (pose) variation can be divided into ND-and ND-based methods. The ND methods _cite_ often infer the deformation between ND images across poses. For instance, Jim nez et al. _cite_ used thin plate splines to infer the non-rigid deformation across poses. Many approaches _cite_ require the pose information of the input image and learn separate models for reconstructing different views. The ND methods capture ND data in different parametric forms and can be roughly grouped into three categories, including pose transformation _cite_, virtual pose synthesis _cite_, and feature transformation across poses _cite_ . The above methods have their inherent shortages. Extra cost and resources are necessitated to capture and process ND data. Because of lacking one degree of freedom, inferring ND deformation from ND transformation is often ill-posed. More importantly, none of the existing approaches simulates how human brain encodes view representations. In our approach, instead of employing any geometric models, view information is encoded with a small number of neurons, which can recover the full spectrum of views together with identity neurons. This representation of encoding identity and view information into different neurons is much closer to our brain system and new to the deep learning literature. We notice that a recent work _cite_ learned identity features by using CNN to recover a single frontal view face image, which is a special case of MVP after removing the random neurons. _cite_ is a traditional deep network and did not learn the view representation as we do. Experimental results show that our approach not only provides rich multi-view representation but also learns better identity features compared with _cite_ . Fig. _ref_ shows examples that different persons may look similar in the front view, but are better distinguished in other views. Thus it improves the performance of face recognition significantly.