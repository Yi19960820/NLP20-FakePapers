Person re-identification aims at matching people from d \nolinebreak ifferent views under surveillance cameras, which has been studied extensively in the past five years. To address the re-identification problem, existing methods exploit either cross-view invariant features ~ _cite_ or cross-view robust metrics~ _cite_ . Recently, Convolutional Neural Network (CNN) have been adopted in person re-identification, ~ \eg~ _cite_ . Deep Learning provides a powerful and adaptive ap \nolinebreak proach to handle computer vision problems without excessive handcraft on image features. The back propagation algorithm dynamically adjusts the parameters in CNN, which unifies both feature extraction and pairwise comparison process in a single network. However, in real-world person re-identification, a person's ap \nolinebreak pearance often undergoes large variations across non-overlapping camera views, due to significant changes in view angle, lighting, background clutter and occlusion (see Fig.~ _ref_) . Hand-crafted concatenation of different appearance features, ~ \eg RGB, HSV colorspaces and LBP descriptor, which are designed to overcome cross-view appearance variations in re-identification tasks, sometimes would be more distinctive and reliable. In order to effectively combine hand-crafted features and deeply learned features, we investigate the combination and complementary of a multi-colorspace hand-crafted features (ELFN) and deep features extracted from CNN. A deep feature fusion Network (FFN) is proposed in order to use hand-crafted features to regularize the CNN process so as to make the convolution neural networks extract features complementary to hand-crafted features. After extracting features by our FFN, traditional metric learning methods can be applied to boost the performance. Experimental results on three challenging person re-identification datasets (VIPeR, CUHKN, PRIDNs) demonstrate the e \nolinebreak ffectiveness of our new features. A significant improvemen \nolinebreak t of Rank-N matching rate is achieved as compared to state-of-the-art methods (N \%, N \% and N \%) on the three datasets. In a word, we show that hand-crafted features could improve the extraction process of CNN features in FFN, achieving a more robust image representation.