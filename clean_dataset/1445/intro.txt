Machine learning tasks are typically subdivided into two groups: supervised (when labels for data are provided by human annotators) and unsupervised (no data labelled) . Recently, more labelled data with millions of examples have become available (for example, Imagenet~ _cite_, Microsoft COCO~ _cite_), which led to significant progress in supervised learning research. This progress is partly due to the emergence of convenient labelling systems like Amazon Mechanical Turk. Still, the human labelling process is expensive and does not scale well. Moreover, it often requires a substantial effort to explain human annotators how to label data. Learning an interest point detector is a task where labelling ambiguity goes to extremes. In images, for example, we are interested in a sparse set of image locations which can be detected repeatably even if the image undergoes a significant viewpoint or illumination change. These points can further be matched for correspondences in related images and used for estimating the sparse ND structure of the scene or camera positions. Although we have some intuition about what properties interest points should possess, it is unclear how to design an optimal detector that satisfies them. As a result, if we give this task to a human assessor, he would probably select whatever catches his eye (maybe corners or blobs), but that might not be repeatable. In some cases, humans have no intuition what points could be "interesting". Let's assume one wants to match new images to untextured parts of an existing ND model~ _cite_ . The first step could be an interest point detection in two different modalities: RGB and depth map, representing the ND model. The goal would be to have the same points detected in both. It is particularly challenging to design such a detector since depth maps look very different from natural images. That means simple heuristics will fail: the strongest corners/blobs in RGB might come from texture which is missing in depth maps. Aiming at being independent of human assessment, we propose a novel approach to interest point detection via unsupervised learning. Up to our knowledge, unsupervised learning for this task has not yet been explored in previous work. Some earlier works hand-crafted detectors like DoG~ _cite_ . More recent works used supervised learning to select a "good" subset of detections from a hand-crafted detector. For example, LIFT~ _cite_ aims to extract a subset of DoG detections that are matched correctly in the later stages of the sparse ND reconstruction. However, relying on existing detectors is not an option in complicated cases like a cross-modal one. Our method, by contrast, learns the solution from scratch. The idea of our method is to train a neural network that maps an object point to a single real-valued response and then rank points according to this response. This ranking is optimized to be repeatable under the desired transformation classes: if one point is higher in the ranking than another one, it should still be higher after a transformation. Consequently, the top/bottom quantiles of the response are repeatable and can be used as interest points. This idea is illustrated in Fig.~ _ref_ . When detecting interest points, it is often required to output not only the position of the point in the image, but also some additional parameters like scale or rotation. The detected values of those parameters are influenced by the transformations applied to the images. All transformations can be split into two groups based on their desired impact on the output of the detector. Transformations for which the detector is supposed to give the same result are called invariant. Transformations that should transform the result of a detector together with the transformation---and thus their parameters have to be estimated as latent variables---are called covariant~ _cite_ . When learning a detector with our method, we can choose covariant and invariant transformations as it suits our goals. This choice is implemented as a choice of training data and does not influence the formulation. The paper is organized as follows. In section~ _ref_, we discuss the related work. In section~ _ref_, we introduce our formulation of the detection problem as the unsupervised learning to rank problem, and show how to optimize it. In section~ _ref_, we demonstrate how to apply our method to interest point detection in images. Finally, in section~ _ref_ we validate our approach experimentally and conclude in section~ _ref_ by summarizing the paper and listing possibilities for future work.