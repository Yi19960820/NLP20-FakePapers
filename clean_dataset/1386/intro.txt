Human parsing aims to segment a human image into multiple semantic parts. It is a pixel-level prediction task which requires to understand human images in both the global level and the local level. Human parsing can be widely applied to human behavior analysis _cite_, pose estimation _cite_ and fashion synthesis _cite_ . Recent advances in human parsing and semantic segmentation _cite_ mostly explore the potential of the convolutional neural network (CNN) . Based on CNN architecture, the is usually used _cite_ which punishes the classification error for each pixel. Despite providing an effective baseline, the pixel-wise classification loss which is designed for per-pixel category prediction, has two drawbacks. First, the pixel-wise classification loss may lead to, such as holes and blur. The reason is that it merely penalizes the false prediction on every pixel without explicitly considering the correlation among the adjacent pixels. For illustration, we train a baseline model (see Section _ref_) with the pixel-wise classification loss. As shown in Fig. _ref_ (a), some pixels which belongs to ``arm'' are incorrectly predicted as ``upper-clothes'' by the baseline. This is undesirable but is the consequence of local inconsistency of the baseline loss. Second, pixel-wise classification loss may lead to in the overall segmentation map, such as unreasonable human poses and incorrect spatial relationship of body parts. Compared to the local inconsistency, the semantic inconsistency is generated from deeper layers. When only looking at a local region, the learned model does not have an overall sense of the topology of body parts. As shown in Fig. _ref_ (b), the ``arm'' is merged with an adjacent ``leg'', indicating incorrect part topology (three legs) . Therefore, the pixel-wise classification loss does not explicitly consider the semantic consistency, so that long-range dependency may not be well captured. In the attempt to address the inconsistency problems, the conditional random fields (CRFs) _cite_ can be employed as a post processing method. However, CRFs usually handle inconsistency in very limited scope (locally) due to the pairwise potentials, and may even generate worse label maps given poor initial segmentation result. As an alternative to CRFs, a recent work proposes the use of adversarial network _cite_ . Since the adversarial loss assesses whether a label map is real or fake by joint configuration of many label variables, it can enforce higher-level consistency, which cannot be achieved with pairwise terms or the per-pixel classification loss. Now, an increasing number of works adopt the routine of combining the cross entropy loss with an adversarial loss to produce label maps closer to the ground truth _cite_ . Nevertheless, the previous adversarial network also has its limitations. First, the single discriminator back propagates only one adversarial loss to the generator. However, the local inconsistency is generated from top layers and the semantic inconsistency is generated from deep layers. The two targeted layers can not be discretely trained with only one adversarial loss. Second, a single discriminator has to look at overall high-resolution image (or a large part of it) in order to supervise the global consistency. As mentioned by numbers of literatures~ _cite_, it is very difficult for a generator to fool the discriminator on a high-resolution image. As a result, the single discriminator back propagates a maximum adversarial loss invariably, which makes the training unbalanced. We call it, as shown in Fig.~ _ref_ . In this paper, the basic objective is to improve the local and semantic consistency of label maps in human parsing. We adopt the idea of adversarial training and at the same time aim to addresses its limitations, the inferior ability in improving parsing consistency with a single adversarial loss and the poor convergence problem. Specifically, we introduce the Macro-Micro Adversarial Nets (MMAN) . MMAN consists of a dual-output generator (_inline_eq_) and two discriminators (_inline_eq_), named Macro _inline_eq_ and Micro _inline_eq_ . The three modules constitute two adversarial networks (Macro _inline_eq_, Micro _inline_eq_), addressing the semantic consistency and the local consistency, respectively. Given an input human image, the CNN-based generator outputs two segmentation maps with different resolution levels, low resolution and high resolution. The input of Macro _inline_eq_ is a low-resolution segmentation map, and the output is the confidence score of semantic consistency. The input of Micro _inline_eq_ is the high-resolution segmentation result, and its outputs is the confidence score of local consistency. A brief pipeline of the proposed framework is shown in Fig.~ _ref_ . It is in two critical aspects that MMAN departs from previous works. First, our method explicitly copes with the local inconsistency and semantic inconsistency problem using two task-specific adversarial networks individually. Second, our method does not use large-sized FOVs on high-resolution image, so we can avoid the poor convergence problem. More detailed description of the merits of the proposed network is provided in Section _ref_ . Our contributions are summarized as follows: