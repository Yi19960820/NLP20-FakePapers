Scene text recognition has drawn remarkable attention in computer vision due to its importance in various real world applications, such as scene understanding, card information entry, street sign reading and so on. Benefiting from recent advancements of deep learning, reading text in natural images has experienced a rapid evolution during the past few years. Despite significant advances, scene text recognition in unconstrained conditions still remains as a challenging problem due to the complex situations such as blurring, distortion, orientation and uneven lighting. Irregular text frequently appears in natural scenes, owing to curved character placement, perspective distortion, etc., as shown in Figure _ref_ . Recognizing text with arbitrary shapes is an extremely difficult task because of unpredictable changeful text layouts. Most existing approaches mainly focus on regular text recognition, which are difficult to be generalized to distorted text. Recently, some attempts have been made towards irregular text recognition. Yang _cite_ utilized a ND attention mechanism to focus on each character and introduced an auxiliary dense character detection task to encourage the learning of text-specific visual representations. However, this method used an exhausting multi-task learning strategy and the inaccurate attention regions will cause recognition errors. Cheng _cite_ proposed the arbitrary orientation network (AON) to extract scene text features in four directions and adopted a weighting mechanism to combine the four feature sequences of different directions. In order to extract features with the same dimension in four directions, AON has to resize the text image into a square shape. However, scene text generally has various aspect ratios, the strategy of scaling to a square will severely destroy the aspect ratio of the text line, especially for long text. Shi _cite_ applied a spatial transformation prior to recognition to transform the input image and rectify the text in it. The Spatial Transformer Network (STN) framework with Thin-Plate Spline (TPS) transformation is utilized to perform text rectification. Although _cite_ has shown impressive results on irregular benchmarks, we observe that the rectified images may still have distortions or lose some character information, especially for severely distorted text, which results in mistaken recognition results. In this paper, we design a novel Recurrent Calibration Network (RCN) to progressively calibrate the irregular text to boost the recognition performance. The recurrent structure iteratively refines the geometric transformation of irregular text under the same parametric capacity. In each iteration, the residual between the previous and current geometric transformation fields is estimated based on the previously calibrated image to get one step closer to the optimal one. In this way, the difficulty of each step is intrinsically relieved and the severe distortions can be eliminated in a progressive manner. Therefore, such design is capable of effectively improving the robustness of the model to large variations of text. Besides, we observe that spatial transformation on output image of the previous step cannot restore the missing character information, and the incomplete appearances will cause recognition errors as well. Therefore, we elaborate a fiducial-point refinement structure to keep the integrity of text during the recurrent process. Instead of the calibrated images, the coordinates of fiducial points are tracked and transmitted during multiple iterations. At each step, the localization network predicts the coordinate offsets with respect to the previous positions, which implicitly reflects the residual spatial transformation. Furthermore, we map the coordinates of fiducial points back to the original input image and sample from the original. In this way, while the coordinates fall outside the calibrated image, mapping back to the original means compensating some missing information. Our method can effectively calibrate the irregular text while preserving the original character information in multiple calibrations. The calibration network is jointly optimized with the recognition network under the same objective in an end-to-end scheme. Therefore, our RCN can automatically learn the optimal transformation for the following recognition task. The main contributions are summarized as follows: (N) We propose a Recurrent Calibration Network (RCN) to progressively calibrate the irregular text to boost the recognition performance. (N) We design a fiducial-point refinement structure to keep the integrity of text during the recurrent process, which avoids the accumulation of missing information in the scenario of iterative calibrations. (N) Our RCN achieves superior performance compared with the state-of-the-art methods on the challenging datasets, especially on irregular benchmarks.