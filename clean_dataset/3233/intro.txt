Cartoons and comics became a popular mean of artistic expression worldwide. Unfortunately, only a limited number of talented people with painting or graphics skills can create them holding on to aesthetic standards. What is more, it also takes a significant amount of time to create a valuable comic graphics. Providing an automatic tool to transfer the style of images or videos to comics could revolutionize the way publishers and individuals create {\it comixified} content. Gatys et al. _cite_ showed that spectacular results in terms of transferring the style between the images can be obtained using convolutional neural networks and their intermediate representations. Further works presented improved versions of the original style transfer algorithm that improve the model in terms of execution speed, results quality and generalization to various styles. Although many publications focused on various applications of style transfer, to our best knowledge, this is the first attempt to evaluate and compare the results obtained by several methods in the context of transferring comic style. More precisely, in this paper we compare several modern style transfer methods and evaluate their effectiveness in terms of how well they propagate various comic style characteristics between the images. In our work, we focus mostly on the most efficient methods, {\it i.e.} the methods whose execution time per image do not exceed N seconds, that enable arbitrary style transfer with infinite number of possible comic styles. The remainder of this paper is organized in the following manner. In Section N we describe all related works that discuss the topic of style transfer. Section N presents an detailed overview of a selected set of the state-of-the-art approaches. Section N describes our experimental setup, image collection process and implementation sources. Section N presents the results of our evaluation. Section N shows results of conducted survey. In Section N we make some conclusions and plans for further research.