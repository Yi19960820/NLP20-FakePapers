computer vision and machine learning, learning a meaningful distance/similarity metric on the original feature presentation of samples, with the given distance constraints (either pairwise similar/dissimilar distance constraints or triplet based relative distance constraints) at the same time, is usually regarded as a crucial and challenging problem, which has been actively studied over the decades. According to the different measure functions (e.g., Mahalanobis distance function and bilinear similarity function), the current metric learning methods can be roughly classified into two categories, i.e., and . The first class, Mahalanobis distance-based methods, refers to learning a pairwise real-valued distance function, which is parameterized by a symmetric Positive Semi-Definite (PSD) matrix. The second class, bilinear similarity-based methods, aims to learn a form of bilinear similarity function which does not need to impose the PSD constraint on learned metrics. Recently, instead of batch manner, learning the metric in an online manner, which refers to online metric learning (OML), has attracted lots of interests, with the goal of learning a discriminative metric with partially known sampled data for efficiently dealing with large-scale learning problem. Generally, to satisfy the online processing speed for large-scale learning problem, OML methods are required to well tackle the following two core issues: (N) how to fast construct the triplet (or pair) in the original data, especially for the large-scale data, and (N) how to fast update the metric with the new coming samples in a real time manner. For fast triplet (or pair) construction (first issue), existing OML methods usually assume that pairwise or triplet constraints can be obtained in advance _cite_, or by employing the random sampling strategy to reduce the size of triplets _cite_ . However, in real applications, it is usually infeasible to access the entire training set at a time, especially when the training set is relative large, constructing the constraints will be both time-and space-consuming. To this end, we propose a novel one-pass triplet construction strategy to rapidly construct triplets in an online manner. In particular, the strategy selects two latest samples from both the same and different classes of currently available samples respectively, to construct a triplet. Compared with Online Algorithm for Scalable Image Similarity (OASIS) _cite_, which utilizes a random sampling strategy and stores the entire training data in memory with space complexity of _inline_eq_ (_inline_eq_ is the feature dimensionality, and _inline_eq_ is the data size, which is very large for large-scale data), our one-pass strategy can vastly reduce the space complexity to _inline_eq_ (_inline_eq_ is the total number of classes, which is usually small) . Also, the time complexity of our triplet construction strategy is _inline_eq_, which is truly fast. For fast metric updating (second issue), several studies _cite_ try to adopt a closed-form solution for accurate computation. Among them, OASIS adopts bilinear similarity learning and has a closed-form solution, while it lacks a good interpretability as Mahalanobis distance metric learning (i.e., linear projection) and the learned similarity function is asymmetric. In contrast, LogDet Exact Gradient Online (LEGO) _cite_ attempts to learn a Mahalanobis distance and has a closed-form solution. In addition, LEGO is not required to maintain the PSD constraint by using LogDet regularization, which is time-consuming in some Mahalanobis distance metric learning methods _cite_ . However, LEGO is designed for pairwise constraints. Compared with LEGO, we developed a different Mahalanobis distance-based OML method for triplet-based constraints, named as OPML, which also has the property of closed-form solution and does not need projection steps to maintain PSD constraint. Specifically, the proposed OPML directly learns the transformation matrix _inline_eq_ (_inline_eq_ is the symmetric PSD matrix usually learnt in Mahalanobis metric learning), such a setting does not require imposing the PSD constraint. By carefully analysing the structure of the triplets based loss and using a few fundamental properties (Lemma _ref_, Lemma _ref_), a closed-form solution at each step is obtained with the time complexity of _inline_eq_ . The major differences between OPML and OASIS/LEGO can be found in Table _ref_ . Also, in some tasks, e.g., abnormal event detection in videos, the data is usually imbalanced: the first several samples may belong to the same class, then the triplet construction strategy will be invalid until the samples of different classes appear. We call this case as cold start case. Furthermore, to deal with the cold start issue, an extension namely COPML is developed in this paper. Specifically, COPML includes a pre-stage by constructing pairwise constraints for two adjacent samples (from the same class) to update the metric. To summarize, compared with previous OML methods, the advantages of our work can be concluded as: First, the proposed OPML and COPML are easy to implement. Second, OPML and COPML are scalable to large datasets with a low space (i.e., _inline_eq_) and time (i.e., _inline_eq_) complexity, where _inline_eq_ is the feature dimensionality. Third, we have derived several theoretical explanations, including the difference bound between learned metrics of ones-pass and batch triplet construction strategies, the average loss bound between these two strategies and the regret bound, to guarantee the effectiveness of our methods. The rest of this paper is organized as follows. In section _ref_, we present the related works of OML methods. Section _ref_ provides the details of the proposed one-pass triplet construction strategy, OPML and COPML algorithms. In section _ref_, we give the theoretical guarantee of our algorithm. The experimental results, comparisons and analysis are given in section _ref_, followed by conclusions in section _ref_ .