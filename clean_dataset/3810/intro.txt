Increased availability of data and computational power has often been followed by progress in computer vision and machine learning. The recent rise of deep learning in computer vision for instance has been promoted by the availability of large image datasets _cite_ and increased computational power provided by GPUs _cite_ . Optical music recognition (OMR) _cite_ is a classical and challenging area of document recognition and computer vision that aims at converting scans of written music to machine-readable form, much like optical character recognition (OCR) _cite_ does for printed text. While results on simplified tasks show promising results _cite_, there is yet no OMR solution that leverages the power of deep learning. We conjecture that this is caused in part by the lack of publicly available datasets of written music, big enough to train deep neural networks. The dataset has been collected with OMR in mind, but as well addresses important aspects of next generation computer vision research that pertain to the size and number of objects per image. Although there is already a number of clean, large datasets available to the computer vision community _cite_, those datasets are similar to each other in the sense that for each image there are a few large objects of interest. Object detection approaches that have shown state-of-the-art performance under these circumstances, such as Faster R-CNN _cite_, SSD _cite_ and YOLO _cite_, demonstrate very poor off-the-shelf performances when applied to environments with large input images containing multiple small objects (see Section _ref_) . Sheets of written music, on the other hand, usually have dozens to hundreds of small salient objects. The class distribution of musical symbols is strongly skewed and the symbols have a large variability in size. Additionally, the OMR problem is very different from modern OCR _cite_: while in classical OCR, the text is basically a ND signal (symbols to be recognized are organized in lines of fixed height, in which they extend from left to right or vice versa), musical notation can additionally be stacked arbitrarily also on the vertical axis, thus becoming a ND signal. This superposition property would exponentially increase the number of symbols to be recognized, if approached the usual way (which is intractable from a computational as well as from a classification point of view) . It also makes segmentation very hard and does not imply a natural ordering of the symbols as for example in the SVHN dataset _cite_ . In this paper, we present the dataset with the following contributions: a) a curated dataset of a collection of hundreds of thousands of musical scores, containing tens of millions of objects to construct a high quality dataset of written music; b) available ground truth for the tasks of object detection, semantic segmentation, and classification; c) comprehensive comparisons with other computer vision datasets (see Section _ref_) and a quantitative and qualitative analysis of (see Section _ref_) ; d) computation of an object classification baseline and a qualitative assessment of current off-the-shelf detection methods along with reasoning why detection needs new approaches on (see Section _ref_) ; e) proposals on how to facilitate next generation computer vision research using (see Section _ref_) . The data, a recommended evaluation scheme and accompanying TensorFlow _cite_ code are freely available .