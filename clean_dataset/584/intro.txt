Human identification through biometrics has been both an important and popular research field. Among the biometric traits, ear is a unique part of the human body in terms of different features such as shape, appearance, posture, and there is usually not much change in the ear structure except that the ear length is prolonged over time _cite_ . Various studies have been conducted and many different approaches have been proposed on ear recognition, however, it still remains as an open challenge, especially when the ear images are collected under uncontrolled conditions as in the Unconstrained Ear Recognition Challenge (UERC) _cite_ . Ear recognition approaches are mainly categorized into four groups, holistic, local, geometric, and hybrid processing _cite_ . In the earlier studies, the most popular feature extraction methods for ear recognition were SIFT _cite_, SURF _cite_, and LBP _cite_ . Due to the popularity of deep learning in recent years and its significant impact on the computer vision field _cite_, deep convolutional neural networks (CNN) based approaches have also been adopted for ear recognition _cite_ . CNNs mainly require a large amount of data for training. However, the amount of samples in the datasets available for ear recognition are rather limited _cite_ . Due to this limitation, CNN-based ear recognition approaches mainly utilize an already trained object classification model, so called a pretrained deep CNN model, from one of the well-known, high performing CNN architectures, for example _cite_ . These pretrained models were trained on the ImageNet dataset _cite_ for generic object classification purposes, therefore, they are required to be adapted to the ear recognition problem. This adaptation is done mainly with a fine-tuning process, where the output classes are updated with subject identities and the employed pretrained deep CNN model is further trained using the training part of an ear dataset. In the field of ear recognition, most of the used datasets have been collected under controlled conditions, and therefore, very high recognition performance has been achieved on them _cite_ . But the proximity of these accuracies to the real world is a topic of debate. Because of this, in-the-wild datasets have been collected in order to imitate real-world challenges confronted in ear recognition better~ _cite_ . These datasets, since they contain images collected from the web, have a large variety, for example, in terms of resolution, illumination, and use of accessories. Sample ear images shown in Fig. _ref_ are from the UERC dataset. It can be seen from Fig. _ref_ that there are accessories, partial occlusions due to hair, and also pose and illumination variations. Because of these significant appearance variations, the performance of the ear recognition systems on the wild datasets, such as on the UERC, is not as high as the ones obtained on the datasets collected under controlled conditions. In this paper, we present a comprehensive study on ear recognition in the wild . We have employed well-known, high performing deep CNN models, namely, AlexNet _cite_, VGG-N _cite_, and GoogLeNet~ _cite_ and proposed a domain adaptation strategy for deep CNN-based ear recognition. We have also provided an in depth analysis of several aspects of ear recognition. Our contributions are summarized as follows: For the experiments, we have used the Multi-PIE ear and the UERC datasets _cite_ . Since Multi-PIE ear dataset is collected under controlled conditions, the achieved results were very high. From the experiments on the UERC dataset, we have shown that the proposed two-stage fine-tuning scheme is very beneficial for ear recognition. With data augmentation and without alignment, for AlexNet _cite_, the correct classification rate is increased from N \% to N \%. For VGG-N _cite_ and GoogLeNet _cite_, the increase is from N \% to N \% and from N \% to N \%, respectively. Combining different deep convolutional neural network models has led to further improvement in performance by N \% compared to the single best performing model. We have observed that data augmentation enhances the accuracy, whereas performing alignment did not improve the performance. However, this point requires further investigation, since only a coarse alignment has been performed by flipping the ear images to one side. Experimental results show that the ear recognition system performs better, when the ear images are cropped from profile faces. Very dark and very bright illumination causes missing details and reflections, which results in performance deteriorations. Experiments to examine the dataset bias have indicated a strong bias among the ear recognition datasets. The remainder of the paper is organised as follows. A brief review of the related work on ear recognition is given in Section N. The employed methods in this work are explained in Section N. In Section N, experimental results are presented and discussed. Finally, Section N provides conclusions and future research directions.