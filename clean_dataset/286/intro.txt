Deep neural networks have recently been achieved breakthroughs in several domains such as computer vision~ _cite_, speech recognition~ _cite_, and natural language processing~ _cite_ . Especially in computer vision, deep convolutional neural networks (CNNs) are actively applied to object recognition tasks like object classification~ _cite_, detection~ _cite_, and semantic segmentation~ _cite_ . Given an input image, semantic segmentation task should finely estimate pixel-level class labels while object classification just classifies its image-level category, so features discriminating details of target objects as well as semantic information of the entire image should be well defined in a training stage. Among the semantic segmentation tasks, semi-or weakly-supervised approaches under weak supervision such as bounding-box annotations~ _cite_, a limited number of segmentation annotations~ _cite_, or image-level labels~ _cite_, are preferred in real applications, since pixel-level labelling for fully-supervised semantic segmentation~ _cite_ requires heavy annotation efforts compared to the semi-or weakly-supervised counterparts. Especially in weakly-supervised semantic segmentation, only the image-level labels are available for training so the pixel-level fine-grained inference for detailed shape near boundary of target objects is quite difficult. Thus, most of the weakly-supervised semantic segmentation approaches exploit appropriate pre/post-processing or additional informative supervision (e.g., superpixel~ _cite_, extraneous segmentation annotations~ _cite_, size constraints of region-of-interests (ROIs) ~ _cite_, and smoothing boundary priors~ _cite_) . In natural images, training under those informative priors enables more accurate pixel-level inference while exploiting spatial coherency between pixels. The ROI segmentation task becomes more challenging in medical images, since only the trained clinicians who have expertise in corresponding medical domains can annotate pixel-level abnormalities. Furthermore, additional image processing commonly used in natural images cannot guarantee improvement of segmentation performance because of different characteristics of target ROIs (e.g., lesion) . In this case, domain-specific pre/post-processing is required, but it also needs domain-specific knowledges and expertise. In this work, a novel method for weakly-supervised semantic segmentation, deconvolutional feature stacking, is proposed. We build a deconvolutional neural network on top of the CNN to reconstruct a rich set of discriminative features from the abstracted features of the top most convolution layer. In a single deconvolution layer, input features are upsampled via unpooling switches defined by the corresponding pooling operation (features are bypassed according to the pooled position, and the rests of the upsampled positions are filled with zero~ _cite_) and convolved by a deconvolution operator. This helps to suppress less discriminative features in a feature extraction stage, since the deconvolution operator reconstructs detailed features from the most discriminative activations. The convolutional weight of the deconvolution operation is tied with that of corresponding convolution layer. This assists training under weak supervision, because `tied weight' confines the search space under the constraint of tight connection between convolution and deconvolution layers. The restored features from all of the deconvolution layers can constitute a rich feature set according to different sizes of receptive fields, and those features are fully utilized in a pixel-level inference stage. Fig.~ _ref_ shows overall architecture of the proposed framework. Features with the highest abstraction level extracted from the last convolution layer is used for building-up details of ROIs. All the feature maps restored from deconvolution layers and the feature map extracted from the last convolution layer are upscaled to be matched with the dimension of the final feature map extracted from the last deconvolution layer. Then, all the feature maps are stacked across channel dimension. The stacked feature map includes from coarse-grained to fine-grained features, so the following convolution layer (bottom of the figure) can selectively extract class-specific key features from the stacked rich feature set. The last convolution layer consists of class number of convolutional filters. Its output maps are softmaxed across channel dimension to assign a single label to each pixel. Since only the image-level labels are available in the weakly-supervised setting, each class-specific map is aggregated into a single value using a global per-map pooling operation. The proposed methodology will be discussed in more detail in Section N. Our contribution is summarized as below: The rest of this paper is organized as follows. Section N introduces related works, and Section N describes the detailed methodology. Experimental set-up and results are presented in Section N, and Section N concludes this paper.