Recent advances in object detection are driven by the success of region proposal methods (\eg, _cite_) and region-based convolutional neural networks (R-CNNs) _cite_ . Although region-based CNNs were computationally expensive as originally developed in _cite_, their cost has been drastically reduced thanks to sharing convolutions across proposals _cite_ . The latest incarnation, Fast R-CNN _cite_, achieves near real-time rates using very deep networks _cite_, . Now, proposals are the test-time computational bottleneck in state-of-the-art detection systems. Region proposal methods typically rely on inexpensive features and economical inference schemes. Selective Search _cite_, one of the most popular methods, greedily merges superpixels based on engineered low-level features. Yet when compared to efficient detection networks _cite_, Selective Search is an order of magnitude slower, at N seconds per image in a CPU implementation. EdgeBoxes _cite_ currently provides the best tradeoff between proposal quality and speed, at N seconds per image. Nevertheless, the region proposal step still consumes as much running time as the detection network. One may note that fast region-based CNNs take advantage of GPUs, while the region proposal methods used in research are implemented on the CPU, making such runtime comparisons inequitable. An obvious way to accelerate proposal computation is to re-implement it for the GPU. This may be an effective engineering solution, but re-implementation ignores the down-stream detection network and therefore misses important opportunities for sharing computation. In this paper, we show that an algorithmic change---computing proposals with a deep convolutional neural network---leads to an elegant and effective solution where proposal computation is nearly cost-free given the detection network's computation. To this end, we introduce novel (RPNs) that share convolutional layers with state-of-the-art object detection networks _cite_ . By sharing convolutions at test-time, the marginal cost for computing proposals is small (\eg, Nms per image) . Our observation is that the convolutional feature maps used by region-based detectors, like Fast R-CNN, can also be used for generating region proposals. On top of these convolutional features, we construct an RPN by adding a few additional convolutional layers that simultaneously regress region bounds and objectness scores at each location on a regular grid. The RPN is thus a kind of fully convolutional network (FCN) _cite_ and can be trained end-to-end specifically for the task for generating detection proposals. RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios. In contrast to prevalent methods _cite_ that use pyramids of images (Figure~ _ref_, a) or pyramids of filters (Figure~ _ref_, b), we introduce novel ``anchor'' boxes that serve as references at multiple scales and aspect ratios. Our scheme can be thought of as a pyramid of regression references (Figure~ _ref_, c), which avoids enumerating images or filters of multiple scales or aspect ratios. This model performs well when trained and tested using single-scale images and thus benefits running speed. To unify RPNs with Fast R-CNN _cite_ object detection networks, we propose a training scheme that alternates between fine-tuning for the region proposal task and then fine-tuning for object detection, while keeping the proposals fixed. This scheme converges quickly and produces a unified network with convolutional features that are shared between both tasks. We comprehensively evaluate our method on the PASCAL VOC detection benchmarks _cite_ where RPNs with Fast R-CNNs produce detection accuracy better than the strong baseline of Selective Search with Fast R-CNNs. Meanwhile, our method waives nearly all computational burdens of Selective Search at test-time---the effective running time for proposals is just N milliseconds. Using the expensive very deep models of _cite_, our detection method still has a frame rate of Nfps () on a GPU, and thus is a practical object detection system in terms of both speed and accuracy. We also report results on the MS COCO dataset _cite_ and investigate the improvements on PASCAL VOC using the COCO data. Code has been made publicly available at (in MATLAB) and (in Python) . A preliminary version of this manuscript was published previously _cite_ . Since then, the frameworks of RPN and Faster R-CNN have been adopted and generalized to other methods, such as ND object detection _cite_, part-based detection _cite_, instance segmentation _cite_, and image captioning _cite_ . Our fast and effective object detection system has also been built in commercial systems such as at Pinterests _cite_, with user engagement improvements reported. In ILSVRC and COCO N competitions, Faster R-CNN and RPN are the basis of several Nst-place entries _cite_ in the tracks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. RPNs completely learn to propose regions from data, and thus can easily benefit from deeper and more expressive features (such as the N-layer residual nets adopted in _cite_) . Faster R-CNN and RPN are also used by several other leading entries in these competitions . These results suggest that our method is not only a cost-efficient solution for practical usage, but also an effective way of improving object detection accuracy.