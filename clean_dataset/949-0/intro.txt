Convolutional Neural Networks (CNNs) ~ _cite_ have led to leap-forward in a large number of computer vision applications. On the task of large scale image classification, particularly ImageNet~ _cite_, CNNs-family models have been dominating. CNNs are able to automatically learn rich hierachical features from input images. However, for images dataset like PASCAL VOC~ _cite_ where objects have a large variation in shape, size, and clutter, directly adopting CNN does not produce satisfactory results: state-of-the-art results for PASCAL VOC object classification are obtained with Bag of Visual Words (BoVW) on top of the CNN features that are learned separately. As shown in Fig.~ _ref_ (a), ImageNet mainly consists of, i.e. single large objects in the canonical perspective are located in the center of these images. Compared with ImageNet, structures of PASCAL VOC images tend to be much more complex. Objects have large variations in location, scale, layout, and appearance; The backgrounds are cluttered; There tends to be multiple objects in an image. A standard pipeline includes (N) local feature extraction using off-the-shelf CNNs that are pretrained on ImageNet; (N) sparse coding~ _cite_ or Fisher Vector~ _cite_ adopted to aggregate local features into a global, fixed-dimensional image representation; (N) classification on the encoded feature space. These specific approaches often produce results that are much better than those by plain CNN~ _cite_ . Due to the complexity of BoVW based methods, most previous works extract representations with a standalone module which cannot be trained together with other modules. Consequently, former modules in their algorithm pipelines such as the CNN feature extractor does not receive error differentials from latter ones, and thus cannot be finetuned. This has negative impacts on the overall performance. In one particular aspect, CNN features are learned from ImageNet, whose object distribution is quite different from that in PASCAL VOC. Without finetuning, the features are likely to be less effective. In this paper, we propose, an end-to-end trainable neural network which takes advantage of both CNN features and the powerful Fisher Vector (FV) ~ _cite_ encoding method. FisherNet densely extracts local features at multiple scales, and aggregates them with FV. FV encodes and aggregates local descriptors with a universal generative Gaussian Mixture Model (GMM) . We model this process into a learnable module, which we call . The Fisher Layer allows back-propagating error differentials as well as optimizing the FV codebook, eventually making the whole network trainable end-to-end. Moreover, FisherNet learns and extracts local patch features with great efficiency. Inspired by the recent success of fast object detection algorithms such as SPPnet~ _cite_ and Fast R-CNN~ _cite_, we share the computation of feature extraction among patches. Experiments show that our FisherNet significantly boosts the performance of an untrained FV, and achieves highly competitive performance on the PASCAL VOC object classification task. In testing, a FisherNet with the AlexNet~ _cite_ takes only _inline_eq_ s to classify one image, and _inline_eq_ s with the VGGN~ _cite_, both over _inline_eq_ faster than the previous state-of-the-art method HCP~ _cite_ .