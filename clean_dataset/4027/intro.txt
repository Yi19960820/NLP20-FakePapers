Person re-identification (re-id) ~ _cite_ aims at matching a target person with a gallery of pedestrian images. It has many video surveillance applications, such as finding criminals~ _cite_, cross-camera person tracking~ _cite_, and person activity analysis~ _cite_ . The problem is challenging because of complex variations of human poses, camera viewpoints, lighting, occlusion, resolution, background clutter, \etc, and thus draws much research attention in recent years~ _cite_ . Although numerous person re-id datasets and methods have been proposed, there is still a big gap between the problem setting itself and real-world applications. In most benchmarks~ _cite_, the gallery only contains manually cropped pedestrian images (Figure~ _ref_), while in real applications, the goal is to find a target person in a gallery of whole scene images, as shown in Figure~ _ref_ . Following the protocols of these benchmarks, most of the existing person re-id methods assume perfect pedestrian detections. However, these manually cropped bounding boxes are unavailable in practical applications. Off-the-shelf pedestrian detectors would inevitably produce false alarms, misdetections, and misalignments, which could harm the final searching performance significantly. In N, Xu~ \etal~ _cite_ made the first step towards closing this gap. They introduced the person search problem to the community, and proposed a sliding window searching strategy based on a combination of pedestrian detection and person matching scores. However, the performance is limited by the handcrafted features, and the sliding window framework is not scalable. In this paper, we propose a new deep learning framework for person search. Different from conventional approaches that break down the problem into two separate tasks---pedestrian detection and person re-identification, we jointly handle both aspects in a single Convolutional Neural Network (CNN) . Our CNN consists of two parts, given a whole input gallery image, a pedestrian proposal net is used to produce bounding boxes of candidate people, which are fed into an identification net to extract features for comparing with the target person. The pedestrian proposal net and the identification net adapt with each other during the joint optimization. For example, the proposal net can focus more on the recall rather than the precision, as false alarms could be eliminated through the latter features matching process. Meanwhile, misalignments of proposals are also acceptable, as they can be further adjusted by the identification net. To improve the scalability of the whole system, inspired by recent advances in object detection~ _cite_, we encourage both parts to share underlying convolutional feature maps, which significantly accelerates the inference procedure. Traditional re-id feature learning mainly employs pairwise or triplet distance loss functions~ _cite_ . However, they are not efficient as only several data samples are compared at each time, and there are _inline_eq_ potential input combinations, where _inline_eq_ is the number of images. Different sampling strategies could significantly impact the convergence rate and quality, but finding efficient sampling strategies becomes much more difficult as _inline_eq_ increases. Another approach is learning to classify identities with the Softmax loss function~ _cite_, which effectively compares all the samples at the same time. But as the number of classes increases, training the big Softmax classifier matrix becomes much slower or even cannot converge. In this paper, we propose a novel Online Instance Matching (OIM) loss function to cope with the problems. We maintain a lookup table of features from all the labeled identities, and compare distances between mini-batch samples and all the registered entries. On the other hand, many unlabeled identities could appear in scene images, which can be served as negatives for labeled identities. We thus exploit a circular queue to store their features also for comparison. This is another advantage brought by the person search problem setting. The proposed parameter-free OIM loss converges much faster and better than the Softmax loss in our experiments. The contribution of our work is three-fold. First, we propose a new deep learning framework to search a target person from a gallery of whole scene images. Instead of simply combining the pedestrian detectors and person re-id methods, we jointly optimize both objectives in a single CNN and they better adapt with each other. Second, we propose an Online Instance Matching loss function to learn identification features more effectively, which enables our framework to be scalable to large datasets with numerous identities. Together with the fast inference speed, our framework is much closer to the real-world application requirements. At last, we collect and annotate a large-scale benchmark dataset for person search, covering hundreds of scenes from street and movie snapshots. The dataset contains _inline_eq_ images, _inline_eq_ identities, and _inline_eq_ pedestrian bounding boxes. We validate the effectiveness of our approach comparing against other baselines on this dataset. The dataset and code are made public to facilitate further research .