According to a recent report published by the American Cancer Society, breast cancer is the most prevalent form of cancer in women, in the USA. In N alone, studies indicate that approximately N, N new cases of invasive breast cancer and N, N cases of in situ breast cancer are expected to be diagnosed, with N, N breast cancer-related deaths expected to occur _cite_ . Consequently, there is a real need for early diagnosis and treatment, in order to reduce morbidity rates and improve patients' quality of life. Histopathology remains crucial to the diagnostic process and the gold standard for differentiating between benign and malignant tissue, and distinguishing between patients suffering from in situ and invasive carcinoma _cite_ . Diagnosis and identification of breast cancer sub-types typically involve collection of tissue biopsies from masses identified using mammography or ultrasound imaging, followed by histological analysis. Tissue samples are usually stained with Hematoxylin and Eosin (H \&E) and subsequently, visually assessed by pathologists using light microscopy. Visual assessment of tissue microstructure and the overall organization of nuclei in histology images is time-consuming and can be highly subjective, due to the complex nature of the visible structures. Consequently, automatic computer-aided-diagnosis systems are essential to reduce the workload of specialists by improving diagnostic efficiency, and to reduce subjectivity in disease classification. Classification of histology images into cancer sub-types and metastases detection in whole-slide images are challenging tasks. Numerous studies have proposed automated approaches to address the same in recent years. Kothari et al. _cite_ examined the utility of biologically interpretable shape-based features for classification of histological renal tumor images. They extracted shape-based features that captured the distribution of tissue structures in each image and employed these features within a multi-class classification model. Doyle et al. _cite_ proposed an automated framework for distinguishing between low and high grades of breast cancer, from H \&E-stained histology images. They employed a large number of image-derived features together with spectral clustering to reduce the dimensionality of the feature space. The reduced feature set was subsequently used to train a support vector machine classifier to distinguish between cancerous and non-cancerous images, and low and high grades of breast cancer. Wang et al. _cite_ proposed an award-winning (at the International Symposium on Biomedical Imaging) deep learning framework for whole-slide classification and cancer metastases detection in breast sentinel lymph node images. In a recent study _cite_, the authors proposed a convolutional neural network (CNN) based approach to classifying H \&E-stained breast histology images into four tissue classes, namely, healthy, benign, in situ carcinoma and invasive carcinoma, with a limited number of training samples. The features extracted by the CNN were used for training a Support Vector Machine classifier. Accuracies of N \% for four class classification and N \% for carcinoma/non-carcinoma classification were achieved. In this study, we investigate the efficacy of transfer-learning for the task of image-wise classification of H \&E-stained breast cancer histology images and examine the classification performance of the pre-trained Inception-VN _cite_ and ResNetN _cite_ networks, on the BACH N challenge data set.