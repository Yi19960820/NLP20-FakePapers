Automated analysis of medical images using neural networks has been used in dermatoscopy for more than a decade _cite_, but recently gained attention since groups have reported high accuracy rates with convolutional neural networks (CNN) for skin images _cite_ and dermatoscopy _cite_, as well as for other medical domains such as fundoscopy _cite_ or chest X-rays _cite_ . CNNs, in brief, are a group of modern and powerful machine learning models that don’t require explicit handcrafted engineering. Rather, they learn to detect visual elements such as colors, shapes and edges by themselves, and combine detections of those internally to a prediction. The only thing needed for them, apart from computing power, is a large number of images and labels to train them, where the labels correspond to the diagnosis in the medical field. Implementing automated classification models, like a CNN, that output probabilities of diagnoses, or the most probable diagnosis, is deemed desirable for a number of reasons within a health care system. Using patient-based methods could ultimately reduce the need for physicians in areas of scarcity and reduce burden on the health care system, but are highly problematic in regard to regulations and safety. A more realistic approach is having decision support systems available to non-specialised physicians that may be easier to implement and have the potential to increase their diagnostic accuracy and decrease referral rates. Integrating classification systems into a specialists’ clinical workflow may increase efficiency and free them from spending a large amount of time on easy to diagnose cases. While these effects are undeniably positive, real-world settings can be problematic for classifiers that output the probability of a diagnosis. Accuracy rates for specified cutoffs are commonly reported in experimental settings on digital images with a verification bias, as mainly pathologically verified diagnoses are deemed the gold standard for ground-truth labels _cite_ . Even in sets using expert evaluations as “labels”, the included cases may not inherit all or enough representations of common banal skin diseases _cite_ . Specialised centers may not bother photo-documenting such common cases due to the additional time required, and given their obvious diagnosis to an expert. Apart from imperfect accuracy rates of neural networks, unforeseen problems can arise in practical use. This is exemplified by an earlier clinical study using an automated skin lesion classifier where melanomas where missed simply because they were not photographed by the user _cite_ . Lastly, classifications of CNNs can be prone to adversarial examples _cite_ raising questions of liability in misdiagnoses of such systems, or falsely vindicating skin lesion removal on insurance funds for cosmetic or financial incentives. A solution for these problems is to keep physicians "in the loop" _cite_ for automated diagnoses. Classification systems could run in the background analyzing images to bring the ones of most concern to a doctor's attention more quickly. These systems could also be used to continuously audit previously diagnosed cases where disagreements between the automated classifier and physician can be flagged and recommended for review. For a successful human-machine collaboration it is key to know why a system makes a specific diagnosis, options being visual question answering or automated captioning _cite_ . For all these systems it is left to the discretion of the user to interpret the results and decide whether they are correct. Herein we explore a different, intuitive and transferrable approach for 'explainable' artificial intelligence (AI), called content based image retrieval () . With CBIR, the user presents an unknown query image to a system, and cases with similar visual features are automatically retrieved and displayed from a database. Example queries and results of automatically retrieved similar images are shown in Figure _ref_ . With the increased performance of convolutional neural networks in regard to classification, previous work has found that those networks also learn filters that correspond to visual elements of an image in later layers of a CNN _cite_ . In other words, one set of filters in a CNN could for example respond to whether a brown network is visible, and another one could respond to a group of blue clods. With many filters present in a CNN, and many ways to combine them as an image moves through the network, it is an active research area to try and understand what set of filters correspond to an exact given visual structure. However, even without knowing what exact filter detects which structure, taken altogether they can be expressed as row of simple numbers (called a “feature vector” or “deep features”), representing all visual elements in an image. By comparing how similar these collected numbers of two images are, one can match faces _cite_, or retrieve visually similar medical data such as histopathologic images _cite_ . Recently, Kawahara et al. _cite_ used such extracted features of a multi-modality network to query a database for similar images and found it had high sensitivity (N \%) but low specificity (N \%) for detecting melanoma (N \% and N \% respectively for a different diagnostic cutoff) . The goals of this study are: