Contour detection is fundamental to a wide range of computer vision applications, including image segmentation~, object detection~ and recognition~ . The task is often carried out by exploring local image cues, such as intensity, color gradients, texture or local structures~ . Take, for example, that ~ use structured random forests to learn local edge patterns, and report current state-of-the-art results with impressive computation efficiency. More recently, object cues are also considered in ~ and ~ to further boost the performance. Despite the constant evolvement of relevant techniques in better solving the problem, seeking an appropriate feature representation remains the cornerstone of such efforts. We are thus motivated to propose a new learning formulation that can generate suitable per-pixel features for more satisfactorily performing contour detection. We consider deep neural networks to construct a desired per-pixel feature learner. In particular, since the underlying task is essentially a classification problem, we adopt deep convolutional neural networks (CNNs) to establish a discriminative approach. However, one subtle deviation from typical applications of CNNs should be emphasized. In our method, we intend to use the CNN architecture, e.g., AlexNet~, to generate features for each image pixel, not just a single feature vector for the whole input image. Such a distinction would call for a different perspective of parameter fine-tuning so that a pre-trained per-image CNN on ImageNet can be adapted into a new model for per-pixel edge classifications. To further investigate the property of the features from different convolutional layers and from various ensembles, we carry out a number of experiments to evaluate their effectiveness in performing contour detection on the benchmark BSDS Segmentation dataset~ . The organization of the paper is as follows. Section~ _ref_ includes related work of contour detection and deep convolutional neural networks. In Section~~ _ref_, we describe the overall model for learning per-pixel features and useful techniques for fine-tuning the parameters. Section~ _ref_ provides detailed experimental results and comparisons to demonstrate the advantages of our method. In Section~ _ref_ we discuss the key ideas of the proposed techniques and possible future research efforts.