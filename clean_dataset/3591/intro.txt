Recently, deep convolutional neural networks have led to significant breakthroughs on many vision problems such as image classification~ _cite_, segmentation~ _cite_, object detection~ _cite_, etc. While showing stronger representation power over many conventional hand-crafted features, CNNs often require a large amount of training data and face certain training difficulties such as overfitting, vanishing/exploding gradient, covariate shift, etc. The increasing depth of recently proposed CNN architectures have further aggravated the problems. To address the challenges, regularization techniques such as dropout~ _cite_ and orthogonality parameter constraints~ _cite_ have been proposed. Batch normalization~ _cite_ can also be viewed as an implicit regularization to the network, by normalizing each layer's output distribution. Recently, deep residual learning~ _cite_ emerged as a promising way to overcome vanishing gradients in deep networks. However, ~ _cite_ pointed out that residual networks (ResNets) are essentially an exponential ensembles of shallow networks where they avoid the vanishing/exploding gradient problem but do not provide direct solutions. As a result, training an ultra-deep network still remains an open problem. Besides vanishing/exploding gradient, network optimization is also very sensitive to initialization. Finding better initializations is thus widely studied~ _cite_ . In general, having a large parameter space is double-edged considering the benefit of representation power and the associated training difficulties. Therefore, proposing better learning frameworks to overcome such challenges remains important. \par In this paper, we introduce a novel convolutional learning framework that can effectively alleviate training difficulties, while giving better performance over dot product based convolution. Our idea is to project parameter learning onto unit hyperspheres, where layer activations only depend on the geodesic distance between kernels and input signals instead of their inner products. To this end, we propose the SphereConv operator as the basic module for our network layers. We also propose softmax losses accordingly under such representation framework. Specifically, the proposed softmax losses supervise network learning by also taking the SphereConv activations from the last layer instead of inner products. Note that the geodesic distances on a unit hypersphere is the angles between inputs and kernels. Therefore, the learning objective is essentially a function of the input angles and we call it generalized angular softmax loss in this paper. The resulting architecture is the hyperspherical convolutional network (SphereNet), which is shown in Fig.~ _ref_ . \par Our key motivation to propose SphereNet is that angular information matters in convolutional representation learning. We argue this motivation from several aspects: training stability, training efficiency, and generalization power. SphereNet can also be viewed as an implicit regularization to the network by normalizing the activation distributions. The weight norm is no longer important since the entire network operates only on angles. And as a result, the _inline_eq_ weight decay is also no longer needed in SphereNet. SphereConv to some extent also alleviates the covariate shift problem~ _cite_ . The output of SphereConv operators are bounded from _inline_eq_ to _inline_eq_ (_inline_eq_ to _inline_eq_ if considering ReLU), which makes the variance of each output also bounded. \par Our second intuition is that angles preserve the most abundant discriminative information in convolutional learning. We gain such intuition from ND Fourier transform, where an image is decomposed by the combination of a set of templates with magnitude and phase information in ND frequency domain. If one reconstructs an image with original magnitudes and random phases, the resulting images are generally not recognizable. However, if one reconstructs the image with random magnitudes and original phases. The resulting images are still recognizable. It shows that the most important structural information in an image for visual recognition is encoded by phases. This fact inspires us to project the network learning into angular space. In terms of low-level information, SphereConv is able to preserve the shape, edge, texture and relative color. SphereConv can learn to selectively drop the color depth but preserve the RGB ratio. Thus the semantic information of an image is preserved. \par SphereNet can also be viewed as a non-trivial generalization of _cite_ . By proposing a loss that discriminatively supervises the network on a hypersphere, _cite_ achieves state-of-the-art performance on face recognition. However, the rest of the network remains a conventional convolution network. In contrast, SphereNet not only generalizes the hyperspherical constraint to every layer, but also to different nonlinearity functions of input angles. Specifically, we propose three instances of SphereConv operators: linear, cosine and sigmoid. The sigmoid SphereConv is the most flexible one with a parameter controlling the shape of the angular function. As a simple extension to the sigmoid SphereConv, we also present a learnable SphereConv operator. Moreover, the proposed generalized angular softmax (GA-Softmax) loss naturaly generalizes the angular supervision in _cite_ using the SphereConv operators. Additionally, the SphereConv can serve as a normalization method that is comparable to batch normalization, leading to an extension to spherical normalization (SphereNorm) . \par SphereNet can be easily applied to other network architectures such as GoogLeNet _cite_, VGG _cite_ and ResNet _cite_ . One simply needs to replace the convolutional operators and the loss functions with the proposed SphereConv operators and hyperspherical loss functions. In summary, SphereConv can be viewed as an alternative to the original convolution operators, and serves as a new measure of correlation. SphereNet may open up an interesting direction to explore the neural networks. We ask the question Our answer to this question is likely to be ``no''.