Machine learning (ML) in medical imaging is a promising field of research, which will bring substantial changes to radiology in the coming years. Mammography, as a ND x-ray projection modality with great clinical significance, is arguably one of the first fields where these techniques will be successfully deployed. Many ML studies focus on (semi) automated detection or classification of cancer . However, there is also a considerable number of studies focusing on radiation dose reduction e.g. by reconstructing images from the raw data through ML algorithms or working directly with ultralow-dose data . In mammography, this would be of great benefit for all patients, and in particular for young women who are more vulnerable to the effects of ionizing radiation. First ML algorithms in CT are already applied in the clinical routine, autonomously optimizing patient table positioning and thus reducing the applied radiation dose . Most advanced ML algorithms are fundamentally opaque and as they, inevitably, find their way onto medical imaging devices and clinical workstations, we need to be aware that they may also be used to manipulate raw data and enable new ways of cyber-attacks, possibly harming patients and disrupting clinical imaging service . One specific genre of ML algorithms, Generative Adversarial Networks (GANs), are of particular importance in this context. GANs are a subclass of deep learning algorithms, itself a class of algorithms within the realm of ML or artificial intelligence (AI) . A GAN consists of two neural networks competing against each other: The first, generator network (G), manipulates sample images and the second, discriminator network (D), has to distinguish between real and manipulated samples . Due to their opposed cost function, the neural networks are competing against each other in order to improve their performance (in game theory this scenario is known as a ``two person zero-sum game'') . Given infinite resources and time, this will theoretically result in G producing samples from the real image distribution (i.e. perfect manipulations) and D completely incapable of discriminating, giving each such sample a probability of N for being either manipulated or real. In our case, we hypothesized that a GAN can learn an implicit representation of what cancer in mammography looks like, and specifically alter images, so they would be misdiagnosed (healthy as cancerous and vice versa) while even a radiologist could not differentiate between manipulated images and real ones. Hence, the purpose of this study was to train a pair of GANs on mammographic data to inject or remove features of malignancy and to determine whether these AI-mediated attacks can be detected by radiologists.