The resurrection of neural networks in recent years, together with the recent emergence of large scale datasets, has enabled super-human performance on many classification tasks~ _cite_ . However, supervised DNNs often require a large number of training samples to achieve a high level of performance. For instance, the ImageNet dataset~ _cite_ has N million hand-annotated images. Although crowdsourcing platforms like Amazon Mechanical Turk have made large-scale annotation possible, some error during the labeling process is often inevitable, and mislabeled samples can impair the performance of models trained on these data. Indeed, the sheer capacity of DNNs to memorize massive data with completely randomly assigned labels~ _cite_ proves their susceptibility to overfitting when trained with noisy labels. Hence, an algorithm that is robust against noisy labels for DNNs is needed to resolve the potential problem. Furthermore, when examples are cheap and accurate annotations are expensive, it can be more beneficial to have datasets with more but noisier labels than less but more accurate labels _cite_ . Classification with noisy labels is a widely studied topic~ _cite_ . Yet, relatively little attention is given to directly formulating a noise-robust loss function in the context of DNNs. Our work is motivated by Ghosh et al. _cite_ who theoretically showed that mean absolute error (MAE) can be robust against noisy labels under certain assumptions. However, as we demonstrate below, the robustness of MAE can concurrently cause increased difficulty in training, and lead to performance drop. This limitation is particularly evident when using DNNs on complicated datasets. To combat this drawback, we advocate the use of a more general class of noise-robust loss functions, which encompass both MAE and CCE. Compared to previous methods for DNNs, which often involve extra steps and algorithmic modifications, changing only the loss function requires minimal intervention to existing architectures and algorithms, and thus can be promptly applied. Furthermore, unlike most existing methods, the proposed loss functions work for both closed-set and open-set noisy labels~ _cite_ . Open-set refers to the situation where samples associated with erroneous labels do not always belong to a ground truth class contained within the set of known classes in the training data. Conversely, closed-set means that all labels (erroneous and correct) come from a known set of labels present in the dataset. The main contributions of this paper are two-fold. First, we propose a novel generalization of CCE and present a theoretical analysis of proposed loss functions in the context of noisy labels. And second, we report a thorough empirical evaluation of the proposed loss functions using CIFAR-N, CIFAR-N and FASHION-MNIST datasets, and demonstrate significant improvement in terms of classification accuracy over the baselines of MAE and CCE, under both closed-set and open-set noisy labels. The rest of the paper is organized as follows. Section~ _ref_ discusses existing approaches to the problem. Section~ _ref_ introduces our noise-robust loss functions. Section~ _ref_ presents and analyzes the experiments and result. Finally, section~ _ref_ concludes our paper.