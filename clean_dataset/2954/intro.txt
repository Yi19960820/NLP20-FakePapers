Clustering methods are very important techniques for exploratory data analysis with wide applications ranging from data mining _cite_, dimension reduction _cite_, segmentation _cite_ and so on. Their aim is to partition data points into clusters so that data in the same cluster are similar to each other while data in different clusters are dissimilar. Approaches to achieve this aim include partitional methods such as _inline_eq_-means and _inline_eq_-medoids, hierarchical methods like agglomerative clustering and divisive clustering, methods based on density estimation such as DBSCAN _cite_, and recent methods based on finding density peaks such as CFSFDP _cite_ and LDPS _cite_ . Image clustering _cite_ is a special case of clustering analysis that seeks to find compact, object-level models from many unlabeled images. Its applications include automatic visual concept discovery _cite_, content-based image retrieval and image annotation. However, image clustering is a hard task mainly owning to the following two reasons: N) images often are of high dimensionality, which will significantly affect the performance of clustering methods such as _inline_eq_-means _cite_, and N) objects in images usually have two-dimensional or three-dimensional local structures which should not be ignored when exploring the local structure information of the images. To address these issues, many representation learning methods have been proposed for image feature extractions as a preprocessing step. Traditionally, various hand-crafted features such as SIFT _cite_, HOG _cite_, NMF _cite_, and (geometric) CW-SSIM similarity _cite_ have been used to encode the visual information. Recently, many approaches have been proposed to combine clustering methods with deep neural networks (DNN), which have shown a remarkable performance improvement over hand-crafted features _cite_ . Roughly speaking, these methods can be categorized into two groups: N) sequential methods that apply clustering on the learned DNN representations, and N) unified approaches that jointly optimize the deep representation learning and clustering objectives. In the first group, a kind of deep (convolutional) neural networks, such as deep belief network (DBN) _cite_ and stacked auto-encoders _cite_, is first trained in an unsupervised manner to approximate the non-linear feature embedding from the raw image space to the embedded feature space (usually being low-dimensional) . And then, either _inline_eq_-means or spectral clustering or agglomerative clustering can be applied to partition the feature space. However, since the feature learning and clustering are separated from each other, the learned DNN features may not be reliable for clustering. There are a few recent methods in the second group which take the separation issues into consideration. In _cite_, the authors proposed deep embedded clustering that simultaneously learns feature representations with stacked auto-encoders and cluster assignments with soft _inline_eq_-means by minimizing a joint loss function. In _cite_, joint unsupervised learning was proposed to learn deep convolutional representations and agglomerative clustering jointly using a recurrent framework. In _cite_, the authors proposed an infinite ensemble clustering framework that integrates deep representation learning and ensemble clustering. The key insight behind these approaches is that good representations are beneficial for clustering and conversely clustering results can provide supervisory signals for representation learning. Thus, two factors, designing a proper representation learning model and designing a suitable unified learning objective will greatly affect the performance of these methods. In this paper, we follow recent advances to propose a unified clustering method named Discriminatively Boosted Clustering (DBC) for image analysis based on fully convolutional auto-encoders (FCAE) . See Fig. _ref_ for a glance of the overall framework. We first introduce a fully convolutional encoder-decoder network for fast and coarse image feature extraction. We then discard the decoder part and add a soft _inline_eq_-means model on top of the encoder to make a unified clustering model. The model is jointly trained with gradually boosted discrimination where high score assignments are highlighted and low score ones are de-emphasized. The our main contributions are summarized as follows: The remaining part of this paper is organized as follows. Some related work including stacked (convolutional) auto-encoders, deconvolutional neural networks, and joint feature learning and clustering are briefly reviewed in Section _ref_ . Detailed descriptions of the proposed FCAE and DBC are presented in Section _ref_ . Experimental results on several real datasets are given in Section _ref_ to validate the proposed methods. Conclusions and future works are discussed in Section _ref_ .