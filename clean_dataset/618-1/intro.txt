Gesture user interfaces are considered as the future way for people to interact with Virtual Reality (VR) or Augmented Reality (AR) applications _cite_ and other devices such as a smart door bell or smart watch _cite_ . Such interfaces can capture and track hand motions in the air, and allow a user to manipulate menus, dialogues, and other virtual objects directly by hand gesture. However, for security related tasks such as sign-up and sign-in, entering the user ID string and password through a virtual keyboard on gesture interfaces become cumbersome due to the lack of keystroke feedback. Existing researches _cite_ exploit the rich information in native gestures, and esp., in-air-handwriting, to authenticate a user. Yet, a usually neglected function is user identification. Authentication is a true or false question, i.e., answering whether the user owns the account which he or she claims to own. On the other hand, identification is a multiple choice question, i.e., answering which account the user wants to login among a database of many accounts. If we make an analogy of the sign-in procedure on a web with a desktop computer, the authentication procedure resembles typing and checking the password, while the identification procedure resembles searching the database given an ID number or ID string. Is it possible to construct a system that is capable of (N) taking a piece of in-air-handwriting of an ID string instead of typing, (N) searching a potentially large database of accounts registered using the in-air-handwriting, and (N) returning the matched identity or account number with high accuracy and short respond time? There are challenges for gesture-based user identification due to the unique characteristics of the hand motion. First, hand motion has inherent fuzziness. Even if the same user writes the same string in the air twice, the generated two motion signals are not identical, but with minor variations. Yet, the system should be able to tolerate the fuzziness and identify these two signals as the same user. This is different from typing an ID string of characters twice where even a single bit difference in the typed ID can cause failure in the identification. Second, it is difficult for many native gestures to provide enough information to enable a large account ID space as well as distinctiveness. Third, the traditional method of hash table for indexing a large account database using an ID string or account number does not work with handwriting signal, unless there is a way to generate a fixed size binary hash code from the signal with tolerance of inherent fuzziness (i.e., fuzzy hash) . In this paper, we propose a framework called FMHash, i.e., Finger Motion Hash, to efficiently obtain a user's account ID from the hand motion signal of writing an ID string in the air. FMHash uses a camera-based gesture user input device to capture the hand motion and a deep convolutional neural network (called FMHashNet) to convert the in-air-handwriting signal to a binary hash code (i.e., deep hashing) . With the hash code of the signals of all accounts, it further builds a hash table to index the whole account database to enable efficient user identification with hash table search. This is similar to face recognition, where a large database of identities are indexed using faces and an ID can be retrieved by presenting an image of a face. However, FMHash has a few unique advantages compared to face recognition. For example, one face is linked to one person, and a user can neither have multiple faces for multiple accounts nor change or revoke his or her own face. Moreover, the users may be worried about privacy because it is impossible to stay completely anonymous if a website requires face image to register. Yet, with in-air-handwriting of an ID string, the user can have multiple accounts with different ID strings, change or revoke the ID string, and stay anonymous by writing something unrelated to the true identity. In summary, our contributions in this paper are as follows: N) We proposed a deep hashing framework of in-air-handwriting for user identification over gesture interface. To our best knowledge, FMHash is the first framework that can generate fuzzy hash code from in-air-handwriting. Our method can accommodate gesture fuzziness by hashing multiple instances of the same handwriting by the same user to the same binary code with high probability of success (_inline_eq_ N \% precision and _inline_eq_ N \% recall with exact hash code match) . N) We designed a regularizer called the pq-regularizer and a progressive training procedure for our neural network model. With the pq-regularizer, hashcode of in-air-handwriting signals of different accounts are separated more than two bits in over N \% of the change. Meanwhile, we can maintain a reasonably fast training speed (_inline_eq_ N minutes for a full training on our dataset) . N) We provided a detailed analysis on the hash code fuzziness with a dataset of N accounts collected by us. The remainder of the paper is organized as follows. Related works on gesture-based authentication and deep hashing are discussed in section II. In section III, the architecture of the proposed framework is presented. Then we show the empirical evaluation results in section IV. Finally we draw the conclusion and discuss future work in section V.